<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2020-09-29T02:40+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">This paper is included in the Proceedings of the 16th USENIX Conference on File and Storage Technologies. Open access to the Proceedings of the 16th USENIX Conference on File and Storage Technologies is sponsored by USENIX The CASE of FEMU: Cheap, Accurate, Scalable and Extensible Flash Emulator The CASE of FEMU: Cheap, Accurate, Scalable and Extensible Flash Emulator</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huaicheng</forename><surname>Li</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingzhe</forename><surname>Hao</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">Hao</forename><surname>Tong</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huaicheng</forename><surname>Li</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingzhe</forename><surname>Hao</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">Hao</forename><surname>Tong</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Swaminatahan</forename><surname>Sundararaman</surname></persName>
							<affiliation key="aff2">
								<orgName type="laboratory">Parallel Machines ‡ CNEX Labs</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matias</forename><surname>Bjørling</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haryadi</forename><forename type="middle">S</forename><surname>Gunawi</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="laboratory">Swaminatahan Sundararaman, Parallel Machines; Matias Bjørling, CNEX Labs; Haryadi S. Gunawi</orgName>
								<orgName type="institution">University of Chicago</orgName>
								<address>
									<addrLine>February 12-15</addrLine>
									<postCode>2018 •</postCode>
									<settlement>Oakland</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">University of Chicago</orgName>
								<orgName type="institution" key="instit2">University of Chicago</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">This paper is included in the Proceedings of the 16th USENIX Conference on File and Storage Technologies. Open access to the Proceedings of the 16th USENIX Conference on File and Storage Technologies is sponsored by USENIX The CASE of FEMU: Cheap, Accurate, Scalable and Extensible Flash Emulator The CASE of FEMU: Cheap, Accurate, Scalable and Extensible Flash Emulator</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>FEMU is a software (QEMU-based) flash emulator for fostering future full-stack soft-ware/hardware SSD research. FEMU is cheap (open-sourced), relatively accurate (0.5-38% variance as a drop-in replacement of OpenChannel SSD), scalable (can support 32 parallel channels/chips), and extensible (support internal-only and split-level SSD research).</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Cheap and extensible research platforms are a key ingredient in fostering wide-spread SSD research. SSD simulators such as DiskSim's SSD model <ref type="bibr" target="#b7">[9]</ref>, FlashSim <ref type="bibr" target="#b12">[13]</ref> and SSDSim <ref type="bibr" target="#b15">[16]</ref>, despite their popularity, only support internal-SSD research but not kernel-level extensions. On the other hand, hardware research platforms such as FPGA boards <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b46">46]</ref>, OpenSSD <ref type="bibr" target="#b5">[7]</ref>, or OpenChannel SSD <ref type="bibr" target="#b9">[11]</ref>, support full-stack software/hardware research but their high costs (thousands of dollars per device) impair large-scale SSD research.</p><p>This leaves software-based emulator such as QEMUbased VSSIM <ref type="bibr" target="#b45">[45]</ref>, FlashEm <ref type="bibr" target="#b47">[47]</ref>, and LightNVM's QEMU <ref type="bibr" target="#b4">[6]</ref>, as the cheap alternative platform. Unfortunately, the state of existing emulators is bleak; they are either outdated, non-scalable, or not open-sourced.</p><p>We argue that it is a critical time for storage research community to have a new software-based emulator (more in §2). To this end, we present FEMU, a QEMU-based flash emulator, with the following four "CASE" benefits.</p><p>First, FEMU is cheap ($0) as it will be an opensourced software. FEMU has been successfully used in several projects, some of which appeared in top-tier OS and storage conferences <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b42">43]</ref>. We hope FEMU will be useful to broader communities.</p><p>Second, FEMU is (relatively) accurate. For example, FEMU can be used as a drop-in replacement for OpenChannel SSD; thus, future research that extends LightNVM <ref type="bibr" target="#b9">[11]</ref> can be performed on top of FEMU with relatively accurate results (e.g., 0.5-38% variance in our tests). With FEMU, prototyping SSD-related kernel changes can be done without a real device.</p><p>Third, FEMU is scalable. As we optimized the QEMU stack with various techniques, such as exitless interrupt  and skipping QEMU AIO components, FEMU can scale to 32 IO threads and still achieve a low latency (as low as 52µs under a 2.3GHz CPU). As a result, FEMU can accurately emulate 32 parallel channels/chips, without unintended queueing delays. Finally, FEMU is extensible. Being a QEMU-based emulator, FEMU can support internal-SSD research (only FEMU layer modification), kernel-only research such as software-defined flash (only Guest OS modification on top of unmodified FEMU), and split-level research (both Guest OS and FEMU modifications). FEMU also provides many new features not existent in other emulators, such as OpenChannel and multidevice/RAID support, extensible interfaces via NVMe commands, and page-level latency variability.</p><formula xml:id="formula_0">S -L 1 -H -L 1 -C -K 1 -H -K 1 -C -A R -S -L R -C -A 1 -S -K D -C -A 1 -E -L 1 -C -L 1 -E -K R -H -L R -H -K R -C -K D -H -L D -H -K D -C -K D -S -L 1 -S -A R -S -K R -C -L D -S -A</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Extended Motivation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">THE STATE OF SSD RESEARCH PLATFORMS:</head><p>We reviewed 391 papers in more than 30 major systems and storage conferences and journals published in the last 10 years, and categorized them as follows:</p><p>1. What was the scale of the research? <ref type="bibr">[1]</ref>: single SSD; <ref type="bibr">[R]</ref>: RAID of SSDs (flash array); or <ref type="bibr">[D]</ref>: distributed/multi-node SSDs. 2. What was the platform being used? <ref type="bibr">[C]</ref>: commodity SSDs; <ref type="bibr">[E]</ref>: software SSD emulators (VSSIM <ref type="bibr" target="#b45">[45]</ref> or FlashEm <ref type="bibr" target="#b47">[47]</ref>); <ref type="bibr">[H]</ref>: hardware platforms (FPGA boards, OpenSSD <ref type="bibr" target="#b5">[7]</ref>, or OpenChannel SSD <ref type="bibr" target="#b4">[6]</ref>); or <ref type="bibr">[S]</ref>: trace-based simulators (DiskSim+SSD <ref type="bibr" target="#b7">[9]</ref> or FlashSim <ref type="bibr" target="#b12">[13]</ref> and SSDSim <ref type="bibr" target="#b15">[16]</ref>).</p><p>3. What layer was modified? <ref type="bibr">[A]</ref>: application layer; <ref type="bibr">[K]</ref>: OS kernel; <ref type="bibr">[L]</ref>: low-level SSD controller logic.</p><p>Note that some papers can fall into two sub-categories (e.g., modify both the kernel and the SSD logic). <ref type="figure" target="#fig_1">Fig- ure 1</ref> shows the sorted order of the combined categories. For example, the most popular category is 1-S-L, where 195 papers target only single SSD (1), use simulator (S), and modify the low-level SSD controller logic (L). However, simulators do not support running applications and operating systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">THE LACK OF LARGE-SCALE SSD RESEARCH:</head><p>Our first motivation is the lack of papers in the distributed SSDs category (D-...), for example, for investigating the impact of SSD-related changes to distributed computing and graph frameworks. One plausible reason is the cost of managing hardware (procurement, installation, maintenance, etc.). The top-8 categories in <ref type="figure" target="#fig_1">Figure 1</ref>, a total of 324 papers (83%), target single SSD (1-...) and flash array (R-...). The highest D category is D-C-A (as highlighted in the <ref type="figure">figure)</ref>, where only 9 papers use commodity SSDs (C) and modify the application layer (A). The next D category is D-H-L, where hardware platforms (H) are used for modifying the SSD controller logic (L). Unfortunately, most of the 6 papers in this category are from large companies with large research budget (e.g., FPGA usage in Baidu <ref type="bibr" target="#b27">[28]</ref> and Tencent <ref type="bibr" target="#b46">[46]</ref>). Other hardware platforms such as OpenSSD <ref type="bibr" target="#b5">[7]</ref> and OpenChannel SSD <ref type="bibr" target="#b4">[6]</ref> also cost thousands of dollars each, impairing multinode non-simulation research, especially in academia.</p><p>2.3 THE RISE OF SOFTWARE-DEFINED FLASH: Today, research on host-managed (aka. "software-defined" or "user-programmable") flash is growing <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b46">46]</ref>. However, such research is mostly done on top of expensive and hard-to-program FPGA platforms. Recently, a more affordable and simpler platform is available, OpenChannel SSD <ref type="bibr" target="#b4">[6]</ref>, managed by Linux-based LightNVM <ref type="bibr" target="#b9">[11]</ref>. Before its inception (2015), there were only 24 papers that performed kernel-only changes, since then, 11 papers have been published, showing the success of OpenChannel SSD.</p><p>However, there remains several issues. First, not all academic communities have budget to purchase such devices. Even if they do, while prototyping the kernel/application, it is preferable not to write too much to and wear out the device. Thus, replacing OpenChannel SSD (during kernel prototyping) with a software-based emulator is desirable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">THE RISE OF SPLIT-LEVEL ARCHITECTURE:</head><p>While most existing research modify a single layer (application/kernel/SSD), some recent works show the benefits of "split-level" architecture <ref type="bibr" target="#b6">[8,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b41">42]</ref>, wherein some functionalities move up to the OS kernel (K) and some other move down to the SSD firmware (L) <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b35">36]</ref>. So far, we found only 40 papers in split-level K+L category (i.e., modify both the kernel and SSD logic layers), mostly done by companies with access to SSD controllers <ref type="bibr" target="#b18">[19]</ref> or academic researchers with Linux+OpenSSD <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b31">32]</ref> or with block-level emulators (e.g., Linux+FlashEm) <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b47">47]</ref>. OpenSSD with its single-threaded, single-CPU, whole-blocking GC architecture also has many known major limitations <ref type="bibr" target="#b42">[43]</ref>. FlashEm also has limitations as we elaborate more below. Note that the kernel-level LightNVM is not a suitable platform for split-level research (i.e., support K, but not L). This is because its SSD layer (i.e., OpenChannel SSD) is not modifiable; the white-box part of OpenChannel SSD is the exposure of its internal channels and chips to be managed by software (Linux LightNVM), but the OpenChannel firmware logic itself is a black-box part.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">THE STATE OF EXISTING EMULATORS:</head><p>We are only aware of three popular software-based emulators: FlashEm, LightNVM's QEMU and VSSIM.</p><p>FlashEm <ref type="bibr" target="#b47">[47]</ref> is an emulator built in the Linux block level layer, hence less portable; it is rigidly tied to its Linux version; to make changes, one must modify Linux kernel. FlashEm is not open-sourced and its development stopped two years ago (confirmed by the creators).</p><p>LightNVM's QEMU platform <ref type="bibr" target="#b4">[6]</ref> is still in its early stage. Currently, it cannot emulate multiple channels (as in OpenChannel SSD) and is only used for basic testing of 1 target (1 chip behind 1 channel). Worse, Light-NVM's QEMU performance is not scalable to emulate NAND latencies as it depends on vanilla QEMU NVMe interface (as shown in the NVMe line in <ref type="figure" target="#fig_2">Figure 2a</ref>).</p><p>VSSIM <ref type="bibr" target="#b45">[45]</ref> is a QEMU/KVM-based platform that emulates NAND flash latencies on a RAM disk, and has been used in several papers. The major drawback of VS-SIM is that it is built within QEMU's IDE interface implementation, which is not scalable. The upper-left red line (IDE line) in <ref type="figure" target="#fig_2">Figure 2a</ref> shows the user-perceived IO read latency through VSSIM without any NAND-delay emulation added. More concurrent IO threads (x-axis) easily multiply the average IO latency (y-axis). For example from 1 to 4 IO threads, the average latency spikes up from 152 to 583µs. The root cause is that IDE is not supported with virtualization optimizations.</p><p>With this drawback, emulating internal SSD parallelism is a challenge. VSSIM worked around the problem by only emulating NAND delays in another background thread in QEMU, disconnected from the main IO path. Thus, for multi-threaded applications, to collect accurate results, users solely depend on VSSIM's monitoring tool [45, <ref type="figure">Figure 3]</ref>, which monitors the IO latencies emulated in the background thread. In other words, users cannot simply time the multi-threaded applications (due to IDE poor scalability) at the user level.</p><p>Despite these limitations, we (and the community) are greatly indebted to VSSIM authors as VSSIM provides a base design for future QEMU-based SSD emulators. As five years have passed, it is time to build a new emulator to keep up with the technology trends.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">FEMU</head><p>We now present FEMU design and implementation. FEMU is implemented in QEMU v2.9 in 3929 LOC and acts as a virtual block device to the Guest OS. A typical software/hardware stack for SSD research is {Application+Host OS+SSD device}. With FEMU, the stack is {Application+Guest OS+FEMU}. The LOC above excludes base OC extension structures from Light-NVM's QEMU and FTL framework from VSSIM.</p><p>Due to space constraints, we omit the details of how FEMU works inside QEMU (e.g., FEMU's FTL and GC management, IO queues), as they are similarly described in VSSIM paper <ref type="bibr">[45, Section 3]</ref>. We put them in FEMU release document <ref type="bibr">[1]</ref>. In the rest of the paper, we focus on the main challenges of designing FEMU: achieving scalability ( §3.1) and accuracy ( §3.2) and increasing usability and extensibility ( §3.3).</p><p>Note that all latencies reported here are user-perceived (application-level) latencies on memory-backed virtual storage and 24 dual-thread (2x) CPU cores running at 2.3GHz. According to our experiments, the average latency is inversely proportional to CPU frequency, for example, QEMU NVMe latency under 1 IO thread is 35µs on a 2.3GHZ CPU and 23µs on a 4.0GHz CPU.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Scalability</head><p>Scalability is an important property of a flash emulator, especially with high internal parallelism of modern SSDs. Unfortunately, stock QEMU exhibits a scalability limitation. For example, as shown in <ref type="figure" target="#fig_2">Figure 2a</ref>, with QEMU NVMe (although it is more scalable than IDE), more IO threads still increases the average IO latency (e.g., with 8 IO threads, the average IO latency already reaches 106µs). This is highly undesirable because typical read latency of modern SSDs can be below 100µs.</p><p>More scalable alternatives to NVMe are virtio and dataplane (dp) interfaces <ref type="bibr" target="#b1">[3,</ref><ref type="bibr" target="#b29">30]</ref> (virtio/dp vs. NVMe lines in <ref type="figure" target="#fig_2">Figure 2a</ref>). However, these interfaces are not as extensible as NVMe (which is more popular). Nevertheless, virtio and dp are also not scalable enough to emulate low flash latencies. For example, at 32 IO threads, their IO latencies already reach 185µs and 126µs, respectively.</p><p>Problems: Collectively, all of the scalability bottlenecks above are due to two reasons: (1) QEMU uses a traditional trap-and-emulate method to emulate IOs. The Guest OS' NVMe driver "rings the doorbell <ref type="bibr" target="#b3">[5]</ref>" to the device (QEMU in our case) that some IOs are in the device queue. This "doorbell" is an MMIO operation that will cause an expensive VM-exit ("world switch" <ref type="bibr" target="#b38">[39]</ref>) from the Guest OS to QEMU. A similar operation must also be done upon IO completion. (2) QEMU uses asynchronous IOs (AIO) to perform the actual read/write (byte transfer) to the backing image file. This AIO component is needed to avoid QEMU being blocked by slow IOs (e.g., on a disk image). However, the AIO overhead becomes significant when the storage backend is a RAMbacked image.</p><p>Our solutions: To address these problems, we leverage the fact that FEMU purpose is for research prototyping, thus we perform the following modifications:</p><p>(1) We transform QEMU from an interrupt-to a polling-based design and disable the doorbell writes in the Guest OS (just 1 LOC commented out in the Linux NVMe driver). We create a dedicated thread in QEMU to continuously poll the status of the device queue (a shared memory mapped between the Guest OS and QEMU). This way, the Guest OS still "passes" control to QEMU but without the expensive VM exits. We emphasize that FEMU can still work without the changes in the Guest OS as we report later. This optimization can be treated as an optional feature, but the 1 LOC modification is extremely simple to make in many different kernels.</p><p>(2) We do not use virtual image file (in order to skip the AIO subcomponent). Rather, we create our own RAM-backed storage in QEMU's heap space (with configurable size malloc()). We then modify QEMU's DMA emulation logic to transfer data from/to our heap-backed storage, transparent to the Guest OS (i.e., the Guest OS is not aware of this change).</p><p>Results: The bold FEMU line in <ref type="figure" target="#fig_2">Figure 2a</ref> shows the scalability achieved. In between 1-32 IO threads, FEMU can keep IO latency stable in less than 52µs, and even below 90µs at 64 IO threads. If the single-line Guest-OS optimization is not applied (the removal of VM-exit), the average latency is 189µs and 264µs for 32 and 64 threads, respectively (not shown in the graph). Thus, we recommend applying the single-line change in the Guest OS to remove expensive VM exits.</p><p>The remaining scalability bottleneck now only comes from QEMU's single-thread "event loop" <ref type="bibr" target="#b2">[4,</ref><ref type="bibr" target="#b14">15]</ref>, which performs the main IO routine such as dequeueing the device queue, triggering DMA emulations, and sending end-IO completions to the Guest OS. Recent works addressed these limitations (with major changes) <ref type="bibr" target="#b8">[10,</ref><ref type="bibr" target="#b22">23]</ref>, but have not been streamlined into QEMU's main distribution. We will explore the possibility of integrating other solutions in future development of FEMU.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Accuracy</head><p>We now discuss the accuracy challenges. We first describe our delay mechanism ( §3.2.1), followed by our basic and advanced delay models ( §3.2.2-3.2.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Delay Emulation</head><p>When an IO arrives, FEMU will issue the DMA read/write command, then label the IO with an emulated completion time (T endio ) and add the IO to our "endio queue," sorted based on IO completion time. FEMU dedicates an "end-io thread" that continuously takes an IO from the head of the queue and sends an end-io interrupt to the Guest OS, once the IO's emulated completion time has passed current time (T endio &gt;T now ).</p><p>The "+50us (Raw)" line in <ref type="figure" target="#fig_2">Figure 2b</ref> shows a simple (and stable) result where we add a delay of 50µs to every IO (T endio =T entry +50µs). Note that the end-to-end IO time is more than 50µs because of the Guest OS overhead (roughly 20µs). Important to say that FEMU also does not introduce severe latency tail. In the experiment above, 99% of all the IOs are stable at 70µs. Only 0.01% (99.99 th percentile) of the IOs exhibit latency tail of more than 105µs, which already exists in stock QEMU. For example, in VSSIM, the 99 th -percentile latency is already over 150µs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Basic Delay Model</head><p>The challenge now is to compute the end-io time (T endio ) for every IO accurately. We begin with a basic delay model by marking every plane and channel with their next free time <ref type="bibr">(T free</ref>  In summary, this basic queueing model represents a single-register and uniform page latency model. That is, every plane only has a single page register, hence cannot serve multiple IOs in parallel (i.e., a plane's T free represents IO serialization in that plane) and the NAND page read, write, and transfer times (T read , T write and T transf er ) are all single values. We also note that GC logic can be easily added to this basic model; a GC is essentially a series of reads/writes (and erases, T erase ) that will also advance plane's and channel's T free .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3">Advanced "OC" Delay Model</head><p>While the model above is sufficient for basic comparative research (e.g., comparing different FTL/GC schemes, some researchers might want to emulate the detailed intricacies of modern hardware. Below, we show how we extend our model and achieve a more accurate delay emulation of OpenChannel SSD ("OC" for short).</p><p>The OC's NAND hardware has the following intricacies. First, OC uses double-register planes; every plane is built with two registers (data+cache registers), hence a NAND page read/write in a plane can overlap with a data transfer via the channel to the plane (i.e., more parallelism). <ref type="figure">Figure 3</ref> contrasts the single-vs. double-register models where the completion time of the second IO to page P2 is faster in the double-register model. Second, OC uses a non-uniform page latency model; that is, pages that are mapped to upper bits of MLC cells ("upper" pages) incur higher latencies than those mapped to lower bits ("Lower" pages); for example 48/64µs for lower/upper-page read and 900/2400µs for lower/upperpage write. Making it more complex, the 512 pages in each NAND block are not mapped in a uniformly interleaving manner as in "LuLuLuLu...", but rather in a specific way, "LLLLLLuLLuLLuu...", where pages #0-6 and #8-9 are mapped to Lower pages, pages #7 and #10 to upper pages, and the rest ("...") have a repeating pattern of "LLuu".</p><p>Results: By incorporating this detailed model, FEMU can act as an accurate drop-in replacement of OC, which we demonstrate with the following results.</p><p>Result 1: <ref type="figure" target="#fig_3">Figure 4</ref> compares the IO latencies on OC vs. FEMU. The workload is 16 IO threads performing random reads uniformly spread throughout the storage space. We map the storage space to different configurations. For example, x=1 and y=1 implies that OC and FEMU are configured with only 1 channel and 1 plane/channel, thus as a result, the average latency is high (z&gt;1550µs) as all the 16 concurrent reads are contending for the same plane and channel. The result for x=16 and y=1 implies that we use 16 channels with 1 plane/channel (a total of 16 planes). Here, the concurrent reads are absorbed in parallel by all the planes and channels, hence a faster average read latency (z&lt;130µs). Overall, Figures 4a and 4b exhibit a highly similar pattern, showing the success of our queuing delay emulation. The latency difference (error) is only between 0.8-11.6%; Error=(Lat femu −Lat oc )/Lat oc .</p><p>Result 2: <ref type="figure" target="#fig_4">Figure 5a</ref> shows the results from running several macrobenchmarks with six filebench personalities, with 16 IO threads of concurrent reads/writes on 16 planes across 4 channels. The figure only shows the latency difference (Error) which contrasts the accuracy of our basic and advanced delay models. With the basic model, the resulting latencies are highly inaccurate (12-57%), but with the advanced model, the error drops to only 0.5-38%, which are 1.5-40× more accurate across the six benchmarks.</p><p>We believe that these errors are reasonable as we deal with delay emulation of tens of µs granularity. We leave further optimization for future work; we might have missed other OC intricacies that should be incorporated into our advanced model (as explained at the end of §2.4, OC only exposes channels and chips, but other details are not exposed by the vendor). Nevertheless, we investigate further the residual errors, as shown in <ref type="figure" target="#fig_4">Figure 5b</ref>. Here, we use the varmail personality but we vary the #IO threads <ref type="bibr">[T]</ref> and #planes <ref type="bibr">[P]</ref>. For example, in the 16 threads on 16 planes configuration (x="16T16P" in <ref type="figure" target="#fig_4">Fig- ure 5b</ref>, which is the same configuration used in experiments in <ref type="figure" target="#fig_4">Figure 5a</ref>), the error is 38%. However, the error decreases in less complex configurations (e.g., 0.7% error with single thread on single plane). Thus, higher errors come from more complex configurations (e.g., more IO threads and more planes), which we explain next.</p><p>Result 3: We find that using an advanced model requires more CPU computation, and this compute overhead will backlog with higher thread count. To show this, <ref type="figure" target="#fig_2">Figure 2b</ref> compares the simple +50µs delay emulation in our raw implementation ( §3.2.1) vs. advanced model. Here, both cases simply add +50µs, but the advanced model must traverse many if-else statements (to check register, plane, and channel next free time), hence the compute overhead. Further scalability optimizations, as discussed at the end of §3.1 can help.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Usability and Extensibility</head><p>Being a software-based emulation platform, FEMU can be extended in many different ways. We now describe existing features/usabilities of FEMU, briefly showcase successful extensions used in our recent work <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b42">43]</ref> as well as possible future work that FEMU features enable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>USENIX Association</head><p>16th USENIX Conference on File and Storage Technologies 87 • FTL and GC schemes: In default mode, our FTL employs a dynamic mapping and a channel-blocking GC as used in other simulators <ref type="bibr" target="#b7">[9,</ref><ref type="bibr" target="#b15">16]</ref>. One of our projects uses FEMU to compare different GC schemes: controller, channel, and plane blocking <ref type="bibr" target="#b42">[43]</ref>. In controller-blocking GC, a GC operation "locks down" the controller, preventing any foreground IOs to be served (as in OpenSSD <ref type="bibr" target="#b5">[7]</ref>). In channel-blocking GC, only channels involved in GC page movement are blocked (as in SSDSim <ref type="bibr" target="#b15">[16]</ref>). In plane-blocking GC, the most efficient one, page movement only flows within a plane without using any channel (i.e., "copyback" <ref type="bibr" target="#b0">[2]</ref>). Sample results are shown in <ref type="figure" target="#fig_5">Figure 6a</ref>. Beyond our work, recent works also show the benefits of SSD partitioning for performance isolation <ref type="bibr" target="#b9">[11,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b36">37]</ref>, which are done on either a simulator or a hardware platform. More partitioning schemes can also be explored with FEMU.</p><p>• White-box vs. black-box mode: FEMU can be used as (1) a white-box device such as OpenChannel SSD where the device exposes physical page addresses and the FTL is managed by the OS such as in Linux Light-NVM or (2) a black-box device such as commodity SSDs where the FTL resides inside FEMU and only logical addresses are exposed to the OS.</p><p>• Multi-device support for flash-array research: FEMU is configurable to appear as multiple devices to the Guest OS. For example, if FEMU exposes 4 SSDs, inside FEMU there will be 4 separate NVMe instances and FTL structures (with no overlapping channels) managed in a single QEMU instance. Previous emulators (VSSIM and LightNVM's QEMU) do not support this.</p><p>• Extensible OS-SSD NVMe commands: As FEMU supports NVMe, new OS-to-SSD commands can be added (e.g., for host-aware SSD management or splitlevel architecture <ref type="bibr" target="#b30">[31]</ref>). For example, currently in Light-NVM, a GC operation reads valid pages from OC to the host DRAM and then writes them back to OC. This wastes host-SSD PCIe bandwidth; LightNVM foreground throughput drops by 50% under a GC. Our conversation with LightNVM developers suggests that one can add a new "pageMove fromAddr toAddr" NVMe command from the OS to FEMU/OC such that the data movement does not cross the PCIe interface. As mentioned earlier, split-level architecture is trending <ref type="bibr" target="#b10">[12,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b43">44]</ref> and our NVMe-powered FEMU can be extended to support more commands such as transactions, deduplication, and multi-stream.</p><p>• Page-level latency variability: As discussed before ( §3.2), FEMU supports page-level latency variability. Among SSD engineers, it is known that "not all chips are equal." High quality chips are mixed with lesser quality chips as long as the overall quality passes the standard. Bad chips can induce more error rates that require longer, repeated reads with different voltages. FEMU can also be extended to emulate such delays.</p><p>• Distributed SSDs: Multiple instances of FEMU can be easily deployed across multiple machines (as simple as running Linux hypervisor KVMs), which promotes more large-scale SSD research. For example, we are also able to evaluate the performance of Hadoop's wordcount workload on a cluster of machines running FEMU, but with different GC schemes as shown in <ref type="figure" target="#fig_5">Figure 6b</ref>. Since HDFS uses large IOs, which will eventually be striped across many channels/planes, there is a smaller performance gap between channel and plane blocking. We hope FEMU can spur more work that modifies the SSD layer to speed up distributed computing frameworks (e.g., distributed graph processing frameworks).</p><p>• Page-level fault injection: Beyond performancerelated research, flash reliability research <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b32">33]</ref> can leverage FEMU as well (e.g., by injecting page-level corruptions and faults and observing how the high-level software stack reacts).</p><p>• Limitations: FEMU is DRAM-backed, hence cannot emulate large-capacity SSDs. Furthermore, for crash consistency research, FEMU users must manually emulate "soft" crashes as hard reboots will wipe out the data in the DRAM. Also, as mentioned before ( §3.2), there is room for improving accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion &amp; Acknowledgments</head><p>As modern SSD internals are becoming more complex, their implications to the entire storage stack should be investigated. In this context, we believe FEMU is a fitting research platform. We hope that our cheap and extensible FEMU can speed up future SSD research.</p><p>We thank Sam H. Noh, our shepherd, and the anonymous reviewers for their tremendous feedback. This material was supported by funding from NSF (grant Nos. CNS-1526304 and CNS-1405959).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Categorization of SSD research. The figure is explained in Section §2.1. The first bar reaches 195 papers.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: QEMU Scalability. The figure shows the scalability of QEMU's IDE, NVMe, virtio, and dataplane (dp) interface implementations, as well as FEMU. The x-axis represents the number of concurrent IO threads running at the user level. Each thread performs random 4KB read IOs. The y-axis shows the user-perceived average IO latency. For Figure (a), the IDE and NVMe lines representing VSSIM and LightNVM's QEMU respectively are discussed in §2.5; virtio, dp, and FEMU lines in §3.1. For Figure (b), the "+50µs (Raw)" line is discussed in §3.2.1; the "+50µs (Adv)" line in "Result 3" part of §3.2.3.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: OpenChannel SSD (OC) vs. FEMU. X: # of channels, Y: # of planes per channel. The figures are described in the "Result 1" segment of Section 3.2.3.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Filebench on OpenChannel SSD (OC) vs. FEMU. The figures are described in the "Result 2" segment of Section 3.2.3. The y-axis shows the latency difference (error) of the benchmark results on OC vs. FEMU (Error=(Lat f emu −Latoc)/Latoc). D-Reg and S-Reg represent the advanced and basic model respectively. The two bars with bold edge in Figures (a) and (b) are the same experiment and configuration (varmail with 16 threads on 16 planes).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Use examples. Figure 6a is described in the "FTL and GC schemes" segment of Section 3.3. Figure 6b is discussed in the "Distributed SSDs" segment of Section 3.3.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>time P1 NAND RAM D-RegDouble-register model: NAND RAM D-Reg P1 C-Reg NAND P2 P2 RAM</head><label></label><figDesc>). For example, if a page write arrives to currently-free channel #1 and plane #2, then we will advance the channel's next freeThus, the end-io time of this write operation will be T endio =T freeOfP lane2 . Now, let us say a page read to the same plane arrives while the write is ongoing. Here, we will advance T freeOfP lane2 by T read , where T read is a configurable read time of a NAND page, and T freeOfChannel1 by T transf er . This read's end-io time will be T endio =T freeOfChannel1 (as this is a read oper- ation, not a write IO).</figDesc><table>NAND 

RAM 
D-Reg 

(a) Single-register model: 

P2 
P1 
P1 
P2 

(b) More parallelism 
(Read P2 
finishes faster) 

D-Reg 
C-Reg 

time 

Figure 3: Single-vs. double-register model. (a) In 

a single-register model, a plane only has one data register (D-
Reg). Read of page P2 cannot start until P1 finishes using the 
register (i.e., the transfer to the controller's RAM completes). 
(b) In a double-register model, after P1 is read to the data reg-
ister, it is copied quickly to the cache register (D-Reg to C-Reg). 
As the data register is free, read of P2 can begin (in parallel 
with P1's transfer to the RAM), hence finishes faster. 

(T freeOfChannel1 =T now +T transf er , where T transf er 
is a configurable page transfer time over a channel) 
and the plane's next free time (T freeOfP lane2 +=T write , 
where T write is a configurable write/programming time 
of a NAND page). </table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Using COPYBACK Operations to Maintain Data Integrity in NAND Flash Devices</title>
		<ptr target="https://www.micron.com/~/media/documents/products/technical-note/nand-flash/tn2941_idm_copyback.pdf" />
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Towards Multi-threaded Device Emulation in QEMU</title>
	</analytic>
	<monogr>
		<title level="j">KVM Forum</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Improving the QEMU Event Loop. KVM Forum</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title/>
		<ptr target="http://www.nvmexpress.org" />
	</analytic>
	<monogr>
		<title level="j">NVMe Specification</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
				<ptr target="http://lightnvm.io" />
		<title level="m">Solid State Drives</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title/>
		<ptr target="http://openssd.io" />
	</analytic>
	<monogr>
		<title level="j">The OpenSSD Project</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">All Flash Array Architecture</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>Violin Memory</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Design Tradeoffs for SSD Performance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitin</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijayan</forename><surname>Prabhakaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ted</forename><surname>Wobber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">D</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Manasse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rina</forename><surname>Panigrahy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the USENIX Annual Technical Conference (ATC)</title>
		<meeting>the USENIX Annual Technical Conference (ATC)</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Adding Advanced Storage Controller Functionality via Low-Overhead Virtualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muli</forename><surname>Ben-Yehuda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Factor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eran</forename><surname>Rom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avishay</forename><surname>Traeger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eran</forename><surname>Borovik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben-Ami</forename><surname>Yassour</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th USENIX Symposium on File and Storage Technologies (FAST)</title>
		<meeting>the 10th USENIX Symposium on File and Storage Technologies (FAST)</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">LightNVM: The Linux Open-Channel SSD Subsystem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matias</forename><surname>Bjørling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Javier</forename><surname>González</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philippe</forename><surname>Bonnet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th USENIX Symposium on File and Storage Technologies (FAST)</title>
		<meeting>the 15th USENIX Symposium on File and Storage Technologies (FAST)</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Hou-Chiang Sun, Ting-Fang Chien, An-Nan Chang, and Cheng-Ding Chen. Software Orchestrated Flash Array</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weafon</forename><surname>Tzi-Cker Chiueh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tsao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 7th</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<title level="m">Annual International Systems and Storage Conference (SYSTOR)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">DFTL: A Flash Translation Layer Employing Demand-based Selective Caching of Page-level Address Mappings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aayush</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youngjae</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bhuvan</forename><surname>Urgaonkar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS)</title>
		<meeting>the 14th International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS)</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">MittOS: Supporting Millisecond Tail Tolerance with Fast Rejecting SLO-Aware OS Interface</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingzhe</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huaicheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">Hao</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chrisma</forename><surname>Pakha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Riza</forename><forename type="middle">O</forename><surname>Suminto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cesar</forename><forename type="middle">A</forename><surname>Stuardo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">A</forename><surname>Chien</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haryadi</forename><forename type="middle">S</forename><surname>Gunawi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th ACM Symposium on Operating Systems Principles (SOSP</title>
		<meeting>the 26th ACM Symposium on Operating Systems Principles (SOSP</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Efficient and Scalable Paravirtual I/O System</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nadav</forename><surname>Har</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">&amp;apos;</forename><surname>El</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nadav</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gordon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Abel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Landau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ben-Yehuda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Muli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Traeger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ladelsky</forename><surname>Avishay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Razya</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 USENIX Annual Technical Conference (ATC)</title>
		<meeting>the 2013 USENIX Annual Technical Conference (ATC)</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Performance Impact and Interplay of SSD Parallelism through Advanced Commands, Allocation Strategy and Data Granularity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuping</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th International Conference on Supercomputing (ICS)</title>
		<meeting>the 25th International Conference on Supercomputing (ICS)</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">FlashBlox: Achieving Both Performance Isolation and Uniform Lifetime for Virtualized SSDs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anirudh</forename><surname>Badam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Caulfield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suman</forename><surname>Nath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sudipta</forename><surname>Sengupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bikash</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moinuddin</forename><forename type="middle">K</forename><surname>Qureshi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th USENIX Symposium on File and Storage Technologies (FAST)</title>
		<meeting>the 15th USENIX Symposium on File and Storage Technologies (FAST)</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Wear Unleveling: Improving NAND Flash Lifetime by Balancing Page Endurance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Jimenez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Novo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th USENIX Symposium on File and Storage Technologies (FAST)</title>
		<meeting>the 12th USENIX Symposium on File and Storage Technologies (FAST)</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">DFS: A File System for Virtualized Flash Storage</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">K</forename><surname>Josephson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lars</forename><forename type="middle">A</forename><surname>Bongo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Flynn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Fusion-Io</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th USENIX Symposium on File and Storage Technologies (FAST)</title>
		<meeting>the 8th USENIX Symposium on File and Storage Technologies (FAST)</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The Multi-streamed Solid-State Drive</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeong-Uk</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeeseok</forename><surname>Hyun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyunjoo</forename><surname>Maeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sangyeun</forename><surname>Cho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">the 6th Workshop on Hot Topics in Storage and File Systems (HotStorage)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">X-FTL: Transactional FTL for SQLite Databases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Woon-Hak</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sang-Won</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bongki</forename><surname>Moon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gi-Hwan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changwoo</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Min</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 ACM SIGMOD International Conference on Management of Data (SIGMOD)</title>
		<meeting>the 2013 ACM SIGMOD International Conference on Management of Data (SIGMOD)</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Towards SLO Complying SSDs Through OPS Isolation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaeho</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donghee</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><forename type="middle">H</forename><surname>Noh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th USENIX Symposium on File and Storage Technologies (FAST)</title>
		<meeting>the 13th USENIX Symposium on File and Storage Technologies (FAST)</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Improving Performance by Bridging the Semantic Gap between Multi-queue SSD and I/O Virtualization Framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Tae</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><forename type="middle">Hyun</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongwoo</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Young</forename><forename type="middle">Ik</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Eom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st IEEE Symposium on Massive Storage Systems and Technologies (MSST)</title>
		<meeting>the 31st IEEE Symposium on Massive Storage Systems and Technologies (MSST)</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">ReFlex: Remote Flash ≈ Local Flash</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ana</forename><surname>Klimovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heiner</forename><surname>Litz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christos</forename><surname>Kozyrakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS)</title>
		<meeting>the 22nd International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS)</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Application-Managed Flash</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungjin</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sang</forename><surname>Woo Jun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuotao</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jihong</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arvind</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th USENIX Symposium on File and Storage Technologies (FAST)</title>
		<meeting>the 14th USENIX Symposium on File and Storage Technologies (FAST)</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A Large-Scale Study of Flash Memory Failures in the Field</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Meza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Onur</forename><surname>Mutlu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 ACM International Conference on Measurement and Modeling of Computer Systems (SIGMETRICS)</title>
		<meeting>the 2015 ACM International Conference on Measurement and Modeling of Computer Systems (SIGMETRICS)</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Decibel: Isolation and Sharing in Disaggregated Rack-Scale Storage</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihir</forename><surname>Nanavati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jake</forename><surname>Wires</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Warfield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th Symposium on Networked Systems Design and Implementation (NSDI</title>
		<meeting>the 13th Symposium on Networked Systems Design and Implementation (NSDI</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">SDF: Software-Defined Flash for Web-Scale Internet Storage System</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiding</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenyu</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanzheng</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS)</title>
		<meeting>the 18th International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS)</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijayan</forename><surname>Prabhakaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">L</forename><surname>Rodeheffer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lidong</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Flash</surname></persName>
		</author>
		<title level="m">Proceedings of the 8th Symposium on Operating Systems Design and Implementation (OSDI)</title>
		<meeting>the 8th Symposium on Operating Systems Design and Implementation (OSDI)</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Towards a De-Facto Standard for Virtual I/O Devices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rusty</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Virtio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGOPS Operating Systems Review (OSR)</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">FlashTier: a Lightweight, Consistent and Durable Storage Cache</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Saxena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">M</forename><surname>Swift</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiying</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 EuroSys Conference (EuroSys)</title>
		<meeting>the 2012 EuroSys Conference (EuroSys)</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Getting Real: Lessons in Transitioning Research Simulations into Hardware Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Saxena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiying</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">M</forename><surname>Swift</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><forename type="middle">C</forename><surname>Arpaci Dusseau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Remzi</forename><forename type="middle">H Arpaci</forename><surname>Dusseau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th USENIX Symposium on File and Storage Technologies (FAST)</title>
		<meeting>the 11th USENIX Symposium on File and Storage Technologies (FAST)</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Flash Reliability in Production: The Expected and the Unexpected</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bianca</forename><surname>Schroeder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raghav</forename><surname>Lagisetty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arif</forename><surname>Merchant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th USENIX Symposium on File and Storage Technologies (FAST)</title>
		<meeting>the 14th USENIX Symposium on File and Storage Technologies (FAST)</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Willow: A User-Programmable SSD</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sudharsan</forename><surname>Seshadri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Gahagan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sundaram</forename><surname>Bhaskaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Bunker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arup</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanqin</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Swanson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th Symposium on Operating Systems Design and Implementation (OSDI)</title>
		<meeting>the 11th Symposium on Operating Systems Design and Implementation (OSDI)</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">DIDACache: A Deep Integration of Device and Application for Flash Based Key-Value Caching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaoyan</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichen</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zili</forename><surname>Shao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th USENIX Symposium on File and Storage Technologies (FAST)</title>
		<meeting>the 15th USENIX Symposium on File and Storage Technologies (FAST)</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Retention Trimming for Lifetime Improvement of Flash Memory Storage Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaijie</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengying</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chun</forename><forename type="middle">Jason</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duo</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edwin H.-M</forename><surname>Sha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems (TCAD)</title>
		<imprint>
			<date type="published" when="2016-01" />
			<biblScope unit="volume">35</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Flash on Rails: Consistent Flash Performance through Redundancy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitris</forename><surname>Skourtis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitris</forename><surname>Achlioptas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><surname>Watkins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><surname>Maltzahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Brandt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 USENIX Annual Technical Conference (ATC)</title>
		<meeting>the 2014 USENIX Annual Technical Conference (ATC)</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Snapshots in a Flash with ioSnap</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sriram</forename><surname>Subramanian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Swaminathan</forename><surname>Sundararaman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nisha</forename><surname>Talagala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><forename type="middle">C</forename><surname>Arpaci-Dusseau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Remzi</forename><forename type="middle">H</forename><surname>Arpaci-Dusseau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 EuroSys Conference (EuroSys)</title>
		<meeting>the 2014 EuroSys Conference (EuroSys)</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Virtualizing I/O Devices on VMware Workstation&apos;s Hosted Virtual Machine Monitor</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeremy</forename><surname>Sugerman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ganesh</forename><surname>Venkitachalam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beng-Hong</forename><surname>Lim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the USENIX Annual Technical Conference (USENIX)</title>
		<meeting>the USENIX Annual Technical Conference (USENIX)</meeting>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">FlashNet: Flash/Network Stack Co-design</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Animesh</forename><surname>Trivedi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikolas</forename><surname>Loannou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernard</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Stuedi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonas</forename><surname>Pfefferle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ioannis</forename><surname>Koltsidas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kornilios</forename><surname>Kourtis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">R</forename><surname>Gross</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 10th Annual International Systems and Storage Conference (SYSTOR)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">An Efficient Design and Implementation of LSM-Tree based Key-Value Store on Open-Channel SSD</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangyu</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiding</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Cong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 EuroSys Conference (EuroSys)</title>
		<meeting>the 2014 EuroSys Conference (EuroSys)</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">ANViL: Advanced Virtualization for Modern Non-Volatile Memory Devices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zev</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sriram</forename><surname>Subramanian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Swaminathan</forename><surname>Sundararaman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nisha</forename><surname>Talagala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><forename type="middle">C</forename><surname>Arpaci-Dusseau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Remzi</forename><forename type="middle">H</forename><surname>Arpaci-Dusseau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th USENIX Symposium on File and Storage Technologies (FAST)</title>
		<meeting>the 13th USENIX Symposium on File and Storage Technologies (FAST)</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Tiny-Tail Flash: Near-Perfect Elimination of Garbage Collection Tail Latencies in NAND SSDs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiqin</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huaicheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingzhe</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">Hao</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Swaminathan</forename><surname>Sundararaman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">A</forename><surname>Chien</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haryadi</forename><forename type="middle">S</forename><surname>Gunawi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th USENIX Symposium on File and Storage Technologies (FAST)</title>
		<meeting>the 15th USENIX Symposium on File and Storage Technologies (FAST)</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">AutoStream: Automatic Stream Management for Multi-streamed SSDs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingpei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajinikanth</forename><surname>Pandurangan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changho</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Balakrishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 10th</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
				<title level="m">Annual International Systems and Storage Conference (SYSTOR)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">VSSIM: Virtual machine based SSD simulator</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinsoo</forename><surname>Yoo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youjip</forename><surname>Won</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joongwoo</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sooyong</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jongmoo</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungroh</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaehyuk</forename><surname>Cha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th IEEE Symposium on Massive Storage Systems and Technologies (MSST)</title>
		<meeting>the 29th IEEE Symposium on Massive Storage Systems and Technologies (MSST)</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Application-Aware and Software-Defined SSD Scheme for Tencent Large-Scale Storage System</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianquan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianlin</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingning</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caihua</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feiling</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaqing</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 22nd IEEE International Conference on Parallel and Distributed Systems (ICPADS)</title>
		<meeting>22nd IEEE International Conference on Parallel and Distributed Systems (ICPADS)</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiying</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leo</forename><forename type="middle">Prasath</forename><surname>Arulraj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><forename type="middle">C</forename><surname>Arpaci-Dusseau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Remzi</forename><forename type="middle">H</forename><surname>Arpaci-Dusseau</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">De-indirection for Flash-based SSDs with Nameless Writes</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th USENIX Symposium on File and Storage Technologies (FAST)</title>
		<meeting>the 10th USENIX Symposium on File and Storage Technologies (FAST)</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
