<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2020-09-29T04:23+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Declaratively Processing Provenance Metadata</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Moore</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Harvard University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Gehani</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">SRI International</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natarajan</forename><surname>Shankar</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">SRI International</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Declaratively Processing Provenance Metadata</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Systems that gather fine-grained provenance metadata must process and store large amounts of information. Filtering this metadata as it is collected has a number of benefits, including reducing the amount of persistent storage required and simplifying subsequent prove-nance queries. However, writing these filters in a procedural language is verbose and error prone. We propose a simple declarative language for processing prove-nance metadata and evaluate it by translating filters implemented in SPADE [9], an open-source provenance collection platform.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>SPADE <ref type="bibr">[9]</ref> is an open source software platform that supports collecting, filtering, storing, and querying provenance metadata. Computational history is reported as a stream of events that describe the relationships between agents, the processes they control, and the data artifacts produced and consumed. This stream is often voluminous and replete with information that is of limited interest. Filtering the event stream to abstract it during collection has multiple benefits. It can dramatically reduce the persistent storage needed, reduce the time to index the provenance, and simplify subsequent querying.</p><p>The specific transformations needed to abstract the provenance depend on the activity domain that is being reported. For example, a stream of individual temperature readings by a single sensor may be combined into one reading that describes the bottom and top of the observed range within a temporal interval. Consequently, SPADE provides a framework for implementing filters (that can be stacked in arbitrary order). A filter receives a stream of provenance graph vertices and edges, and can rewrite their annotations (in which domain-specific semantics are embedded). Each filter can propagate the * while visiting SRI International vertices and edges to the next filter, drop the graph elements, or even synthesize new ones. However, since a filter must be implemented as procedural Java code, it can be verbose and is prone to mismatches between the user's intent and the implementation realized. To alleviate these difficulties, we propose a declarative programming language for processing streams of provenance metadata.</p><p>Declarative programming languages, in particular Datalog, have been used for a number of provenance reasoning and processing tasks, including query specification <ref type="bibr">[5,</ref><ref type="bibr">7,</ref><ref type="bibr">14]</ref>, transformation <ref type="bibr">[8]</ref>, and dependency inference <ref type="bibr">[3]</ref>. However, all of these tasks consider offline analysis of provenance metadata. Outside of the provenance community, there has been significant research on languages and systems for event processing <ref type="bibr">[4]</ref> and on declarative languages for event-based distributed programming <ref type="bibr" target="#b0">[1,</ref><ref type="bibr">13]</ref>.</p><p>In this paper, we explore using a declarative event processing language to process provenance metadata. We propose a simple domain-specific language for event processing based on Datalog which we call Simple Event Logic (SEL). We have implemented a meta-interpreter for SEL in SWI-Prolog and used it to prototype modules implementing provenance processing tasks found in SPADE.</p><p>We introduce SEL in Section 2. Section 5 demonstrates the use of declarative programs to write provenance filters. In Section 6, we summarize our experience and describe likely avenues for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">SEL</head><p>SEL extends Datalog¬ (Datalog with negation and aggregate functions <ref type="bibr">[17]</ref>) with a synchronous model of time, a single temporal operator "previously" (written '?'), and a simple module system.</p><p>SEL's temporal model is similar to synchronous programming languages like Esterel, Lustre, and Signal <ref type="bibr" target="#b1">[2,</ref><ref type="bibr">11,</ref><ref type="bibr">12]</ref>. At each instant in time, an arbitrary number of instantaneous events may occur. Instants in time have a total ordering, but physical time is not observable (unless provided explicitly as an attribute of an event). New instants are triggered when new events are introduced to the program by an external source: for example, when new provenance-related events are reported by the operating system.</p><p>Events are represented as Datalog facts and may have 0 or more attributes. Inference rules generate new events that occur simultaneously with the events that trigger them. Inference rules may also depend on the presence (or absence) of events in the immediately previous instant. Complex events can be abstracted by modules to simplify programs and facilitate code reuse.</p><p>Well-formed Datalog programs with negation and aggregate functions must be stratifiable: the dependency graph of inference rules should have no cycles with negated or aggregate goals. SEL programs must satisfy a slightly weaker constraint: temporal stratifiability <ref type="bibr" target="#b0">[1]</ref>. Temporally stratifiable programs may contain cycles with negated or aggregate goals, but those goals must be preceded by a "previously" operator-such programs are stratifiable in each instant, but admit nonmonotonic reasoning across instants.</p><p>We give a high level description SEL's formal semantics in the next section before demonstrating the language and its syntax with a small example.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Semantics</head><p>The semantics of SEL was inspired by the DEDALUS language for distributed programming <ref type="bibr" target="#b0">[1]</ref>. DEDALUS is a declarative, Datalog-based programming language with support for mutable state and asynchronous communication. Unlike other languages that have attempted to combine imperative features with Datalog, the semantics of DEDALUS are purely declarative and are given by a transformation into a restricted sublanguage of Datalog¬, which the authors call DEDALUS 0 .</p><p>Likewise, we give the semantics of SEL in terms of a restricted sublanguage of Datalog¬. Like DEDALUS 0 , this core language has two syntactic restrictions:</p><p>1. Timestamps: The final argument of all relations must be a natural number denoting a "timestamp."</p><p>2. Sequencing constraints: The timestamps T 1 , . . . , T n of all subgoals in a rule must be related to the timestamp of the head of the rule, S, by either an equality constraint, T i = S, or a successor constraint</p><formula xml:id="formula_0">successor(T i , S).</formula><p>Unlike DEDALUS 0 , we do not require that all subgoals of a rule share the same timestamp. This allows some programs to be expressed more concisely at the expense of a slightly more complicated well-foundedness check for temporal stratification of negation and aggregation. Temporally stratifiable programs meeting these restrictions have a unique (possibly infinite) minimal model: the set of facts true at each instant in time for each relation. We take this minimal model as the semantics of the program.</p><p>The desugaring process from SEL to this core language is straightforward. A timestamp attribute is added to the schema of each relation. Within each inference rule, a constraint is added relating the timestamp of each subgoal to the timestamp of the rule head. If the subgoal is prefixed with a "previously" operator, a successor constraint is added; otherwise, an equality constraint is added.</p><p>Modules are transformed by inlining their definitions where they are imported, renaming events to unique names to avoid clashes. To allow module 'clocks' to differ, additional rules are added that relate timestamps from different modules only when an input event for an included module is triggered.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">SEL By Example</head><p>Listing 1 gives an example SEL program that monitors a hypothetical boiler for dangerous conditions. The program comprises two modules, delta (defined in lines 1-10) and boiler (defined in lines <ref type="bibr">[12]</ref><ref type="bibr">[13]</ref><ref type="bibr">[14]</ref><ref type="bibr">[15]</ref><ref type="bibr">[16]</ref><ref type="bibr">[17]</ref><ref type="bibr">[18]</ref><ref type="bibr">[19]</ref><ref type="bibr">[20]</ref><ref type="bibr">[21]</ref><ref type="bibr">[22]</ref><ref type="bibr">[23]</ref><ref type="bibr">[24]</ref><ref type="bibr">[25]</ref><ref type="bibr">[26]</ref><ref type="bibr">[27]</ref>.</p><p>The delta module takes as input a stream of value events, each with a single numeric attribute. The module outputs a stream of change events as the value parameter changes. The attribute of the change event is the difference between the new value and the old value. For each pair of a current value event and a value event in the previous instant, the single inference rule (lines 5-8) generates a change event if the attribute of a current value differs from the previous one.</p><p>The boiler module takes as input a stream of pressure readings from sensors in the boiler and switch on/off events from the boiler control panel. In line 17, sensor readings arriving in the same instance (from different sensors) are averaged using an aggregate function. The inference rule in lines 22-23 triggers an alert event if the average pressure reading exceeds the safety limits of the boiler.</p><p>The program also monitors for unexpected changes in pressure. An unexpected change in pressure is a positive change in pressure that occurs while the boiler is off. Monitoring this property requires tracking the state of the boiler. Lines 19-20 generate a heating event in every instant the boiler is on. The first inference rule records that the boiler is on if it has been switched on. The second inference rule denotes that the boiler remains on if it was previously on (?heating) and has not been turned 1 module delta . 2 input value /1. 3 output change /1.     Listing 1: Monitoring a boiler for dangerous conditions. off (¬switch_off). To detect changes in boiler pressure, line 15 imports the delta module using pressure events as its input stream. Finally, the inference rule in lines 24-25 triggers an event if a positive change occurs while the boiler is not in heating mode.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Processing Provenance Metadata</head><p>SPADE incorporates filters that apply a number of transforms to incoming streams provenance events in order to reduce storage requirements, increase performance, and simplify subsequent queries. SPADE filters are also used to abstract provenance information from detailed, lowlevel event streams (e.g., provenance data reported by an OS) and fuse provenance metadata received via disparate reporting mechanisms. To evaluate the applicability of declarative programing to the problem of processing streams of provenance events, we translated several SPADE filters into SEL programs.</p><p>We represent SPADE provenance metadata in SEL as streams of vertex, edge, and attribute events. Our encoding is similar to Missier and Belhajjame's <ref type="bibr">[14]</ref> encoding of the PROV specification in DLV Datalog. All vertices and edges have an associated ID and type (e.g., "artifact" or "wasGeneratedBy") derived from the Open Provenance Model <ref type="bibr">[15]</ref>. Attribute events associate keyvalue pairs with IDs.</p><p>In the remainder of this section, we give examples of two types of provenance filters in SPADE and their SEL implementations. <ref type="bibr" target="#b0">1</ref>       Listing 2: Aggregating runs of IO events.</p><p>Aggregation Keeping track of fine-grained provenance metadata provides a detailed view of the relationships between data object involved in a computation, but at the expense of additional storage and processing overhead. For example, SPADE includes a number of reporting interfaces that receive detailed metadata about file I/O. SPADE supports a number of filters for aggregating this metadata into provenance events <ref type="bibr">[10]</ref>. Listing 2 gives a snippet of one of these filters, IORuns, translated into SEL. The IORuns filter aggregates successive file reads or writes into a single provenance artifact.</p><p>The IORuns module relies on the Aggregate module given in Listing 3. The Aggregate module provides two services: buffering events and aggregating the attributes of multiple provenance elements. Lines 6-14 retain events until they are either passed to the next module by an emit/1 input event or dropped by a drop/1 event. The aggr/2 input event records relationships between provenance items. When a provenance element is emitted, it is associated with the attributes of all sub-1 module Aggregate .   In lines 6-10, IORuns immediately forwards non-filerelated provenance elements to its output. File-related events are buffered by the Aggregate module. The reading/4 event associates an edge ID, process, and file name with each series of successive reads of a file by a process (lines 12-21). If a process reads from a file that it is already reading, the new provenance elements are aggregated with the first read in the sequence (lines <ref type="bibr">[23]</ref><ref type="bibr">[24]</ref><ref type="bibr">[25]</ref><ref type="bibr">[26]</ref><ref type="bibr">[27]</ref><ref type="bibr">[28]</ref>. When a series of reads is broken by a write to the same file by any process, the aggregated provenance elements are output (lines 30-35). Similar rules buffer and aggregate writes and emit pending metadata when a process ends, but we omit them here for brevity.</p><p>Our SEL implementation of IORuns, including the Aggregate module, is 74 non-comment lines of code comprising 25 inferences rules. While this is actually slightly more than the original Java implementation (Listing 6 in Appendix 7), there are three advantages to the SEL implementation. First, it is modular: the Aggregate module can be reused by other filters. Second, it is declarative: the inference rules for emit/1 make clear what provenance data is generated by the module. In the original implementation, this required understanding the control flow of the entire filter, including the effect of imperative updates to a number of two-level hash tables. Finally, our SEL implementation aggregates the attributes of subsequent reads, whereas the original implementa-1 module LLVMFilter . 2 input vertex /2 , edge /4 , attr /3 , relevant /1. 3 output vertex_out /2 , edge_out /2 , attr_out /3. 4 import Aggregate .     Filtering SPADE also supports the collection of finegrained, application-specific provenance metadata by instrumenting programs to report function calls and returns <ref type="bibr">[16]</ref>. To cope with the volume of metadata produced, SPADE allows users to specify a set of interesting functions. A filter drops metadata associated with irrelevant functions.</p><p>The module in Listing 4 implements this filter in SEL. The relevant/1 input event defines a set of functions for which provenance metadata should be collected. Provenance nodes are relevant if they represent calls to relevant functions or artifacts used or generated by a relevant function (lines <ref type="bibr">[6]</ref><ref type="bibr">[7]</ref><ref type="bibr">[8]</ref><ref type="bibr">[9]</ref><ref type="bibr">[10]</ref><ref type="bibr">[11]</ref><ref type="bibr">[12]</ref><ref type="bibr">[13]</ref><ref type="bibr">[14]</ref>. An edge is relevant if it involves relevant process nodes (lines <ref type="bibr">[16]</ref><ref type="bibr">[17]</ref><ref type="bibr">[18]</ref><ref type="bibr">[19]</ref><ref type="bibr">[20]</ref><ref type="bibr">[21]</ref><ref type="bibr">[22]</ref><ref type="bibr">[23]</ref><ref type="bibr">[24]</ref><ref type="bibr">[25]</ref><ref type="bibr">[26]</ref><ref type="bibr">[27]</ref>. Because whether an artifact is relevant depends on the edges it connects to (which may not have arrived yet), the module must maintain a buffer of artifact nodes. Like the original SPADE implementation, the filter assumes that artifacts share edges with either only relevant or only irrelevant process nodes. Thus, it is possible to determine when a provenance element is irrelevant (lines 29-34) and drop it from the buffer (lines 38-39).</p><p>Unlike the Java implementation (Listing 7 in Appendix 7), the declarative rules defining relevant and irrelevant provenance elements make clear the semantic conditions under which artifact nodes are buffered, dropped, or output.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Future Directions</head><p>As other provenance researchers have observed <ref type="bibr">[3,</ref><ref type="bibr">7,</ref><ref type="bibr">8,</ref><ref type="bibr">14]</ref>, Datalog is a natural choice for representing, querying, and reasoning about provenance. Our experience translating SPADE filters from Java into SEL suggests that using a declarative language also makes it easier to design and implement tools for processing streams of provenance metadata.</p><p>Buffer management remains a key challenge when implementing provenance filters. Many provenance filters, including the examples in Section 5, require knowledge of past or future provenance events to determine how to process a metadata element. In both the Java and SEL implementations of our filters, this buffer is explicitly managed. Ensuring that buffers do not grow too large while still retaining relevant information is a source of significant complexity. We foresee two possible solutions to this challenge. Operationally, we could incorporate buffering primitives like sliding windows seen in event processing languages <ref type="bibr">[4]</ref>. Declaratively, we plan to investigate using known query optimization techniques to attempt to infer from a filter's inference rules what current events might trigger rules in the future, and thus provide automatic buffer management.</p><p>Incorporating a query language into systems that process streams of provenance metadata opens up new avenues of research in online provenance queries. SPADE supports collecting system-wide provenance information from operating system and network reporting interfaces. Online provenance queries could allow this data to be used to detect anomalies or report on system status in real time rather than retrospectively.</p><p>For example, consider the SEL module LeakDetector in Listing 5. LeakDetector monitors a stream of provenance events to detect when sensitive data may be leaked to the network by tracking possible data flows through processes and artifacts. By actively processing systemwide provenance data, this module can detect a possible security violation as it happens and provide an alert. The original provenance data can then be audited for additional information.      Listing 5: Monitoring provenance for security.</p><p>In addition to the filters and queries presented in this paper, existing declarative provenance transformations could be applied to enforce privacy policies <ref type="bibr">[8]</ref>, integrate additional workflow information <ref type="bibr">[3]</ref>, or support certification with claims and evidence from formal tools <ref type="bibr">[6]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>[3] Shawn Bowers, Timothy McPhillips, and Bertram</head><p>Ludäscher. Declarative rules for inferring finegrained data provenance from scientific workflow execution traces. In 4th International Provenance and Annotation Workshop, pages 82-96. SpringerVerlag, 2012.</p><p>[4] Francois Bry, Michael Eckert, Opher Etzion, Jon Riecke, and Adrian Paschke. Event processing languages. Tutorial in DEBS 2009, 2009.</p><p>[   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">SPADE filters in Java</head><p>Listings 6 and 7 give snippets from the Java implementation of the SPADE filters in Section 5. SPADE is available at http://code.google.com/p/data-provenance under the GPLv3.  Listing 7: Code snippets from the Java implementation of LLVMFilter.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>4 5</head><label>4</label><figDesc>change ( Change ) : - 6 value ( Cur ) , ? value ( Old ) , 7 Cur != Old , Change = Cur -Old . 8 9 end delta . 10 11 module boiler . 12 input switch_on /0 , switch_off /0 , sensor /1. 13 output alert /1. 14 import delta with value = pressure .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>15 16 pressure ( average &lt;P &gt;) : -sensor ( P ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>17 18 heating : -switch_on . 19 heating : -? heating , ¬switch_off .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>20 21 alert ( ' Too much pressure ! ') : - 22 pressure ( P ) , P &gt; 100. 23 alert ( ' Shut off failed ! ') : - 24 ¬heating , change ( D ) , D &gt;= 0.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>5 6</head><label>5</label><figDesc>emit ( ID ) : - 7 vertex ( ID , Type ) , Type != artifact . 8 emit ( ID ) : - 9 edge ( ID , Type ,_ , _ ) , 10 Type != used , Type != wa sGenera tedBy . 11 12 read ( ID , Process , Artifact , File ) : - 13 edge ( ID , used , Process , Artifact ) , 14 attr ( Artifact , location , File ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>15 16 reading ( ID , Process , Artifact , File ) : - 17 read ( ID , Process , Artifact , File ) , 18 ¬? reading (_ , Process ,_ , File ). 19 reading ( ID , Process , Artifact , File ) : - 20 reading ( ID , Process , Artifact , File ) , 21 ¬write (_ ,_ ,_ , File ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>22 23 aggr ( ReadSeries , Read ) : - 24 reading ( ReadSeries , Process ,_ , File ) , 25 read ( Read , Process ,_ , File ). 26 aggr ( ReadArtifact , Artifact ) : - 27 reading (_ , Process , ReadArtifact , File ) , 28 read (_ , Process , Artifact , File ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>29 30 emit ( Artifact ) : - 31 reading (_ ,_ , Artifact , File ) , 32 write (_ ,_ ,_ , File ). 33 emit ( Read ) : - 34 reading ( Read ,_ ,_ , File ) , 35 write (_ ,_ ,_ , File ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>22 emit ( ID ) , vertex ( ID , Type ). 23 edge_out ( ID , Type , Src , Dst ) : - 24 emit ( ID ) , edge ( ID , Type , Src , Dst ). 25 attr_out ( ID , Key , Value ) : - 26 emit_attr ( ID , Attr ) , attr ( Attr , Key , Value ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Listing 3 :</head><label>3</label><figDesc>Buffering and aggregating provenance events. elements specified by aggr/2 (Lines 16-18 and 24-25).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>5 6</head><label>5</label><figDesc>relevant_node ( ID ) : - 7 attr ( ID , function , Name ) , 8 relevant ( Name ). 9 relevant_node ( Artifact ) : - 10 edge (_ , used , Process , Artifact ) , 11 relevant_node ( Process ). 12 relevant_node ( Artifact ) : - 13 edge (_ , wasGeneratedBy , Artifact , Process ) , 14 relevant_node ( Artifact ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>15 16</head><label>15</label><figDesc>relevant_edge ( ID ) : - 17 edge ( ID , used , Process , Artifact ) , 18 relevant_node ( Process ). 19 relevant_edge ( ID ) : - 20 edge ( ID , wasGeneratedBy , Artifact , Process ) , 21 relevant_node ( Process ). 22 relevant_edge ( ID ) : - 23 edge ( ID , wasTriggeredBy , Caller , _ ) , 24 relevant_node ( Caller ). 25 relevant_edge ( ID ) : - 26 edge ( ID , wasTriggeredBy ,_ , Callee ) , 27 relevant_node ( Callee ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head></head><label></label><figDesc>28 29 i rr el ev a nt _e dg e ( ID ) : - 30 edge ( ID ,_ ,_ , _ ) , ¬relevant_edge ( ID ). 31 i rr el ev a nt _n od e ( ID ) : - 32 edge (_ ,_ , ID , _ ) , ¬relevant_node ( ID ). 33 i rr el ev a nt _n od e ( ID ) : - 34 edge (_ ,_ ,_ , ID ) , ¬relevant_node ( ID ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>35 36</head><label>35</label><figDesc>emit ( ID ) : -relevant_node ( ID ). 37 emit ( ID ) : -relevant_edge ( ID ). 38 drop ( ID ) : -ir r el ev an t _n od e ( ID ). 39 drop ( ID ) : -ir r el ev an t _e dg e ( ID ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head></head><label></label><figDesc>Listing 4: Filtering application-level provenance. tion simply discards them.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head>9</head><label></label><figDesc>tainted ( Process , Secret ) : - 10 edge (_ , used , Process , Artifact ) , 11 tainted ( Artifact , Secret ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head></head><label></label><figDesc>12 13 tainted ( Artifact , Secret ) : - 14 edge (_ , wasGeneratedBy , Artifact , Process ) , 15 tainted ( Process , Secret ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head></head><label></label><figDesc>16 17 leak ( Secret , Connection ) : - 18 edge (_ , wasGeneratedBy , Connection , Process ) , 19 attr ( Connection , subtype , network ) , 20 tainted ( Process , Secret ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_22"><head></head><label></label><figDesc>21 22 tainted ( Node , Secret ) : - 23 ? tainted ( Node , Secret ) , 24 ¬attr ( Node , ' end ' ,_ ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_24"><head>5 ]</head><label>5</label><figDesc>Shirley Cohen, Sarah Cohen-Boulakia, and Susan Davidson. Towards a model of provenance and user views in scientific workflows. In 3rd Interna- tional Conference on Data Integration in the Life Sciences, pages 264-279, 2006. [6] Simon Cruanes, Grégoire Hamon, Sam Owre, and Natarajan Shankar. Tool integration with the evi- dential tool bus. In 14th International Conference on Verification, Model Checking, and Abstract In- terpretation, pages 275-294, 2013. [7] Saumen Dey, Sven Köhler, Shawn Bowers, and Bertram Ludäscher. Datalog as a lingua franca for provenance querying and reasoning. In 4th USENIX Workshop on the Theory and Practice of Provenance, 2012. [8] Saumen C. Dey, Daniel Zinn, and Bertram Ludäscher. Propub: towards a declarative ap- proach for publishing customized, policy-aware provenance. In 23rd International Conference on Scientific and Statistical Database Management, pages 225-243, 2011. [9] Ashish Gehani and Dawood Tariq. SPADE: Sup- port for provenance auditing in distributed environ- ments. In 13th ACM/IFIP/USENIX International Conference on Middleware, pages 101-120, 2012. [10] Ashish Gehani, Dawood Tariq, Basim Baig, and Tanu Malik. Policy-Based Integration of Prove- nance Metadata. In 12th IEEE International Sym- posium on Policies for Distributed Systems and Networks. IEEE Computer Society, 2011.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_25"><head>[</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_26"><head>1</head><label></label><figDesc>public void putVertex ( A bstractV ertex incom ingVerte x ) { 2 if ( i ncoming Vertex instanceof Artifact ) { 3 vertexBuffer . add ( incomin gVertex ); 4 } else { 5 p ut In Nex tF il te r ( inco mingVert ex ); 6 return ; 7 } 8 if ( vertexBuffer . size () &gt; BUFFER_SIZE ) 9 Logger . getLogger ( " IORuns " ). warning ( " *** Vertex Buffer full . Dropping ! ))) " ); 10 } 11 12 public void putEdge ( AbstractEdge incomingEdge ) { 13 if ( incomingEdge instanceof Used ) { 14 Used usedEdge = ( Used ) incomingEdge ; 15 String fileV ertexHas h = usedEdge . g e t D e s t i n a t i o n V e r t e x (). getAnnotation ( artifactKey ); 16 String p r o c e s s V e r t e x H a s h = Integer . toString ( usedEdge . ge t So ur ce V er te x (). hashCode ()); 17 if (! reads . containsKey ( fileVert exHash )) { 18 HashSet &lt; String &gt; tempSet = new HashSet &lt; String &gt;(); 19 tempSet . add ( p r o c e s s V e r t e x H a s h ); 20 reads . put ( fileVertexHash , tempSet ); 21 } else { 22 HashSet &lt; String &gt; tempSet = reads . get ( fil eVertexH ash ); 23 if ( tempSet . contains ( p r o c e s s V e r t e x H a s h )) { 24 vertexBuffer . remove ( usedEdge . g e t D e s t i n a t i o n V e r t e x ()); 25 return ; 26 } else { tempSet . add ( p r o c e s s V e r t e x H a s h ); } 27 } 28 vertexBuffer . remove ( usedEdge . g e t D e s t i n a t i o n V e r t e x ()); 29 p ut In Ne x tF il te r ( usedEdge . g e t D e s t i n a t i o n V e r t e x ()); 30 p ut In Ne x tF il te r ( usedEdge ); 31 if ( writes . containsKey ( fileVert exHash )) { 32 HashSet &lt; String &gt; tempSet = writes . get ( fi leVerte xHash ); 33 tempSet . remove ( p r o c e s s V e r t e x H a s h ); 34 } 35 } else if ( incomingEdge instanceof WasG enerate dBy ) { 36 WasG enerated By wgb = ( WasGene ratedBy ) incomingEdge ; 37 String fileV ertexHas h = wgb . g e tS ou rc e Ve rt ex (). getAnnotation ( artifactKey ); 38 String p r o c e s s V e r t e x H a s h = Integer . toString ( wgb . g e t D e s t i n a t i o n V e r t e x (). hashCode ()); 39 if (! writes . containsKey ( fileVe rtexHash )) { 40 HashSet &lt; String &gt; tempSet = new HashSet &lt; String &gt;(); 41 tempSet . add ( p r o c e s s V e r t e x H a s h ); 42 writes . put ( fileVertexHash , tempSet ); 43 } else { 44 HashSet &lt; String &gt; tempSet = writes . get ( fi leVerte xHash ); 45 if ( tempSet . contains ( p r o c e s s V e r t e x H a s h )) { 46 vertexBuffer . remove ( wgb . ge tS o ur ce Ve r te x ()); 47 return ; 48 } else { tempSet . add ( p r o c e s s V e r t e x H a s h ); } 49 } 50 vertexBuffer . remove ( wgb . ge tS ou r ce Ve r te x ()); 51 p ut In Nex tF il te r ( wgb . g et S ou rc eV e rt ex ()); 52 p ut In Nex tF il te r ( wgb ); 53 if ( reads . containsKey ( fi leVertex Hash )) { 54 HashSet &lt; String &gt; tempSet = reads . get ( fil eVertexH ash ); 55 tempSet . remove ( p r o c e s s V e r t e x H a s h ); 56 } 57 } else { p ut I nN ex t Fi lt er ( incomingEdge ); } 58 } Listing 6: Code snippets from the Java implementation of the IORuns filter.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_27"><head>1</head><label></label><figDesc>public void putVertex ( A bstractV ertex incoming ) { 2 if ( incoming instanceof Process ) { 3 if ( m e t h o d s T o M o n i t o r . contains ( incoming . getAnnotation ( " FunctionName " ))) { 4 p ut InNe x tF il te r ( incoming ); 5 } 6 } else { 7 String ID = incoming . getAnnotation ( " ID " ); 8 artifacts . put ( ID , 1); 9 } 10 } 11 12 public void putEdge ( AbstractEdge incoming ) { 13 if ( incoming instanceof Used ) { 14 Artifact artifact = ( Artifact ) incoming . g e t D e s t i n a t i o n V e r t e x (); 15 Process process = ( Process ) incoming . ge t So ur ce V er te x (); 16 String ArgID = artifact . getAnnotation ( " ID " ); 17 if ( m e t h o d s T o M o n i t o r . contains ( process . getAnnotation ( " FunctionName " ))) { 18 if ( artifacts . containsKey ( ArgID )) / / E v e r y A r t i f a c t i s u s e d a t m o s t t w i c e 19 { 20 if ( artifacts . get ( ArgID ) == 1) / / E v e r y A r t i f a c t i s u s e d a t m o s t t w i c e 21 { 22 artifacts . put ( ArgID , artifacts . get ( ArgID ) + 1); / / I n c r e m e n t C o u n t e r 23 put In Ne x tF il t er ( artifact ); 24 } else { 25 / / I f A r t i f a c t s e e n t w i c e r e m o v e i t f r o m t h e HashMap 26 artifacts . remove ( ArgID ); 27 } 28 p utIn Ne x tF il te r ( incoming ); 29 } 30 } else { 31 / / I f we do n o t w a n t t o m o n i t o r t h e A r t i f a c t r e m o v e i t f r o m t h e HashMap 32 artifacts . remove ( ArgID ); 33 } 34 35 } else if ( incoming instanceof Wa sGenerat edBy ) { 36 Process process = ( Process ) incoming . g e t D e s t i n a t i o n V e r t e x (); 37 Artifact artifact = ( Artifact ) incoming . ge t So ur ce V er te x (); 38 String ArgID = artifact . getAnnotation ( " ID " ); 39 if ( m e t h o d s T o M o n i t o r . contains ( process . getAnnotation ( " FunctionName " ))) { 40 if ( artifacts . containsKey ( ArgID )) { 41 if ( artifacts . get ( ArgID ) == 1) { 42 artifacts . put ( ArgID , artifacts . get ( ArgID ) + 1); 43 put In Ne x tF il t er ( artifact ); 44 } else { 45 artifacts . remove ( ArgID ); 46 } p utIn Ne x tF il te r ( incoming ); 48 } 49 } else { 50 artifacts . remove ( ArgID ); 51 } 52 } else / / W a s T r i g g e r e d B y 53 { 54 Abst ractVert ex source = incoming . g e tS ou rc e Ve rt ex (); 55 Abst ractVert ex destination = incoming . g e t D e s t i n a t i o n V e r t e x (); 56 if ( m e th o d s T o M o n i t o r . contains ( source . getAnnotation ( " FunctionName " ))) { 57 if ( m e t h o d s T o M o n i t o r . contains ( destination . getAnnotation ( " FunctionName " ))) { 58 p utIn Ne x tF il te r ( incoming ); 59 } 60 } 61 } 62 }</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This material is based upon work supported by the National Science Foundation under Grants CNS-0917375 and IIS-1116414, and the National Aeronautics and Space Administration under Cooperative Agreement NNX08AY53A. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the National Science Foundation or the National Aeronautics and Space Administration.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Dedalus: datalog in time and space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Alvaro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>William</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil</forename><surname>Marczak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><forename type="middle">M</forename><surname>Conway</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Hellerstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Russell</forename><surname>Maier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sears</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Datalog&apos;10: 1st International Conference on Datalog Reloaded</title>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">The ES-TEREL synchronous programming language: design, semantics, implementation. Science of Computer Programming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gérard</forename><surname>Berry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georges</forename><surname>Gonthier</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992" />
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="87" to="152" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
