<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2020-09-29T02:49+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">When Apache Spark Meets FPGAs: A Case Study for Next-Generation DNA Sequencing Acceleration</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Ting</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Los Angeles</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Cong</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Los Angeles</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenman</forename><surname>Fang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Los Angeles</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Lei</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Los Angeles</settlement>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Wei</surname></persName>
							<email>peng.wei.prc@cs.ucla.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Los Angeles</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">When Apache Spark Meets FPGAs: A Case Study for Next-Generation DNA Sequencing Acceleration</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>FPGA-enabled datacenters have shown great potential for providing performance and energy efficiency improvement. In this paper we aim to answer one key question: how can we efficiently integrate FPGAs into state-of-the-art big-data computing frameworks like Apache Spark? To provide a generalized methodology and insights for efficient integration, we conduct an in-depth analysis of challenges at single-thread, single-node multi-thread, and multi-node levels, and propose solutions including batch processing and the FPGA-as-a-Service framework to address them. With a step-by-step case study for the next-generation DNA sequencing application , we demonstrate how a straightforward integration with 1,000x slowdown can be tuned into an efficient integration with 2.6x overall system speedup and 2.4x energy efficiency improvement.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Nowadays, power and energy efficiency of generalpurpose processors have become two of the primary constraints that limit the performance scaling of conventional datacenters. Harnessing FPGA-based heterogeneous platforms, which provide low power, high energy efficiency and reprogrammability, is considered one of the most promising approaches to yield continued performance and energy efficiency improvement. For example, Microsoft has deployed FPGAs into its datacenters to accelerate the ranking stage of the Bing search engine with almost 2x throughput improvement while consuming only 10% more power <ref type="bibr" target="#b17">[17]</ref>. IBM has also deployed FPGAs in its data engine for large and fast-growing NoSQL data stores <ref type="bibr" target="#b4">[4]</ref>. In addition, Intel, with acquisition of Altera, is providing QPI-based CPU-FPGA platforms for datacenters <ref type="bibr">[10]</ref>. Predictably, there will be many FPGA-enabled datacenters in the near future.</p><p>With the emerging FPGA-enabled datacenter trend, one key question is: how can we efficiently integrate FPGAs into state-of-the-art big-data computing frameworks like Apache Spark <ref type="bibr" target="#b20">[20]</ref>? According to our case study, a straightforward FPGA integration can actually lead to a slowdown by 1,000x compared to a CPU-only cluster. Our goal is to provide generalized insights for efficient integration of FPGA accelerators into the Spark MapReduce framework <ref type="bibr" target="#b20">[20]</ref>, and turn the slowdown back to performance and energy efficiency improvement.</p><p>Our approach is to conduct an in-depth case study for the acceleration of an important and representative application: next-generation DNA sequencing <ref type="bibr" target="#b18">[18]</ref>. We choose this application for the following two reasons. First, it is an important application that is transitioning into clinical use where time is a matter of life and death. Moreover, the FPGA accelerator for this application represents a category of fine-grained accelerators that impose further challenges to the integration. Unlike conventional coarse-grained accelerators, these fine-grained accelerators execute for a very short time (e.g., a microsecond or so) but will be invoked many (e.g., hundreds of millions) times, and thus a straightforward offloading of the CPU computation onto the FPGA board could significantly degrade the overall performance due to the overwhelming JVM-FPGA communication overhead (e.g., a few milliseconds for data to be transferred from JVM to native machine and then to FPGA).</p><p>In summary, this paper makes the following contributions. 1. Methodology and insights for efficient integration of FPGAs into big-data computing frameworks like Spark, including what challenges are expected at single-thread (Section 4.1), single-node multi-thread (Section 4.2), and multi-node levels (Section 4.3), as well as how to address them. 2. Design and deployment of an FPGA-enabled Spark cluster that features batch processing to alleviate JVM-FPGA communication overhead and the FPGAas-a-Service (FaaS) framework to efficiently share FPGAs among multiple CPU threads, achieving 2.6x better performance than a CPU-only cluster for the emerging DNA sequencing application, while consuming only 8% more power per server.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background and Related Work</head><p>There is an increasing trend to integrate FPGA accelerators into modern datacenters. For example, Microsoft has developed a customized FPGA board, Catapult, and placed it into each server to accelerate the ranking stage of the Bing search engine in a 1,632-node cluster <ref type="bibr" target="#b17">[17]</ref>. With a key focus on discussing the robust design of the large-scale system architecture, this publication did not reveal many details of the programming framework. Moreover, IBM has proposed the Coherent Accelerator Processor Interface (CAPI) to connect a PCIe-based FPGA board to a POWER8 processor, and integrated such FPGAs into its in-memory data structure store Redis to accelerate its Data Engine for NoSQL <ref type="bibr" target="#b4">[4]</ref>. In this paper we aim to provide a more generalized methodology and insight for efficient integration of FPGA accelerators into state-of-the-art big-data computing frameworks like Spark, and therefore stimulate more innovations in this very hot area. Meanwhile, there are also some efforts that integrate GPU accelerators into Hadoop and Spark. For example, in <ref type="bibr" target="#b8">[8]</ref>, <ref type="bibr">Grossman et al.</ref> proposed an automated flow to generate OpenCL kernels for Hadoop programs in a GPU-equipped cluster. In <ref type="bibr" target="#b14">[14]</ref>, Li et al. integrated GPU accelerators with Spark for deep learning algorithms. While these approaches usually target the integration of coarse-grained accelerators, we mainly focus on the integration of fine-grained FPGA accelerators, which introduces more challenges, like efficient communication and sharing as discussed in Section 4.1 and Section 4.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Cluster Scale Acceleration: Case Study 3.1 Next-Generation DNA Sequencing</head><p>Next-generation sequencing results from a combination of chemical engineering and computer science innovations. To sequence a human's entire genome, a number of copies of the individual's genome are fragmented into small pieces, called reads, and the sequencers determine the order of nucleotides for each read. The sequenced reads are stored as ASCII strings (roughly 100 characters each), and aligned to specific locations of a reference genome (a string of 3 billion characters) to be assembled into an entire DNA sequence.</p><p>Generally, a sequencing instance processes billions of reads, and each read is independently sequenced and aligned. This billion-degree parallelism makes it a good candidate for cluster scale acceleration. While single-machine software tools, such as Burrows-Wheeler Aligner (BWA) <ref type="bibr" target="#b13">[13]</ref>, Bowtie <ref type="bibr" target="#b12">[12]</ref> and Genome Analysis Toolkit (GATK) <ref type="bibr" target="#b15">[15]</ref> are still widely used for read alignment and successive data analysis, a few cluster scale tools have been proposed to serve as alternatives.</p><p>In <ref type="bibr" target="#b6">[6]</ref>, Chen et al. proposed CS-BWAMEM, a Sparkbased MapReduce implementation for mapping the short reads onto the reference genome. In <ref type="bibr" target="#b16">[16]</ref>, Massie et al. proposed ADAM, another Spark-based implementation, which provides a set of formats, APIs and tools for data analysis on aligned reads.</p><p>Conceptually, the sequencing algorithm consists of two phases, seeding and extending. In the seeding phase, a read uses its substrings of various lengths, called seeds, to find candidate alignment positions on the reference genome. In the extending phase, each seed is extended leftward and/or rightward to both ends of the read via a two-dimension dynamic programming algorithm, the  Smith-Waterman (S-W) algorithm <ref type="bibr" target="#b19">[19]</ref>. In this paper we focus on the extending phase of CS-BWAMEM (since it is more time-consuming) and present the integration process of CS-BWAMEM and a S-W FPGA accelerator.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">FPGA Acceleration for S-W Algorithm</head><p>FPGA acceleration for the S-W algorithm has attracted great attention in the past. Various approaches have been proposed and implemented and achieves over 100x speedup compared to CPU and even GPU based so-</p><formula xml:id="formula_0">lutions [21][3][5][2]</formula><p>. While the proposed accelerators show a great potential for accelerating the S-W computational kernel, FPGA researchers did not pay enough attention to the system-wide integration of the accelerators. In this paper we focus on the integration of the S-W accelerator in <ref type="bibr" target="#b5">[5]</ref> into the Spark-based CS-BWAMEM, where the FPGA accelerator achieves around 120x and 10.5x kernel-level speedup over the single-thread and 16-thread CPU in our experimental system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Experimental Setup</head><p>Our experimental system comprises a cluster of 1 master node and 6 worker nodes, as shown in <ref type="figure" target="#fig_0">Figure 1</ref>. Except for the master node of the Spark framework, all Spark's worker nodes are equipped with a PCIe-attached Alpha Data ADM-PCIE-7V3 FPGA board <ref type="bibr" target="#b0">[1]</ref>. <ref type="table" target="#tab_1">Table 1</ref> lists the detailed configuration of each server. Currently, we have only six FPGA boards available, which limits the cluster size. Nevertheless, it is sufficient to demonstrate our integration methodology and insights, which can be easily applied to larger clusters. We are planning to incorporate more FPGA boards into our cluster in the future. We use Spark 1.5.1 as our cluster computing framework and HDFS 2.5.2 as our underlying distributed file system, and run CS-BWAMEM 0.2.2 on top of them. As illustrated in <ref type="figure" target="#fig_0">Figure 1</ref>, each read is aligned by a CS-BWAMEM's map function that invokes the S-W kernel. Our test cases are derived from the genome sample of a human with breast cancer (HCC1954 <ref type="bibr" target="#b7">[7]</ref>). The sample contains almost 1 billion reads, each with 101 nucleotides (denoted by a 101-character ASCII string). The performance of DNA sequencing applications is often measured by the number of reads aligned in a unit of time. In this paper we use the notation of "kilo reads per second (KRPS)".</p><p>For convenience, we will denote the original CS-BWAMEM program as CS-BWAMEM/CPU, and the CS-BWAMEM program with the S-W accelerator as CS-BWAMEM/FPGA in the rest of this paper. CS-BWAMEM will be also used in the scenarios where both CS-BWAMEM/CPU and CS-BWAMEM/FPGA fit.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Challenges and Solutions 4.1 Harnessing FPGA in JVM</head><p>Spark programs are mainly written in Java and/or Scala, and run on JVMs. FPGA accelerators are typically manipulated by C/C++ programs, and JVMs do not support the use of FPGAs by default. Therefore, the first step of Spark-FPGA integration at the single-thread level is to bridge the gap between Java/Scala and C/C++.</p><p>While the Java Native Interface (JNI) serves as a standard tool to address this issue, it does not always deliver an efficient solution. In the singlethread scenario, we compare the performance of CS-BWAMEM/CPU and CS-BWAMEM/FPGA, and find that CS-BWAMEM/CPU achieves 2.1 KRPS (kilo reads per second) while CS-BWAMEM/FPGA, with the straightforward Spark-FPGA integration, reaches merely 1.6 RPS. In other words, the straightforward integration does not fulfill the 120x speedup, but instead decreases the overall performance by three orders of magnitude.</p><p>After an in-depth analysis, we find that the main reason for the performance degradation is the tremendous JVM-FPGA communication overhead aggregated through all the invocations of the S-W accelerator. To be specific, one read produces 24 S-W invocations (either software or hardware implementation) on average, and it takes about 480µs for the software to process them in JVM. That is, each S-W invocation of the software version should cost no more than 20µs on average. Meanwhile, a complete routine of a S-W accelerator invocation involves: 1) data copy between a JVM and a native machine, 2) DMA transfer between a native machine and an FPGA board though PCIe, and 3) computation on the FPGA board. The communication process, including 1) and 2), costs over 25ms per invocation. That is, even if an accelerator could reduce the computation time of the S-W kernel down to 0, the communication overhead would degrade the performance by 1000x.</p><p>The tremendous JVM-FPGA communication overhead has to be alleviated to make the Spark-FPGA integration work efficiently. In CS-BWAMEM/CPU, each </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S-W #1</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S-W #2</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S-W #3</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S-W #4</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S-W #1</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S-W #1</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S-W #2</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S-W #3</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S-W #4</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S-W #5</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S-W #6</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S-W #1</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S-W #2</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S-W #3</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S-W #4</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S-W #5</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S-W #6</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S-W #1</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S-W #2</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S-W #3</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S-W #1</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S-W #2</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S-W #3</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S-W #1</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S-W #2</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S-W #3</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S-W #4</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S-W #5</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S-W #6</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S-W #7</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S-W #8</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S-W Batch Read Batch</head><p>Dependency Chain of a read's S-W Tasks <ref type="figure">Figure 2</ref>: Batch processing in CS-BWAMEM S-W task has only 1-2KB input data and 20B output data. These small payloads result in an extremely low communication bandwidth utilization of both DRAM (from a JVM to a native machine) and PCIe (from a native machine to an FPGA). This phenomenon motivates our approach of batching a group of reads together and offloading them to the FPGA board at a time to improve the bandwidth utilization.</p><p>To make batch processing work, a fundamental condition is that there should be adequate independent tasks to process as a whole. A Spark MapReduce program inherently offers a massive degree of parallelism. All map function calls in a map stage are completely independent of each other. Therefore, it is both necessary and feasible to conduct batch processing for CS-BWAMEM. To be specific, we merge a certain number of CS-BWAMEM/FPGA's map tasks (derived from the straightforward integration) into a new map function, and conduct a series of code transformations to batch the S-W kernel invocations from different map tasks together.</p><p>However, there is a delicate issue in CS-BWAMEM that imposes challenges in the code transformation for batch processing, which is illustrated in <ref type="figure">Figure 2</ref>. First, a read generates N leftward/rightward extending tasks, indicating that a map function of CS-BWAMEM (before the code transformation for batch processing) needs to process N S-W tasks (a row in <ref type="figure">Figure 2</ref>), where N is highly varied for different reads. Moreover, all these S-W tasks generated in the same read are chain-dependent (a row in <ref type="figure">Figure 2</ref>) and thus cannot be batched together. Therefore, a batched map function has to consider multiple reads (rows) as a group and produce multiple S-W batches (each column a batch) for this group. To better hide the communication, only S-W batches (within reads) with batch size no less than a threshold (64 in our experiments) would be offloaded to the FPGA accelerator. All other smaller S-W batches are processed on CPU. <ref type="figure">Figure 3</ref> shows the performance of processing a set of reads in CS-BWAMEM/FPGA with different batch sizes (the number of reads in a batch), as well as the performance of CS-BWAMEM/CPU. We can see that the FPGA integration starts to outperform the CPU-only version when the read batch size reaches 16k. The performance continues to increase until the program runs <ref type="formula">1 2 4 8 1 6 3 2 6 4 1 2 8 2 5 6 5 1 2 1</ref>  (1) </p><formula xml:id="formula_1">v 1 = 1; while(!connect_to_host()) ; (2) send_buf_id(); while(!v 2 ) ; (4) read_results_from_buf(); free_buf();</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Sharing FPGAs Among Threads</head><p>Due to the high performance of FPGA accelerators, offloading a single-thread CPU workload onto the FPGA usually makes the FPGA underutilized, which leaves opportunities for FPGA accelerators to be shared by multiple threads in a single node. The major challenge is how to efficiently manage the FPGA accelerator resources among multiple CPU threads. To tackle this challenge, we propose an FPGA-as-a-Service (FaaS) framework and implement the FPGA management in a node-level accelerator manager.</p><p>The FaaS framework abstracts the FPGA accelerator and its management software on the CPU (called Accelerator Manager (AM)) as a server, and treats each CPU thread as a client. Client threads communicate with AM via a hybrid of JNI and network sockets. Different client threads send requests independently to the AM to accelerate S-W batches, and the AM processes the requests in a first-come-first-serve way. <ref type="figure" target="#fig_3">Figure 4</ref> describes the functionality and the detailed implementation of the FaaS framework.</p><p>In the single-thread version, CS-BWAMEM/FPGA's map functions have been modified into batched map functions. The S-W tasks from these map functions have also been reorganized into a series of S-W batches, which are sent through JNI to the native library that manipulates the FPGA accelerator. The FaaS framework extends the native library into AM, and extends the communication mechanism between the batched map function and AM as follows.</p><p>1. When a batched map function in a CPU thread needs to use the FPGA accelerator, it will first allocate a shared memory buffer and then send the input data from JVM to this buffer through JNI. 2. The batched map function sends a request to AM through a socket to use the accelerator. The request contains only the address of the shared buffer created in Step 1, thus generating negligible overhead. 3. If the accelerator is available, it will be locked and start to process the S-W batch; otherwise, the batched map function waits in a spin loop until it successfully gets permission to use the accelerator. 4. After the accelerator completes the current S-W batch, it will write the output data back to the shared memory buffer created in Step 1, and become available again to accept another request. <ref type="figure" target="#fig_4">Figure 5</ref> shows the performance comparison between CS-BWAMEM/CPU and CS-BWAMEM/FPGA with different number of CPU threads. We can see that the speedup of FPGA-equipped system over the CPU-only system slightly decreases from about 4x (single-thread) to 3x (16 hyper-threads) due largely to thread contention, but still maintains a decent speedup. The performance of CS-BWAMEM/FPGA starts to decrease when 20 hyperthreads share the FPGA board. Meanwhile, the performance of CS-BWAMEM/CPU sightly decreases at this point as well, which indicates that hyper-threading does not always help performance improvement for CS-BWAMEM. Therefore, we will use 16 hyper-threads per CPU throughout this paper since it achieves the best performance for both CS-BWAMEM/CPU and CS-BWAMEM/FPGA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Scaling FPGAs into Cluster Scale</head><p>Finally, we address challenges when scaling FPGA integration into cluster scale. Based on our case study, when a computational kernel is inside a map function of a Spark MapReduce program, the inter-node communica- tion will be completely independent of the FPGA board in each server. That is, Spark application developers who wants to harness the power of FPGA accelerators for computational kernels residing in map functions merely need to consider up to the single-node multi-thread level.</p><p>Overall Performance and Power. After overcoming all the challenges at various levels, now we have an efficient integration of CS-BWAMEM/ FPGA. As shown in <ref type="figure">Figure 6</ref>, the performance of Spark-FPGA integration scales well with one to six worker nodes, where each node runs 16 threads. Through the efficient integration of FPGA accelerators, CS-BWAMEM/FPGA improves the overall system performance of a 6-worker cluster by 2.6x, compared to CS-BWAMEM/CPU. Under the same configuration, CS-BWAMEM/FPGA consumes only 8% additional power per worker node. That is, CS-BWAMEM/FPGA achieves 2.4x energy efficiency improvement and 2.6x performance speedup. This result goes along with Microsoft's findings for the ranking stage of the Bing search engine where the performance is improved by 2x while consuming 10% more power per server. It is quite promising that FPGAs can greatly improve performance and energy efficiency in datacenters.</p><p>Analysis of Communication Overhead. To better demonstrate the effectiveness of FPGA acceleration, we present the detailed execution time breakdown (normalized to the CS-BWAMEM/CPU baseline) of our 6-worker Spark-FPGA system in <ref type="figure" target="#fig_5">Figure 7</ref>. The upper bar illustrates that the S-W accelerator targets at 86% of the overall execution time, where the rest 14% of time mainly involves Spark's task scheduling and the S-W tasks that are processed on CPU. As shown in the lower bar, the S-W accelerator reduces the acceleratable part (86%) to 8% while paying a 16% communication overhead. The communication between the Spark program and AM through JNI introduces 5% overhead, and the communication between AM and the FPGA accelerator through PCIe introduces another 11% overhead. The existence of the above communication overhead reduces the overall system speedup to 2.6x. We can see that there is still room to improve the overall performance if FPGA fabric can be brought closer to CPU so as to further reduce the CPU-FPGA communication overhead.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Lessons Learned and Open Discussion</head><p>This paper presented an in-depth analysis of challenges and corresponding solutions when integrating FPGA accelerators into Spark at single-thread, single-node multithread, and multi-node levels. Using the next-generation DNA sequencing application CS-BWAMEM and its Smith-Waterman accelerator integration as a case study, we demonstrated how we turned a 1000x slowdown of the straightforward integration into an efficient integration with 2.6x system-wide performance improvement, at the cost of consuming only 8% more power.</p><p>We summarize some lessons we learned and discuss some open topics as below.</p><p>1. By decoupling the design and implementation of the FPGA accelerator and scale-out software, it is feasible to efficiently integrate existing FPGA accelerators into MapReduce programs with affordable programming efforts. Our case study shows that an over 2x speedup and energy efficiency can be achieved with modest code transformations. 2. It is important to generalize the FaaS framework to automatically manage and share FPGA accelerators in the Spark-FPGA integration. There are also research opportunities to further extend it to a generic accelerator management framework that harnesses a variety of heterogeneous devices, such as GPUs, FPGAs and even ASICs. At UCLA, we are developing a runtime system called Blaze <ref type="bibr" target="#b9">[9]</ref>[11] that extends Spark to enable automatic FPGA and GPU accelerator sharing among threads, as well as task pipelining to alleviate JVM-FPGA communication overhead. 3. The JVM-FPGA communication overhead appears as a primary performance bottleneck in Spark-FPGA integration. Worse still, one of our future studies, DNA sequencing acceleration on a Spark-GPU-FPGA cluster, also demonstrates the same issue on the GPU side. Batch processing alleviates this overhead to some extent, but it is not always trivial to transform a given MapReduce program into a batched style. It could be greatly helpful if batching-oriented programming model extensions or (semi)-automated code transformation tools could be proposed for MapReduce.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: An overview of the Spark-FPGA cluster</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Figure 3: Performance under different read batch sizes</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: FPGA as a Service (FaaS) framework out of memory, where the batch size exceeds 512k. With the batch size of 512k, CS-BWAMEM/FPGA achieves around 8 KRPS and is around 4x faster than CS-BWAMEM/CPU in the single-thread case.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Performance under different number of threads</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 7 :</head><label>7</label><figDesc>Figure 6: Performance under different number of nodes CS-BWAMEM/CPU</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="true"><head>Table 1 : Experimental setup</head><label>1</label><figDesc></figDesc><table>Host CPU 
two 6-core Xeon E5-2620v3@2.40GHz 
Host Memory 
48GB DDR3-1600 
FPGA Fabric 
Xilinx Virtex 7@200MHz 
CPU ↔ FPGA 
PCIe Gen3 x8, 8GB/s as advertised 
FPGA Device Memory 
16GB DDR3-1600 
Development Environment 
SDAccel 2015.1.5 

</table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work was supported in part by C-FAR, one of the six SRC STARnet Centers, sponsored by MARCO and DARPA, and by NSF/Intel Innovation Transition Grant awarded to the Center for Domain-Specific Computing.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alpha</forename><surname>Data</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adm-Pcie-7v3</forename><surname>Datasheet</surname></persName>
		</author>
		<ptr target="http://www.alpha-data.com/pdfs/adm-pcie-7v3.pdf" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Heterogeneous hardware/software acceleration of the BWA-MEM DNA alignment algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmed</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Sima</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V.-M</forename><surname>Houtgast</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Bertels</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Al-Ars</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/ACM International Conference on Computer-Aided Design</title>
		<meeting>the IEEE/ACM International Conference on Computer-Aided Design<address><addrLine>Piscataway, NJ, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Press</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="240" to="246" />
		</imprint>
	</monogr>
	<note>ICCAD &apos;15</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Hardware acceleration of genetic sequence alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arram</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tsoi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Luk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Reconfigurable Computing: Architectures, Tools and Applications</title>
		<editor>P. Brisk, J. de Figueiredo Coutinho, and P. Diniz</editor>
		<imprint>
			<biblScope unit="volume">7806</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heidelberg</forename><surname>Springer Berlin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="13" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">IBM Data Engine for NoSQL -Power Systems Edition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brech</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Rubio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hollinger</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
		<respStmt>
			<orgName>IBM Systems Group</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Tech. rep</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A novel high-throughput acceleration engine for read alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-T</forename><surname>Cong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Field-Programmable Custom Computing Machines (FCCM)</title>
		<imprint>
			<date type="published" when="2015-05" />
			<biblScope unit="page" from="199" to="202" />
		</imprint>
	</monogr>
	<note>IEEE 23rd Annual International Symposium on</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A fast and scalable read aligner at the cloud scale for whole genome sequencing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-T</forename><surname>Cong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Peto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Spellman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhou</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cs-Bwamem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">High Throughput Sequencing Algorithms and Applications (HITSEQ)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Characterization of paired tumor and non-tumor cell lines established from patients with breast cancer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gazdar</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">F</forename><surname>Kurvari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Virmani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gollahon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Sakaguchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wester-Field</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kodagoda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Stasny</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Cun-Ningham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">T</forename><surname>Wistuba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">I</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">T</forename><surname>Al</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of cancer</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="page" from="766" to="774" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Motivating the design of a distributed, heterogeneous programming system with machine-learning applications. Parallel and Distributed Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grossman</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Breternitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sarkar</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Hadoopcl2</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on PP</title>
		<imprint>
			<biblScope unit="page" from="1" to="1" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Deploying accelerators at datacenter scale using Spark</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">U</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Spark Summit</title>
		<imprint>
			<biblScope unit="page">2016</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Intel-Altera heterogeneous architecture research platform (HARP) program</title>
		<ptr target="http://www.sigarch.org/2015/01/17/call-for-proposals-intel-altera-heterogeneous-architecture-research-platform-program/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Cong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">W C H</forename><surname>Muhuan Huang</surname></persName>
		</author>
		<title level="m">Heterogeneous datacenters: Options and opportunities. Design Automation Conference</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Fast gapped-read alignment with Bowtie 2</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Langmead</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salzberg</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">L</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature methods</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="357" to="359" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Fast and accurate short read alignment with burrows-wheeler transform</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">I</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Durbin</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="1754" to="1760" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">HeteroSpark: A Heterogeneous CPU/GPU Spark Platform for Deep Learning Algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">I</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luo</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Spark Summit</title>
		<imprint>
			<biblScope unit="page">2015</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The Genome Analysis Toolkit: a MapReduce framework for analyzing next-generation DNA sequencing data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mckenna</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hanna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Banks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Sivachenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cibulskis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kernyt-Sky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Garimella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Altshuler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gabriel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Daly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">T</forename><surname>Al</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome research</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="1297" to="1303" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Rethinking dataintensive science using scalable analytics systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nothaft</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">A</forename><surname>Massie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Danford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Laserson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Yeksigian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kottalam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ahuja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hammerbacher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Linderman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Franklin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">D</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patterson</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data</title>
		<meeting>the 2015 ACM SIGMOD International Conference on Management of Data<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="631" to="646" />
		</imprint>
	</monogr>
	<note>SIGMOD &apos;15, ACM</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A reconfigurable fabric for accelerating large-scale datacenter services</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Putnam</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Caulfield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chung</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">S</forename><surname>Chiou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Constantinides</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Demme</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Esmaeilzadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fowers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gopal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">P</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">T</forename><surname>Al</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceeding of the 41st Annual International Symposium on Computer Architecuture</title>
		<meeting>eeding of the 41st Annual International Symposium on Computer Architecuture</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="13" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Next-generation DNA sequencing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shendure</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">I</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature biotechnology</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="1135" to="1145" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Identification of common molecular subsequences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Smith</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Waterman</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Molecular Biology</title>
		<imprint>
			<biblScope unit="volume">147</biblScope>
			<biblScope unit="page" from="195" to="197" />
			<date type="published" when="1981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Resilient Distributed Datasets: A Fault-tolerant Abstraction for In-memory Cluster Computing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zaharia</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chowdhury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Dave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mccauley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Franklin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Shenker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stoica</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th USENIX Conference on Networked Systems Design and Implementation</title>
		<meeting>the 9th USENIX Conference on Networked Systems Design and Implementation</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="2" to="2" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Implementation of the Smith-Waterman Algorithm on a Reconfigurable Supercomputing Platform</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gao</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">R</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st International Workshop on High-performance Reconfigurable Computing Technology and Applications</title>
		<meeting>the 1st International Workshop on High-performance Reconfigurable Computing Technology and Applications</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="39" to="48" />
		</imprint>
	</monogr>
	<note>HPRCTA &apos;07, ACM</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
