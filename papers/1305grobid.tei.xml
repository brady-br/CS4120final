<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2020-10-01T14:47+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Conceptual Partitioning: An Efficient Method for Continuous Nearest Neighbor Monitoring</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyriakos</forename><surname>Mouratidis</surname></persName>
							<email>kyriakos@cs.ust.hk</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marios</forename><surname>Hadjieleftheriou</surname></persName>
							<email>marioh@cs.bu.edu</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Boston University</orgName>
								<address>
									<settlement>Boston</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitris</forename><surname>Papadias</surname></persName>
							<email>dimitris@cs.ust.hk</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Hong Kong University of Science and Technology Clear Water Bay</orgName>
								<address>
									<settlement>Hong Kong</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Conceptual Partitioning: An Efficient Method for Continuous Nearest Neighbor Monitoring</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Given a set of objects P and a query point q, a k nearest neighbor (k-NN) query retrieves the k objects in P that lie closest to q. Even though the problem is well-studied for static datasets, the traditional methods do not extend to highly dynamic environments where multiple continuous queries require real-time results, and both objects and queries receive frequent location updates. In this paper we propose conceptual partitioning (CPM), a comprehensive technique for the efficient monitoring of continuous NN queries. CPM achieves low running time by handling location updates only from objects that fall in the vicinity of some query (and ignoring the rest). It can be used with multiple, static or moving queries, and it does not make any assumptions about the object moving patterns. We analyze the performance of CPM and show that it outperforms the current state-of-the-art algorithms for all problem settings. Finally, we extend our framework to aggregate NN (ANN) queries, which monitor the data objects that minimize the aggregate distance with respect to a set of query points (e.g., the objects with the minimum sum of distances to all query points).</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Early work in spatial databases focused on the point k-NN query that retrieves the k (≥1) objects from a static dataset that are closest (according to Euclidean distance) to a static query point. The existing algorithms (e.g., <ref type="bibr">[H84, RKV95, HS99]</ref>) consider that the data are indexed with a spatial access method and utilize some pruning bounds to restrict the search space. In addition, several papers study variations of NN search such as reverse NNs <ref type="bibr">[SRAA01]</ref> and constrained NNs <ref type="bibr">[FSAA01]</ref>. Recently, the focus has shifted towards moving NN queries and/or objects in clientserver architectures. Song and Roussopoulos <ref type="bibr">[SR01]</ref> reduce the number of moving NN queries over static objects by introducing some redundancy. In particular, when a k-NN query is processed, the server sends to the client a number m &gt; k of neighbors. The k nearest neighbors at a new location q' will be among the m objects of the first query q provided that the distance between q and q' is within a range determined by k and m. For the same settings (moving query -static data objects), Zhang et al. <ref type="bibr">[ZZP+03]</ref> propose the concept of location-based queries that return the NN of q along with its Voronoi cell, i.e., the area around the query point where the NN set remains the same. The Voronoi cell is computed on-the-fly using an R-tree on the data objects. Given clients and data objects that move with linear and known velocities, time-parameterized [TP03] queries report, in addition to the current NN set, its validity period and the next change of the result (that will occur at the end of the validity period). Linear NN <ref type="bibr">[BJKS02, TP03]</ref> queries return all NN sets up to a future timestamp q t assuming that there are no updates of the velocity vectors between the current time and q t . All the above techniques target the efficient processing of a single snapshot query since they report the NN set at the query time, possibly with some validity information (e.g., expiry time, Voronoi cell), or generate future results based on predictive features (e.g., velocity vectors of queries or data objects). On the other hand, continuous monitoring: (i) involves multiple longrunning queries (from geographically distributed clients), (ii) is concerned with both computing and keeping the results up to date, (iii) usually assumes main-memory processing to cope with the intensive (object or query) location updates, (iv) attempts to minimize factors such as the CPU or communication cost (as opposed to I/O overhead). Continuous monitoring of spatial queries is becoming increasingly important due to the wide availability of inexpensive and compact positioning devices, the evolution of mobile communications and the need for improved location-based services. Consequently, several techniques (reviewed in Section 2) have been developed in the last few years for continuous range and NN queries. In this paper, we propose the conceptual partitioning monitoring (CPM) method for NN queries in highly dynamic environments. The data objects are indexed by a main-memory grid G consisting of cells with size δ×δ (assuming two-dimensional space). Each cell c in the grid is associated with the list of objects residing therein. The running queries are stored along with their current result in a query table QT. When a query q arrives at the system, its initial result is computed by the NN search module of CPM. CPM organizes the cells into (hyper) rectangles based on their proximity to q. This conceptual partitioning provides a natural processing order of the cells in G, so that the NN search considers the minimal set of cells in order to retrieve the NNs of q. We refer to the set of encountered cells as the influence region of q. The next task of CPM is to monitor the results of the queries upon the arrival of object updates. Clearly, only updates affecting the influence region of a query can potentially invalidate its current result. To restrict processing to such updates and to efficiently compute the changes in the results, we maintain book-keeping information in the object index and the query table. We also show that it is often possible to compute the new result of an affected query among the objects that issue updates, without searching in</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">RELATED WORK</head><p>The first monitoring method for spatial queries, called Q-index <ref type="bibr">[PXK+02]</ref>, assumes static range queries over moving objects. The queries are indexed by an R-tree and moving objects probe the index to find the queries that they influence. Q-index avoids the expensive (due to intensive updates) maintenance of an index on the objects. In addition, it utilizes the concept of safe regions to reduce the number of updates. In particular, each object p is assigned a circular or rectangular region, such that p needs to issue an update only if it exits this area (otherwise, it does not influence the result of any query). MQM <ref type="bibr">[CHC04]</ref>, another range monitoring method, partitions the workspace into rectangular subdomains. Each object in the system is assigned a resident domain, consisting of adjacent sub-domains. An object is aware only of the range queries intersecting its resident region, and reports its location to the server when it crosses the boundary of any of these queries. The number of sub-domains that form an object's resident region depends on how many queries it can store and process concurrently. When an object exits its resident region, it requests a new one from the server. To decide the new resident region, the server uses a binary partitioning tree, which maintains for each sub-division of the workspace the queries that intersect it. This method applies only to static ranges. To deal with moving range queries, Gedik and Liu <ref type="bibr">[GL04]</ref> propose another distributed system, called Mobieyes. Mobieyes partitions the workspace using a grid and maintains the monitoring regions of the queries. The monitoring region of a query is defined as the union of the grid cells it can potentially intersect, provided that its center remains within its current cell. Objects falling in the monitoring region of a query receive information about the query position and velocity, and notify the server when they enter or leave the predicted query region. Note that this way the objects store locally and monitor their spatial relationship only with queries that they might actually affect when they move, saving their limited storage and processing resources. On the other hand, queries issue updates to the server when they change velocity vector, or when they move out of their current cell. <ref type="bibr">Mokbel et al. [MXA04]</ref> present SINA, a system that centrally processes continuous range queries over mobile data. SINA is based on shared execution and incremental evaluation. Shared execution is achieved by implementing query evaluation as a spatial join between the objects and the queries. Incremental evaluation implies that the query processor computes only the updates of the previously reported answers, as opposed to reevaluating the queries from scratch. The result updates are either positive or negative. The former category corresponds to objects entering the range of a query, while the latter one to objects leaving a range. Both the object and the query indexes are implemented as disk-resident regular grids. Let U P and U q be the set of objects and queries that issue location updates since the previous evaluation cycle. Processing begins with the hashing phase that joins U P and U q in-memory to produce positive updates. Next, the invalidation phase generates negative updates for objects in U P that move out of their current cell and queries in U q that exit cells that they used to overlap with. Finally, movement within the same cell is handled in the joining phase; for each cell that contains objects in U P or intersects queries in U q , SINA joins the new objects with the existing queries, and the new queries with the static objects. The resulting updates are merged with the updates of the previous phases (potentially canceling out some of them), and are reported to the client. All the aforementioned methods focus on range query monitoring, and their extension to NN queries is either impossible or nontrivial. Henceforth, we discuss algorithms that target explicitly NN processing. <ref type="bibr">Koudas et al. [KOTZ04]</ref> describe DISC, a technique for e-approximate k-NN queries over streams of multidimensional points. The returned k th NN lies at most e distance units farther from q than the actual k th NN of q. DISC partitions the space with a regular grid of granularity such that the maximum distance between any pair of points in a cell is at most e. To avoid keeping all arriving data in the system, for each cell c it maintains only K points falling therein and discards the rest. It is proven that an exact k-NN search in the retained points corresponds to a valid ek-NN answer over the original dataset provided that k≤K. DISC indexes the data points with a B-tree that uses a space-filling curve mechanism to facilitate fast updates and query processing. The authors show how to adjust the index to: (i) use the minimum amount of memory in order to guarantee a given error bound e, or (ii) achieve the best possible accuracy, given a fixed amount of memory. DISC can process both snapshot and continuous ek-NN queries. <ref type="bibr">Yu et al. [YPK05]</ref> propose a method, hereafter referred to as YPK-CNN 1 , for continuous monitoring of exact k-NN queries.</p><p>Objects are assumed to fit in main memory and are indexed with a regular grid of cells with size δ×δ. YPK-CNN does not process updates as they arrive, but directly applies the changes to the grid. Each NN query installed in the system is re-evaluated every T time units. When a query q is evaluated for the first time, a twostep NN search technique retrieves its result. The initial step visits the cells in a square R around the cell c q covering q until k objects are found. <ref type="figure">Figure 2</ref>.1a, shows an example of a single NN query where the first candidate NN is p 1 with distance d from q; p 1 is not necessarily the actual NN since there may be objects (e.g., p 2 ) in cells outside R with distance smaller than d. To retrieve such objects, the second step searches in the cells intersecting the square SR centered at c q with side length 2⋅d+δ, and determines the actual k NN set of q therein. In <ref type="figure">Figure 2</ref>.1a, YPK-CNN processes p 1 up to p 6 and returns p 2 as the actual NN. The accessed cells appear shaded. When re-evaluating an existing query q, YPK-CNN makes use of its previous result in order to restrict the search space. In particular, it computes the maximum distance d max of the current locations of the previous NNs (i.e., d max is the distance of the previous neighbor that moved furthest). The new SR is a square centered at c q with side length 2⋅d max +δ. In <ref type="figure">Figure 2</ref>.1b, assume that the current NN p 2 of q moves to location p′ 2 . Then, the rectangle defined by d max = dist(p′ 2 ,q) is guaranteed to contain at least one object (i.e., p 2 ). YPK-CNN collects all objects (p 1 up to p 10 ) in the cells intersecting SR and identifies the new NN p 1 . Finally, when a query q changes location, it is handled as a new one (i.e., its NN set is computed from scratch). Yu et al. also discuss the application of YPK-CNN with a hierarchical grid that improves performance for highly skewed data. SEA-CNN [XMA05] focuses exclusively on monitoring the NN changes, without including a module for the first-time evaluation of an arriving query q (i.e., it assumes that the initial result is available). Objects are stored in secondary memory, indexed with a regular grid. The answer region of a query q is defined as the circle with center q and radius best_dist, where best_dist is the distance of the current k th NN. Book-keeping information is stored in the cells that intersect the answer region of q to indicate this fact. When updates arrive at the system, depending on which cells they affect and whether these cells intersect the answer region of the query, SEA-CNN determines a circular search region SR around q, and computes the new k NN set of q therein. To determine the radius r of SR, the algorithm distinguishes the following cases: (i) If some of the current NNs move within the answer region or some outer objects enter the answer region, SEA-CNN sets r=best_dist and processes all objects falling in the answer region in order to retrieve the new NN set. (ii) If any of the current NNs moves out of the answer region, processing is similar to YPK-CNN; i.e., r = d max (where d max is the distance of the previous NN that moved furthest from q), and the NN set is computed among the objects lying in SR. Assume that in <ref type="figure">Figure  2</ref>.2a the current NN p 2 issues an update reporting its new location p′ 2 . SEA-CNN sets r=d max =dist(p′ 2 ,q), determines the cells intersecting SR (these cells appear shaded), collects the corresponding objects (p 1 up to p 10 ), and retrieves the new NN p 1 . (iii) Finally, if the query q moves to a new location q′, then SEA-CNN sets r = best_dist+dist(q,q′), and computes the new k NN set of q by processing all the objects that lie in the circle centered at q′ with radius r. For instance, in <ref type="figure">Figure 2</ref>.2b the algorithm considers the objects falling in the shaded cells (i.e., objects from p 1 up to p 10 except for p <ref type="bibr">7</ref> and p 9 ) in order to retrieve the new NN (p 5 ).  <ref type="table" target="#tab_2">Table 2</ref>.1 summarizes the properties of existing methods for monitoring spatial queries. The processing type refers to whether mobile objects have some computing capabilities, or the entire processing cycle takes place in a central server. For instance, Qindex is classified as a distributed method since the objects decide whether they exit their safe regions before they issue an update. On the other hand, SINA follows a centralized paradigm since each object issues an update whenever it moves, independently of whether it influences any query or not. In summary, the only existing techniques applicable to continuous monitoring of exact k-NN queries are YPK-CNN and SEA-CNN. Similar to these methods CPM also assumes centralized processing (in main memory 2 ). We compare CPM against YPK-CNN and SEA-CNN both qualitatively (in Section 4) and experimentally (in Section 6). In the next section, we present CPM in detail.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">CONCEPTUAL PARTITIONING MONITORING</head><p>In accordance with real-world scenarios, we assume 2D 3 data objects and queries that change their location frequently and in an unpredictable manner. An update from object p is a tuple &lt;p.id, x old , y old , x new , y new &gt;, implying that p moves from (x old , y old ) to (x new , y new ). A central server receives the update stream and continuously monitors the k NNs of each query q installed in the system. Similar to existing approaches (e.g., YPK-CNN, SEA-CNN), we use a grid index since a more complicated datastructure (e.g., main memory R-tree) would be very expensive to maintain dynamically. The extent of each cell on every dimension is δ, so that the cell c i,j at column i and row j (starting from the low-left corner of the data space) contains all objects with x coordinate in the range [i⋅δ, (i+1)⋅δ) and y co-ordinate in the range [j⋅δ, (j+1)⋅δ). Conversely, an object with co-ordinates (x,y) belongs to the cell c i,j , where i= ⎣x/δ⎦ and j= ⎣y/δ⎦. CPM (and SEA-CNN) can also be applied with the hierarchical grid of <ref type="bibr">[YPK05]</ref>. Section 3.1 describes the NN computation algorithm, which constitutes the core module of CPM. Then, Sections 3.2 and 3.3 discuss the handling of location updates. The query point c q</p><p>The cell containing q n</p><p>The number of queries installed in the system dist(p,q)</p><p>Euclidean distance from object p to query point q best_NN</p><p>The best NN list of q best_dist</p><p>The distance of the k th NN from q mindist <ref type="bibr">(c,q)</ref> Minimum distance between cell c and query point q <ref type="table" target="#tab_3">Table 3</ref>.1: Frequently used symbols and functions</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">The NN computation module of CPM</head><p>Given a cell c and a query q, mindist(c,q) is the minimum possible distance between any object p∈c and q. Let best_NN be the list of the k best NNs (of q) found so far, and best_dist be the distance of the k th of them. If mindist(c,q)≥best_dist, we can safely prune c because it cannot contain any object lying closer to q than any of the current NNs. Based on this observation, a naive way to process a NN query q in P, is to sort all cells c∈G according to mindist(c,q), and visit them in ascending mindist(c,q) order. For each considered cell, we compute dist(p,q) for the objects p inside, and update accordingly the best_NN list. The search terminates when the cell c under consideration has mindist(c,q) ≥ best_dist. <ref type="figure">Figure 3</ref>.1a illustrates this process for a 1-NN query q. The algorithm visits only the shaded cells and encounters in total two objects, p 1 and p 2 . Between them, p 2 is returned as the result of the query. It can be easily shown that the above algorithm processes only the cells that intersect the circle centered at q with radius equal to the distance between q and its k th NN. These cells have to be visited anyway in order to avoid false misses; therefore, the naïve algorithm is optimal in terms of the number of processed cells. Nevertheless, in practice it may be very expensive, since it requires computing the mindist for all cells and subsequently sorting them. CPM overcomes this problem and avoids unnecessary computations by utilizing a conceptual space partitioning. Each rectangle rect is defined by a direction and a level number. The direction could be U, D, L, or R (for up, down, left and right) depending on the relative position of rect with respect to q. The level number indicates the number of rectangles between rect and c q . Lemma 3.1 regulates the visiting order among rectangles of the same direction. Lemma 3.1: For rectangles DIR j and DIR j+1 of the same direction DIR with level numbers j and j+1, respectively, it holds that mindist(DIR j+1 ,q) = mindist(DIR j ,q) + δ.</p><p>Proof: Without loss of generality, assume that the direction is D. The minimum distance of q from either rectangle equals the length of its projection on the top edge of the rectangle. Since the side length of the cells is δ, it follows that mindist(DIR j+1 ,q) = mindist(DIR j ,q) + δ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>񮽙</head><p>Based on Lemma 3.1, the NN computation module of CPM visits cells in ascending mindist(c,q) order, thus, preserving the property of processing the minimal set of cells. In particular, CPM initializes an empty heap H and inserts (i) the cell c q with key mindist(c q ,q)=0, and (ii) the level zero rectangles for each direction DIR, with key mindist(DIR 0 ,q). Then, it starts deheaping entries iteratively. If the de-heaped entry is a cell, it examines the objects inside and updates accordingly the best_NN. If the de-heaped entry is a rectangle DIR lvl , it inserts into H (i) each cell c∈DIR lvl with key mindist(c,q) and (ii) the next level rectangle DIR lvl+1 with key mindist(DIR lvl+1 ,q) = mindist(DIR lvl ,q) +δ. The algorithm terminates when the next entry in H (corresponding either to a cell or a rectangle) has key greater than or equal to best_dist. Proof of correctness: Let best_NN be the list of NNs returned by the algorithm, and best_dist be the distance of the k th NN. Clearly, all cells c inserted at some point into H do not contain any better NN than the objects in best_NN. This is guaranteed by the sorting property of the heap and the fact that dist(p,q) ≥ mindist(c,q) holds ∀p∈c. In order to prove correctness, it suffices to show that each cell that was not inserted into H cannot contain any object closer to q than best_dist. This part of the proof is based on the observation that, at any point, the heap H contains exactly four rectangle entries, one for each direction. We call these rectangles boundary boxes. Let the boundary box of direction DIR be DIR lvl . The algorithm has considered all cells falling into rectangles DIR i with i&lt;lvl. From Lemma 3.1 it follows that all cells c belonging to DIR i with i&gt;lvl have mindist(c,q)&gt;mindist(DIR lvl ,q). Since mindist(DIR lvl ,q) ≥ best_dist for each boundary box DIR lvl , and since all the unexplored space falls in some rectangle of some direction DIR with level greater than lvl, best_NN is the correct result of q. 񮽙 In the example of <ref type="figure">Figure 3</ref>.2a, CPM initially inserts into the heap the cell c q = c 4,4 and the rectangles of level zero, i.e., H = {&lt;c 4,4 ,0&gt;, &lt;U 0 ,0.1&gt;, &lt;L 0 ,0.2&gt;, &lt;R 0 ,0.8&gt;, &lt;D 0 ,0.9&gt;} (the numbers indicate mindist assuming that δ=1). Then it de-heaps c 4,4 , which is empty 4 and ignored. The next entry in H is U 0 . CPM en-heaps the cells of U 0 , as well as rectangle U 1 and proceeds in the same way until it de-heaps &lt;c 3,3 ,1&gt;, where it finds the first candidate NN p 1 with best_dist=dist(p 1 ,q)=1.7. Since, the next entry in H has key less than best_dist, it continues until it de-heaps c 2,4 and discovers the new candidate p 2 , with best_dist = dist(p 2 ,q) = 1.3. The algorithm terminates (with p 2 as the NN) when the top heap entry is c 5,6 because mindist(c 5,6 ,q) ≥best_dist. The final point that requires clarification concerns the bookkeeping information and related structures maintained for efficient search and handling of updates (to be discussed shortly). CPM keeps (in main memory) a query table QT that stores for each query, its co-ordinates, the current result, the best_dist, the visit list, and the search heap H:</p><p>• best_dist determines the influence region of q, i.e., the set of cells that intersect the circle centered at q with radius best_dist. Only updates affecting these cells can influence the NN result.</p><p>• The visit list of q consists of all cells c processed during NN search, sorted on mindist(c,q). Each cell entry de-heaped from H is inserted at the end of the list. In our example, the visit list of q contains the shaded cells in <ref type="figure">Figure 3</ref>.2a.</p><p>• The search heap H contains the cell and rectangle entries that were en-heaped, but not de-heaped during NN search (i.e., their mindist from q is greater than or equal to best_dist). The contents of H in our example are the shaded cells in <ref type="figure">Figure 3</ref>.2b, plus the four boundary boxes U 2 , D 1 , L 2 , and R 1 .</p><p>In addition, each cell c of the grid is associated with (i) the list of data objects within its extents, and (ii) the list of queries whose influence region contains c. For example, cell c 3,3 contains q in its influence list, while c 5,6 does not. <ref type="table">The structures of the query  table and the object grid</ref>  Upon termination, the heap H is also stored in QT. The algorithm is optimal in the sense that it processes the minimal set of cells for retrieving the NN set of q. As opposed to the naïve algorithm discussed in the beginning of the section, the only redundant mindist computations concern the cells that were en-heaped but not de-heaped (i.e., the shaded cells in <ref type="figure">Figure 3.</ref> Get the next entry of H 9.</p><p>If it is a cell entry &lt;c, mindist(c,q)&gt; 10.</p><p>For each object p∈c, update best_NN &amp; best_dist if necessary 11.</p><p>Insert an entry for q into the influence list of c 12.</p><p>Insert &lt;c, mindist(c,q)&gt; at the end of visit_list 13. Else // it is a rectangle entry &lt;DIR lvl , mindist(DIR lvl ,q)&gt; 14.</p><p>For each cell c in DIR lvl 15.</p><p>Insert &lt;c, mindist(c,q)&gt; into H 16.</p><p>Insert &lt;DIR lvl+1 , mindist(DIR lvl ,q)+δ&gt; into H 17. Until the next entry has key ≥ best_dist or H is empty 18. Update the influence region information of q to &lt;q, best_dist&gt; </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Handling a single object update</head><p>Assume, for simplicity, that a single update from p∈P arrives at a time. The first step is to delete p from its old cell c old . CPM scans the influence list of c old and identifies the queries that contain p in their best_NN set. Specifically, for each query q (in the influence list of c old ), if p∈q.best_NN and dist(p,q) ≤ best_dist, then the k NN set of q remains the same, but the order of the NNs can potentially change. Therefore, CPM updates the order in q.best_NN to reflect the new dist(p,q). On the other hand, if p∈q.best_NN and dist(p,q) &gt; best_dist (i.e., p is a NN that has moved farther from q than best_dist), there may exist objects (not in q.best_NN) that lie closer to q than p; thus, q is marked as affected to indicate this fact and ignored for now. Next, CPM inserts p into its new cell c new , and scans the influence list of c new . For each entry q therein, if q has been marked as affected it ignores it. Otherwise, if dist(p,q) &lt; q.best_dist, it evicts the current k th NN from the result, inserts p into q.best_NN, and updates q.best_dist. The last step re-computes the NN set of every query q that is marked as affected. <ref type="figure">Figure 3</ref>.5a illustrates update handling, assuming that object p 4 moves to position p' <ref type="bibr">4</ref> . CPM first deletes p 4 from the object list of c 5,6 , which has an empty influence list and, hence, the deletion does not affect any result. Next, it inserts p 4 into its new cell c 5,3 , whose influence list contains an entry for q. Since dist(p' 4 ,q) &gt; best_dist, update handling terminates without any change in the result. Assume that, later on, object p 2 moves to a new position p' 2 , as shown in <ref type="figure">Figure 3</ref>.5b. Since the old cell c 2,4 contains q in its influence list, CPM checks the query table entry for q and detects that p 2 = best_NN. Query q is marked as affected because dist(p' 2 ,q) &gt; best_dist.  Get the next element &lt;c, mindist(c,q)&gt; of visit_list 4.</p><p>For each object p∈c, update best_NN &amp; best_dist if necessary 5.</p><p>Insert an entry for q into the influence list of c 6. Until the next element has key ≥ best_dist or visit_list is empty 7. If the first entry in H has key &lt; best_dist 8.</p><p>(Same as lines 7-17 of <ref type="figure">Figure 3</ref>.4) 9. Set influence region information of q to &lt;q, best_dist&gt; </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Handling multiple updates</head><p>So far we have dealt with processing a single update. However, in the general case, there is a set U P of object updates that arrive during the time interval between two consecutive update handling cycles. Processing incrementally each update in U P , as discussed in Section 3.2, guarantees correctness of the result. However, this can be improved upon. Consider the example of <ref type="figure">Figure 3</ref>.7a, where U P contains location updates for p 2 and p 3 . If p 2 is processed first, q will be marked as affected (p 2 is the current NN and moves farther than best_dist), triggering the NN recomputation module. This, however, is unnecessary because object p 3 moves closer to q than the previous best_dist, and we could simply replace the outgoing NN p 2 with the incoming p 3 . In general, let O be the set of outgoing NNs (i.e., NNs that move farther from q than best_dist) and I be the set of incoming objects (i.e., objects other than the current NNs that move closer to q than best_dist). The circle with center q and radius best_dist contains objects I ∪ best_NN -O. If |I|≥|O| (where |I| and |O| are the cardinalities of I and O, respectively), this circle includes at least k objects. Therefore, we can form the new NN set from the k best objects in I ∪ best_NN -O without invoking re-computation. We embed this enhancement in the CPM algorithm as follows. Before processing U P , we record the current best_dist of q. During update handling, we maintain the in_list of the k best incoming objects (we do not need more than the k best incomers in any case). At the end of the procedure, if in_list contains more than |O| objects, we merge the NNs in best_NN -O with in_list, and keep the best k among them to form the new result of q. We resort to NN recomputation only if in_list contains fewer than |O| objects. <ref type="figure">Figure 3</ref>.8 shows the complete update handling module of CPM. An important remark is that if |I|≥|O|, the influence region of q shrinks. Consequently, line 22 deletes q from the influence lists of the cells that no longer belong to it. Note that, at any time, the visit list contains a superset of the cells in the influence region of q. Therefore, we can simply scan the cells c in the visit list with mindist(c,q) between the new and the old value of best_dist, and delete q from their influence lists. The new influence region of q in our example is shown in <ref type="figure">Figure 3</ref>.7b. After update handling, the visit list contains a superset of the cells in the influence region (i.e., the visit list still includes the shaded cells in <ref type="figure">Figure 3.7a)</ref>.</p><p>Update Handling (G, QT, U P ) // Input= G: the grid, QT: query table, U P : set of updates in P 1. For each query q in QT 2.</p><p>Set q.out_count=0; // Counter of outgoing NNs 3.</p><p>Initialize a sorted list q.in_list of size k 4. For each update &lt;p.id,x old ,y old ,x new ,y new &gt;∈U P 5.</p><p>Delete p from its old cell c old 6.</p><p>For each query q in the influence list of c old 7.</p><p>If p∈q.best_NN 8.</p><p>If dist(p,q) ≤ q.best_dist // p remains in the NN set 9.</p><p>Update the order in q.best_NN 10.</p><p>Else // p is an outgoing NN 11.</p><p>Evict p from q.best_NN 12.</p><p>q  In addition to data objects, queries may also be dynamic; i.e., some are terminated, new ones arrive at the system, while others move. When a query is terminated, we delete its entry from QT and remove it from the influence lists of the cells in its influence region. For new arrivals, we execute the NN computation algorithm of <ref type="figure">Figure 3</ref>.4. When an existing query q moves, we treat the update as a termination of the old query, and an insertion of a new one, posed at its new location. Queries that receive updates are ignored when handling object updates in order to avoid waste of computations for obsolete queries. <ref type="figure">Figure 3</ref>.9 presents the complete CPM algorithm, covering all update types.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>NN Monitoring (G, QT)</head><p>// Input= G: the grid indexing P, QT: query table 1. In every processing cycle do 2. U q = set of query updates 3.</p><p>U P = set of updates in P 4.</p><p>Invoke Update Handling (G, QT, U P ) ignoring queries in U q 5.</p><p>For each query q in U q 6.</p><p>If q is a terminated or a moving query 7.</p><p>Delete q from QT and from inf. lists of cells in its inf. region 8.</p><p>If q is a new or a moving query 9.</p><p>NN Computation (G, q); 10.</p><p>Inform client for updated results</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 3.9: The CPM algorithm</head><p>In general, the nearest neighbors of q are concentrated in a small area of the workspace and the influence region of q contains few cells. Therefore, the influence list overhead, and the search heap/visit list sizes are expected to be small. However, in case that the physical memory of the system is exhausted, we can directly discard the search heap and the visit list of q to free space. Even without this information, CPM can continue monitoring q; the difference is that we have to invoke the NN computation algorithm from scratch (instead of NN re-computation) in line 24 of the update handling module of <ref type="figure">Figure 3</ref>.8.  objects on average). As δ decreases, C inf increases, the shape of the influence region better approximates Θ q , and O inf approaches k (which is its minimum value). On the other hand, a large δ leads to a small number of cells which, however, contain a large number of objects. <ref type="figure">Figure 4</ref>.1 illustrates the effect of δ on C inf and O inf , assuming a 1-NN query q. The shaded cells correspond to the influence region of q, which in <ref type="figure">Figure 4</ref>.1a contains C inf =39 cells and O inf =1 objects. For a larger value of δ, in <ref type="figure">Figure 4</ref>.1b, C inf =8</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">PERFORMANCE ANALYSIS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Analysis of CPM</head><p>and O inf =8. To estimate C SH , assume for simplicity that q is located at the center of its cell c q . The boundary boxes are of the same level in each direction. It follows that C SH is the number of cells that intersect the circumscribed square of Θ q . Thus, C SH can be approximated by 4⋅⎡best_dist/δ⎤ 2 . Similar to C inf , C SH decreases as δ increases, e.g., in <ref type="figure">Figure 4</ref>.1a, C SH =49, while in <ref type="figure">Figure 4</ref>.1b,</p><formula xml:id="formula_0">C SH =9.</formula><p>In summary, the space consumed by the influence lists of the cells and the query table, is inversely proportional to δ 2 . Similarly, both the size of the influence lists and the size of the query table are linear to n and k. Concerning the computational cost of CPM, index update time is linear to N and f obj . The result maintenance task takes linear time with respect to n, and is expected to grow as f qry increases. The time of NN computation for a new or a moving query depends strongly on the cell size; a small value for δ incurs high overhead due to heap operations, while a large value implies a high number O inf of processed objects. (a) Small δ (b) Large δ <ref type="figure">Figure 4</ref>.1: The effect of δ on the performance of CPM</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Qualitative comparison with existing methods</head><p>Next, we illustrate the superiority of CPM over the existing methods through some update handling scenarios. YPK-CNN reevaluates periodically every query q, even if the object updates have not affected any cell in its vicinity. This is due to the fact that it does not include a mechanism for detecting queries influenced by location updates. Furthermore, in the general case, YPK-CNN visits more cells than necessary when performing NN search for moving and new queries. Consider the 1-NN computation of query q in <ref type="figure">Figure 4</ref>.2a. As discussed in Section 2 (the example is the same as <ref type="figure">Figure 2</ref>.1), YPK-CNN processes 25 cells and six objects (p 1 up to p 6 ). Finally, it also incurs redundant computations for static queries. Assuming that in <ref type="figure">Figure 4</ref>.2b the current NN p 2 moves to location p′ 2 , YPK-CNN processes 49 cells and ten objects (p 1 up to p 10 ). Clearly, the unnecessary computations increase with dist(p′ 2 ,q). On the other hand, CPM (i) only processes queries whose influence region intersects some updated cell, and (ii) the NN computation and re-computation modules restrict the search space to the minimum number of cells around q (i.e., shaded cells in <ref type="figure">Figure 4.2)</ref>. SEA-CNN also performs redundant computations in several cases. First, assume that the only updates are from incoming objects and/or NNs that move within distance best_dist from q. For instance, in <ref type="figure">Figure 4</ref>.3a, p 6 moves closer to q than best_dist. SEA-CNN visits all cells intersecting the circle centered at q with radius r = best_dist and determines the new NN (p' 6 ) among the processed objects p 1 , p 2 and p' <ref type="bibr">6</ref> . On the other hand, CPM directly compares dist(p' 6 ,q) with best_dist and sets p' 6 as the result without visiting any cells. When k is larger, the computational waste of SEA-CNN increases because it considers a higher number of objects, even though there might be few changes in the result. Another weak point of SEA-CNN concerns handling of outgoing NNs, which is similar to YPK-CNN. Recall that when p 2 moves to p′ 2 , SEA-CNN processes ten objects p 1 up to p 10 (see <ref type="figure">Figure 2</ref>.2a), while CPM considers only four objects (see <ref type="figure">Figure  4</ref>.2b). SEA-CNN incurs higher cost than CPM also in the case that q changes position. In <ref type="figure">Figure 4</ref>.3b, assuming that q moves to q′, CPM considers only cells intersecting the circle with center at q′ and radius dist(p 5 ,q′), and retrieves the NN (p 5 ) by processing only two objects (p 4 and p 5 ) in total. SEA-CNN considers 33 cells and eight objects. A final remark about SEA-CNN is that it does not handle the case where some of the current NNs go off-line. On the contrary, CPM trivially deals with this situation by treating off-line NNs as outgoing ones. Summarizing, the speed of the objects does not affect the running time of CPM since update handling is restricted to the influence regions of the queries. On the other hand, the performance of both YPK-CNN and SEA-CNN (as also observed in <ref type="bibr">[YPK05]</ref> and <ref type="bibr">[XMA05]</ref>) degrades with object speed because the search region for a static query is determined by how far the furthest previous NN has moved since the last evaluation. For moving queries, CPM examines the minimum possible number of cells (which is independent of the query moving distance), whereas the cost of SEA-CNN increases with the velocity of q.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">AGGREGATE NNS AND OTHER QUERY TYPES</head><p>In this section we extend the CPM algorithm to aggregate NN queries starting with the sum function. Given a set of query points Q = {q 1 ,q 2 ,…,q m }, a sum ANN query continuously reports the data object p that minimizes adist(p,Q) = ∑ qi∈Q dist(p,q i ). The basis of our method remains the conceptual partitioning of the space around the query Q. Since Q now consists of a set of query points, the partitioning applies to the space around the minimum bounding rectangle M of Q. <ref type="figure">Figure 5</ref>.1a exemplifies the partitioning into rectangles in the case of a 1-ANN query Q = {q 1 ,q 2 ,q 3 }. We define amindist(c,Q) = ∑ qi∈Q mindist(c,q i ), which is a lower bound for the distance adist(p,Q) of any object p∈c. The definition of amindist(DIR lvl ,Q) for a rectangle DIR lvl is similar. The cell processing order is derived by corollary 5.1, which is based on the same geometric observations as Lemma 3.1 (and, hence, we omit its proof). Corollary 5.1 (f=sum): For rectangles DIR j and DIR j+1 of the same direction DIR with level numbers j and j+1, it holds that amindist(DIR j+1 ,Q) = amindist(DIR j ,Q) + m⋅δ, where m is the number of points in Q. The ANN search module of CPM is essentially the same as the algorithm in <ref type="figure">Figure 3</ref>.4. The difference is that in the beginning of the search, we en-heap (in line 4) all cells c intersecting M. The sorting key is amindist(c,Q) and amindist(DIR lvl ,Q) for the enheaped cells and rectangles, respectively. When an object p is processed, we compute adist(p,Q) and update accordingly the list of best ANNs found so far (i.e., best_NN). The algorithm terminates when the next entry in H has amindist greater than or equal to best_dist. In our example, the algorithm terminates with p 2 as the result, after processing all the shaded cells in <ref type="figure">Figure  5</ref>.1b. Similar to Section 3.1, the influence region of Q is the set of cells c with amindist(c,Q)≤best_dist; only updates affecting these cells can change the ANN result. Note that the influence region of a query is no longer a circle, but has an irregular shape (i.e., the shaded region in <ref type="figure">Figure 5</ref>.1b). Update handling is the same as in Section 3, the difference being that we use the aggregate distance function instead of the Euclidean one. When f=min, an ANN query Q retrieves the object(s) in P with the smallest distance(s) from any point in Q. The ANN search considers cells and rectangles in ascending amindist order. For a cell c, amindist(c,Q) = min qi∈Q mindist(c,q i ), while for a rectangle DIR lvl , amindist(c,DIR lvl ) = min qi∈Q mindist(DIR lvl ,q i ). Corollary 5.2 dictates the cell processing order. Corollary 5.2 (f=min or f=max): For rectangles DIR j and DIR j+1 of the same direction DIR with level numbers j and j+1, it holds that amindist(DIR j+1 ,Q) = amindist(DIR j ,Q) + δ.</p><p>The ANN search and update handling modules of CPM are similar to the sum case. Furthermore, for the min function, we can improve the O(m) time required to compute amindist(DIR 0 ,Q) to O(1). The MBR M of Q contains by definition one point of Q on each edge. Therefore, computing amindist(DIR 0 ,Q) for each direction DIR reduces to calculating the minimum distance between rectangle DIR 0 and the closest edge of M. For example, amindist(D 0 ,Q) equals to the distance between the top edge of D 0 and the bottom edge of M. An interesting observation about the min aggregate function is that the influence region of Q contains cells that intersect at least one of the circles centered at some q i with radius best_dist. <ref type="figure">Figure 5</ref>.2a shows an example where Q = {q 1 ,q 2 ,q 3 } and f=min. The result of the query is p 2 , and the influence region of Q appears shaded. When f=max, CPM monitors the object(s) of P that have the lowest maximum distance(s) from points in Q. For each cell c, amindist(c,Q) = max qi∈Q mindist(c,q i ), while for each boundary box DIR lvl , amindist(DIR lvl ,Q) = max qi∈Q mindist(DIR lvl ,q i ). Corollary 5.2 holds also in the case of max, whereas computing amindist(DIR 0 ,Q) for each direction DIR can be performed in O(1) time: amindist(DIR 0 ,Q) equals the minimum distance between DIR 0 and the opposite edge of M. In <ref type="figure">Figure 5</ref>.2b we illustrate the case where Q = {q 1 ,q 2 ,q 3 } and f=max. The result of the query is object p 4 , and the corresponding influence region consists of the shaded cells.  propose algorithms for static datasets indexed by R-trees. The adaptation of CPM to this problem inserts into the search heap only cells and conceptual rectangles that intersect the constraint region. Assume, for instance, that in <ref type="figure">Figure 5</ref>.3 we want to monitor the NN to the northeast of q. CPM en-heaps only the cells c 4,4 , c 4,5 , c 5,4 , c 5,5 and rectangles U 0 , R 0 , U 1 , R 1 . Inside c 5,5 , object p 3 is identified as the NN. Note that object p 1 (the unconstrained NN) is not encountered at all since its cell is not visited, whereas p 2 is processed but not reported. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">EXPERIMENTAL EVALUATION</head><p>In this section we evaluate the performance of CPM and compare it with YPK-CNN and SEA-CNN. In accordance with the experimental study of <ref type="bibr">[XMA05]</ref>, our datasets are created with the spatiotemporal generator of <ref type="bibr">[B02]</ref>. The input of the generator is the road map of Oldenburg (a city in Germany). The output is a set of objects (e.g., cars, pedestrians) moving on this network, where each object is represented by its location at successive timestamps. An object appears on a network node, completes the shortest path to a random destination, and then disappears. We use the default velocity values of the generator for slow, medium, and fast object speeds. Objects with slow speed cover a distance that equals 1/250 of the sum of the workspace extents per timestamp. Medium and fast speeds correspond to distances that are 5 and 25 times larger, respectively. The NN queries are generated similarly, i.e., they are objects moving on the same network, but they stay in the system throughout the simulation. The queries are evaluated at every timestamp and the simulation length is 100 timestamps. In the implementation of SEA-CNN, we use the NN search algorithm of YPK-CNN to compute the initial results of the queries, or to retrieve the new NN sets when some of the current NNs disappear.   Next we examine scalability issues. <ref type="figure">Figure 6</ref>.2a measures the effect of the object population N on the running time. The generator is tuned so that the average object population during the simulation equals the desired value N. Similarly, <ref type="figure">Figure 6</ref>.2b illustrates the CPU overhead as a function of the number n of queries in the system. The cost of all algorithms increases linearly to both N and n. However, YPK-CNN and SEA-CNN are much more sensitive than CPM to these parameters, confirming the scalability of our approach. Note that a cell may be accessed multiple times within a cycle, if it is involved in the processing of multiple queries. For CPM, cell accesses occur during the NN computation algorithm (for moving queries), and during NN re-computation (for stationary queries, when there are more outgoing NNs than incomers). YPK-CNN re-evaluates the queries in every timestamp, and therefore induces cell visits for each query in every processing cycle. SEA-CNN accesses cells whenever some update affects the answer region of a query and/or when the query moves. CPM significantly outperforms its competitors because: (i) it does not search the grid if the update information suffices to maintain the results, and (ii) even if the updates necessitate computation from scratch or re-computation of the NN sets, CPM processes the minimal number of cells. An interesting observation is that for k=1 and k=4, CPM accesses less than one cell per query on the average. This happens because queries of case (ii) have a small cost (i.e., 1-2 cell visits), which is counter-balanced by queries of case (i) that do not incur any visits.  <ref type="figure">Figure 6</ref>.5a compares the performance of CPM, YPK-CNN and SEA-CNN versus the percentage of objects that move within a timestamp (i.e., the object agility f obj ). As expected (see Section 4.1), the running time of CPM scales linearly with the object agility, due to the increasing index update cost. In order to quantify the effect of the query agility f qry (i.e., the probability that a query moves within a timestamp), we vary f qry from 10% to 50% and keep the remaining parameters fixed to their default values. As shown in <ref type="figure">Figure 6</ref>.5b, the CPU time of CPM increases linearly with f qry because NN computations (for moving queries) are more expensive than result maintenance for static queries. Note that YPK-CNN is rather insensitive to the query agility because the incremental maintenance of the NN set (for stationary queries) has similar cost to the two-step NN computation (for moving queries). (a) Effect of object agility (f obj ) (b) Effect of query agility (f qry ) <ref type="figure">Figure 6</ref>.5: CPU time versus object and query agility</p><p>In the remaining two experiments, we compare individually the NN computation and result maintenance modules of the alternative methods. First, we monitor 5K constantly moving queries (i.e., queries that issue location updates in every timestamp), while varying the object population N. The query results are computed from scratch at every processing cycle; therefore, we can study the efficiency of the NN computation modules. SEA-CNN is omitted (since it does not include an explicit mechanism for obtaining the initial NN set). As shown in <ref type="figure">Figure 6</ref>.6a, CPM outperforms YPK-CNN and the performance gap increases with N. Finally, we process 5K static queries (i.e., f qry =0%), while varying the object population N. This way we eliminate the NN computations from scratch (apart from the initial query evaluation) and measure the pure result maintenance cost. As shown in <ref type="figure">Figure 6</ref>.6b, the behavior of YPK-CNN and SEA-CNN is similar, while CPM induces considerably fewer computations. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">CONCLUSIONS</head><p>This paper investigates the problem of monitoring continuous NN queries over moving objects. The task of the query processor is to constantly report the results of all queries, as location updates stream by from both the objects and the queries. Our contribution is an efficient processing method, referred to as the conceptual partitioning monitoring (CPM) algorithm. CPM is based on a conceptual partitioning of the space around each query q, in order to restrict the NN retrieval and the result maintenance computations to objects that lie in the vicinity of q. The core of CPM is its NN computation module, which retrieves the first-time results of incoming queries, and the new results of existing queries that change location. This module produces and stores book-keeping information to facilitate fast update handling. Keeping the NN set of a query q up-to-date is performed by processing on-line the object updates as they arrive. If the new NN set of a query can be determined solely by the previous result and the set of updates, then access to the object grid G is avoided. Otherwise, CPM invokes the NN re-computation module, which uses the book-keeping information stored in the system to reduce the running time (compared to NN computation from scratch). CPM is a generally applicable technique, since it does not require any knowledge about the object or query moving patterns (e.g., velocity vectors), and can concurrently process multiple (static or moving) queries. We analyze its performance and compare it with the existing state-of-the-art methods. As demonstrated by a qualitative analysis and by an extensive experimental study, CPM outperforms its competitors. Finally, to support the generality of the proposed methodology, CPM is applied to aggregate NN monitoring, where a query consists of a set of points and the optimization goal depends on an aggregate function (such as sum, min and max). In the future, we intend to explore the problem of continuous monitoring for variations of NN search, such as reverse NNs. A preliminary approach on this topic considers one-dimensional streams and aggregate reverse NN <ref type="bibr">[KMS02]</ref>. It would be interesting to develop alternative approaches for the continuous monitoring of multiple (conventional) reverse NN queries in spaces of higher dimensionality.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 . 1 :</head><label>21</label><figDesc>YPK-CNN examples</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 . 1 :</head><label>31</label><figDesc>Figure 3.1b illustrates the conceptual partitioning of the space around the cell c q of q. Each rectangle rect is defined by a direction and a level number. The direction could be U, D, L, or R (for up, down, left and right) depending on the relative position of rect with respect to q. The level number indicates the number of rectangles between rect and c q . Lemma 3.1 regulates the visiting order among rectangles of the same direction. Lemma 3.1: For rectangles DIR j and DIR j+1 of the same direction DIR with level numbers j and j+1, respectively, it holds that</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 . 3 :</head><label>33</label><figDesc>Figure 3.4 presents the full functionality of the CPM NN computation including the maintenance of the data structures. The influence lists of the encountered cells are updated in line 11, while, in line 12, each processed cell is inserted into the visit list of q. Line 18 stores the new best_dist value in the query table. Upon termination, the heap H is also stored in QT. The algorithm is optimal in the sense that it processes the minimal set of cells for retrieving the NN set of q. As opposed to the naïve algorithm discussed in the beginning of the section, the only redundant mindist computations concern the cells that were en-heaped but not de-heaped (i.e., the shaded cells in Figure 3.2b). As shown in Section 4.1, the number of such cells and rectangles is small. Furthermore, as discussed next, CPM utilizes these computations for the efficient handling of updates.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 . 4 :</head><label>34</label><figDesc>Figure 3.4: The NN computation module of CPM</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 3 . 5 :</head><label>35</label><figDesc>Figure 3.6 illustrates the re-computation module that retrieves the new NN set of the affected queries. The algorithm is based on the same principles as the NN search module of CPM (Figure 3.4), but re-uses the information stored in the query table to reduce the running time. In particular, it starts processing sequentially the cells stored in the visit list of q, and then it continues with the entries of the search heap H. Note that all the cells in the visit list have mindist less than (or equal to) the entries of H. It follows that the NN re-computation algorithm considers cells c in ascending mindist(c,q) order, which guarantees the correctness of the result, as well as the minimality of the set of processed cells. The benefits of NN re-computation over computation from scratch are: (i) it utilizes the previously computed mindist values, and (ii) it significantly reduces the number of heap operations (insertions/deletions). Recall that the cost of each heap operation is logarithmic to the heap size, while the "get next" operation on the visit list (in line 3 of Figure 3.6) is O(1).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 3 . 6 :</head><label>36</label><figDesc>Figure 3.6: The NN re-computation module of CPM</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 3 . 8 :</head><label>38</label><figDesc>Figure 3.8: The update handling module of CPM</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>Cells visited by YPK-CNN Cells visited by CPM (shaded) b e st _ d is t (a) NN search (b) Update handling Figure 4.2: CPM versus YPK-CNN</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>be st _d is t Cells visited by SEA_CNN Cells visited by CPM (a) p 6 issues an update (b) q moves to q′ Figure 4.3: CPM versus SEA-CNN</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 5 . 1 :</head><label>51</label><figDesc>ANN monitoring for f=sum</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 5 . 2 :</head><label>52</label><figDesc>ANN monitoring for f=min and f=max Finally, CPM can easily handle constrained variations of NN (and ANN) search that retrieve the NNs of a query point in a user- specified area of the data space. Ferhatosmanoglu et al. [FSAA01]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 5 . 3 :</head><label>53</label><figDesc>Figure 5.3: Monitoring of a constrained NN query</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 6 . 1 :</head><label>61</label><figDesc>Figure 6.1: CPU time versus grid granularity</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 6 . 2 :</head><label>62</label><figDesc>Figure 6.3a shows the CPU time as a function of the number k of NNs (using the default values for the remaining parameters). Figure 6.3b plots (in logarithmic scale) the number of cell accesses per query per timestamp. A cell visit corresponds to a complete scan over the object list in the cell. Note that a cell may be accessed multiple times within a cycle, if it is involved in the processing of multiple queries. For CPM, cell accesses occur during the NN computation algorithm (for moving queries), and during NN re-computation (for stationary queries, when there are more outgoing NNs than incomers). YPK-CNN re-evaluates the queries in every timestamp, and therefore induces cell visits for each query in every processing cycle. SEA-CNN accesses cells whenever some update affects the answer region of a query and/or when the query moves. CPM significantly outperforms its competitors because: (i) it does not search the grid if the update information suffices to maintain the results, and (ii) even if the updates necessitate computation from scratch or re-computation of the NN sets, CPM processes the minimal number of cells. An interesting observation is that for k=1 and k=4, CPM accesses less than one cell per query on the average. This happens because queries of case (ii) have a small cost (i.e., 1-2 cell visits), which is counter-balanced by queries of case (i) that do not incur any visits.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Figure 6 .Figure 6 . 4 :</head><label>664</label><figDesc>Figure 6.4a illustrates the CPU time with respect to the object speed. The performance of CPM is practically unaffected by the speed of objects. On the contrary, both YPK-CNN and SEA-CNN degenerate when objects move fast, as anticipated in Section 4.2. Figure 6.4b depicts the effect of the query speed on the running time of the algorithms. The cost of CPM and YPK-CNN is independent of the query velocity, since both techniques compute the results of the moving queries from scratch. On the other hand, SEA-CNN is negatively affected because, as discussed in Section</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Figure 6 . 6 :</head><label>66</label><figDesc>CPU time for constantly moving and static queries</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 .1: Properties of monitoring methods</head><label>2</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 .</head><label>3</label><figDesc></figDesc><table>1 summarizes 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>// Input= G: the grid indexing P // q: the query 1. best_dist = ∞; best_NN = NULL; 2. Insert a new entry for q into the query table 3. Initialize an empty heap H 4. Insert &lt;c q , 0&gt; into H 5. For each direction DIR insert &lt;DIR 0 , mindist(DIR 0 ,q)&gt; into H 6.</head><label></label><figDesc>2b). As shown in Section 4.1, the number of such cells and rectangles is small. Furthermore, as discussed next, CPM utilizes these computations for the efficient handling of updates.</figDesc><table>NN Computation (G, q) 
Initialize an empty list visit_list 
7. Repeat 
8. 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>The insertion of p 2 into its new cell c 0,6 does not trigger any additional processing (because the influence list of c 0,6 is empty). Finally, CPM invokes the NN re- computation module to find the new NN (p' 4 ) of</head><label></label><figDesc></figDesc><table>the affected 
query q. 

q 

p 1 

p 2 

p 4 
p 3 

c 2,4 c 3,3 

c 2,6 
c 5,6 

p' 4 

Influence region 

c 5,3 

best_dist 

q 

p 1 

p 2 

p 3 

c 2,4 c 3,3 

c 2,6 

p' 4 

New influence region 

c 5,3 

p' 2 
c 0,6 

b 
e 
s 
t_ 
d 
is 
t 

(a) p 4 issues an update 
(b) p 2 issues an update 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>(a) p 2 and p 3 issue updates (b) p 3 becomes the NN of q Figure 3.7: An update handling example</head><label></label><figDesc></figDesc><table>q 

p 1 

p 2 

p 4 
p 3 

c 2,4 c 3,3 

c 2,6 
c 5,6 

Influence region 

p' 2 

p' 3 

best_dist 

q 

p 1 

p 4 

c 3,3 

c 5,6 

New influence region 

p' 3 

b e st _ d is t 

c 3,5 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>.out_count = q.out_count +1; 13. Insert p into its new cell c new 14. For each query q in the influence list of c new 15. If dist(p,q)≤q.best_dist and p∉q.best_NN // p is an incomer 16. Update q.in_list with p 17. For each query q in QT 18. If q.in_list contains at least q.out_count objects 19. candidate_list = q.in_list ∪ q.best_NN ; 20. q.best_NN = the best k objects in candidate_list 21. Update q.best_dist, Set inf. region of q to &lt;q, p.best_dist&gt; 22.</head><label></label><figDesc></figDesc><table>Delete q from inf. lists of cells no longer in its inf. region 
23. Else // Not enough incoming objects 
24. 
NN Re-Computation (G, q); 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" validated="false"><head>cells C inf in the influence region of a k-NN query q, (ii) the number O inf of objects in the influence region, and (iii) the total number C SH of cells stored either in the visit list or in the search heap of q. Thenentry consumes s etr =3 memory units for the cell (rectangle) column/row and mindist. The first component of the space overhead is the size of the grid index. The grid contains N objects, consuming s obj ⋅N=3⋅N space, plus the auxiliary influence lists of the cells. For each query q, we insert its id into the influence lists of C inf cells. Assuming n concurrent k-NN queries, the grid index has total size Space G = 3⋅N + n⋅C inf . The query table contains one entry for each query q. The memory dedicated for an entry is s obj + 2⋅k + s etr ⋅(C SH +4); s obj =3 is required for the id and co-ordinates of q, while 2⋅k space is used for the object ids of the k NNs and their distances from q. The s etr ⋅(C SH +4)=3⋅(C SH +4) component corresponds to the storage overhead of the visit list and the search heap H; these two structures combined contain C SH cells plus four rectangle entries. It follows that the size of the query table is Space QT = n⋅(15+2⋅k+3⋅C SH ). In total, the memory requirements of CPM are Space CPM = Space G + Space QT = 3⋅N + n⋅(15+2⋅k+3⋅C SH +C inf ) memory units. In order to estimate the running time per processing cycle, we assume that N⋅f obj objects and n⋅f qry queries issue location updates following random displacement vectors. The total cost is Time CPM = N⋅f obj ⋅Time ind + n⋅f qry ⋅Time mq + n⋅(1-f qry )⋅Time sq , where Time ind is the index update time for a single object, Time mq is the time required for the NN computation of a moving query, and Time sq is the time required for updating the NNs of a static query. The object lists of the cells are implemented as hash tables so that the deletion of an object from its old cell and the insertion into its new one takes expected Time ind =2. For each moving query we have to invoke the NN computation algorithm of Figure 3.4 with cost Time mq = C SH ⋅logC SH + O inf ⋅logk + 2⋅C inf . The first factor is due to the heap operations. The number of entries in H throughout the NN search procedure is upper-bounded by C SH +4 ≈ C SH . Since insertion and deletion is logarithmic to the size of the heap, the overall time spent on heap operations is C SH ⋅logC SH . The algorithm processes O inf objects, taking O inf ⋅logk time cumulatively; each object is probed against the best_NN list to update the result, taking logk time with a red-black tree implementation of best_NN. Removing or inserting q from/into the influence list of a cell takes constant expected time (the lists are implemented as hash-tables). Therefore, updating the influence lists of all cells falling in the old and the new influence region costs 2⋅C inf . For estimating Time sq , observe that at any time instant, the objects are distributed uniformly in the workspace. This implies that the circle with radius best_dist always contains k objects, or equivalently, there are as many incoming objects as outgoing NNs. Let there be |O| outgoing NNs. In the worst case, all the remaining k-|O| NNs move. Re-ordering the remaining NNs and inserting the |I|=|O| incomers into best_NN takes Time sq = k⋅logk. Summing over all queries and the index update time, the computational overhead of a processing cycle is Time CPM = 2⋅N⋅f obj + n⋅f qry ⋅(C SH ⋅logC SH + O inf ⋅logk + 2⋅C inf ) + n⋅(1-f qry )⋅k⋅logk. It remains to estimate the numbers C inf (O inf ) of influencing cells (objects) and cells C SH in the visited list and heap of a random query q. Let Θ q be the circle centered at q with radius equal to best_dist. For uniform data, the ratio of the area of Θ q to the area of the workspace equals k/N so that best_dist= k/π⋅N . The influence region of q consists of cells intersecting Θ q . The number of these cells is roughly C inf = π⋅⎡best_dist/δ⎤ 2 , and the corresponding objects are O inf = C inf ⋅N⋅δ 2 (each cell contains N⋅δ 2</head><label></label><figDesc>, we estimate the values of these parameters as functions of δ, and conclude with observations about the expected performance of CPM in practice. For simplicity, we assume that the minimum unit of memory can store a (real or integer) number. The amount of memory required for an object is s obj =3 for its id and two co-ordinates. Similarly, each heap/visit list</figDesc><table>In order to study the performance of CPM and analyze the effect 

of the cell size δ, we assume that the objects (queries) are 

uniformly distributed 5 in a unit square workspace. First, we 
provide formulae for the space/time overhead with respect to: (i) 
the number of </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12" validated="false"><head>Table 5 .</head><label>5</label><figDesc></figDesc><table>1 summarizes the parameters 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13" validated="false"><head>Table 6 .</head><label>6</label><figDesc></figDesc><table>1: System parameters (ranges and default values) 

Initially, we generate 5K queries and 100K objects, according to 
the default parameters of Table 6.1. We process the queries with 
each monitoring algorithm, and measure the overall running time 
by varying the grid granularity. Figure 6.1 illustrates the results 
for grid sizes ranging between 32×32 and 1024×1024. CPM 
clearly outperforms both competitors for all grid sizes. SEA-CNN 
is worse than YPK-CNN because it incurs unnecessary 
computations for moving queries, as explained in Section 4.2. A 

128×128 grid (i.e., δ = 1/128) constitutes a good tradeoff between 

the CPU time and the space requirements for all methods 6 . 

Therefore, we perform the remaining experiments using δ = 

1/128. 

CPM 
SEA-CNN 
YPK-CNN 

32 
64 
128 
256 
512 
1024 

2 
2 
2 
2 
2 
2 

Number of cells in G 

</table></figure>

			<note place="foot" n="1"> Yu et al. [YPK05] actually propose three methods. YPK-CNN is shown to be the best in their experimental evaluation.</note>

			<note place="foot" n="2"> Even though SEA-CNN assumes that objects reside in secondary memory, it can be also used for memory-resident data.</note>

			<note place="foot" n="3"> We focus on two-dimensional Euclidean spaces, but the proposed techniques can be applied to higher dimensionality and other distance metrics. Furthermore, for ease of presentation, the examples demonstrate retrieval of a single NN.</note>

			<note place="foot" n="4"> Note that, from now on, we ignore the empty cells in our examples for the sake of clarity.</note>

			<note place="foot" n="5"> Although, admittedly, the uniformity assumption does not hold in practice, similar to previous work [YPK05], we use it to obtain general observations about the effect of the problem parameters.</note>

			<note place="foot" n="6"> The space overhead is 2.854 MBytes, 3.074 MBytes, and 3.314 MBytes for YPK-CNN, SEA-CNN and CPM, respectively.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENTS</head><p>This work was supported by grant HKUST 6180/03E from Hong Kong RGC. The authors would like to thank Kevin Di Filippo for proof-reading the paper.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A Framework for Generating Networkbased Moving Objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brinkhoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">GeoInformatica</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="153" to="180" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Nearest Neighbor and Reverse Nearest Neighbor Queries for Moving Objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Benetis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Jensen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Karciauskas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Saltenis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IDEAS</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Processing RangeMonitoring Queries on Heterogeneous Mobile Objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cao</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<publisher>MDM</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ferhatosmanoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Stanoi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Abbadi</surname></persName>
		</author>
		<title level="m">Constrained Nearest Neighbor Queries. SSTD</title>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gedik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mobieyes</surname></persName>
		</author>
		<title level="m">Distributed Processing of Continuously Moving Queries on Moving Objects in a Mobile System. EDBT</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">A Distance Scan Algorithm for Spatial Access Structures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Henrich</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1984" />
			<publisher>ACM GIS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Distance Browsing in Spatial Databases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hjaltason</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Samet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM TODS</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="265" to="318" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Reverse Nearest Neighbor Aggregates Over Data Streams</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Korn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Muthukrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Srivastava</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
			<publisher>VLDB</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Approximate NN queries on Streams with Guaranteed Error/performance Bounds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Koudas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ooi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<publisher>VLDB</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mokbel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Aref</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sina</surname></persName>
		</author>
		<title level="m">Scalable Incremental Processing of Continuous Queries in Spatio-temporal Databases. SIGMOD</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Papadias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mouratidis</surname></persName>
		</author>
		<title level="m">Group Nearest Neighbor Queries. ICDE</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Query Indexing and Velocity Constrained Indexing: Scalable Techniques for Continuous Queries on Moving Objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Prabhakar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kalashnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Aref</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hambrusch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computers</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1124" to="1140" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Roussopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Vincent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nearest Neighbor Queries. SIGMOD</title>
		<imprint>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Roussopoulos</surname></persName>
		</author>
		<title level="m">Nearest Neighbor Search for Moving Query Point. SSTD</title>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Discovery of Influence Sets in Frequently Updated Databases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Stanoi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Riedewald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Abbadi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
			<publisher>VLDB</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Spatial Queries in Dynamic Environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Papadias</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM TODS</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="101" to="139" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mokbel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Aref</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sea-Cnn</surname></persName>
		</author>
		<title level="m">Scalable Processing of Continuous K-Nearest Neighbor Queries in Spatio-temporal Databases. ICDE</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Monitoring K-Nearest Neighbor Queries Over Moving Objects. ICDE</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Pu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Koudas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Location-based Spatial Queries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Papadias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lee</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
			<publisher>SIGMOD</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
