<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2020-09-29T02:56+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">How to Teach an Old File System Dog New Object Store Tricks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eunji</forename><surname>Lee</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Chungbuk National University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youil</forename><surname>Han</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Chungbuk National University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suli</forename><surname>Yang</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of Wisconsin-Madison</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><forename type="middle">C</forename><surname>Arpaci-Dusseau</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of Wisconsin-Madison</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Remzi</forename><forename type="middle">H</forename><surname>Arpaci-Dusseau</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of Wisconsin-Madison</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">How to Teach an Old File System Dog New Object Store Tricks</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Many data service platforms use local file systems as their backend storage. Although this approach offers advantages in portability, extensibility, and ease of development , it may suffer from severe performance degradation if the mapping between the services required by the data service platform and the functions provided by the local file system is not carefully managed. This paper presents in-depth analysis of performance problems in current data service platforms that use file systems as their backend storage and proposes three novel strategies that are essential to solving the current performance problems. We demonstrate the efficacy of our strategies by implementing a prototype object store in Ceph, called SwimStore (Shadowing with Immutable Metadata Store). We experimentally show that SwimStore provides high performance with little variation, as well as a large reduction in write traffic.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>We are witnessing an explosive growth of digital data both in volume and variety.</p><p>To cope with such rapidly growing unstructured data, there has been a surge of interest in data service platforms such as distributed NoSQL systems like BigTable <ref type="bibr" target="#b1">[2]</ref>, Cassandra <ref type="bibr" target="#b4">[5]</ref>, HBase <ref type="bibr" target="#b7">[8]</ref>, MongoDB <ref type="bibr" target="#b16">[17]</ref>, Ceph <ref type="bibr" target="#b31">[32]</ref>, Swift <ref type="bibr" target="#b0">[1]</ref>, distributed file systems like GFS <ref type="bibr" target="#b5">[6]</ref> and HDFS <ref type="bibr" target="#b24">[25]</ref>, and embedded key-value stores like LevelDB <ref type="bibr" target="#b6">[7]</ref>, HyperLevelDB <ref type="bibr" target="#b9">[10]</ref>, and RocksDB <ref type="bibr" target="#b2">[3]</ref>.</p><p>Most data service platforms use a layered approach rather than building the platform end-to-end. For example, BigTable <ref type="bibr" target="#b1">[2]</ref> and HBase <ref type="bibr" target="#b7">[8]</ref> rely on a distributed file system underneath, which is subsequently backed by a local file system. Cassandra <ref type="bibr" target="#b4">[5]</ref> and MongoDB <ref type="bibr" target="#b16">[17]</ref> use a per-node storage engine that is typically running atop a file system. Embedded key-value stores such as LevelDB <ref type="bibr" target="#b6">[7]</ref> and RocksDB <ref type="bibr" target="#b2">[3]</ref> employ a local file system as their storage backend. The fundamental rationale behind this layered architecture is abstraction. Abstracting away underlying details, the layered approach permits ease of development and maintenance in building a complicated data service platform.</p><p>A layered approach, however, sometimes backfires when the lower layer was not originally designed for the upper layer; that is the case between many data service platforms and the local file system underneath. Most of file systems today and their POSIX standard interface were not intended to serve as a local storage engine for other data service platforms, so as it has been pointed out in <ref type="bibr" target="#b30">[31]</ref>, there is a mismatch between the two, both inside and outside.</p><p>Inside, local file systems are optimized for systemwide performance and reliability, largely ignoring demands from individual applications. Thus, the upper layer applications have very little control over what's going on inside the file system. As a result, the upper layer can suffer from degraded QoS (Quality-ofService) resulting from unintended and unexpected entanglement <ref type="bibr" target="#b13">[14]</ref> within the file system. Such entanglement arises, for example, from periodic flushing of dirty blocks and journaling for consistent metadata update. Both techniques aim to fulfill the file system's original objectives (the former for enhancing system-wide performance and the latter for improving reliability), but they can potentially lead to serious performance fluctuations, which greatly degrade the QoS.</p><p>Outside, local file systems do not provide support for atomic update, which is a crucial functionality required from the underlying storage backend in data service platforms. <ref type="bibr" target="#b0">1</ref> This functional mismatch forces data service platforms to use write-ahead logging <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b21">22]</ref>, resulting in significant increase in write traffic due to double writes (one to the log and the other to home locations) 2 . In addition to the traffic increase, the double writes adversely affect the QoS due to periodic flushing of dirty blocks, one form of entanglement in the file system.</p><p>To address the performance problems arising from the mismatch, two approaches have been actively pursued in recent years. The first approach, as exemplified by BlueStore <ref type="bibr" target="#b30">[31]</ref>, an object store for Ceph, is to bypass the file system and access the raw block device directly. This bare-bones approach has a performance advantage over the one with a file system as an intermediary. However, it suffers from the loss of numerous advantages of the file system abstraction such as portability, extensibility, and  <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b8">9]</ref>. This approach might remedy the performance problem, but results in a loss of generality by optimizing the file system for specific workloads.</p><p>Our approach is different; we use the file system and the POSIX standard interface as they are, but use files in a manner that minimizes the inefficiency of layering and takes better control over the performance. To this end, we first analyze the current data service platforms in terms of the performance and controllability, particularly correlating them with the underlying file system workings. Then, we present a set of strategies to store unstructured data items over a file system achieving higher performance and QoS. The first strategy is to use files as metadata immutable containers for storing data items much like a virtual disk file that stores the contents of a virtual machine's hard disk drive <ref type="bibr" target="#b29">[30]</ref>. This approach eliminates not only most of metadata update in the file system but also, and more importantly, write traffic fluctuations arising from forcing the metadata, which is needed to maintain the file system consistency. We also use multiple container files of different allocation unit sizes to minimize the complexity arising from fragmentation.</p><p>Second, we use in-file shadow paging to eliminate the double write problem associated with the write-ahead logging approach. Although we use shadow paging, we do not have to address the accompanying garbage collection issue since the underlying file system provides a level of indirection and thus the garbage collection can easily be performed by deallocating blocks associated with the garbage using the hole punching feature <ref type="bibr" target="#b11">[12]</ref> supported by most modern file systems. Also, we make use of intent logging to implement a transaction where data update by shadow paging is one type of record, which points to the target area of update. Finally, we use a variation of the transactional checksum <ref type="bibr" target="#b18">[19]</ref> to remove the ordering between the data update and log write.</p><p>As a proof of concept, we implement a prototype object store for Ceph called SwimStore (ShadoWing with Immutable Metadata Store) built atop a local file system</p><p>The measurement study shows that SwimStore improves the performance by twofold, reducing the write traffic by more than a half, compared to other object stores in Ceph such as FileStore and KStore. Even when compared with BlueStore, which bypasses the file system and accesses the raw block device directly, SwimStore performs competitively while retaining all the benefits of the file system abstraction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Overview of Data Service Platforms</head><p>The data service platforms mostly rely on a local file system for their final backend storage, while a raw block device is accessed directly on some occasions. This trend raises one central question: what is the best way to store unstructured data atop a local file system? To find an answer to this question, we classify data service platforms into two types, according to how they store data items over a local file system, and investigate strengths and weaknesses of each type. <ref type="table" target="#tab_0">Table 1</ref> summarizes the key features of data service platforms. Packing: This architecture maintains multiple items in a single file. The most common instance of this architecture is the log-structured merge tree (LSM tree), which is extensively used as in-file data structures in numerous key-value stores <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b12">13]</ref>. The LSM tree buffers data items in memory and batches them into a file when the amount of written data reaches the limit <ref type="bibr" target="#b20">[21]</ref>. The data items are maintained in sorted order by key, managed by a skip list in memory <ref type="bibr" target="#b19">[20]</ref> and by a sorted-string table (sstable) within a file. The multiple sstables are periodically merged into fewer ones for better read performance and space reclaiming, which is called compaction. The LSM tree has the advantage of using the full bandwidth of the underlying storage, translating small sized updates into a sequential write stream <ref type="bibr" target="#b17">[18]</ref>. Moreover, keeping data in sorted order makes it possible to retrieve data with O(log(n)) complexity and to process a range query quickly without any additional indexing.</p><p>However, the LSM tree originally targets the small data items, and thus it does not perform well for large writes. When a write is large, the memory buffer fills up quickly, forcing a frequent flush of buffered data. This activity results in a large number of sstables that con-  tains only a few items but also have ranges that overlap with others. In this situation, the cost of data retrieval increases significantly because a system has to search multiple sstables that have a range encompassing the target key. To avoid this weakness, the compaction must be performed at short intervals so as to make a globally sorted sequence of data items. Unfortunately, the write amplification by compaction is exceedingly destructive when the write size is large because the performance is dictated by the total amount of write traffic. Furthermore, in the packing architecture, the partial update of data items is challenging. Thus, LSM tree based key-value stores handle such operations (e.g., append, update, or truncate) by inserting an updated data item as a whole, which is particularly expensive for large data. Mapping: This architecture associates a data item with a file, and it is mainly used in distributed object stores (e.g., Ceph, Swift) and distributed file systems (e.g., GFS, HDFS). As opposed to key-value stores, these systems are designed to target on large items. HDFS processes data on a block granularity whose default size is 64MB. Ceph's object store was originally meant to be a backend for a distributed file system in which the objects are multiple MBs. The primary benefit of this approach lies in the increased developer velocity. By associating a data item with a file, we can rely on a number of great functionalities of a file system, such as indexing, caching, and space management, instead of developing them from scratch. Furthermore, as most of these mechanisms have been carefully designed and heavily tested over past decades, their use can help to improve system reliability. Also, the partial manipulation of items becomes easier because the file systems already support such functions for file components.</p><p>However, this approach also has a downside. First, this design, which is tightly coupled with the file system causes the data service platform to be greatly affected by file system internal activity. As a result, data service platforms might confront unexpected delay or performance oscillation incurred by out-of-control workings of the underlying file systems. In addition, the high dependency on the file system facilities implies that the implementation efficiency can be severely constrained by the limited POSIX APIs. For example, maintaining additional metadata for data items is not easy when those items are stored as a file because conventional file systems allow only a limited number of attributes for a file, and these limitations even vary across file systems.</p><p>Besides this, the absence of required operations such as atomic updates and efficient file grouping / splitting, and file enumeration in sorted order lead us to suffer from sub-optimal performance in many cases. Finally, the file system metadata can be a burden in the presence of a myriad of files, amplifying write traffic greatly, particularly for small data items.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Quantitative Analysis</head><p>We perform a quantitative analysis on current backend storage architectures, particularly focusing on the correlation between their performance and the underlying file system behaviors.</p><p>Experimental Setup: Our empirical study is performed using Ceph <ref type="bibr" target="#b31">[32]</ref>, a distributed object store platform, be-cause it enables the fair comparison of two architectures by offering an option for choosing backend storage between packing (KStore) and mapping (FileStore) architectures <ref type="bibr" target="#b10">[11]</ref>. KStore is an object store provided by Ceph that manages data using embedded key-value store (i.e., RocksDB), representing the packing architecture. FileStore, which is also in Ceph, stores each object as a file, representing the mapping architecture. By comparing these object stores, we examine how different backend storage architectures of the NoSQL systems work in general for various environments.</p><p>All our experiments are performed on Amazon EC2 clusters; each machine consists of Intel Xeon quad-core running at 2.5GHz, 16GB DDR, and two 256 GiB SSDs. We use Ubuntu Server 16.04 and XFS file system.</p><p>Performance: We investigate the performance of different backend architectures with respect to the object size by measuring the IOPS of KStore (packing) and FileStore (mapping) writing 4KB and 1MB objects. <ref type="figure">Figure  1</ref> shows that KStore provides 1.57x higher IOPS than FileStore for small writes, while FileStore outperforms KStore by 1.6x for large writes. We attribute the low performance of FileStore in small writes to the severe metadata overhead coming from file creation and indexing, which is mostly offset in large writes. On contrary, the LSM tree based packing architecture turns out to be a poor fit for handling large objects, supposedly due to the frequent compaction and resultant write amplification.</p><p>Write Amplification: To validate our reasoning, we measure the total write traffic for each scenario and break down it according to where it comes from. <ref type="figure" target="#fig_1">Figure 2</ref> shows FileStore amplifies write traffic by 8.8x for small writes, leading to the huge write amplification by a file system. When the objects are large, KStore yields larger write amplification than FileStore, paying the additional cost for compaction. Note that FileStore has no compaction because it does not keep objects sorted, depending on file system facilities for object retrieval or traversal. In both object stores, the double-write penalty is observed which arises from write-ahead logging.</p><p>Controllability: <ref type="figure">Figure 1</ref> shows the performance change over time when writing small and large objects for 60s. We can see that FileStore suffers from the periodic performance fluctuation both in small and large writes. In this case, the performance jitter results from the periodic bulky writes invoked by the background file system activities. Specifically, FileStore uses buffered I/O by default, in which updates are buffered in a page cache and batched to storage by a periodic flush daemon or a journaling commit process. This mechanism increases overall I/O performance, but it is detrimental for QoS because it can slow down a system at untimely point.</p><p>KStore manifests with different patterns of performance spikes. Our detailed analysis reveals that the cause of performance fluctuation here lies in the userlevel activity (i.e., compaction), not a file system. Because RocksDB (operating in KStore) holds data in a user-level buffer, instead of making use of the systemlevel page cache, it can avoid the unexpected delay rooted from a page cache. However, without careful consideration, this approach can suffer from a more serious performance problem. For an example, as illustrated in <ref type="figure">Figure 1</ref>, KStore provides a poor performance in large writes, because the frequent compaction of RocksDB decreases I/O bandwidth significantly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">SwimStore</head><p>In the previous section, we examined the pros and cons of two different backend architectures that run atop a local file system. In this section, we present SwimStore, a new backend storage architecture that pursues the following goals: (1) providing excellent performance for various sizes of data, (2) taming performance oscillation by minimizing out-of-control background activities (e.g., compaction, periodic flush) (3) reducing write amplification by eliminating the logging and metadata overhead. We achieve these goals with three key strategies.</p><p>Metadata Immutable Container: Metadata updates are a main source of performance degradation when using a file system as a backend storage. They are particularly problematic when the small data is stored as a file, like in FileStore. Creating a new file, although conceptually simple, involves the update of numerous types of metadata and incurs significant overheads. To avoid this overhead, we use a file as a container for multiple data items thereby amortizing its creation overheads over them. Furthermore, we make the container metadata immutable meaning that the container does not incur the file metadata manipulation when storing objects within it. This concept is realized by creating a group of preallocated files at deployment, eliminating all of the runtime metadata updates associated with file creations and space allocation.</p><p>In-file Shadow Paging: Another problem of using a file system as a storage backend is double writes resulting from write-ahead logging. This behavior can be more harmful in large writes where the performance is determined by the total I/O traffic. Moreover, the writes to the file system after logging are performed by buffered I/Os, which introduce fluctuations in write traffic by periodic flushings. In SwimStore, we use a shadow paging technique where data update is made in an out-of-place manner and the space taken up by old data is recycled after the update is persisted <ref type="bibr" target="#b21">[22]</ref>. In SwimStore, the outof-place update is made to a free area in the container file with the O DIRECT and O DSYNC flags set. This syn-chronous update may increase the response time but its delay can be made comparable to accessing the raw device directly by pre-allocating the file data blocks in advance. Indeed, the shadowing technique is hard to use in conjunction with the LSM tree, because its synchronous and out-of-place write does not allow items to be sorted in a memory buffer, forcing every write to storage. Note that a write request, which needs to be handled with atomicity in the object store, comprises a series of sub-operations involving updates of multiple data and metadata <ref type="bibr" target="#b3">[4]</ref>. To make all updates take place by a primitive action, we use a small intent log that records the location of target data (e.g., file name, offset, and length), and the associated metadata. In the intent log, we record a checksum over not only the data written but also including all the log records of the transaction, thereby safely recovering from a crash without ordering constraints. Slotted Allocation with Hole-punching: In shadow paging, after a data is updated, the old copy becomes garbage and needs to be recycled to make free space. The free space management in general and garbage collection in particular are one of the most difficult problems in storage management systems <ref type="bibr" target="#b23">[24]</ref>. Our approach in this paper is to use multiple container files whose allocation unit sizes are recursively doubled. For example, the first container file may have an allocation unit size of 4 KiB, the second 8 KiB, etc. With this setting, when new data is written, its space allocation is made by the container file whose allocation unit size is best fit. Also, the whole unit is allocated to avoid the need to manage fragments. Similarly, when the allocated space is recycled, the whole allocation unit is returned.</p><p>This space management enables to avoid external fragmentation, but it impedes the aggregation of multiple writes, which is particularly useful optimization for highly concurrent workloads. To hold onto the benefits of aggregated I/O, SwimStore makes use of the hole punching feature <ref type="bibr" target="#b11">[12]</ref> supported by most modern file systems along with slotted allocation. The punch-hole function deallocates physical space associated with the file range, preventing space waste by the file data not in use. By using this feature for bursty writes appropriately, we can achieve the high performance and space efficiency simultaneously.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Performance Evaluation</head><p>The prototype of SwimStore is implemented with 12K LOC in Ceph 12.01 running on Linux 4.4.0. We measure the performance on the same experimental platforms as described in § 3. We create ten container files at the deployment time whose allocation sizes are recursively doubled (4KB to 2MB). The data blocks of container files are pre-allocated by means of fallocate system call. It is noteworthy that Ceph maintains the meta-  <ref type="figure">Figure 3</ref>: IOPS and Total Write Traffic. data for each object, such as object name or timestamp. SwimStore and FileStore both manage the object metadata using the embedded key-value store, which is LevelDB here, because metadata updates are mostly small sized. For performance evaluation, we use the Rados benchmark offered by Ceph <ref type="bibr" target="#b31">[32]</ref> which issues write requests to the object store layer, so as to observe their performances in a more general and clear environment. <ref type="figure">Figure 3</ref> compares the IOPS of different object stores when varying the object size from 4KB to 1MB. For the more practical analysis, we also study BlueStore, which currently serves as the default backend storage of Ceph, managing a raw device directly bypassing a file system. In the figure, we can observe that SwimStore provides excellent performance for the full range of object sizes. This result is contrast to KStore that delivers high IOPS for small writes, but provides drastically decreased performance for large writes. Compared to FileStore, SwimStore offers a twofold performance for varying object sizes. SwimStore also outperforms FileStore and KStore in terms of the write amplification; FileStore and KStore have upto 4.8x and 3x more writes, respectively, compared to SwimStore. This result demonstrates that our strategies devised to reduce the write traffic in object store is highly effective in a real system. <ref type="figure">Figure 3</ref> shows that SwimStore achieves performance comparable to that of BlueStore without the burden of managing the raw block device. SwimStore even outperforms BlueStore for write sizes smaller than 32 KiB. We attribute this performance advantage for small writes to an optimization we perform in SwimStore: wherever possible, we aggregate multiple write operations to improve throughput. We find that this optimization is particularly useful for highly concurrent workloads, which are common in data service platforms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>This paper presents SwimStore, a backend storage architecture for data service platforms that achieves high write performance, low write amplification, and little performance variations, running atop a file system. The prototype of SwimStore built within Ceph outperforms FileStore and KStore which also use a file system, and pro-vides at least competitive performance as compared to BlueStore.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Write Traffic Break-down.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="true"><head>Table 1 : Summary of Data Service Platforms.</head><label>1</label><figDesc></figDesc><table>Type 
Platform 
Backend Structure 
within a File System 

Data Integrity 
Support 

Target 
Environment 
Key-value store RocksDB, LevelDB, HyperLevelDB 
LSM Tree 
Logging 
Local 
Dynamo 
LSM Tree 
Logging 
Distributed 
Document store 
MongoDB, CouchDB 
LSM Tree 
Logging 
Distributed 
Column store 
HBase, BigTable, Cassandra 
LSM Tree 
Logging 
Distributed 
Object store 
Ceph, Swift 
Store item as a File 
Logging 
Distributed 
Distr. File System 
GFS, HDFS 
Store item as a File 
Logging 
Distributed 

ease of development. 
The second approach is to add new features such as 
atomic update to the file system interface </table></figure>

			<note place="foot" n="1"> The O ATOMIC flag support is underway in XFS, but it is neither yet supported in the mainstream kernel nor considered in other file systems [9, 29]. 2 Many file systems use journaling, a form of write-ahead logging, internally but its purpose is for guaranteeing consistency of the file system&apos;s data and metadata, not for supporting an interface for an atomic write [15, 23, 27, 28].</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Acknowledgments</head><p>We thank the anonymous reviewers and ADG members for their insightful comments. This work was supported by Basic Science Research Program through the National Research Foundation of Korea (NRF) funded by the Ministry of Education (No. 2017R1D1A1B03031494).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Apple</forename><surname>Swift</surname></persName>
		</author>
		<ptr target="https://docs.openstack.org/swift/latest/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Bigtable: A distributed storage system for structured data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">C</forename><surname>Wal-Lach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Burrows</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chandra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Fikes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gruber</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">E</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Computer Systems</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="4" />
			<date type="published" when="2008-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">A persistent key-value store</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Facebook</surname></persName>
		</author>
		<ptr target="http://rocksdb.org" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Object storage: The future building block for storage systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Factor</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Meth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Naor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rodeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Satran</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Local to Global Data Interoperability-Challenges and Technologies</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="119" to="123" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Foundation</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">A S</forename><surname>Cassandra</surname></persName>
		</author>
		<ptr target="https://github.com/apache/cassandra" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The google file system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ghemawat</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gobioff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leung</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th ACM Symposium on Operating Systems Principles</title>
		<meeting>the 19th ACM Symposium on Operating Systems Principles<address><addrLine>Bolton Landing, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="29" to="43" />
		</imprint>
	</monogr>
	<note>SOSP &apos;03, ACM</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Google</forename><surname>Leveldb</surname></persName>
		</author>
		<ptr target="http://github.com.google/leveldb" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Analysis of hdfs under hbase: a facebook messages case study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harter</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Borthakur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Aiyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">S</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Arpaci-Dusseau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arpaci-Dusseau</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">H</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th USENIX Conference on File and Storage Technologies</title>
		<meeting>the 12th USENIX Conference on File and Storage Technologies<address><addrLine>Santa Clara, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="199" to="212" />
		</imprint>
	</monogr>
	<note>FAST &apos;14, USENIX Association</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Failure-atomic file updates for linux</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hellwig</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Linux Foundation</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>Linux Piter</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyperdex</forename><surname>Hyperleveldb</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Understanding write behaviors of storage backends in ceph object store</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lee</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-Y</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-S</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-Y</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cho</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 IEEE International Conference on Massive Storage Systems and Technology</title>
		<meeting>the 2017 IEEE International Conference on Massive Storage Systems and Technology</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">LINUX. fallocate punch-hole</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Separating keys from values in ssd-conscious storage</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">U</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Pillai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Gopalakrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Arpaci-Dusseau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arpaci-Dusseau</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">H</forename><surname>Wisckey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Storage (TOS)</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Physical disentanglement in a container-based file system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">U</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Do</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Al-Kiswany</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Arpaci-Dusseau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arpaci-Dusseau</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">H</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th Symposium on Operating Systems Design and Implementation</title>
		<meeting>the 11th Symposium on Operating Systems Design and Implementation<address><addrLine>Broomfield, CO</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="81" to="96" />
		</imprint>
	</monogr>
	<note>OSDI &apos;14, USENIX Association</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The new ext4 filesystem: current status and future plans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathur</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bhattacharya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Dilger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vivier</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Linux Symposium</title>
		<meeting>the Linux Symposium</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="21" to="33" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">ARIES: A transaction recovery method supporting fine-granularity locking and partial rollbacks using writeahead logging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohan</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Haderle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lindsay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Pirahesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Schwarz</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Database Systems</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="94" to="162" />
			<date type="published" when="1992-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mongodb</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Mongodb</surname></persName>
		</author>
		<ptr target="https://www.mongodb.com" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The log-structured merge-tree (lsm-tree)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oneil</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Gawlick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oneil</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acta Informatica</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="351" to="385" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prabhakaran</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Iron File</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Systems</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006-06" />
			<pubPlace>Madison</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of Wisconsin</orgName>
		</respStmt>
	</monogr>
<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A skip list cookbook</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pugh</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">University of Maryland</title>
		<meeting><address><addrLine>Los Angeles, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Building key-value stores using fragmented log-structured merge trees</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raju</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kadekodi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chidambaram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abra-Ham</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Pebblesdb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th Symposium on Operating Systems Principles</title>
		<meeting>the 26th Symposium on Operating Systems Principles<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="497" to="514" />
		</imprint>
	</monogr>
	<note>SOSP &apos;17, ACM</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Database Management Systems. McGraw-Hill Computer Science Series</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramakrishnan</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gehrke</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<publisher>McGraw-Hill</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reiser</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Reiserfs</surname></persName>
		</author>
		<ptr target="https://www.namesys.com" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">The design and implementation of a log-structured file system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rosenblum</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ousterhout</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">K</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Computer Systems</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="26" to="52" />
			<date type="published" when="1992-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">The hadoop distributed file system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shvachko</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Radia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chansler</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th IEEE Symposium on Mass Storage Systems and Technologies</title>
		<meeting>the 36th IEEE Symposium on Mass Storage Systems and Technologies<address><addrLine>Incline Village, NV, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
	<note>MSST &apos;10</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Enabling transactional file access via lightweight kernel extensions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">P</forename><surname>Spillane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gaikwad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chinni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Zadok</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wright</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">P</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th USENIX Conference on File and Storage Technologies</title>
		<meeting>the 7th USENIX Conference on File and Storage Technologies<address><addrLine>San Francisco, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="29" to="42" />
		</imprint>
	</monogr>
	<note>FAST &apos;09, USENIX Association</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Scalability in the xfs file system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sweeney</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Doucette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Nishimoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peck</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the USENIX 1996 Annual Technical Conference</title>
		<meeting>the USENIX 1996 Annual Technical Conference<address><addrLine>San Diego, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
	<note>ATC &apos;96, USENIX Association</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Journaling the linux ext2fs filesystem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tweedie</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Fourth Annual Linux Expo</title>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Failure-atomic updates of application data in a linux file system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Mendez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Mannarswamy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">P</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">B</forename><surname>And Iii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th USENIX Conference on File and Storage Technologies</title>
		<meeting>the 13th USENIX Conference on File and Storage Technologies<address><addrLine>Santa Clara, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="203" to="211" />
		</imprint>
	</monogr>
	<note>FAST &apos;15, USENIX Association</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Io virtualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Waldspurger</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rosenblum</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="page" from="66" to="73" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">a new storage backend for ceph, one year in</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weil</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bluestore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VAULT Linux Storage and Filesystems Conference</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>Linux Foundation</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Ceph: A scalable, high-performance distributed file system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weil</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Brandt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">L</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">D E</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maltzahn</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th Symposium on Operating Systems Design and Implementation</title>
		<meeting>the 7th Symposium on Operating Systems Design and Implementation<address><addrLine>Berkeley, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="307" to="320" />
		</imprint>
	</monogr>
	<note>OSDI &apos;06, USENIX Association</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Extending acid semantics to the file system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wright</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">P</forename><surname>Spillane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sivathanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zadok</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Storage</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<date type="published" when="2007-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Lsm-trie: an lsmtree-based ultra-large key-value store for small data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">U</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 USENIX Conference on Usenix Annual Technical Conference</title>
		<meeting>the 2015 USENIX Conference on Usenix Annual Technical Conference</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="71" to="82" />
		</imprint>
	</monogr>
	<note>USENIX Association</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
