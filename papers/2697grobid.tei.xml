<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2020-09-29T02:50+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Paracloud: Bringing Application Insight into Cloud Operations</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shripad</forename><surname>Nadgowda</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">IBM TJ Watson Research Center</orgName>
								<address>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sahil</forename><surname>Suneja</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">IBM TJ Watson Research Center</orgName>
								<address>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Canturk</forename><surname>Isci</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">IBM TJ Watson Research Center</orgName>
								<address>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Paracloud: Bringing Application Insight into Cloud Operations</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Applications have commonly been oblivious to their cloud runtimes. This is primarily because they started their journey in IaaS clouds, running on a guestOS inside VMs. Then to increase performance, many guestOSes have been paravirtualized making them virtualization aware, so that they can bypass some of the virtualiza-tion layers, as in virtio. This approach still kept applications unmodified. Recently, we are witnessing a rapid adoption of containers due to their packaging benefits, high density, fast start-up and low overhead. Applications are increasingly being on-boarded to PaaS clouds in the form of application containers or appc, where they are run directly on a cloud substrate like Kuber-netes or Docker Swarm. This shift in deployment practices present an opportunity to make applications aware of their cloud. In this paper, we present Paracloud framework for application containers and discuss the Para-cloud interface (PaCI) for three cloud operations namely migration, auto-scaling and load-balancing.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Traditionally applications were deployed on physical servers and they had certain assumptions about their platforms. For example, they will be long running on their platform with dedicated resources. It influenced application design, for instance many applications started allocating large buffer caches to optimize IO. Then as applications started on-boarding on IaaS clouds encapsulated in VM running on guestOS, certain properties about their platform changed. In cloud, they are routinely migrated for maintenance, load balancing, server consolidations; auto-scaled for elasticity in performance and cost. As a result, their operations and management on cloud became inefficient. For example, large buffer caches (although empty) created overhead during live migration. Since applications were oblivious to the cloud platform through abstraction of VMs, much of the invention was done to optimize VMs on this new cloud platform in the form of paravirtualized drivers for memory ballooning <ref type="bibr" target="#b0">[1]</ref>, migrations <ref type="bibr" target="#b1">[2]</ref> <ref type="bibr" target="#b2">[3]</ref>.</p><p>Recently containers started gaining acceptance as a lightweight alternative to virtual machines (VMs), owing to technology maturity and popularization by platforms like Docker <ref type="bibr">[4]</ref>, CoreOSs rocket <ref type="bibr" target="#b3">[5]</ref>, Cloud Foundry Warden <ref type="bibr" target="#b4">[6]</ref>. Containers are being adopted as a foundational vitualization capability in building Platform-asa-Service (PaaS) cloud solutions, e.g. Amazon Container service <ref type="bibr" target="#b5">[7]</ref>, Google Container Engine <ref type="bibr">[8]</ref> and IBMs Container Servicebluemix. And applications are being ported on the PaaS cloud in the form of application containers or appc which are run directly on-top of the cloud substrate like kubernetes, docker swarm or mesos and are truly becoming cloud-native.</p><p>However, across these shifts of the deployment environments, what continues to prevail is the need of incorporating application awareness in the platform management operations <ref type="bibr" target="#b6">[9,</ref><ref type="bibr" target="#b7">10]</ref>. With containers, the communication gap between the application and the cloud management layer has improved further, with removal of the guestOS to facilitate a direct communication channel. Therefore, we believe it is the right time to make applications aware of the characteristics of their cloud platforms and revisit and revise their assumptions about them. Kubernetes, for example, has enabled Downward APIs <ref type="bibr" target="#b8">[11]</ref> and Container hooks <ref type="bibr" target="#b9">[12]</ref> to allow applications to introspect their runtime cluster lifecycle and become cluster native.</p><p>In Paracloud we are extending the notion of 'application knows best' in to container clouds. In this work we propose a uniform Paracloud interface (PaCI) to enable a bi-directional communication channel between application containers and the cloud management substrate. We highlight the benefits of PaCI in terms of incorporating application-awareness at the cloud management layer, as well as cloud-awareness at the applications level, with three use-cases namely migration, auto-scaling and loadbalancing. We describe PaCI's design for one of the most popular container cloud platform i.e. kubernetes, and evaluate its benefits for an auto-scaling use case.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background and Related Work</head><p>Taking example of the Linux kernel, since the early days, it has been positioned as a general-purpose operating system to host all kinds of application, taking responsibility for managing memory, scheduling, file-access for them all. But as different applications started posing different behavior and requirements, kernel allowed applications to share their anticipated file or memory access behaviour via system calls such as f advise or madvise as <ref type="figure">Figure 1</ref>: Application runtime evolution shown in <ref type="figure">Fig. 1(a)</ref>. Using these hints to choose the appropriate read-ahead and caching techniques enabled kernel to improve application performance and avoid redundant operations. The benefits of such hints have been reported for several applications <ref type="bibr" target="#b10">[13,</ref><ref type="bibr" target="#b11">14,</ref><ref type="bibr" target="#b12">15,</ref><ref type="bibr" target="#b13">16,</ref><ref type="bibr" target="#b14">17,</ref><ref type="bibr" target="#b16">18]</ref> and distributed filesystems <ref type="bibr" target="#b17">[19,</ref><ref type="bibr" target="#b18">20,</ref><ref type="bibr" target="#b19">21]</ref>. Java runtime on the other hand has taken an approach to manage heap memory by itself in JVM to insulate from host machine's peculiarities and also because it can manage memory better by identifying and garbage collecting orphaned objects.</p><p>Applications today are increasingly being hosted directly on top of container clouds like kubernetes, docker swarm and mesos in the form of application containers. Like their traditional counterparts, these clouds are becoming a general-purpose operating platform to host various kinds of applications (containers). However, they have to additionally deal with the management concerns similar to those of VM clouds. The need for application awareness has long been recognized in literature, and the fact that an application is deployed in cloud makes it ever more important <ref type="bibr" target="#b20">[22,</ref><ref type="bibr" target="#b21">23,</ref><ref type="bibr" target="#b7">10,</ref><ref type="bibr" target="#b22">24,</ref><ref type="bibr" target="#b23">25]</ref>.</p><p>Moving over to higher level management tasks, benefits of application assistance has been explored in both physical and virtual systems, in the context of faulttolerance <ref type="bibr" target="#b6">[9,</ref><ref type="bibr" target="#b24">26]</ref>, physical memory management <ref type="bibr" target="#b25">[27]</ref>, checkpointing <ref type="bibr" target="#b6">[9]</ref>, migration <ref type="bibr" target="#b26">[28]</ref>, QoS adherence <ref type="bibr" target="#b27">[29,</ref><ref type="bibr" target="#b20">22]</ref>, memory overcommitment <ref type="bibr" target="#b28">[30,</ref><ref type="bibr" target="#b29">31]</ref>, load balancing <ref type="bibr" target="#b30">[32]</ref> and scaling <ref type="bibr" target="#b22">[24,</ref><ref type="bibr" target="#b31">33,</ref><ref type="bibr" target="#b32">34]</ref>. Others have also explored moving management functionailites into the application itself <ref type="bibr">[4]</ref>. Alternatives to using applications level knowledge for management tasks have also been explored via statistical learning and prediction-based approaches <ref type="bibr" target="#b33">[35,</ref><ref type="bibr" target="#b34">36,</ref><ref type="bibr" target="#b35">37]</ref>.</p><p>In the past, different techiques have been employed to extract application level knowledge for aiding management operation. This includes installing paravirtualization drivers <ref type="bibr" target="#b26">[28]</ref>, in-guest controller agents <ref type="bibr" target="#b24">[26,</ref><ref type="bibr" target="#b36">38,</ref><ref type="bibr" target="#b37">39,</ref><ref type="bibr" target="#b32">34]</ref> (both referred to as PVD in <ref type="figure">Fig. 1(b)</ref>), leveraging or extending language runtime capabilities like apache modules or JDBC interfaces <ref type="bibr" target="#b28">[30]</ref>, or modifying the application directly <ref type="bibr" target="#b38">[40]</ref>.</p><p>With containers clouds, the principle of 'application knows best' does not change. What does change is the nature of the interface between applications and the hosting layer, which becomes closer to the traditional systems with the removal of the guestOS abstraction of VMs. Also, the scale of management operations grows, owing to an even greater flexibility and elasiticity afforded by the container abstraction.</p><p>Thus, with a similar intention of incorporating application-awareness at the cloud management layer, as well as cloud-awareness at the application level, the goal of our work is to provide a uniform interface (PaCI in <ref type="figure">Fig. 1(c)</ref>) to enable such bi-directional communication. One way to realize this channel for container-based OS virtualization is via a generic signal-and-syscall (or ioctl) based implementation. However, in this work we present an implementation for a higher-level abstraction layer for easier consumability, by targeting the popular Kubernetes container platform.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Paracloud Orchestration Usecases</head><p>Amongst various cloud management tasks, here we specifically target three operations -namely migration, auto-scaling and load-balancing, to highlight how our Paracloud interface can help make them more efficient for both the application and the cloud management layer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Migration</head><p>Although migration may seem redundant for stateless application containers, it is still pertinent to several stateful microservice applications like databases (e.g., Mysql, Cassandra), message brokers (kafka), and coordination services (zookeeper), amongst others. This is being acknowledged and supported in standard frameworks like Kubernetes' 'StatefulSet'. Portability of stateful containers is also explored in existing solutions like ClusterHQ's Flocker <ref type="bibr" target="#b39">[41]</ref>, Virtuozzo <ref type="bibr" target="#b40">[42]</ref> and Picocenter <ref type="bibr" target="#b41">[43]</ref>. At the same time, it has certain inefficiencies that we would like to address below.</p><p>During initialization, many applications, like databases, tend to allocate large memory buffers to optimize their IO operations. Similarly, application runtimes, like JVM, allocate large operating heap memory which they manage themselves such as via custom garbage collection policies. This becomes a problem when such application containers are to be migrated 1 . In stop-and-copy based migration, this increases application downtime by also migrating non-dirty or unused, speculatively cached or to-be-garbage-collected pages. Although the downtime is lower for pre-copy or postcopy migration, unnecessary page transfer processing on an already troubled host (that influenced application offloading in the first place), possibly also coupled with a congested network outflow, can still slow down the readiness of a migrated application.</p><p>Although it may be possible to add certain memory filtration heuristics to the migration process, but the application can do a far better job of minimizing its state for checkpointing or transfer. Therefore, in Paracloud we propose signaling an application container to be migrated, and allowing a short migration grace-period for 'preparation'. This allows application to minimize its memory footprint, for example by running its garbage collector to release heap-memory, flushing its IO buffers, releasing all temporary resources like temp files. It can even exercise aggressive eviction on its cache by flushing less common objects, or optionally settle at a consistent state pre-transfer. Similarly, on restoration at the target, the application container is signaled to re-configure itself to the new environment. During restore grace-period, application can perform sanity checks, re-acquire its memory share for caching, as well as any temporary or lost resources like network connections, register its service, and re-discover other services.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Auto-scaling</head><p>It is one of the core capability for any cloud platform to enable elasticity for their workloads. Policy-based scaling techniques, which are common in today's clouds, scale out instances when certain resource-use metrics grow beyond a particular threshold. For instance, a sample policy could be to increase container instances when the average memory utilization of the container is greater than 70% for a duration of 1 minute. We argue that such externally monitored metrics may not be true indicators of demand to derive auto-scaling policies. For example, most database applications(e.g. Mysql, ElasticSearch) tend to perform various auxiliary functions besides storing and accessing data, like periodic log rotation, data compaction, data pruning, auditing and consistency checks etc. These functions are commonly designed to exploit slack. They consume resources over the actual workload processing when there are free cycles, and can cause false-positive auto-scaling triggers. Another issue with black-box triggers is that several modern applications are designed to respond to their operat-ing environment constraints. For example, ElasticSearch (ES) aims to keep as much of its index in memory. Therefore, a memory-based auto-scaling trigger, oblivious to this behavior, can start scaling number of ES instances once memory grows beyond a certain threshold, as the new instances start to grow their memory footprint, it continues to further scale up the instances, resulting in a chain reaction.</p><p>In contrast, Paracloud provides a way for an application to indicate whether it really desires new instances to be forked, given its current operational state. The auto-scaler on sensing an increased usage beyond the set threshold, can signal the container indicating an upcoming scaling operation, allowing it to optionally dictate its intention. The application can validate the trigger against its actual state, and try to minimize usage of some resources if its operational state allows, for example by running its garbage collector or flushing some caches and buffers. This gives cloud users a trade-off knob, where they can intelligently balance performance and operational cost.</p><p>Another use of Paracloud interface is for the application to itself proactively hint the auto-scaler for a more prompt service, based on its key performance indicators. Furthermore, Paracloud also enables an application container to specify the type of sibling instances it needs. Auto-scaling typically forks a brand-new instance which then has to be initialized, configured and cache-warmed, thereby delaying the achievement of steady-state performance for the application as a whole. Instead, it may be advantageous to hot-scale the instance with a preinitialized state and a warm cache <ref type="bibr" target="#b42">[45]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Load Balancing</head><p>A cloud host's resources (CPU, memory, IO) are usually over-committed to save costs by increasing density (i.e. number of colocated instances existing at any given time). During high resource contention, some of the instances (containers) are either killed or migrated. These may be selected based upon their priorities or current resource allocations. For example, one common practice is to kill containers consuming most resources. But intuitively, those could be amongst the most active and/or stateful containers on the host, which could have been kept running by killing other less-active and/or stateless applications' instances (a stateful application gets hurt worse, having to re-warm its cache on reinstanitaition <ref type="bibr" target="#b42">[45]</ref>).</p><p>Such scenarios can be handled better by tying Paracloud with cloud load balancers. Cloud applications are typically deployed as "replica sets", with multiple identical instances available at any given time, which are loadbalanced by an ingress controller like haproxy <ref type="bibr" target="#b43">[46]</ref>. With Paracloud, we propose to expose an appYield interface between containers and the cloud platform, enabling applications to yield themselves temporarily during high resource contentions, similar to Linux' sched yieldbased co-operative scheduling <ref type="bibr" target="#b44">[47]</ref>. For a host under pressure, its containers get notified with a yield request notification. Such notification would contain information about the resource under contention, and the health status of the container's replica/peer instances. An application can then decide to yield, releasing the contended resource, or risk termination. The load-balancer would temporarily tag the instance out-of-service, bringing it back into action once the resource contention smoothes out. Essentially, the application stays alive but dormant. Similarly, the application can also advertise its statefulness over Paracloud so that the host can accordingly target a 'less critical' application if possible. It is important to acknowledge that such co-operative scheduling is helpful only when the resource contention is transient, and work better with the existence of some 'incentive' schemes for applications to yield, than perhaps with the autocratic yield-or-die regime.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">System Design</head><p>We design Paracloud interfaces to ensure consumability and simplicity. Therefore PaCIs are implement on the Kubernetes container platform. Kubernetes advocates building applications that are cluster-aware and has basic machinery in place in the form of Container Lifecycle Hooks <ref type="bibr" target="#b9">[12]</ref> to inform containers about management lifecycle events. Currently two container hooks are facilitated, PostStart and PreStop. PostStart hook is called immediately after container is created and PreStop hook is called before it is terminated. These hooks are captured and processed inside container in hook handlers. Kubernetes supports two handler types, Exec to execute a command or script in container namespace, and HTTP to invoke a specified http endpoint of container. Application containers that participate in cluster lifecycle are termed as cluster-native.</p><p>In Paracloud we motivate the extension of the scope of cluster-native applications beyond just lifecycle events to critical cloud operations like auto-scaling, migration and load-balancing. We have currently designed six new interfaces for Kubernetes substrate as summarized in <ref type="table">Table  1</ref>. We envision addition of new interfaces in support of other Paracloud operations like placement, compliance, security and monitoring.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">PaCI Definitions</head><p>PaCIs are completely optional for applications. Therefore hook handler invocations are not retried on cloud platform and all PaCIs are designed as asynchronous so they do not block any cloud operation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PaCI</head><p>Delivery guarantees preMigrate↑ at-most-once postRestore↑ at-most-once reqYield↑ at-least-once appYield↓ -chkAutoscale↑ at-least-once hotScale↓ - <ref type="table">Table 1</ref>: Paracloud Interfaces; ↑ = interface implementation as a container hook; ↓ = extension to Kubernetes API set.</p><p>Migration: The preMigrate hook is sent after container is scheduled for migration but before it is checkpointed. postRestore hook is sent after container is restored to running state and before it is reported as available. Both these hooks follow at-most-once delivery guarantees since the hook handler might not be idempotent. Applications can have different grace-period requirements to process hook handlers. Therefore, we allow applications to configure these grace-periods as container labels.</p><p>Load-balancing: When a compute node is heavily loaded, cloud platform invokes reqYield hook on all containers on that node. It follows at-least-once guarantee since a hook might be called multiple times during the lifetime of application container. The hook handler in response evaluates yield chances and calls appYield API on Kubernetes if it decides to yield reseources. Multiple appYield calls are processed in the same order they are received. When the node load drops to an acceptable level, the remaining yield calls are ignored. Containers for which yield call is accepted are temporarily removed from load-balancer.</p><p>Auto-scaling: For every auto-scale triggered on the platform, the chkAutoscale hook is called on the corresponding containers to validate the scaling request. This gives the applications a chance to mitigate the auto-scaling conditions in the case of false positives. In the handler, containers can release the heavily-used resources to clear the trigger. For example, when high memory usage triggers an auto-scale, the application can employ garbage collection or flush caches to reduce its footprint. This hook also allows a configurable grace-period for handler processing and mitigation actions. If the auto-scale condition still holds true after grace-period, application scaling is implemented by the platform. If the application wants to hot scale by creating a clone of one of its running instance, it calls hotScale API on Kubernetes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">PaCI Sidecar Implementation</head><p>In Paracloud we implement hook handlers and the Kubernetes client for PaCI calls in sidecar containers. Sidecar containers are a common microservice composite container pattern for providing supporting services, such  <ref type="formula">9 12 15 18 21 24 27 30 33 36 39 42</ref>   as service discovery and logging, to main application containers by creating new containers that share namespaces with them. The important benefit of this pattern is that the sidecar containers can be developed independently without changing applications. Most PaCIs actions, like garbage collection, cache flush, post-restore service registration, evaluating auto-scale criteria can be implemented in sidecar containers with minimum disruption and high consumability by most applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Evaluation</head><p>In this paper we focus on the auto-scaling use-case for Paracloud. As described in the previous section, Paracloud uses the chkAutoscale hook to inform the container of an autoscale trigger and the hotScale API to actuate a hot scale if requested by the container. Traditionally, auto-scaling uses cold scaling, wherein new container instances are created from a pristine image. In hot scale new instances are created by live-cloning the running state of the container. In the below experimental evaluation we show how an application can optimize its performance by judiciously employing hot scaling when advantageous.</p><p>We use MySQL 5.7.15 from Docker Hub as our test application and YCSB <ref type="bibr" target="#b45">[48]</ref> as the benchmark. The container is configured with 512MB memory. The workload consists of two runs of 400K read operations against a 200MB database table consisting of 50K records of 4KB size each. The Kubernetes cluster triggers an autoscale when container used memory &gt;80% for more than 30 seconds. We use Haproxy to arbitrate requests among multiple instances using the round-robin policy. We also enable query cache for MySQL engine and monitor its rate of low memory pruning.</p><p>We run two sets of experiments with different access patterns, zip f ian for popularity-based long tail access and uni f orm for random access pattern. The application exhibits similar memory usage in both experiments, as shown in <ref type="figure">Fig. 2(a)</ref>. This usage pattern triggers an autoscale at around 50s, which is communicated to the container via chkAutoscale. In each experiment the application can respond in one of three ways: (i) do nothing, which triggers a cold autoscale; (ii) take mitigating actions, such as releasing memory resources, to revert the autoscale trigger; and (iii) request a hotScale. In our evaluation we exercise the first and third options. This shows that requesting a hotScale for the zip f ian access leads to significant performance improvements, while employing cold scaling performs better for uni f orm. <ref type="figure">Fig. 2(b)</ref> shows the results for zip f ian. Containertriggered hot scaling helps reduce the latency of application by˜20%by˜ by˜20% immediately. In comparison, cold scaling requires a ramp-up time for cache warming to attain the same performance. 2(c) shows the contrasting results for uni f orm. In this case, the container does not initiate a hotScale. As a result cold scaling is applied, which improves performance by reducing latency by 20%. The figure also shows the latency if hot scaling were applied, where it actually deteriorates performance. These results demonstrate the substantial advantages with Paracloud providing application insight in cloud operations.</p><p>While the advantage of hot scaling in zip f ian is expected, its negative effect for uni f orm is interesting. This is because with with hot scaling applications can inherit bad state as well as good state. Only judicious application of scaling techniques, driven by the applications themselves, can lead to net benefits. In the uni f orm case, the hot scaled container inherits the thrashing state of the MySQL query cache which dampens the initial scale-out gain. This can be observed from the high pruning rate of uni f orm in <ref type="figure">Fig. 2(a)</ref>. Cold scaling in such scenarios performs fundamentally better since it removes cache pruning overheads and only incurs cold cache miss latencies. Thus, the containerized application can simply use this additional pruning rate signal to decide on when to request hotScale, while the container runtime is oblivious to these characteristics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We presented our Paracloud idea for container clouds, wherein application insights are brought into the cloud platform thorough a generic Paracloud interface (PaCI). The critical inference here is that applications have intimate knowledge of their own operating state parameters, which are typically different for every application. The cloud platform cannot gauge these parameters reli-ably for all applications. Paracloud can help bridge this gap and provide a shared-responsibility model, where all the cloud functions like auto-scaling, migration, loadbalancing, etc. are implemented by the platform with application insight and cooperation through PaCIs. We are planning to extend the scope of PaCI to cover many more cloud operations and establish them as a standard design choice during application development.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Discussion</head><p>First, we would like to establish that Paracloud framework is beneficial for both application developers and cloud providers. For developers there's motivation to make their applications more agile, cost-efficient, consistent and highly elastic on clouds, while for providers it helps ease their operational overheads for different kinds of applications and satisfy SLAs. How disruptive is this model ? As illustrated above for auto-scaling use case, few common PaCIs can be implemented as a sidecar containers for applications. But, some PaCIs requires support from the applications with revision in their design and implementation, for example, to release resources during migration, acquiring resources for vertical auto-scaling, identifying and bookkeeping of relevant operational states etc. But, we believe this is an incremental feature addition as-oppose to the complete application re-modeling imposed by eventdriven serverless architectures or single address space unikernels. How secure are these interfaces? Although not limited by design, currently we are regulating applicability of Paracloud to a single tenant platform wherein different hosted applications have trust amongst their peers. But, at the same time we are doing security profiling of PaCIs by evaluating their security implications and any possible exploitation in multi-tenant environments, so they can be hardened. Open Issues: (i) Should PaCI be vendor-agnostic, perhaps via a signal-and-syscall implementation? (ii) Better incentives than yield-or-die may be needed for less crude, escalation inhibitive, and more harmonious existence in the load balancing scenario. (iii) Whether PaCIs are applicable for non-containerized deployments ?</p></div>
			<note place="foot" n="1"> Several container runtimes today support migration; Docker, for example, achieves this via the popular CRIU [44] checkpoint-restore Linux utility.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Memory resource management in vmware esx server</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Carl A Waldspurger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGOPS Operating Systems Review</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">SI</biblScope>
			<biblScope unit="page" from="181" to="194" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Post-copy based live virtual machine migration using adaptive pre-paging and dynamic self-ballooning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kartik</forename><surname>Hines</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gopalan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2009 ACM SIGPLAN/SIGOPS international conference on Virtual execution environments</title>
		<meeting>the 2009 ACM SIGPLAN/SIGOPS international conference on Virtual execution environments</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="51" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Application-assisted live migration of virtual machines with java applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai-Yuan</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan-Lung</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth European Conference on Computer Systems</title>
		<meeting>the Tenth European Conference on Computer Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page">15</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Coreos</surname></persName>
		</author>
		<ptr target="https://coreos.com/rkt/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cloudfoundry</surname></persName>
		</author>
		<ptr target="https://github.com/cloudfoundry/warden" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title/>
		<ptr target="https://aws.amazon.com/ecs/" />
	</analytic>
	<monogr>
		<title level="j">Amazon EC2 Container Service</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Software implemented fault tolerance: Technologies and experience</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yennun</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chandra</forename><surname>Kintala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">FTCS</title>
		<imprint>
			<date type="published" when="1993" />
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="2" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Self-managing cloud-native applications: Design, implementation, and experience. Future Generation Computer Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giovanni</forename><surname>Toffetti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandro</forename><surname>Brunner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Blöchlinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Spillner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">Michael</forename><surname>Bohnert</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kubernetes</surname></persName>
		</author>
		<ptr target="https://kubernetes.io/docs/user-guide/downward-api/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Container lifecycle hooks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kubernetes</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Lucene and fadvise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Mccandless</surname></persName>
		</author>
		<ptr target="http://blog.mikemccandless.com/2010/06/lucene-and-fadvisemadvise.html" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Solr / Lucene madvise performance ?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Bowyer</surname></persName>
		</author>
		<ptr target="http://people.apache.org/~gbowyer/madvise-perf/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<ptr target="https://github.com/mongodb/mongo/tree/master/src/third_party/gperftools-2.5" />
		<title level="m">Google Performance Tools system alloc in MoongoDB</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Using direct I/O with Oracle</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Don</forename><surname>Burleson</surname></persName>
		</author>
		<ptr target="http://www.dba-oracle.com/art_orafaq_oracle_direct_io.htm" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mysql</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Optimizing InnoDB Disk I</title>
		<ptr target="https://dev.mysql.com/doc/refman/5" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Tuning RRDtool for performance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tobias</forename><surname>Oetiker</surname></persName>
		</author>
		<ptr target="http://oss.oetiker.ch/rrdtool-trac/wiki/TuningRRD" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Add HDFS support for fadvise readahead and drop-behind</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hdfs</forename><surname>Hadoop</surname></persName>
		</author>
		<ptr target="https://issues.apache.org/jira/browse/HDFS-2465" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hildebrand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Myklebust</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Falkner</surname></persName>
		</author>
		<ptr target="http://www.potaroo.net/ietf/idref/draft-hildebrand-nfsv4-fadvise/" />
		<imprint/>
		<respStmt>
			<orgName>NFSv4 Working Group</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Lustre File System Acceleration Using Server or Storage-Side Caching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Coomer</surname></persName>
		</author>
		<ptr target="http://www.opensfs.org/wp-content/uploads/2014/04/D2S27LustreFileSystemAccelerationUsingServerorStorageSide-Caching.pdf" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Cloud monitoring for optimizing the qos of hosted applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Khalid</forename><surname>Alhamazani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajiv</forename><surname>Ranjan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fethi</forename><surname>Rabhi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lizhe</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karan</forename><surname>Mitra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2012 IEEE 4th International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="765" to="770" />
		</imprint>
	</monogr>
	<note>Cloud Computing Technology and Science</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Incorporating uncertainty into incloud application deployment decisions for availability</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qinghua</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiwei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liming</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Len</forename><surname>Bass</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhanwen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sherif</forename><surname>Sakr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Paul L Bannerman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Sixth International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="454" to="461" />
		</imprint>
	</monogr>
	<note>Cloud Computing (CLOUD)</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">An extreme automation framework for scaling cloud applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lr Jian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IBM Journal of Research and Development</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="8" to="9" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Analyzing auto-scaling issues in cloud environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanieh</forename><surname>Alipour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abdelwahab</forename><surname>Hamoulhadj</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 24th Annual International Conference on Computer Science and Software Engineering</title>
		<meeting>24th Annual International Conference on Computer Science and Software Engineering</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="75" to="89" />
		</imprint>
	</monogr>
	<note>IBM Corp.</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">End-to-end arguments in system design</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jerome</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Saltzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David D</forename><surname>David P Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Computer Systems (TOCS)</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="277" to="288" />
			<date type="published" when="1984" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Application-assisted physical memory management</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sitaram</forename><surname>Iyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juan</forename><surname>Navarro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Druschel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<publisher>Citeseer</publisher>
		</imprint>
	</monogr>
<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Application-assisted live migration of virtual machines with java applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai-Yuan</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan-Lung</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth European Conference on Computer Systems</title>
		<meeting>the Tenth European Conference on Computer Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page">15</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Q-clouds: managing performance interference effects for qos-aware clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ripal</forename><surname>Nathuji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aman</forename><surname>Kansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alireza</forename><surname>Ghaffarkhah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th European conference on Computer systems</title>
		<meeting>the 5th European conference on Computer systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="237" to="250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Applications know best: Performancedriven memory overcommit with ginkgo</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abel</forename><surname>Michael R Hines</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcio</forename><surname>Gordon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilma Da</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyung</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muli</forename><surname>Ryu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Benyehuda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Cloud Computing Technology and Science (CloudCom)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="130" to="137" />
		</imprint>
	</monogr>
	<note>IEEE Third International Conference on</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Memory overbooking and dynamic control of xen virtual machines in consolidated environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jin</forename><surname>Heo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pradeep</forename><surname>Padala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhikui</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Integrated Network Management, 2009. IM&apos;09. IFIP/IEEE International Symposium on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="630" to="637" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Leveraging endpoint flexibility in dataintensive clusters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mosharaf</forename><surname>Chowdhury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srikanth</forename><surname>Kandula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ion</forename><surname>Stoica</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGCOMM Computer Communication Review</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013" />
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="231" to="242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Auto-scaling to minimize cost and meet application deadlines in cloud workflows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marty</forename><surname>Humphrey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">High Performance Computing, Networking, Storage and Analysis (SC), 2011 International Conference for</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Enabling cost-aware and adaptive elasticity of multi-tier cloud applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Moustafa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Ghanem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yike</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michelle</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Osmond</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Future Generation Computer Systems</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="82" to="98" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Press: Predictive elastic resource scaling for cloud systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenhuan</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohui</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Wilkes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Network and Service Management (CNSM), 2010 International Conference on</title>
		<imprint>
			<publisher>Ieee</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="9" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Improving management of distributed services using correlations and predictions in sla-driven cloud computing systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandru-</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Antonescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Torsten</forename><surname>Braun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Network Operations and Management Symposium (NOMS)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Empirical prediction models for adaptive resource provisioning in the cloud</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sadeka</forename><surname>Islam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacky</forename><surname>Keung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Future Generation Computer Systems</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="155" to="162" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Appraise: application-level performance management in virtualized server environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhikui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Gmach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharad</forename><surname>Singhal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><forename type="middle">J</forename><surname>Watson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wilson</forename><surname>Rivera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><forename type="middle">D</forename><surname>Hyser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Network and Service Management</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Andreas Menychtas, and Theodora Varvarigou. A self-adaptive hierarchical monitoring mechanism for clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Katsaros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Kousiouris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Spyridon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimosthenis</forename><surname>Gogouvitis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kyriazis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Systems and Software</title>
		<imprint>
			<biblScope unit="volume">85</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1029" to="1041" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Dynamic resource management on distributed systems using reconfigurable applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>José</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><forename type="middle">K</forename><surname>Moreira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Naik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IBM Journal of Research and Development</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="303" to="330" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Clusterhq</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Flocker</surname></persName>
		</author>
		<ptr target="https://docs.clusterhq.com/en/1.0.3/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Containers checkpointing and live migration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrey</forename><surname>Mirkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Kuznetsov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kir</forename><surname>Kolyshkin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Linux Symposium</title>
		<meeting>the Linux Symposium</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="85" to="92" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Supporting long-lived, mostlyidle applications in cloud environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Litton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Cangialosi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theophilus</forename><surname>Benson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dave</forename><surname>Levin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Mislove</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Picocenter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EuroSys&apos;16</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page">37</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Comparing scaling methods for linux containers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shripad</forename><surname>Nadgowda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sahil</forename><surname>Suneja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Kanso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">To appear in the IEEE Third International Workshop on Container Technologies and Container Clouds</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">The Reliable, High Performance TCP/HTTP Load Balancer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Haproxy</surname></persName>
		</author>
		<ptr target="http://www.haproxy.org/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Linux Programmer&apos;s Manual. sched yieldyield the processor</title>
		<ptr target="http://man7.org/linux/man-pages/man2/sched_yield.2.html" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Benchmarking cloud serving systems with ycsb</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Brian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Cooper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erwin</forename><surname>Silberstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raghu</forename><surname>Tam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Russell</forename><surname>Ramakrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sears</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st ACM symposium on Cloud computing</title>
		<meeting>the 1st ACM symposium on Cloud computing</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="143" to="154" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
