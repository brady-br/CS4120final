<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2020-10-16T20:10+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">KyotoEBMT System Description for the 2nd Workshop on Asian Translation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Richardson</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raj</forename><surname>Dabre</surname></persName>
							<email>dabre@nlp.ist.i.kyoto-u.ac.jp</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenhui</forename><surname>Chu</surname></persName>
							<email>chu@pa.jst.jp</email>
							<affiliation key="aff1">
								<orgName type="institution">Japan Science and Technology Agency</orgName>
								<address>
									<addrLine>Kawaguchi-shi</addrLine>
									<postCode>332-0012</postCode>
									<settlement>Saitama</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabien</forename><surname>Cromières</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Japan Science and Technology Agency</orgName>
								<address>
									<addrLine>Kawaguchi-shi</addrLine>
									<postCode>332-0012</postCode>
									<settlement>Saitama</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Toshiaki</forename><surname>Nakazawa</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Japan Science and Technology Agency</orgName>
								<address>
									<addrLine>Kawaguchi-shi</addrLine>
									<postCode>332-0012</postCode>
									<settlement>Saitama</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sadao</forename><surname>Kurohashi</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Graduate School of Informatics</orgName>
								<orgName type="institution">Kyoto University</orgName>
								<address>
									<postCode>606-8501</postCode>
									<settlement>Kyoto</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">KyotoEBMT System Description for the 2nd Workshop on Asian Translation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>This paper introduces the Ky-otoEBMT example-based machine translation framework. Since last year&apos;s workshop we have replaced input trees with forests, improved alignment, added new features, and introduced bilingual neural network reranking. The major benefits of our system include online example retrieval and flexible reordering. We also use syntactic dependency analysis for both source and target languages in the hope of learning how to translate non-local structure. The system implementation (this paper refers to version 1.0) is available as open-source.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>This paper describes the KyotoEBMT system used in the 2nd Workshop on Asian Translation <ref type="bibr" target="#b17">(Nakazawa et. al, 2015)</ref>.</p><p>Our system is a fully-fledged ExampleBased Machine Translation (EBMT) platform making use of both source-language and target-language dependency structure. This approach has been explored comparatively less in studies on syntax-based SMT/EBMT, which tend to focus on constituent trees rather than dependency trees, and on tree-to-string rather than tree-to-tree approaches. Furthermore, we employ separate dependency parsers for each language rather than projecting the dependencies from one language to another, as in <ref type="bibr" target="#b23">(Quirk et. al, 2005</ref>).</p><p>The dependency structure information is used end-to-end: for improving the quality of the alignment of the translation examples, for constraining the translation rule extraction and for guiding the decoding. We believe that dependency structure, which considers more than just local context, is important in order to generate fluent and accurate translations of complex sentences across distant language pairs.</p><p>The experiments described in this paper focus on technical domain translation for Japanese-Chinese and Japanese-English, however our implementation is applicable to any domain and language pair for which there exist parallel sentences and dependency parsers.</p><p>A further unique characteristic of our system is that, again contrary to the majority of similar systems, it does not rely on precomputation of translation rules. Instead it matches each input sentence to the full database of translation examples before extracting translation rules online. This has the merit of maximizing the information available when creating and combining translation rules, while retaining the ability to produce excellent translations for input sentences similar to an existing translation example.</p><p>The system is mostly developed in C++ and is available as open source. The code and documentation are available from http://nlp.ist.i.kyoto-u.ac.jp/kyotoebmt/. Experiments are facilitated through the inclusion of an end-to-end experiment management system (EMS) which has been greatly improved in this version. The framework is simple to use and supports model training with multiple threads or across a cluster. <ref type="figure">Figure 1</ref> shows the basic structure of the KyotoEBMT translation pipeline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">System Overview</head><p>The training process begins with parsing and aligning parallel sentences from the training corpus. The alignments are then used to build an example database ('translation mem- <ref type="figure">Figure 1</ref>: The translation pipeline can be roughly divided in 3 steps.</p><p>Step 1 is the creation of the example database, trained from a parallel corpus. Step 2 is the parsing of an input sentence and the generation of sets of initial hypotheses. Step 3 consists in decoding and reranking. The tuning of the weights for decoding and reranking is done by a modified version of step 3. ory') containing 'examples' or 'treelets' that form the hypotheses to be combined during decoding.</p><p>Translation is performed by first parsing an input sentence then searching for treelets matching entries in the example database. The retrieved treelets are combined by a lattice-based decoder that optimizes a log linear model score. Finally, we use a reranker to select the optimal translation from the n-best list provided by the decoder using additional non-local features (see section 3.4). <ref type="figure">Figure 2</ref> shows the process of combining examples matching the input tree to create an output sentence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Example retrieval and translation hypothesis construction</head><p>An important characteristic of our system is that we do not extract and store translation rules in advance: the alignment of translation examples is performed offline. However, for a given input sentence i, the steps for finding examples partially matching i and extracting their translation hypotheses is an online process. This approach could be considered to be more faithful to the original EBMT approach advocated by <ref type="bibr" target="#b18">Nagao (1984)</ref>. It has already been proposed for phrase-based <ref type="bibr" target="#b1">(Callison- Burch et al., 2005</ref>), hierarchical <ref type="bibr" target="#b14">(Lopez, 2007)</ref>, and syntax-based ( <ref type="bibr" target="#b6">Cromières and Kurohashi, 2011</ref>) systems. It does not however, seem to be very commonly integrated in syntax-based MT. This approach has several benefits. The first is that we are not required to impose a limit on the size of translation hypotheses. Systems extracting rules in advance typically restrict the size and number of extracted rules for fear of becoming unmanageable. In particular, if an input sentence is the same or very similar to one of our translation examples, we will be able to retrieve a perfect translation. A second advantage is that we can make use of the full context of the example to assign features and scores to each translation hypothesis.</p><p>The main drawback of our approach is that it can be computationally more expensive to retrieve arbitrarily large matchings in the example database online than it is to match precomputed rules. We use the techniques described in <ref type="bibr" target="#b6">Cromières and Kurohashi (2011)</ref> to perform this step as efficiently as possible.</p><p>Once we have found an example translation (s, t) for which s partially matches i, we proceed to extract a translation hypothesis from it. A translation hypothesis is defined as a generic translation rule for a part p of the input sentence that is represented as a targetlanguage treelet, with non-terminals representing the insertion positions for the translations of other parts of the sentence. A translation hypothesis is created from a translation example as follows:</p><p>1. We project the part of s that is matched into the target side t using the alignment of s and t. This is trivial if each word of s and t is aligned, but this is not typically the case. Therefore our translation hypotheses will often have some target words/nodes marked as optionals: this means that we will decide if they should be added to the final translation only at the moment of combination.</p><p>2. We insert the non-terminals as child nodes of the projected subtree. This is <ref type="figure">Figure 2</ref>: The process of translation. The source sentence is parsed and matching subtrees from the example database are retrieved. From the examples, we extract translation hypotheses than can contain optional target words and several position for each non-terminals. For example the translation hypothesis containing "textbook" has three possible position for the non-terminal X3 (as a left-child before "a", as a left-child after "a" or as a right-child). The translation hypotheses are then combined during decoding. Choice of optional words and final non-terminal positions is also done during decoding. simple if i, s and t have the same structure and are perfectly aligned, but again this is not typically the case. A consequence is that we will sometimes have several possible insertion positions for each non-terminal. The choice of insertion position is again made during combination.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Decoding</head><p>After having extracted translation hypotheses for as many parts of the input tree as possible, we need to decide how to select and combine them. Our approach here is similar to what has been proposed for Corpus-Based Machine Translation. We first choose a number of features and create a linear model scoring each possible combination of hypotheses (see Section 3.3). We then attempt to find the combination that maximizes this model score.</p><p>The combination of rules is constrained by the structure of the input dependency tree. If we only consider local features 1 , then a simple bottom-up dynamic programming approach can efficiently find the optimal combination with linear O(|H|) complexity 2 . However, non-local features (such as language models) will force us to prune the search space. This pruning is done efficiently through a variation of cube-pruning <ref type="bibr" target="#b5">(Chiang, 2007</ref>). We use KenLM 3 (Heafield, 2011) for computing the target language model score. Decoding is made more efficient by using some of the more advanced features of KenLM such as state-reduction (( <ref type="bibr" target="#b13">Li and Khudanpur, 2008)</ref>, <ref type="figure">(Heafield et al., 2011)</ref>) and rest-cost estimations( <ref type="bibr" target="#b11">Heafield et al., 2012</ref>).</p><p>Compared with the original cube-pruning algorithm, our decoder is designed to handle an arbitrary number of non-terminals. In addition, as we have seen in Section 2.1, the translation hypotheses we initially extract from examples are ambiguous in term of which target word is going to be used and which will be the final position of each non-terminal. In order to handle such ambiguities, we use a lattice-based internal representation that can encode them efficiently (see <ref type="figure" target="#fig_0">Figure 3</ref>). This lattice representation also allows the decoder to make choices between various morphological variations of a word (e.g. be/is/are). We use the decoding algorithm described in ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Improvements from WAT2014</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Alignment</head><p>Based on the findings of <ref type="bibr" target="#b20">Neubig and Duh (2014)</ref>, we experimented with supervised alignment using Nile ( <ref type="bibr" target="#b25">Riesa et al., 2011</ref>) as part of our translation framework. We found that using supervised alignments made a considerable improvement to translation quality. Since Nile supports only constituency parses, we also perform constituency parsing for source and target languages for generating bidirectional word alignments.</p><p>For the initial alignments for Nile, we use the alignments generated from the model described in last year's system description ( <ref type="bibr" target="#b24">Richardson et al., 2014</ref>), which makes use of our dependency parses in order to capture non-local reorderings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Forest Input</head><p>We found that the quality of the source-side dependency parsing had an important impact 3 http://kheafield.com/code/kenlm/ on translation quality. Unfortunately, parsing errors are unavoidable. Chinese parsing is maybe especially challenging and our Chinese parser still produces a significant number of parsing errors. In order to mitigate this problem, last year we used a k-best list of input parses. We found this was somewhat successful but inefficient, and therefore have moved from a k-best list representation of multiple parses to a more compact and efficient forest representation.</p><p>In the future, we will consider also using forests for all the translation examples (and not just the input sentence).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Features</head><p>During decoding we use a linear model to score each possible combination of hypotheses. This linear model is based on a linear combination of both local features (local to each translation hypothesis) and non-local features (such as a 5-gram language model score of the final translation). Despite our already relatively large set of dense features, we found there were a number of cases where these features were not enough to differentiate between good and bad translation hypotheses.</p><p>This year we have added ten new features, now reaching a total of 52, a selection of which are shown below:</p><p>• Forest parse scores The optimal weights for each feature are as before estimated using the implementation of k-best batch MIRA (Cherry and Foster, 2012) included in Moses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Reranking</head><p>A final reranking step allows us to use more advanced features for selecting the best translations. We reranked the n-best output of our system using several additional language models: a standard 7-gram language model with Modified Kneser-Ney smoothing, a Recurrent Neural Network Language Model (RNNLM) <ref type="bibr" target="#b15">(Mikolov et. al, 2010)</ref> and several variations of a Bilingual Recurrent Neural Network Language Model.</p><p>The RNNLM model was trained with hidden layer size 200, and 5000 sentences from the training fold were used as validation data.</p><p>For the bilingual language model, we used the Neural Machine Translation Model of <ref type="bibr" target="#b0">(Bahdanau et. al, 2014)</ref> which has an open source implementation in the GroundHog/Theano framework 4 . For each language pair we trained two models, one for each translation direction. In addition, for Japanese and Chinese, we considered two types of segmentation: the segmentation produced by our morphological analyzer, and a character-level segmentation. We had therefore up to four models per language pair. Rescoring our translations with these models gave up to four additional features. It is interesting to note that although trying to directly translate our input sentences using these neural MT models typically resulted in a comparatively low BLEU score, they turned out to be useful for reranking in our system. This is probably due to the fact that, since they represent a very different approach to translation, the models tend to learn different aspects of the translation and make different mistakes to our system. Using a character-based segmentation further ensured the neural models learned a different kind of information. The models took two to four days each to train on a GPU. The settings we used were mostly the defaults of the implementations 5 .</p><p>Reranking was conducted by first calculating the various language model scores for each</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>We conducted translation experiments on the four language pairs in the scientific papers subtask: Japanese-English (JA-EN), EnglishJapanese (EN-JA), Japanese-Chinese (JA-ZH) and Chinese-Japanese (ZH-JA).</p><p>The proposed system used the following dependency parsers and show below their approximate parsing accuracies (micro-average), which were evaluated by hand on a random subset of sentences from the test data. The parsers were trained on domains different to those used in the experiments.</p><p>• English: NLParser 6 (92%) <ref type="bibr" target="#b2">(Charniak and Johnson, 2005)</ref> • Japanese: KNP (96%) ( <ref type="bibr" target="#b12">Kawahara and Kurohashi, 2006)</ref> • Chinese: SKP (88%) <ref type="bibr" target="#b26">(Shen et al., 2012)</ref> For generating input for Nile we used the following constituency parsers:</p><p>• English: Berkeley Parser ( <ref type="bibr" target="#b22">Petrov et al., 2006</ref>)</p><p>• Japanese: Cyklark (Oda et al., 2015)</p><p>• Chinese: Berkeley Parser ( <ref type="bibr" target="#b22">Petrov et al., 2006</ref>)</p><p>Forests were created by packing the 200-best dependency parses for Japanese and English, and 50-best parses for Chinese. <ref type="table">Table 1</ref> shows the results of our proposed system (WAT15) and a comparison with the system from last year (WAT14) (Richardson et al., 2014) and official baseline (phrasebased SMT, for details see <ref type="bibr" target="#b17">Nakazawa et al. (2015)</ref>). We give results for evaluation on the test set after tuning (WAT15, WAT14) and tuning plus reranking (WAT15+Rerank, WAT14+Rerank). Tuning was conducted over 10 iterations on the development set using an n-best list of length 500, and we used the 1000-best for reranking. WAT15+Rerank was the strongest system in our comparison, outperforming the official baseline, non-reranked system (WAT15) and last year's systems in all metrics for all languages, with the minor exception of JA-ZH human evaluation for reranked vs. nonreranked.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper we have described the latest version of the KyotoEBMT example-based translation system. Since last year we have improved alignment, introduced forest input, added new features and used bilingual neural network features in reranking.</p><p>In our preparation for this workshop we have focused mainly on improving JapaneseChinese and Chinese-Japanese translation, particularly in terms of dealing with poor quality Chinese dependency parses. As future work we plan to perform more extensive error analysis on the other language pairs. We also found that despite using forest input there are still many issues caused by incorrect parsing and will consider in the future how best to overcome this.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: A translation hypothesis endoded as a lattice. This representation allows us to handle efficiently the ambiguities of our translation rules. Note that each path in this lattice corresponds to different choices of insertion position for X2, morphological forms of "be", and the optional insertion of "at".</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>•</head><label></label><figDesc>Number of content/function words aligned to content/function words • Number of times a subtree is inserted in a position (left or right of parent) that is not the most common in the training data • Number of examples sharing the same in- formation used to create an initial hy- pothesis • Similarity between source and input word embeddings (Mikolov et al., 2013)</figDesc></figure>

			<note place="foot" n="1"> The score of a combination will be the sum of the local scores of each translation hypothesis. 2 H = set of translation hypotheses</note>

			<note place="foot" n="4"> https://github.com/lisa-groundhog/GroundHog 5 More precisely, the hidden layer size was 1000. Training done with a minibatch size of 64 and the adadelta algorithm (rho = 0.95, eps = 1e-6). Vocabulary size was reduced to 20,000 for the word-segmented model. Backpropagation through time number of steps increased to up to 100 for the character-based models. translation in the n-best list. These features were added to those used in the first round of tuning, then one final iteration of tuning was run. The tuning algorithm and settings were the same as for standard tuning. This retuning step was added in order to find an optimal combination of the additional features with related features such as sentence length and the score given by the 5-gram language model used inside the decoder.</note>

			<note place="foot" n="6"> Converted to dependency parses with in-house tool.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.0473</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">In arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Scaling phrase-based statistical machine translation to larger corpora and longer phrases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Bannard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josh</forename><surname>Schroeder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics</title>
		<meeting>the 43rd Annual Meeting on Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="255" to="262" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Charniak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Johnson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Coarse-to-Fine n-Best Parsing and MaxEnt Discriminative Reranking</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 43rd Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Batch Tuning Strategies for Statistical Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Cherry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Foster</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HLT-NAACL</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Hierarchical phrase-based translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Chiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computational Linguistics</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Efficient retrieval of tree translation examples for syntax-based machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabien</forename><surname>Cromières</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sadao</forename><surname>Kurohashi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2011 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Translation Rules with Right-Hand Side Lattices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabien</forename><surname>Cromières</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sadao</forename><surname>Kurohashi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Overview of the Patent Machine Translation Task at the NTCIR-10 Workshop</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isao</forename><surname>Goto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ka</forename><forename type="middle">Po</forename><surname>Chow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eiichiro</forename><surname>Sumita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Tsou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th NTCIR Workshop Meeting on Evaluation of Information Access Technologies (NTCIR-10)</title>
		<meeting>the 10th NTCIR Workshop Meeting on Evaluation of Information Access Technologies (NTCIR-10)</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">KenLM: faster and smaller language model queries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenneth</forename><surname>Heafield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the EMNLP 2011 Sixth Workshop on Statistical Machine Translation</title>
		<meeting>the EMNLP 2011 Sixth Workshop on Statistical Machine Translation</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Left language model state for syntactic machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenneth</forename><surname>Heafield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tetsuo</forename><surname>Kiso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Federico</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Workshop on Spoken Language Translation</title>
		<meeting>the International Workshop on Spoken Language Translation</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Language model rest costs and spaceefficient storage</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenneth</forename><surname>Heafield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alon</forename><surname>Lavie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</title>
		<meeting>the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A Fully-Lexicalized Probabilistic Model for Japanese Syntactic and Case Structure Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daisuke</forename><surname>Kawahara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sadao</forename><surname>Kurohashi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Human Language Technology Conference of the NAACL</title>
		<meeting>the Human Language Technology Conference of the NAACL</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A scalable decoder for parsing-based machine translation with equivalent language model state maintenance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Khudanpur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second Workshop on Syntax and Structure in Statistical Translation</title>
		<meeting>the Second Workshop on Syntax and Structure in Statistical Translation</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Hierarchical phrase-based translation with suffix arrays</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lopez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLPCoNLL</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Recurrent Neural Network Based Language Model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Karafiat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukas</forename><surname>Burget</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Cernocky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Khudanpur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th Annual Conference of the International Speech Communication Association</title>
		<meeting>the 11th Annual Conference of the International Speech Communication Association</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Efficient Estimation of Word Representations in Vector Space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Workshop at ICLR</title>
		<meeting>Workshop at ICLR</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Overview of the 2nd Workshop on Asian Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Toshiaki</forename><surname>Nakazawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hideya</forename><surname>Mino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isao</forename><surname>Goto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sadao</forename><surname>Kurohashi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eiichiro</forename><surname>Sumita</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Workshop on Asian Translation (WAT2015)</title>
		<meeting>the 2nd Workshop on Asian Translation (WAT2015)</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">A framework of a mechanical translation between Japanese and English by analogy principle</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Makoto</forename><surname>Nagao</surname></persName>
		</author>
		<editor>A. Elithorn and R. Banerji. Artificial and Human Intelligence</editor>
		<imprint>
			<date type="published" when="1984" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Alignment by bilingual generation and monolingual derivation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Toshiaki</forename><surname>Nakazawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sadao</forename><surname>Kurohashi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING 2012</title>
		<meeting>COLING 2012</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">On the Elements of an Accurate Tree-to-String Machine Translation System</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Duh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 52nd Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Ckylark: A More Robust PCFG-LA Parser</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yusuke</forename><surname>Oda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sakriani</forename><surname>Sakti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomoki</forename><surname>Toda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Satoshi</forename><surname>Nakamura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL 2015: Demo Track</title>
		<meeting>NAACL 2015: Demo Track</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Learning Accurate, Compact, and Interpretable Tree Annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leon</forename><surname>Barrett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Romain</forename><surname>Thibaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING-ACL</title>
		<meeting>COLING-ACL</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Dependency Treelet Translation: Syntactically Informed Phrasal SMT</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Quirk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arul</forename><surname>Menezes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Cherry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics</title>
		<meeting>the 43rd Annual Meeting on Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">KyotoEBMT System Description for the 1st Workshop on Asian Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabien</forename><surname>Cromières</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Toshiaki</forename><surname>Nakazawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sadao</forename><surname>Kurohashi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st Workshop on Asian Translation</title>
		<meeting>the 1st Workshop on Asian Translation</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Feature-Rich Language-Independent Syntax-Based Alignment for Statistical Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Riesa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ann</forename><surname>Irvine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A Reranking Approach for Dependency Parsing with Variable-sized Subtree Features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mo</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daisuke</forename><surname>Kawahara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sadao</forename><surname>Kurohashi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 26th Pacific Asia Conference on Language Information and Computing</title>
		<meeting>26th Pacific Asia Conference on Language Information and Computing</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
