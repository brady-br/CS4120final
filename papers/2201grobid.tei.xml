<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2020-09-29T02:31+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Empirical Study of Power Consumption of x86-64 Instruction Decoder</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikael</forename><surname>Hirki</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Helsinki Institute of Physics</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Aalto University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhonghong</forename><surname>Ou</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kashif</forename><forename type="middle">N</forename><surname>Khan</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Helsinki Institute of Physics</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Aalto University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jukka</forename><forename type="middle">K</forename><surname>Nurminen</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Helsinki Institute of Physics</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Aalto University</orgName>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">VTT Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tapio</forename><surname>Niemi</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Helsinki Institute of Physics</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Empirical Study of Power Consumption of x86-64 Instruction Decoder</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>It has been a common myth that x86-64 processors suffer in terms of energy efficiency because of their complex instruction set. In this paper, we aim to investigate whether this myth holds true, and determine the power consumption of the instruction decoders of an x86-64 processor. To that end, we design a set of microbench-marks that specifically trigger the instruction decoders by exceeding the capacity of the decoded instruction cache. We measure the power consumption of the processor package using a hardware-level energy metering model called the Running Average Power Limit (RAPL), which is supported in the latest Intel architectures. We leverage linear regression modeling to break down the power consumption of each processor component, including the instruction decoders. Through a comprehensive set of experiments , we demonstrate that the instruction decoders can consume between 3% and 10% of the package power when the capacity of the decoded instruction cache is exceeded. Overall, this is a somewhat limited amount of power compared with the other components in the processor core, e.g., the L2 cache. We hope our finding can shed light on the future optimization of processor archi-tectures.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Making data centers more energy efficient requires finding and eliminating new sources of inefficiency. With the recent introduction of ARM-based servers, we will soon have more CPU architectures to choose from. These servers are based on the new ARMv8 architecture that adds support for 64-bit computing. The first prototypes started shipping in 2014 <ref type="bibr" target="#b0">[1]</ref>. Energy efficiency of the first models has been somewhat poor but efficiency is expected to improve in later models <ref type="bibr" target="#b1">[2]</ref>.</p><p>The most commonly cited difference between ARM and Intel processors is the instruction set <ref type="bibr" target="#b4">[5]</ref>. Intel processors use the x86-64 instruction set, which is a Complex Instruction Set Computer (CISC) architecture; while ARM designs are based on the Reduced Instruction Set Computer (RISC) architecture. CISC instructions are more complex: a single instruction can load a value from memory and add it to a register. Today these CISC instructions are decoded into smaller micro-operations, i.e. one instruction is translated into one or more microoperations. A common myth is that decoding the x86-64 instructions is somehow expensive.</p><p>In this paper, we aim to investigate the myth that decoding x86-64 instructions is expensive. We leverage the new features that are present in Intel processor architectures from Sandy Bridge onwards. The two features are the Running Average Power Limit (RAPL) and a micro-op (short for micro-operation) cache. RAPL <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b7">8]</ref> allows measuring the processor energy consumption at high accuracy. The micro-op cache allows the instruction decoders to be shut down while decoded instructions are served from the cache, thus improving energy efficiency. Our core idea is to design microbenchmarks that exhaust the micro-op cache, thus triggering the instruction decoders. This allows us to specifically measure the power consumed by the instruction decoders. The code for our microbenchmarks is available at https://github.com/mhirki/idq-bench2.</p><p>Our paper makes the following major contributions:</p><p>• We develop a set of microbenchmarks to accurately measure the power consumption of the instruction decoders in an x86-64 processor.</p><p>• We show that the percentage of power consumed by the instruction decoders is between 3% and 10% of the total package power.</p><p>• We conclude that the x86-64 instruction set is not a major hindrance in producing an energy-efficient processor architecture.</p><p>The rest of the paper is structured as follows. Section 2 gives a more detailed explanation of processor architecture and the Intel RAPL feature. Section 5 reviews the related work. Section 3 presents the hardware and software configuration as well as the implementation of our microbenchmarks. Section 4 presents the results obtained using our microbenchmarks. Finally, Section 6 concludes our paper and presents an idea for future work.  Before the new cache, the Intel architecture relied on a very small decoded instruction buffer and four instruction decoders. Three of the decoders are simple decoders that can only decode a single instruction into a single micro-op. The fourth decoder can receive any instruction and produce up to four micro-ops per cycle. Thus, instructions that are translated into more than one micro-op can only be decoded by the complex decoder. This creates a potential bottleneck if the frequency of complex instructions is high.</p><p>The micro-op cache solves performance problems in some cases. In addition, it allows shutting down the instruction decoders when they are not used, thus saving power. The capacity of the micro-op cache is 1536 micro-ops, which is equivalent to eight kilobytes of x86 code at maximum.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Running Average Power Limit (RAPL)</head><p>Intel introduced the RAPL feature in their Sandy Bridge architecture. It produces an estimate of the energy consumed by the processor using a model based on microarchitectural counters. RAPL is always enabled in supported models and the energy estimates are updated every millisecond. RAPL supports up to four different power domains depending on the processor model. The Package domain estimates the energy consumed by the entire processor chip. Power plane 0 is a subdomain which estimates the energy consumed by the processor cores. Power plane 1 is another subdomain which estimates the energy consumed by the integrated graphics in desktop models. The DRAM domain is a separate domain which estimates the energy used by the dual in-line memory modules (DIMMs) installed in the system. In this paper, we present measurements of the RAPL Package domain exclusively. The hardware used in the experiments is listed in Table 1. An Intel Haswell desktop processor, released in 2013, is used for the experiments. The Turbo Boost feature is disabled to make the experiments repeatable without relying on thermal conditions. Meanwhile, disabling Turbo Boost ensures that the processor does not exceed its base frequency of 3.4 GHz. In addition, the hyperthreading feature is disabled in the BIOS of the machine on purpose. This gives access to eight programmable performance counters, compared with only four when hyperthreading is enabled.  <ref type="table" target="#tab_1">Table 2</ref> states the software components used in the experiments. Certain kernel settings are adjusted to ensure that the experiments are repeatable. The Cpufreq governor is set to performance that runs the processor at the highest available frequency when it is not idle. This prevents the processor from running at frequencies lower than 3.4 GHz. The Non-maskable interrupt (NMI) watchdog is disabled, which frees up one programmable performance counter. In addition, support for transparent hugepages is disabled since it can change performance characteristics while programs are running. The performance counters are read using both the PAPI (Performance Application Programming Interface) library <ref type="bibr" target="#b13">[14]</ref> and the Perf tool. Perf is a low-level performance analysis tool that is shipped with the Linux kernel. The RAPL counters are read using the MSR driver interface.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methodology 3.1 Hardware and Software</head><p>GCC 4.4.7 is used as the compiler in the experiments since it is the default for the Linux distribution. The same compiler is likely still used by many applications running on Scientific Linux 6. The compiler flag -O2 is used to produce optimized binaries. Model-specific optimizations, such as Advanced Vector eXtensions (AVX), are not used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Microbenchmark Design</head><p>We design a series of microbenchmarks to measure the power consumption of the instruction decoders of the x86-64 processor. The benchmarks execute a single line of code in a loop. We manually unroll the loop up to 2048 times. This allows us to easily increase the size of the code to exceed the capacity of Intel's micro-op cache. In turn, it forces the processor to use the instruction decoders at least periodically. We can then compare the power consumption against a loop with a smaller unroll count. If the loop is still executed in the same amount of time, the observed difference in power consumption can be attributed to the instruction decoding pipeline.</p><p>Loop unrolling is a well-known optimization technique used by compilers. In simple cases, where the number of iterations n is divisible by some integer k, the loop body can simply be repeated k times. The number of iterations for the unrolled loop is n/k. Unrolling increases performance by minimizing the number of branch instructions that need to be executed. Branch instructions are used for jumping from the end of the loop to its beginning. A correctly-predicted branch instruction consumes only one clock cycle in a pipelined processor. Thus, loop unrolling is most beneficial for very small loops.</p><p>The microbenchmarks use simple arithmetic operations such as addition and multiplication. Different benchmarks use either floating-point (double-or singleprecision) or integer (32-bit or 64-bit) data types. They operate either on large arrays or simply on values stored in registers. The following code listing written in the C language shows the operations used in microbenchmark #1:</p><formula xml:id="formula_0">D += A[ j ] + B [ j ] * C [ j ] ;</formula><p>Here A, B and C are floating-point arrays stored in memory. The variable D contains a floating point value stored in a register. The benchmarks do not write to memory because that would require an additional parameter in the power model. The following C code shows microbenchmark #2:</p><formula xml:id="formula_1">D += (A[ j ] &lt;&lt; 3 ) * (A[ j ] &lt;&lt; 4 ) * ( ( B [ j ] &lt;&lt; 2 ) * 5 + 1 ) ;</formula><p>In this case, A and B are integer arrays. Since instructions that access memory generate at least two micro-ops and hence are forced through the complex decoder, we need to add several filler operations that generate only one micro-op. Here we use bitwise shifts, multiplications and additions as filler operations. This approach eliminates the complex decoder as a performance bottleneck, allowing us to stress all four decoders.</p><p>We write many variations of each benchmark. In addition to the previous two benchmarks, we have dozens of different variations of them. We vary the type of operations (addition, multiplication, bitwise shift) used in the benchmarks. Furthermore, we change the size of the arrays so that they fit different caches such as L1 or L2 caches. We also vary the data types (double-or singleprecision). The filler operations introduce additional opportunities for instruction-level parallelism, thus putting additional load on the instruction decoders.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental Evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Power Consumption versus Code Size</head><p>Our first step is to try a large number of different unroll counts using only a single benchmark. This gives us a better understanding of how energy consumption develops as the code size increases due to higher unroll count. We can then identify which components are responsible for the changes in energy consumption.  we can see that energy consumption initially decreases until it reaches its minimum at unroll factor of 64. We do not observe any performance gains in the running time of the loop. Therefore, the reduction in energy consumption can be attributed to the reduced branch prediction activity. At unroll factor of 128, we can see an increase in energy consumption that is caused by the instruction decoders. After this, the energy consumptions grows as the hit ratio for the micro-op cache drops. Between unroll factors 1024 and 2048, we see a big jump in energy consumption that is due to the L1 instruction cache capacity being exceeded. We see that the energy consumption continues growing as the L2 cache activity increases.</p><p>Based on <ref type="figure" target="#fig_2">Figure 2</ref>, we can extrapolate that energy consumption will keep growing for an even larger loop as the L2 cache will be exhausted. Eventually, the translation lookaside buffer (TLB) will also be exhausted, at which point there will be a big performance penalty and correspondingly, big increase in energy consumption.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Regression Modeling</head><p>We employ linear regression modeling to further isolate the power consumption of the instruction decoders. We implement two cases with different unroll counts in each of our microbenchmarks. The extreme case is the point when the capacity of the micro-op cache is exceeded. From <ref type="figure" target="#fig_2">Figure 2</ref>, we can see that this point is at an unroll count of 128 for benchmark #1. This is our extreme case. We also define a normal case for comparison that is the extreme case's unroll count divided by two. In this example, the normal case is at an unroll count of 64, which is the energy minimum in <ref type="figure" target="#fig_2">Figure 2</ref>. Having dozens of benchmarks that implement these two cases allows us to produce enough data to accurately model the power consumption of different processor components such as the execution units, the instruction decoders and the different caches.  <ref type="table" target="#tab_3">Table 3</ref> lists the performance events selected. They reflect the components stressed by our benchmarks. The total number of benchmarks we use is 49. This number includes the different variants of each benchmark. In addition, each benchmark has two cases: the normal one and the extreme one. We run each case for 11 seconds on our test machine. During the execution, we measure power consumption at a rate of 50 samples per second using RAPL. We also use the Perf tool to record performance events at the same rate. We need to adjust the Perf timestamps to match with our power consumption data because the Linux kernel does not use real time for performance events. In addition, we have to filter out anomalous values in the performance data. We use the ordinary least squares method to construct a linear model for the package power consumption. Equation 1 shows the resulting power model obtained using linear regression. The result is the predicted package power consumption as measured in watts. The input parameters are measured as the number of events per second. For example, the value of cycles/second would be 3.4 billion (or 3.4 × 10 9 ) for a single core of our test machine. The coefficient of determination (R 2 ) for our model is 0.989. Therefore, we believe the model accurately represents the different CPU components when running our benchmarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Power Breakdowns</head><p>In <ref type="table" target="#tab_4">Table 4</ref>, we select two microbenchmarks for more detailed examination. We select benchmark #1 because of its high L2 &amp; L3 cache power consumption. The L2 and L3 caches are major components and they allow putting the instruction decoders into perspective. Benchmark #2 is selected because of the high power consumption in the instruction decoders. At the same time, #2 does not use the L2 cache. Therefore, #2 demonstrates the maximum power consumption of the instruction decoders.</p><p>We discovered that our benchmarks appear to trigger the L2 prefetchers even though the data fits into the L2 cache. This problem appears to be limited to synthetic benchmarks running on the Haswell platform. The prefetchers appear to be fetching data from the L3 cache, which causes additional power consumption. Therefore, we have labeled the component as "L2 &amp; L3 cache" in our power breakdowns.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Uncore static 12%</head><p>Cores static 44%</p><p>Micro-op Execution 10%</p><p>Instruction decoders 3%</p><p>L1 cache dynamic 9%</p><p>L2 &amp; L3 cache dynamic 22% <ref type="figure">Figure 3</ref>: Package power consumption breakdown of microbenchmark #1, which stresses the L2 cache using floating-point operations. <ref type="figure">Figure 3</ref> shows the power consumption breakdown for our microbenchmark #1. It demonstrates the power consumption of different CPU components as predicted by  our power model. This <ref type="figure">figure corresponds</ref> to the benchmark #1 in <ref type="table" target="#tab_4">Table 4</ref>. We have labeled the constant term as uncore static in this figure since it roughly corresponds to the static power consumption of the uncore component in the processor. This term includes the static power consumption of components such as the L3 cache and the memory controller. Based on <ref type="figure">Figure 3</ref>, the power consumption of the instruction decoders is very small compared with the other components. Only 3% of the total package power is consumed by the instruction decoding pipeline in this case. It should be noted that the hit ratio for the micro-op cache is 45%, which means that only 55% of micro-ops come from the decoders. Therefore, the instruction decoders can in theory consume twice as much power. This can happen with older generation architectures like Nehalem, which is the predecessor of Sandy Bridge. The Nehalem architecture lacks the micro-op cache, so it has to decode every single instruction in our benchmark.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Uncore static 13%</head><p>Cores static 47%</p><p>Micro-op Execution 22%</p><p>Instruction decoders 10% L1 cache dynamic 8% <ref type="figure">Figure 4</ref>: Power consumption breakdown of microbenchmark #2, which stresses the L1 cache using integer operations. <ref type="figure">Figure 4</ref> illustrates a power breakdown for our benchmark #2, which uses integer operations (as opposed to floating-point operations used in benchmark #1). Because of this, benchmark #2 reaches a much higher instructions per cycle (IPC) count. The higher IPC count causes the execution units and instruction decoders to consume more power. The micro-op cache hit ratio for #2 is also lower, which causes even more work for the instruction decoders. As a result, the instruction decoders end up consuming 10% of the total package power in benchmark #2. Nevertheless, we would like to point out that this benchmark is completely synthetic. Real applications typically do not reach IPC counts as high as this. Thus, the power consumption of the instruction decoders is likely less than 10% for real applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Work</head><p>Many power models have been proposed for modeling the power consumption of entire computer systems and individual components <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b14">15]</ref>. McCullough et al. <ref type="bibr" target="#b12">[13]</ref> evaluated earlier approaches to modeling power consumption. Their conclusion is that quadratic and other non-linear models are often required for accurate power modeling. This is due to the fact that many utilization metrics or performance counters do not scale linearly with low-level hardware activity. In this paper, we use a linear model because we choose components that can be modeled linearly using the parameters available. In addition, we use the Haswell architecture, which is significantly more energy efficient than older architectures. Our selection of performance events is also different from existing work. For example, we use the IDQ.MITE UOPS performance event introduced in Sandy Bridge. To our best knowledge, Oboril et al. <ref type="bibr" target="#b14">[15]</ref> are the only ones who have used this performance event besides us. They present power consumption breakdowns similar to ours. However, they do not use microbenchmarks specifically targeting the instruction decoders like we do.</p><p>The energy efficiency of different Intel and ARM platforms has been compared using numerous workloads <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b15">16]</ref>. The results suggest that ARM gives good energy efficiency in specific workloads using specific parameters while Intel has more stable performance across a wider range of parameters. In addition, a few studies have attempted to investigate the significance of the instruction set <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b9">10]</ref>. Blem et al. <ref type="bibr" target="#b4">[5]</ref> concluded that the in-struction set by itself is a fairly insignificant part of whole microprocessor design. A limitation of their work is that they did not measure the instruction decoders directly. Our paper addresses this limitation. Isen et al. <ref type="bibr" target="#b9">[10]</ref> stated that Intel benefits from advanced microarchitectural features such as micro-op fusion that has helped close the gap between CISC and RISC instruction sets.</p><p>Microbenchmarks have been used for deriving power models before. Isci and Martonosi <ref type="bibr" target="#b8">[9]</ref> use microbenchmarks to derive the power consumption of 22 different components of the Pentium 4 processor. Similar to our work, they use performance counters to estimate the activity of different components. However, our microbenchmarks are more focused on the instruction decoders. <ref type="bibr">Leng et al. [12]</ref> model the power consumption General Purpose GPUs (GPGPUs). Their work shows that a microbenchmark-based approach works even for a different class of hardware.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion and Future Work</head><p>We designed a series of microbenchmarks to determine the power consumption of the instruction decoders in our x86-64 processor. We model the power consumption using linear regression analysis. Our linear model predicts the power consumption of different components including the execution units, instruction decoders, and L1 and L2 caches. The result demonstrates that the decoders consume between 3% and 10% of the total processor package power in our benchmarks. The power consumed by the decoders is small compared with other components such as the L2 cache, which consumed 22% of package power in benchmark #1. We conclude that switching to a different instruction set would save only a small amount of power since the instruction decoder cannot be eliminated completely in modern processors.</p><p>In the future, we plan to port our microbenchmarks to an ARM platform. This allows us to directly compare the energy consumption of different components between two different architectures. Another interesting platform to benchmark would be the Intel Atom, which is a low-power x86 design. The Atom does not support AVX instructions, which should simplify the decoders and thus reduce their power consumption.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Simplified version of the Intel Haswell pipeline.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 depicts</head><label>1</label><figDesc>Figure 1 depicts a simplified version of the Intel Haswell pipeline. This simplified version highlights the micro-op cache, a new feature first introduced in the Sandy Bridge architecture. Before the new cache, the Intel architecture relied on a very small decoded instruction buffer and four instruction decoders. Three of the decoders are simple decoders that can only decode a single instruction into a single micro-op. The fourth decoder can receive any instruction and produce up to four micro-ops per cycle. Thus, instructions that are translated into more than one micro-op can only be decoded by the complex decoder. This creates a potential bottleneck if the frequency of complex instructions is high. The micro-op cache solves performance problems in some cases. In addition, it allows shutting down the instruction decoders when they are not used, thus saving power. The capacity of the micro-op cache is 1536 micro-ops, which is equivalent to eight kilobytes of x86 code at maximum.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Package energy consumption of microbenchmark #1 with different loop unroll counts.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 shows the processor energy consumption for different unroll counts.</head><label>2</label><figDesc>Figure 2 shows the processor energy consumption for different unroll counts. The energy is measured in joules as reported by the Intel RAPL feature. From the figure,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="true"><head>Table 1 : Hardware used in the experiments.</head><label>1</label><figDesc></figDesc><table>Processor: 
Intel Core i7-4770 @ 3.40 GHz 
Architecture: 
Haswell 
Cores: 
4 
L3 cache: 
8 MB 
Turbo Boost: 
Supported but disabled 
Hyperthreading: 
Supported but disabled 
RAM: 
2x 8 GB Kingston DDR3, 
1600 MHz (dual-channel) 
Motherboard: 
Intel DH87RL 
Power supply: 
Corsair TX750 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Software and kernel parameters used in the ex-
periments. 

Operating system: 
Scientific Linux 6.6 
Kernel: 
Linux 4.1.6 
Cpufreq governor: 
Performance 
NMI watchdog: 
Disabled 
Transparent hugepages: 
Disabled 
Compiler: 
GCC 4.4.7 
Performance measurement: PAPI library 5.4.1 
and Perf 4.1.6 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="true"><head>Table 3 : Performance events used in the linear regression model.</head><label>3</label><figDesc></figDesc><table>Event name: 
Description: 
CPU CLK UNHALTED.THREAD P 
The number of clock cycles for each core. 
UOPS ISSUED.ANY 
The number of micro-ops issued to the execution units. 
IDQ.MITE UOPS 
The number of micro-ops produced by the instruction decoders. 
MEM LOAD UOPS RETIRED.L1 HIT 
The number of hits in the L1 data cache. 
L2 RQSTS.REFERENCES 
The number requests to the L2 cache (including L2 prefetchers). 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Power consumption breakdown by processor 
components for two different microbenchmarks as pre-
dicted by our model. 

Microbenchmark: 
#1 
#2 
Type: 
Floating-point Integer 
Instructions per cycle: 
1.67 
3.86 
Uncore (W): 
6.0 
6.0 
Cores (W): 
22.1 
22.1 
Execution units (W): 
4.9 
10.4 
Instruction decoders (W): 
1.8 
4.8 
L1 cache (W): 
4.8 
3.8 
L2 &amp; L3 cache (W): 
11.2 
0.1 
Micro-op cache hit ratio: 
44.8% 
29.6% 

</table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Acknowledgments</head><p>This study was supported by the Green Big Data project of the Helsinki Institute of Physics. We would like to thank David Abdurachmanov, Peter Elmer and Giulio Eulisse for their ideas and feedback.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">AppliedMicro announces the availability of X-C1 development kits featuring X-Gene</title>
		<imprint>
			<date type="published" when="2014-11" />
		</imprint>
	</monogr>
	<note>press release</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Heterogeneous high throughput scientific computing with APM X-Gene and Intel Xeon Phi</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abdurachmanov</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bockelman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Elmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Eu-Lisse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Knight</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muzaffar</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In Journal of Physics: Conference Series</title>
		<imprint>
			<biblScope unit="volume">608</biblScope>
			<date type="published" when="2015" />
			<publisher>IOP Publishing</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Towards green data centers: A comparison of x86 and ARM architectures power efficiency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aroca</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">V</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">M</forename><surname>Alves</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Parallel and Distributed Computing</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="page" from="1770" to="1780" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Complete system power estimation using processor performance events</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bircher</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">L</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">K</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computers</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="page" from="563" to="577" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Understanding the relevance of ISA being RISC or CISC to performance, power, and energy on modern architectures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Blem</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Menon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Vijayaraghavan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sankar-Alingam</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Comput. Syst</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page">34</biblScope>
			<date type="published" when="2015-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">RAPL: Memory power estimation and capping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Gorbatov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hanebutte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><forename type="middle">R</forename><surname>Khanna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">E</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th ACM/IEEE International Symposium on Low Power Electronics and Design (ISLPED)</title>
		<meeting>the 16th ACM/IEEE International Symposium on Low Power Electronics and Design (ISLPED)</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Full-system power analysis and modeling for server environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Economou</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rivoire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kozyrakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>And Ran-Ganathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Modeling, Benchmarking, and Simulation (MoBS</title>
		<meeting>the Workshop on Modeling, Benchmarking, and Simulation (MoBS</meeting>
		<imprint>
			<date type="published" when="2006-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Measuring energy consumption for short code paths using RAPL</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H ¨ Ahnel</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Obel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Olp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>And H ¨ Artig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGMETRICS Performance Evaluation Review</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="13" to="17" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Runtime power monitoring in high-end processors: Methodology and empirical data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isci</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martonosi</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th annual IEEE/ACM International Symposium on Microarchitecture</title>
		<meeting>the 36th annual IEEE/ACM International Symposium on Microarchitecture</meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A tale of two processors: Revisiting the RISC-CISC debate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isen</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">K</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2009 SPEC Benchmark Workshop on Computer Performance Evaluation and Benchmarking</title>
		<meeting>the 2009 SPEC Benchmark Workshop on Computer Performance Evaluation and Benchmarking</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="57" to="76" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Performance evaluation and energy efficiency of high-density HPC platforms based on Intel, AMD and ARM processors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jarus</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Varrette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Oleksiak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bouvry</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Energy Efficiency in Large Scale Distributed Systems</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="182" to="200" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">GPUWattch: enabling energy optimizations in GPGPUs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leng</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hetherington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Eltantawy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gilani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">S</forename><surname>Aamodt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>And Reddi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGARCH Computer Architecture News</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="487" to="498" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Evaluating the effectiveness of model-based power characterization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mccullough</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chandrashekar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kuppuswamy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Snoeren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gupta</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">K</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the USENIX Annual Technical Conference</title>
		<meeting>the USENIX Annual Technical Conference</meeting>
		<imprint>
			<publisher>ATC</publisher>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">PAPI: A portable interface to hardware performance counters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mucci</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Browne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Deane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">O</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Department of Defense HPCMP Users Group Conference</title>
		<meeting>the Department of Defense HPCMP Users Group Conference</meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="7" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">High-resolution online power monitoring for modern microprocessors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oboril</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Ewert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tahoori</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">B</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Design, Automation &amp; Test in Europe Conference &amp; Exhibition (DATE)</title>
		<meeting>the 2015 Design, Automation &amp; Test in Europe Conference &amp; Exhibition (DATE)</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>EDA Consortium</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Energy-and cost-efficiency analysis of ARMbased clusters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">U</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Nurminen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">K</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yla-Jaaski</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing</title>
		<meeting>the 12th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing</meeting>
		<imprint>
			<publisher>CCGrid</publisher>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
