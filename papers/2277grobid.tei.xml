<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2020-09-29T02:33+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Representativeness in the Benchmark for Vulnerability Analysis Tools (B-VAT)</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kayla</forename><forename type="middle">N</forename><surname>Afanador</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Naval Postgraduate School</orgName>
								<orgName type="department" key="dep2">Naval Postgraduate School</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cynthia</forename><forename type="middle">E</forename><surname>Irvine</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Naval Postgraduate School</orgName>
								<orgName type="department" key="dep2">Naval Postgraduate School</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Representativeness in the Benchmark for Vulnerability Analysis Tools (B-VAT)</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>A variety of tools are used to support software vulnerability analysis processes. However, when analysts want to select the optimal tool for a particular use case, or attempt to compare a new tool against others, no standard method is available to do so. In addition, we have determined that although vulnerabil-ities can be categorized into vulnerability types, these types are often disproportionately represented in current datasets. Hence, when comparative analyses of tools based upon these data sets are conducted, the results are distorted and unreal-istic. To address this problem, we are building a Benchmark for Vulnerability Analysis Tools (B-VAT). Representativeness is a key element of a good benchmark. In this paper, we use stratified sampling to identify a representative set of vulnerabilities from over 800 CWE&apos;s and 75,000 CVE&apos;s. This set becomes the foundation upon which we will build a purpose-based benchmark for vulnerability analysis tools. By using the correlation between current CWE and CVE data, the proposed B-VAT will assess tools using vulnerabilities in the proportions their types occur in the wild.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The security community relies on tools to support software vulnerability analysis processes. However, there is no benchmark to support the comparison of vulnerability analysis tools. One current comparison approach is to see how well tools perform using test cases.</p><p>Hundreds of thousands of publicly available test cases containing known software flaws are aggregated into datasets of vulnerabilities, each with its own structure, test cases, supported languages, and reporting method, e.g., Juliet Test Suite <ref type="bibr" target="#b0">[1]</ref>. Databases such as the Software Assurance Reference Dataset (SARD) attempt to inject order by providing a consolidated repository of vulnerability datasets and test cases <ref type="bibr" target="#b1">[2]</ref>. Unfortunately, even the SARD, which contains 40 datasets and over 170,000 test cases, is not exhaustive-it excludes datasets such as the Cyber Grand Challenge (CGC)</p><p>Corpus <ref type="bibr" target="#b2">[3]</ref>, and OWASP Benchmark Project <ref type="bibr" target="#b3">[4]</ref>. We will show that many of these datasets contain an unrealistic representation of weakness types, i.e., Common Weakness Enumeration (CWE) entries, when compared to known vulnerability instances in the wild, i.e., accepted Common Vulnerabilities and Exposures (CVE) entries. Consequently, even if vulnerability analysis tools were assessed using all of the SARD test cases, the results would would still not reflect reality. In our effort to create a Benchmark for Vulnerability Analysis Tools (B-VAT), test cases that are statistically representative of the vulnerabilities found in the wild are needed.</p><p>The CWE provides a repository of weakness types, and the CVE, a dictionary of vulnerability instances. A weakness is a mistake in software or hardware that, under proper conditions, could lead to the introduction of a vulnerability <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6]</ref>. A vulnerability is an occurrence of one or more weaknesses that can be used to, "modify or access unintended data, interrupt proper execution, or perform incorrect actions that were not specifically granted to the party who uses the weakness" <ref type="bibr" target="#b5">[6]</ref>.</p><p>We analyzed four popular datasets of software vulnerabilities: Juliet C/C++, Juliet Java <ref type="bibr" target="#b0">[1]</ref>, the CGC Corpus <ref type="bibr" target="#b2">[3]</ref>, and the OWASP Benchmark <ref type="bibr" target="#b3">[4]</ref>. Each contains test cases that can be used to assess vulnerability analysis tools. We show that none represent vulnerability types in the proportions those types occur in the wild. By correlating the data from 839 CWE's, and over 75,000 CVE's we identify a representative set of known vulnerabilities that can be used to design a purpose-based benchmark for vulnerability analysis tools. This paper makes the following contributions:</p><p>• We synthesize 839 CWE's with over 75,000 CVE's to determine the relative proportions of vulnerability instances and weakness types in the wild.</p><p>• We analyze four popular software vulnerability datasets, and show that none accurately represents vulnerability instances and weakness types as they occur in the wild.</p><p>• We perform stratified sampling to determine the appropriate number of test cases for each weakness type. This provides the foundational data upon which B-VAT is being constructed.</p><p>We next provide a brief background on benchmarks, and identify the key benchmark property motivating this paper: representativeness. Section 3 explores how representativeness is achieved, and Section 4 offers a conclusion and future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">The Benchmark</head><p>There are many types of computer benchmarks. In the 1960's traditional benchmarks were used to compare the speed with which computers accomplished basic data processing functions <ref type="bibr" target="#b6">[7]</ref>. In 1965, Joslin proposed an application benchmark that used specific applications to emphasize the relative throughput performance of different system configurations <ref type="bibr" target="#b7">[8]</ref>. Specification-based benchmarks define functions, and include required inputs and expected output <ref type="bibr" target="#b8">[9]</ref>. Gustafson defined a purpose-based benchmark that, "explicitly and comprehensively measures the ability of a computing system to reach a goal of human interest" <ref type="bibr" target="#b9">[10]</ref>. Our benchmark has a clear purpose: to facilitate comparison of vulnerability analysis tools. For this reason, we are designing a purpose-based benchmark.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Benchmark Characteristics</head><p>Researchers have proposed a number of desirable benchmark characteristics <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b11">[12]</ref><ref type="bibr" target="#b12">[13]</ref>. We consider the following key characteristics for B-VAT:</p><p>Relevant The benchmark problems should be closely connected to reality. Repeatable The same results should be consistently reproduced when the benchmark is run with the same tool. Usable The benchmark should be able to be used in multiple operating environments, and run with a variety of tools. Fair The benchmark should impartially measure each tool. Verifiable There should be confidence that benchmark results are accurate. Determining the relevance of benchmark problems involves a number of elements. From a design perspective, relevance involves two dimensions: the breadth of the benchmark's applicability, and the degree to which benchmark problems are relevant in each area <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b11">12]</ref>. In this paper, we focus on relevance, and specifically on the representativeness of the problems in B-VAT. See Section 4 for a description of future work related to B-VAT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">A Representative Set</head><p>The most important property of a benchmark relates to its problems <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b9">10]</ref>. Joslin called this the "representativeness" of a benchmark, and Gustafson the benchmark's "problem size." Gustafson proposed a balance between a benchmark's problem size and its usefulness -too many problems in a benchmark raises its cost, while too few reduces its utility <ref type="bibr" target="#b9">[10]</ref>. We will refer to benchmark problems as test cases.</p><p>We define a representative set of vulnerabilities as a subset of vulnerabilities instances that adequately represents the larger set of known vulnerability instances and types <ref type="bibr" target="#b13">[14]</ref>. We identify a representative set from a repository of over 75,000 accepted CVE's published between 2014 and 2019.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Vulnerability Instances</head><p>Much like the SARD, the CVE provides organization and standardization. The CVE is a dictionary of publicly known vulnerability and exposure instances <ref type="bibr" target="#b14">[15]</ref>. Each entry describes an instance of a vulnerability, and includes metadata such as a unique identifier (CVE ID), standardized description, and where applicable, a corresponding CWE entry <ref type="bibr" target="#b0">1</ref> . We cannot predict future vulnerabilities; our work is constrained to the set of "known known" and "known unknown" vulnerabilities <ref type="bibr" target="#b15">[16]</ref>. Additionally, we recognize that the CVE is not exhaustive, however, it provides an extensive repository of known vulnerability instances that is suitable for our purposes.</p><p>To date, the greatest number, 21, 598, of publicly disclosed vulnerabilities and exposures was reported by the CVE in 2018. Over half, 93, 056 out of 160, 544, of all of vulnerabilities ever reported (excluding 2020) by the CVE were published between 2014 to 2019 <ref type="bibr" target="#b14">[15]</ref>. We use these six years of 75, 535 community-accepted CVE's as the set from which we identify a representative subset of vulnerability instances.</p><p>The CVE provides instances of known vulnerabilities, and the simplest method to identify a representative subset from these data would be to take a random sample of the larger set. However, a simple random sample may result in the misrepresentation of vulnerability types <ref type="bibr" target="#b16">[17]</ref>. By using the existing correlation between CVE ID's and CWE ID's we can link each CVE ID to one of ten CWE pillars and take a stratified sample of the set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Weakness Types</head><p>What the CVE provides for vulnerability instances, the CWE provides for weakness types. The CWE is a repository of over 1200 hardware and software weaknesses, and provides a common language, identifier, and definition for each weakness type referenced. CWE entries are organized into a number of views to support different objectives. We use view CWE-1000, Research Concepts, that includes a hierarchy of 839 CWE entries. The hierarchy contains one of the following abstraction types for each CWE ID <ref type="bibr" target="#b17">[18]</ref>: Pillar Weaknesses that are described in the most abstract fashion (10 CWE's). Pillars include: Class Abstract weakness, typically independent of any specific language or technology (96 CWE's). Base A more specific type of weakness (441 CWE's). Variant A weakness that is described at a very low level of detail, typically limited to a specific language or technology (285 CWE's). Composite A set of weaknesses that must all be present simultaneously in order to produce an exploitable vulnerability (7 CWE's). The weakness hierarchy presented by view CWE-1000 can be organized into ten rooted trees. A rooted tree is a tree with a single root vertex that is distinguished from all others. Each pillar in the hierarchy is a root node of a rooted tree.  <ref type="bibr" target="#b18">[19]</ref>, pandas <ref type="bibr" target="#b19">[20]</ref>, and D3 <ref type="bibr" target="#b20">[21]</ref> we crawled over 1000 individual pages on the CWE website to create and visualize the tree data structures for each of the ten CWE Pillars. This approach allows us to view the most up-todate information on CWE relationships and hierarchies. Then, by using CWE-1000 as the root node of a tree we can create a single rooted tree that includes every CWE in the CWE-1000 view. <ref type="figure" target="#fig_0">Figure 1</ref> depicts the ten CWE pillars and their 839 children as a hierarchical radial dendrogram with root node CWE-1000. We use the CWE relationship and hierarchy data to organize the CVE's into ten strata (see Section 3.4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Combining Types with Instances</head><p>Of the 75, 535 community-accepted CVE's, 55, 128 have an associated CWE ID. By using the correlations between CVE ID's and CWE ID's, we classify each of these vulnerability instances by their weakness type. <ref type="figure" target="#fig_1">Figure 2</ref> shows the sum of known vulnerability instances (CVE IDs), by type (CWE IDs) from 2014-2019. This visualization shows the relative proportions of CWE ID's in the wild. The enclosing circles show the cumulative size of each of the ten CWE pillars (i.e. subtrees), while maintaining relationship and hierarchical data. The exterior circle represents root node, CWE-1000.  for comparison. These diagrams illustrate the stark contrast between the types of weaknesses in the wild, and those in current vulnerability datasets 2 .</p><p>Like the CVE, each test case in the reviewed datasets has a corresponding CWE ID that can be traced to a pillar node. <ref type="table">Table 1</ref> shows the relative percentages of test cases in each pillar by vulnerability dataset. It shows that none of the vulnerability datasets accurately reflects vulnerabilities as they have occurred in the wild, i.e., CVE's from 2014-2019. By taking a stratified sample of the CVE-CWE data we propose a subset of test cases for B-VAT that proportionately represents vulnerability instances, and weakness types. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">A Stratified Sample</head><p>Stratified sampling is a statistical method that allows subgroups, or strata to be proportionately represented <ref type="bibr" target="#b21">[22]</ref>, thus providing a representative sample of a larger population. Unlike random sampling, which may result in the misrepresentation of vulnerability instances and weakness types, stratified sampling allows us to preserve the relative proportions of each pillar, or strata.  between CWE and CVE entries our B-VAT will represent vulnerability instances and weakness types in the proportions they occur in the wild. In this paper, we used CWE pillars as the strata in our sample, however, it may be prudent to add additional variables before taking a stratified sample. For example, we could also include a severity ranking for each CVE, and force our sample to include vulnerability instances with a high severity <ref type="bibr" target="#b22">[23]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion and Future work</head><p>Despite the large number of tools used to support software vulnerability assessments, there is no benchmark that permits evaluation and comparison of those tools. To address this problem, we are developing a Benchmark for Vulnerability Analysis Tools. In this paper, we have discussed a fundamental property of B-VAT: representativeness. We examined four popular datasets of software vulnerability test cases: Juliet C/C++, Juliet Java, the OWASP Benchmark, and the CGC Corpus, and determined that none represent vulnerabilities as they have occurred in the wild from 2014-2019. First, we synthesized the data from 839 CWE's and over 75,000 CVE's, then we used stratified sampling to identify a distribution of weakness types that is representative of known vulnerability instances. This analysis provides a foundation for B-VAT; however, much work remains. Currently, we are exploring the impact of including additional variables before taking a stratified sample (e.g., relevance of specific CVE's and CWE's, severity rankings, and a weighted component for rare vulnerabilities). After determining the desired number of test cases for B-VAT, we must determine a method to score vulnerability analysis tools. Existing datasets contain over 150,000 test cases; <ref type="table" target="#tab_5">Table 3</ref> shows the collective number of available test cases corresponding to each pillar. We are exploring methods to reuse these test cases in a more representative way, as described in this paper.  This work is ongoing, and we welcome collaboration. All data and code is available upon request.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Pillar</head><p>We wish thank Lyn Whitaker for valuable discussions.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: CWE view 1000 as a hierarchical radial dendrogram</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Sum of vulnerability instances (CVE ID) by type (CWE ID) from 2014-2019</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Comparison of sunburst diagrams</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>CWE-703 Improper Check or Handling of Exceptional Condi- tions 9. CWE-707 Improper Neutralization 10. CWE-710 Improper Adherence to Coding Standards</head><label></label><figDesc></figDesc><table>1. CWE-284 Improper Access Control 
2. CWE-435 Improper Interaction Between Multiple Correctly-
Behaving Entities 
3. CWE-664 Improper Control of a Resource Through its Life-
time 
4. CWE-682 Incorrect Calculation 
5. CWE-691 Insufficient Control Flow Management 
6. CWE-693 Protection Mechanism Failure 7. CWE-697 Incorrect Comparison 
8. </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true"><head>Table 2 shows the proportionate strati- fied sample size of each pillar.</head><label>2</label><figDesc></figDesc><table>Pillar 
Total CVE's Stratified Sample 

CWE-284 
5,847 
245 
CWE-435 
40 
2 
CWE-664 
24,957 
1,042 
CWE-682 
1,397 
58 
CWE-691 
1,419 
59 
CWE-693 
2,571 
107 
CWE-697 
15 
1 
CWE-703 
168 
7 
CWE-707 
17,657 
737 
CWE-710 
1,030 
43 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 2 : Stratified sample size of each CWE pillar</head><label>2</label><figDesc></figDesc><table>These sample sizes become the number of test cases in the 
B-VAT aligned to each CWE pillar. By using the correlation 

2 We have similar diagrams for each of the datasets reviewed. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 3 : Available open-source test cases</head><label>3</label><figDesc></figDesc><table></table></figure>

			<note place="foot" n="1"> CVE entries published prior to the development of the CWE (2006) do not include a CWE ID</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Boland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">E</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">;</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">/</forename><surname>C++</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Java Test</forename><surname>Suite</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="88" to="90" />
			<date type="published" when="2012-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Sard: Thousands of reference programs for software assurance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">E</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Cyber Secur. Inf. Syst. Tools Test. Tech. Assur. Softw. Dod Softw. Assur. Community Pract</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">5</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Cyber grand challenge corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Caswell</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">OWASP Benchmark</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wichers</surname></persName>
		</author>
		<ptr target="https://owasp.org/www-project-benchmark/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cve -Terminology</forename></persName>
		</author>
		<ptr target="https://cve.mitre.org/about/terminology.html#vulnerability" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">CWE -About -CWE Overview</title>
		<ptr target="https://cwe.mitre.org/about/index.html" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The Evolution of Benchmarking as a Computer Performance Evaluation Technique</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">C</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">E</forename><surname>Crews</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">MIS Quarterly</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="1985-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">2.1: Application Benchmarks: The Key to Meaningful Computer Evaluations.pdf</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">O</forename><surname>Joslin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM 20th National Conference</title>
		<imprint>
			<publisher>USAF</publisher>
			<date type="published" when="1965" />
			<biblScope unit="page" from="27" to="37" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">How to Build a Benchmark</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">V</forename><surname>Kistowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Arnold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Huppler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-D</forename><surname>Lange</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Henning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th ACM/SPEC International Conference on Performance Engineering -ICPE &apos;15</title>
		<meeting>the 6th ACM/SPEC International Conference on Performance Engineering -ICPE &apos;15</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Purpose-Based Benchmarks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gustafson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The International Journal of High Performance Computing Applications</title>
		<imprint>
			<date type="published" when="2004-11" />
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="475" to="487" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">SPEC CPU2000: Measuring CPU performance in the New Millennium</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Henning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="28" to="35" />
			<date type="published" when="2000-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The Art of Building a Good Benchmark</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Huppler ; Ing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hutchison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kanade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kittler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Kleinberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Mattern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Naor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Nierstrasz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Pandu Rangan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Performance Evaluation and Benchmark</title>
		<editor>B. Steffen, M. Sudan, D. Terzopoulos, D. Tygar, M. Y. Vardi, G. Weikum, R. Nambiar, and M. Poess</editor>
		<meeting><address><addrLine>Berlin, Heidelberg; Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2009" />
			<biblScope unit="volume">5895</biblScope>
			<biblScope unit="page" from="18" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Analysis of benchmark characteristics and benchmark performance prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">H</forename><surname>Saavedra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Computer Systems (TOCS)</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="344" to="384" />
			<date type="published" when="1996-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Finding representative set from massive data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K H</forename><surname>Tung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiong</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Fifth IEEE International Conference on Data Mining (ICDM&apos;05)</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page">8</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">CVE -Home</title>
		<ptr target="https://cve.mitre.org/about/index.html" />
	</analytic>
	<monogr>
		<title level="j">MITRE</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Dod news briefing-secretary rumsfeld and gen. myers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rumsfeld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">US Department of Defense</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Sampling Methods in Research Methodology; How to Choose a Sampling Technique for Research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Taherdoost</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SSRN Electronic Journal</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">CWE -A Comparison of the CWE Development and Research Views</title>
		<ptr target="https://cwe.mitre.org/documents/views/view-comparison.html" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Beautiful Soup Documentation -Beautiful Soup 4.9.0 documentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonard</forename><surname>Richardson</surname></persName>
		</author>
		<ptr target="https://www.crummy.com/software/BeautifulSoup/bs4/doc/#id19" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Data Structures for Statistical Computing in Python</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wes</forename><surname>Mckinney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th Python in Science Conference</title>
		<editor>Stéfan van der Walt and Jarrod Millman</editor>
		<meeting>the 9th Python in Science Conference</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="56" to="61" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">D 3 DataDriven Documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bostock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Ogievetsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2301" to="2309" />
			<date type="published" when="2011-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><forename type="middle">S</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stanley</forename><surname>Lemeshow</surname></persName>
		</author>
		<title level="m">Sampling of Populations: Methods and Applications</title>
		<imprint>
			<publisher>John Wiley &amp; Sons</publisher>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">A complete guide to the common vulnerability scoring system version 2.0,&quot; in Published by FIRST-forum of incident response and security teams</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Scarfone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Romanosky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">23</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
