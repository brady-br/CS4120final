<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2020-09-29T02:23+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Your Coflow has Many Flows: Sampling them for Fun and Speed Your Cooow Has Many Flows: Sampling Them for Fun and Speed</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>July 10-12, 2019</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akshay</forename><surname>Jajoo</surname></persName>
							<email>ajajoo@purdue.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Purdue University</orgName>
								<orgName type="institution" key="instit2">Purdue University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">Charlie</forename><surname>Hu</surname></persName>
							<email>ychu@purdue.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Purdue University</orgName>
								<orgName type="institution" key="instit2">Purdue University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojun</forename><surname>Lin</surname></persName>
							<email>linx@purdue.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Purdue University</orgName>
								<orgName type="institution" key="instit2">Purdue University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akshay</forename><surname>Jajoo</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Purdue University</orgName>
								<orgName type="institution" key="instit2">Purdue University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">Charlie</forename><surname>Hu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Purdue University</orgName>
								<orgName type="institution" key="instit2">Purdue University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojun</forename><surname>Lin</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Purdue University</orgName>
								<orgName type="institution" key="instit2">Purdue University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Your Coflow has Many Flows: Sampling them for Fun and Speed Your Cooow Has Many Flows: Sampling Them for Fun and Speed</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2019 USENIX Annual Technical Conference</title>
						<meeting>the 2019 USENIX Annual Technical Conference <address><addrLine>Renton, WA, USA</addrLine></address>
						</meeting>
						<imprint>
							<date type="published">July 10-12, 2019</date>
						</imprint>
					</monogr>
					<note>This paper is included in the Open access to the Proceedings of the 2019 USENIX Annual Technical Conference is sponsored by USENIX. https://www.usenix.org/conference/atc19/presentation/jajoo</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Cooow scheduling improves data-intensive application performance by improving their networking performance. State-of-the-art online cooow schedulers in essence approximate the classic Shortest-Job-First (SJF) scheduling by learning the cooow size online. In particular, they use multiple priority queues to simultaneously accomplish two goals: to sieve long cooows from short cooows, and to schedule short cooows with high priorities. Such a mechanism pays high overhead in learning the cooow size: moving a large cooow across the queues delays small and other large cooows, and moving similar-sized cooows across the queues results in inadvertent round-robin scheduling. We propose PPPPPP, a new online cooow scheduler that exploits the spatial dimension of cooows, i.e., a cooow has many ows, to drastically reduce the overhead of cooow size learning. PPPPPP pre-schedules sampled ows of each cooow and uses their sizes to estimate the average ow size of the cooow. It then resorts to Shortest Cooow First, where the notion of shortest is determined using the learned cooow sizes and cooow contention. We show that the sampling-based learning is robust to ow size skew and has the added beneet of much improved scalability from reduced coordinator-local agent interactions. Our evaluation using an Azure testbed, a publicly available production cluster trace from Facebook shows that compared to the prior art Aalo, PPPPPP reduces the cooow completion time (CCT) in average (P90) cases by 1.50× (8.00×) on a 150-node testbed and 2.72× (9.78×) on a 900-node testbed. Evaluation using additional traces further demonstrates PPPPPP&apos;s robustness to ow size skew.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Motivation</head><p>In big data analytics jobs, speeding up the communication stage where the data is transferred between compute nodes is important to speed up the jobs. However, improving network level metrics such as ow completion time may not translate into improvements at the application level metrics such as job completion time. The cooow abstraction <ref type="bibr" target="#b16">[18]</ref> was proposed to bridge such a gap. The abstraction captures the collective network requirements of applications, as reduced cooow completion time (CCT) can directly lead to faster job completion time <ref type="bibr" target="#b18">[20,</ref><ref type="bibr" target="#b22">24]</ref>.</p><p>There have been a number of eeorts on network designs for cooows <ref type="bibr" target="#b5">[7,</ref><ref type="bibr" target="#b19">21,</ref><ref type="bibr" target="#b25">27]</ref> that assume complete prior knowledge of cooow sizes (The cooow size is deened as the total size of its constituent ows.). However, in many practical settings, cooow characteristics are not known a priori. For example, multi-stage jobs pipeline data from one stage to the next as soon as the data is generated, which makes it diicult to know the size of each ow <ref type="bibr" target="#b20">[22,</ref><ref type="bibr" target="#b38">40]</ref>. A recent study <ref type="bibr" target="#b38">[40]</ref> shows various other reasons why it is not very plausible to learn ow sizes from applications, for example, learning ow sizes from applications requires changing either the network stack or the applications.</p><p>Scheduling cooows in such non-clairvoyant settings, however, is challenging. The major challenge in developing an eeective non-clairvoyant cooow scheduling scheme has centered around how to learn the cooow sizes online quickly and accurately, as once the cooow sizes (bytes to be transferred) can be estimated, one can apply variations of the classic Shortest-Job-First (SJF) algorithm such as Shortest Cooow First <ref type="bibr" target="#b19">[21]</ref> or apply an LP solver (e.g., <ref type="bibr" target="#b5">[7]</ref>).</p><p>State-of-the-art online non-clairvoyant schedulers such as Saath <ref type="bibr" target="#b28">[30]</ref>, Gravtion <ref type="bibr" target="#b27">[29]</ref> and Aalo <ref type="bibr" target="#b17">[19]</ref> in essence learn cooow sizes and approximate SJF using discrete priority queues, where all newly arriving cooows start from the highest priority queue, and move to lower priority queue as they send more data (without nishing), i.e., cross the per-queue thresholds. In this way, the smaller cooows nish in high priority queues, while the larger cooows gradually move to the lower priority queues where they nish after smaller cooows.</p><p>To realize the above idea in scheduling cooows which have ows at many network ports, i.e., in a distributed setting, Aalo uses a global coordinator to assign cooows to logical priority queues, and uses the total bytes sent by all ows of a cooow as its logical "length" in moving cooows across the queues. The logical priority queues are mapped to local priority queues at each port, and the individual local ports then schedule the ows in its local priority queues, e.g., by enumerating ows from the highest to lowest priority queues and using FIFO to order the ows within each queue.</p><p>In essence, Aalo learns cooow sizes by actually scheduling the cooow, a "try and miss" approach to approximate SJF. As cooow sizes are not known, in each queue, Aalo schedules each cooow for a xed amount of data (try). If the cooow does not nish (miss), it is demoted to a lower priority queue.</p><p>Afterwards, such a cooow will no longer block cooows in higher priority queues.</p><p>Using multiple priority queues to learn the relative cooow sizes of cooows this way, however, negatively aaects the average CCT and the scalability of the coordinator:</p><p>(1) Intrinsic queue-transit overhead: Every cooow that Aalo transits through the queues before reaching its nal queue worsens the average CCT because during transitions, such a cooow eeectively blocks other shorter cooows in the earlier queues it went through, which would have been scheduled before this cooow starts in a perfect SJF.</p><p>(2) Overhead due to inadvertent round-robin: Although Aalo attempts to approximate SJF, it inadvertently ends up doing round-robin for cooows of similar sizes as it moves them across queues. Aalo assigns a xed threshold of data transfer for each cooow in each queue. Assume there are "N" cooows in a queue that do not nish in that queue. Aalo schedules one cooow (chosen using FIFO) and demotes it to a lower priority queue when the cooow reaches the data threshold. At that point, the next cooow from the same queue is scheduled, which joins the previous cooow at a lower priority queue after exhausting its quantum, and this cycle continues as cooows of similar sizes move through the queues. EEectively, these cooows experience the roundrobin scheduling which is known to have the worst average CCT <ref type="bibr" target="#b37">[39]</ref>, when jobs are of similar sizes.</p><p>(3) Limited scalability from frequent updates from local ports: To support the try-and-error style learning, the coordinator requires frequent updates from all local ports of the bytes sent for each cooow in order to move cooows across multiple queues timely. This results in high load on the central coordinator from receiving frequent updates and calculating and sending new rate allocations, which limits the scalability of the overall approach.</p><p>Empirical measurement We quantify the cooow size learning overhead of Aalo, deened as the portion of the bytes of a cooow that has been transferred (or the fraction of its CCT spent in doing so) before reaching its correct queue, using a trace from Facebook clusters <ref type="bibr" target="#b3">[4]</ref> (see detailed methodology in §8). <ref type="figure" target="#fig_0">Figure 1</ref> shows that 40% of the cooows that moved beyond the initial queue reached the correct priority queue after spending more than 20% of their CCT moving across early queues.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Our Contribution</head><p>We propose PPPPPP, a new non-clairvoyant cooow scheduler with a dramatically diierent approach to learning cooow sizes to enable online SJF. To leverage optimal scheduling SJF in cooow scheduling, it is vital to learn the cooow sizes quickly and accurately. PPPPPP achieves this objective by exploiting the spatial dimension of cooows, i.e., a cooow typically consists of many ows, via sampling, a highly eeective technique used in large-scale surveys <ref type="bibr" target="#b32">[34]</ref>. In particular, PPPP pre-schedules sampled ows, called pilot ows, of each cooow and uses their measured size to estimate the cooow size. It then resorts to SCF using the estimated job size. Intuitively, such a sampling scheme avoids all three sources of overhead in Aalo -Once the cooow sizes are learned, the cooows are assigned to the correct queues, which avoids the intrinsic queue-transit and round-robin eeects. Further, a sampling-based design has an important beneetit ooers much higher scalability than priority-queue-based learning in Aalo. This is because unlike Aalo, after estimating the cooow size, PPPPPP clients do not need to send periodic updates of bytes sent-so-far to the centralized coordinator.</p><p>Developing a complete non-clairvoyant cooow scheduler based on the simple sampling idea raises three questions: (1) Why is sampling more eecient than the priority-queuebased cooow size learning? (2) Will sampling be eeective in the presence of skew of ow sizes? (3) How to design the complete scheduler architecture? We systematically address these questions with design rational, theoretical analysis, system design, prototyping, and extensive evaluation.</p><p>In summary, this paper makes the following contributions:</p><p>(1) Using a production datacenter trace from Facebook, we show that the prior art scheduler Aalo spends substantial amount of time and network bandwidth in learning cooow sizes, which negatively aaects the CCT of cooows.</p><p>(2) We propose the novel idea of applying sampling in the spatial dimension of cooow to signiicantly reduce the overhead of online learning cooow sizes. (3) We present theoretical underpinning explaining why sampling remains eeective in the presence of ow size skew. (4) We present the design and implementation of PPPPPP.</p><p>(5) We extensively evaluate PPPPPP via simulations and testbed experiments, and show that compared to the prior art, the new design reduces the average CCT by 1.51× for the Facebook cooow trace and by 1.36× for a trace with properties similar to a Microsoft production cluster. (6) The CCT improvement mainly stems from reduced cooow size learning overhead. PPPPPP reduces the median latency and data sent in nding the right queue for cooows in Aalo by 19.0× and 20.0×, respectively ( §8.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background and Problem Statement</head><p>We start with a brief review of the cooow abstraction and the need for non-clairvoyant cooow scheduling. We then state the network model and problem formulation.</p><p>Cooow abstraction In data-parallel applications such as Hadoop <ref type="bibr" target="#b0">[1]</ref> and Spark <ref type="bibr" target="#b1">[2]</ref>, the job completion time heavily depends on the completion time of the communication stage <ref type="bibr" target="#b10">[12,</ref><ref type="bibr" target="#b18">20]</ref>. The cooow abstraction <ref type="bibr" target="#b16">[18]</ref> was proposed to speed up the communication stage to improve application performance. A cooow is deened as a set of ows between several nodes that accomplish a common task. For example, in map-reduce jobs, the set of all ows from all map to all reduce tasks in a single job forms a typical cooow. The cooow completion time (CCT) is deened as the time duration between when the rst ow arrives and the last ow completes. In such applications, improving CCT is more important than improving individual ows' completion time (FCT) for improving the application performance <ref type="bibr" target="#b17">[19,</ref><ref type="bibr" target="#b19">21,</ref><ref type="bibr" target="#b22">24,</ref><ref type="bibr" target="#b27">29,</ref><ref type="bibr" target="#b28">30]</ref>.</p><p>Non-clairvoyant cooows Data-parallel directed acyclic graphs (DAGs) typically have multiple stages which are represented as multiple cooows with dependencies between them. Recent systems (e.g., <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b20">22,</ref><ref type="bibr" target="#b26">28,</ref><ref type="bibr" target="#b34">36]</ref>) employ optimizations that pipeline the consecutive computation stages which removes the barrier at the end of each cooow, making knowing ow sizes of each cooow beforehand diicult. Thus in this paper, we focus on non-clairvoyant cooow scheduling which do not assume knowledge about cooow characteristics such as ow sizes upon cooow arrival.</p><p>Non-blocking network fabric We assume the same nonblocking network fabric model in recent network designs for cooows <ref type="bibr" target="#b5">[7,</ref><ref type="bibr" target="#b17">19,</ref><ref type="bibr" target="#b19">21,</ref><ref type="bibr" target="#b27">29,</ref><ref type="bibr" target="#b28">30]</ref>, where the datacenter network fabric is abstracted as a single non-blocking switch that interconnects all the servers, and each server (computing node) is abstracted as a network port that sends and receives ows. In such a model, the ports, i.e., server uplinks and downlinks, are the only source of contention as the network core is assumed to be able to sustain all traac injected into the network. We note that the abstraction is to simplify our description and analysis, and is not required or enforced in our evaluation.</p><p>Problem statement Our goal is to develop an eecient nonclairvoyant cooow scheduler that optimizes the communication performance, in particular the average CCT, of data-intensive applications without prior knowledge, while guaranteeing starvation freedom and work conservation and being resilient to the network dynamics. The problem of non-clairvoyant cooow scheduling is NP-hard because cooow scheduling even assuming all cooows arrive at time 0 and their size are known in advance is already NP-hard <ref type="bibr" target="#b19">[21]</ref>. Thus practical non-clairvoyant cooow schedulers are approximation algorithms. Our approach is to dynamically prioritize cooows by eeciently learning their ow sizes online.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Key Idea</head><p>Our new non-clairvoyant cooow scheduler design, PPPPPP, is based on a key observation about cooows that a cooow has a spatial dimension, i.e., it typically consists of many ows. We thus propose to explicitly learn cooow sizes online by using sampling, a highly eeective technique used in large-scale surveys <ref type="bibr" target="#b32">[34]</ref>. In particular, PPPPPP preschedules sampled ows, called pilot ows, of each cooow and uses their measured sizes to estimate the cooow size. It then resorts to SJF or variations using the estimated cooow sizes. Developing a complete non-clairvoyant cooow scheduler based on the simple sampling idea raises three questions:</p><p>(1) Why is sampling more eecient than the priority-queuebased cooow size learning? Would scheduling the remaining ows after sampled pilot ows are completed adversely aaect the cooow completion time?</p><p>(2) Will sampling be eeective in the presence of skew of ow sizes?</p><p>(3) How to design the complete scheduler architecture?</p><p>We answer the rst two questions below, and present the complete architecture design in §4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Why is sampling more eecient?</head><p>Scheduling pilot ows rst before the rest of the ows can potentially incur two sources of overhead. First, scheduling pilot ows of a newly arriving cooow consumes port bandwidth which can delay other cooows (with already estimated sizes). However, compared to the multi-queue based approach, the overhead is much smaller for two reasons: (1) PPPPPP schedules only a small subset of the ows (e.g., fewer than 1% for cooows with many ows). (2) Since the CCT of a cooow depends on the completion of its last ow, some of its earlier nishing ows could be delayed without aaecting the CCT. PPPPPP exploits this observation and schedules pilot ows on the least-busy ports to increase the odds that it only aaects earlier nishing ows of other cooows.</p><p>Second, scheduling pilot ows rst may elongate the CCT of the newly arriving cooow itself whose other ows cannot start until the pilot ows nish. This is again typically insigniicant for two reasons: (1) A cooow (e.g., from a MapReduce job) typically consists of ows from all sending ports to all receiving ports. Conceptually, pre-scheduling one out of multiple ows from each sender may not delay the cooow progress at that port, because all ows at that port have to be sent anyway. (2) Cooow scheduling is of high relevance in a busy cluster (when there is a backlog of cooows in the network), in which case the CCT of cooow is expected to be much higher than if it were the only cooow in the network, and hence the piloting overhead is further dwarfed by a cooow's actual CCT.</p><p>3.2 Why is sampling eeective in the presence of skew?</p><p>The ow sizes within a cooow may vary (skew). Intuitively, if the skew across ow sizes is small, sampling even a small number of pilot ows will be suucient to yield an accurate estimate. Interestingly, even if the skew across ow sizes is large, our experiment indicates that sampling is still highly eeective. In the following, we give both the intuition and theoretical underpinning for why sampling is eeective. Consider, for example, two cooows and the simple setting where both cooows share the same set of ports. In order to improve the average CCT, we wish to schedule the shorter cooow ahead of the longer cooow. If the total sizes of the two cooows are very diierent, then even a moderate amount of estimation error of the cooow sizes will not alter their ordering. On the other hand, if the total sizes of the two cooows are close to each other, then indeed the estimation errors will likely alter their ordering. However, in this case since their sizes are not very diierent anyway, switching the order of these two cooows will not signiicantly aaect the average CCT.</p><p>Analytic results. To illustrate the above eeect, we show that the gap between the CCT based on sampling and assuming perfect knowledge is small, even under general ow size distributions. Speciically, cooows C 1 and C 2 have cn 1 and cn 2 ows, respectively. Here, we assume that n 1 and n 2 are xed constants. Thus, by taking c to be larger, we will be able to consider wider cooows. Assume that each ow of</p><formula xml:id="formula_0">C 1 (correspondingly, C 2 ) has a size that is distributed within a bounded interval [a 1 , b 1 ] ([a 2 , b 2 ]) with mean µ 1 (µ 2 ), i.i.d.</formula><p>across ows. However, the exact distributions can be arbitrary. Let T c be the total completion time when the exact ow sizes are known in advance. Let˜TLet˜ Let˜T c be the average CCT by sampling m 1 and m 2 ows from C 1 and C 2 , respectively. Without loss of generality, we assume that n 2 µ 2 ≥ n 1 µ 1 . Then, using Hoeeding's Inequality, we can show that,</p><formula xml:id="formula_1">lim c→∞˜T c→∞˜ c→∞˜T c − T c T c ≤ 4 exp   − 2(n 2 µ 2 − n 1 µ 1 ) 2 n 2 (b 2 −a 2 ) √ m 2 + n 1 (b 1 −a 1 ) √ m 1 2    n 2 µ 2 − n 1 µ 1 n 2 µ 2 + 2n 1 µ 1</formula><p>(1) (Note that here we have used the fact that, since both cooows share the same set of ports and c is large, the CCT is asymptotically proportional to the cooow size.) Equation (1) can be interpreted as follows. First, due to the rst exponential term, the relative gap betweeñ T c and T c decreases as b 1 − a 1 and b 2 − a 2 decrease. In other words, as the skew of each cooow decreases, sampling becomes more eeective. Second, when b 1 − a 1 and b 2 − a 2 are xed, if n 2 µ 2 − n 1 µ 1 is large (i.e., the two cooow sizes are very diierent), the value of the exponential function will be small. On the other hand, if n 2 µ 2 − n 1 µ 1 is close to zero (i.e., the two cooow sizes are close to each other), the numerator on the second term on the right hand side will be small. In both cases, the relative gap betweeñ T c and T c will also be small, which is consistent with the intuition explained earlier. The largest gap occurs when n 2 µ 2 − n 1 µ 1 is on the same order as</p><formula xml:id="formula_2">n 2 (b 2 −a 2 ) √ m 2 + n 1 (b 1 −a 1 ) √ m 1</formula><p>. Finally, although these analytical results assume that both cooows share the same set of ports, similar conclusions on the impact of estimation errors due to sampling also apply under more general settings.</p><p>The above analytical results suggest that, when c is large, the relative performance gap for CCT is a function of the number of pilot ows sampled for each cooow, but is independent of the total number of ows in each cooow. In practice, large cooows will dominate the total CCT in the system. Thus, these results partly explain that, while in our experiments the number of pilot ows is never larger than 1% of the total number of ows, the performance of our proposed approach is already very good.</p><p>Finally, the above analytical results do not directly tell us how to choose the number of pilot ows, which likely depends on the probability distribution of the ow size. In practice, we do not know such distribution ahead of time. Further, while choosing a larger number of pilot ows reduces the estimation errors, it also incurs higher overhead and delay. Therefore, our design ( §4) needs to have practical solutions that carefully address these issues.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">PPPPPP Design</head><p>In this section, we present the detailed design of PPPPPP, which addresses three design challenges: (1) Cooow size estimation: How to choose and schedule the pilot ows for each newly arriving cooow? (2) Starvation avoidance: How to schedule cooows after size estimation using variations of SJF that avoid starvation? (3) Cooow scheduling: How to schedule among all the cooows with estimated sizes?  <ref type="formula">(2)</ref> local agents that run on individual ports. A computing framework such as Spark <ref type="bibr" target="#b40">[42]</ref> rst registers (removes) a cooow when a job arrives ((nishes). Upon a new cooow arrival, old cooow completion, or pilot ow completion, the coordinator calculates a new cooow schedule, which includes (1) cooows that are to be scheduled in the next time slot, and (2) ow rates for the individual ows of a cooow, and pushes this information to the local agents which use this information to allocate their bandwidth. The local agents will follow the current schedule until they receive a new schedule. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">PPPPPP architecture</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Sampling pilot ows</head><p>As discussed in §3, PPPPPP estimates the size of a cooow online by actually scheduling a subset of its ows (pilot ows) at their ports. We do not schedule the ows of a cooow other than the pilot ows until the completion of the pilot ows in order to avoid unnecessary extra blocking of other potentially shorter cooows. How many pilot ows? When a new cooow arrives, PPPP rst needs to determine the number of pilot ows. As discussed at the end of §3, the number of pilot ows aaects the trade-oo between the cooow size estimation accuracy and scheduling overhead. For cooows with skewed ow sizes, accurately estimating the total cooow size potentially requires sampling the sizes of many pilot ows. However, scheduling pilot ows has associated overhead, i.e., if the cooow turns out to be a large cooow and should have been scheduled to run later under SJF.</p><p>We explore several design options for choosing the number of pilot ow. Two natural design choices are using a constant number of pilot ows or a xed fraction of the total number of ows of a cooow. In addition, we observe that typical cooows consist of ows between a set of senders (e.g., mappers) and a set of receivers (e.g., reducers) <ref type="bibr" target="#b21">[23]</ref>. We thus include a third design choice of a xed fraction of sending ports. This design also spreads the pilot ows to avoid having multiple pilot ows contending for the same sending ports. We empirically found that ( §8.2) limiting the pilot ows to 5% to 10% of the number of its sending ports (e.g., mappers in a MapReduce cooow) strikes a good balance between estimation accuracy and overhead. We note the total number of ows sampled in this case is still under 1%.</p><p>Finally, we estimate the total cooow size as S = f i · N, where N is the number of ows in a cooow, and f i is the average size of the sampled pilot ows. Which ows to probe? Second, PPPPPP needs to decide which ports to schedule the chosen number of probe ows for a cooow. For this, we use a simple heuristic where, upon the arrival of a new cooow, we select the ports for its pilot ows that are least busy, i.e., having pilot ows from the least number of other cooows. PPPPPP starts with the least busy sending port and iterates over receiving ports starting with the least busy receiving port and assigns the ow if it exists. It then updates the statistics for the number of pilot ows scheduled at each port and repeats the above process. Such a choice will likely delay fewer cooows when the pilot ows are scheduled and hence reduce the elongation on their CCT. We note that such an online heuristic may not be optimal; more sophisticated algorithms can be derived by picking ports for multiple cooows together. However, we make this design choice for its simplicity and low time complexity to ensure that the coordinator makes fast decisions. How to schedule pilot ows? In PPPPPP, we prioritize the pilot ows of a new cooow over existing ows to accelerate learning the size of the new cooow. In particular, at each port, pilot ows have high priority over non-pilot ows. If there are multiple outstanding pilot ows (of diierent cooows) at a port, PPPPPP schedules them in the FIFO order.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Cooow scheduling with starvation avoidance</head><p>Once the sizes of cooows are learned, we can apply variations of the SJF policy to schedule them. However, it is well known that such policies can lead to starvation. There are many ways to mitigate the starvation issue. However, a subtlety arises where even slight diierence in how starvation is addressed can result in diierent performance. For example, the multiple priority queues in Aalo has the beneet of ensuring progress of all cooows, but assigning diierent time-quanta to diierent priority queues can result in diierent average CCT for the same workload. To ensure the fairness of performance comparison with Aalo, we need to ensure that both PPPPPP and Aalo provide the same level of starvation freedom (or progress measure).</p><p>For this reason, in this paper, we inherit the multiple priority queue structure from Aalo for cooow scheduling. As in Aalo, PPPPPP sorts the cooows among multiple priority queues. In particular, PPPPPP uses N queues, Q 0 to Q N−1 , with each queue having lower queue threshold Q lo q and higher threshold Q hi q , where Q lo 0 = 0, Q hi N−1 = ∞, Q lo q+1 = Q hi q , and the queue thresholds grow exponentially, i.e., Q hi q+1 = E · Q hi q . The overall cooow scheduling in PPPPPP works as follows. After the cooow size is estimated using pilot ows, PPPPPP assigns the cooow to the priority queue using inter-cooow policies discussed in §4.4. Within a queue, we use FIFO to schedule cooows. Lastly, we use weighted sharing of network bandwidth among the queues, where a priority queue receives a network bandwidth based on its priority. As in Aalo, the weights decrease exponentially with decrease in the priority of the queues.</p><p>Using FIFO within the priority queue and weighted fair sharing among the queues together ensure the same starva-tion freedom and thus meaningful performance comparison between PPPPPP and Aalo <ref type="bibr" target="#b17">[19]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Inter-cooow scheduling policies</head><p>In PPPPPP, we explore four diierent scheduling policies based on diierent combinations of cooow size and contention, two size-based policies (A, B) as in Aalo, a contention-based, similar to the intra-queue policy used in Saath <ref type="bibr" target="#b28">[30]</ref>  We use the following parameters of a cooow to deene the metrics in scheduling algorithms: (1) average ow length (l) from piloting, (2) number of ows (n), (3) number of sender and receiver ports (s, r), (4) total amount of data sent so far (d), (5) contention (c), deened as the number of other cooows sharing any ports with the given cooow, and (6) port-wise contention (c p ), deened as the number of other cooows blocked at a given port p.</p><p>PPPPPP uses Policy D by default, as it results in the least average CCT ( §8). For all policies, we continue to use the priority-queue based scheduling, and the algorithms only diier in what metric they use in assigning cooows to the priority queues. In contrast, Aalo does not handle inter-cooow contention, and uses the total bytes sent so far (d) to move cooows across multiple priority queues.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Rate allocation</head><p>Once the scheduling order of the cooows is determined, we need to determine the rates for the individual ows at each port. First, since we want to quickly nish the pilot ow, at any port that has pilot ows, PPPPPP assigns the entire port bandwidth to the pilot ows. For the remaining ports, as discussed in §4.3, across multiple queues, PPPPPP assigns weighted shares of the port bandwidth, by assigning them varying numbers of scheduling intervals according to the weights assigned to each priority queues.</p><p>Second, at each scheduling interval, PPPPPP assigns rates for the ows of the cooow in the head of the FIFO queue as follows. It assigns equal rates at all the ports containing its ows as there is no beneet in speeding-up its ows at certain ports when its CCT depends on the slowest ow. At each port, we could use max-min fairness to schedule the individual ows of the cooow (to diierent receivers), and then assign the rate of the slowest ow to all the ows in the cooow. Afterwards, the port-allocated bandwidths are incremented accordingly at the coordinator, which then allocates rates for the next cooow in the same FIFO queue, and so on.</p><p>Though the above max-min approach has the advantage of minimizing bandwidth wastage, it slows down the coordinator which has to iterate over many ows. In our experiments, we used a simple scheme where we assign the entire bandwidth at the sender and receiver ports to one ow of the cooow at the head of the FIFO queue at a time. We found that this simple scheme has very marginal eeect on CCTs but makes the rate assignment process considerably faster.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Additional design issues</head><p>Thin cooow bypass Recall that, in PPPPPP, when a new cooow arrives, PPPPPP only schedules its pilot ows. All other ows of that cooow are delayed until the pilot ows nish and cooow size is known. However, such a design choice can inadvertently lead to higher CCTs for cooows, particularly for thin cooows, e.g., a two--ow cooow would end up serializing scheduling its two ows, one for the piloting purpose.</p><p>To avoid CCT degradations for thin cooows, we schedule all ows of a cooow if its width is under a threshold (set to 7 in PPPPPP; §8.6 provides sensitivity analysis for thresholds).</p><p>Failure tolerance and recovery Cluster dynamics such as stragglers or node failure can delay some of the ows of a cooow or start new ows, increasing their CCT. The PPPPPP design automatically self-adjusts to speed up cooows that are aaected by cluster dynamics using the following mechanisms: (1) It adjusts the cooow size as the amount of data left by the cooow, which is essentially the diierence between the size calculated using pilot ows and amount of data already sent. (2) It calculates contention only on the ports that have unnnished ows.</p><p>Work Conservation By default, PPPPPP schedules non-pilot ows of a cooow only after all its pilot ows are over. This can lead to some ports being idle where the non-pilot ows are waiting for the pilot ows to nish. In such cases, PPPPPP schedules non-pilot ows of cooows which are still in the sampling phase at those ports. In work conservation, the cooows are scheduled in the FIFO order of arrival of cooows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Scalability Analysis</head><p>Compared to learning cooow sizes using priority queues (PQbased) <ref type="bibr" target="#b17">[19,</ref><ref type="bibr" target="#b28">30]</ref>, learning cooow sizes by sampling PPPPPP not only reduces the learning overhead as discussed in §3.1 and shown in §8.2, but also signiicantly reduces the amount of interactions between the coordinator and local agents and thus makes the coordinator highly scalable, as summarized in <ref type="table" target="#tab_0">Table 1</ref>.</p><p>First, PQ-based learning requires much more frequent update from local agents. PQ-based learning estimates cooow sizes by incrementally moving cooows across priority queues according to the data sent by them so far. As such, the scheduler needs frequent updates (every δ ms) of data sent per cooow from the local agents. In contrast, PPPPPP directly estimates a cooow's size upon the completion of all its pilot ows. The only updates PPPPPP needs from the local agents are about the ow completion which is needed for updating contentions and removing ows from active consideration.. Second, PQ-based learning results in much more frequent rate allocation. In sampling-based approach, since cooow sizes are estimated only once, cooows are re-ordered only upon cooow completion or arrival events or in the case of contention based policies only when contention changes, which is triggered by completion of all the ows of a cooow at a port. In contrast, in PQ-based learning, at every δ interval, cooow data sent are updated and cooow priority may get updated, which will trigger new rate assignment.</p><p>Our scalability experiments in §9.3 connrms that PPPPPP achieves much higher scalability than Aalo.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Implementation</head><p>We implemented both PPPPPP and Aalo scheduling policies in the same framework consisting of the global coordinator and local agents <ref type="figure" target="#fig_1">(Fig. 2</ref>), in 5.2 KLoC in C++.</p><p>Coordinator: The coordinator schedules the cooows based on the operations received from the registering framework. The key implementation challenge for the coordinator is that it needs to be fast in computing and updating the schedules. The PPPPPP coordinator is optimized for speed using a variety of techniques including pipelining, process aanity, and concurrency whenever possible.</p><p>Local agents: The local agents update the global coordinator only upon completion of a ow, along with its length if it is a pilot ow. Local agents schedule the cooows based on the last schedule received from the coordinator. They comply to the last schedule until a new schedule is received. To intercept the packets from the ows, local agents require the compute framework to replace datasend(), datarecv() APIs with the corresponding PPPPPP APIs, which incurs very small overhead.</p><p>Cooow operations: The global coordinator runs independently from, and is not coupled to, any compute framework, which makes it general enough to be used with any framework. It provides RESTful APIs to the frameworks for cooow operations: (a) register() for registering a new cooow when it enters, (b) deregister() for removing a cooow when it exits, and (c) update() for updating cooow status whenever there is a change in the cooow structure, e.g., during task migration and restarts after node failures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Evaluation Highlights</head><p>We evaluated PPPPPP using a 150-node and a 900-node testbed cluster in Azure and using large scale simulations by utilizing a publicly available Hive/MapReduce trace collected from a 3000-machine, 150-rack Facebook production cluster <ref type="bibr" target="#b3">[4]</ref> and multiple derived traces with varying degrees of ow size skew to measure PPPPPP's robustness to skew.</p><p>• Facebook (FB) trace: The trace contains 150 ports and 526 (&gt; 7 × 10 5 ows) cooows, that are extracted from Hive/MapReduce jobs from a Facebook production cluster. Each cooow consists of pair-wise ows between a set of senders and a set of receivers.</p><p>Due to the lack of other publicly available cooow trace 1 , we derived three additional traces using the original Facebook trace in order to more thoroughly evaluate PPPPPP under varying cooow size skew:</p><p>• Low-skew--ltered: Starting with the FB trace, we ltered out cooows that have skew (max ow length/min ow length) less than a constant k. We generated ve traces in this class with k = 1, 2, 3, 4, 5. The ltered traces have 142, 100, 65, 51 and 43 cooows, respectively.</p><p>• Mantri-like: Starting with the FB trace, we adjusted the sizes of the ows sent by the mappers, keeping the total reducer data the same as given in the original trace, to match the skew of a large Microsoft production cluster trace as described in Mantri <ref type="bibr" target="#b10">[12]</ref>. In particular, the sizes are adjusted so that the coeecients of variation across mapper data are about 0.34 in the 50 th percentile case and 3.1 in the 90 th percentile case. This trace has the same numbers of cooows and ports as the FB trace.</p><p>• Wide-cooows-only: We ltered out all the cooows in the FB trace with the total number of ows ≤ 7, the default thin cooow bypass threshold (thinLimit) in PPPP . The ltered trace has 269 cooows spreading over 150 ports.</p><p>The primary performance metrics used in the evaluation are CCT or CCT speedup, deened as the ratio of a CCT under other baseline algorithms and under PPPPPP, piloting overhead, and cooow size estimation accuracy.</p><p>The highlights of our evaluation results are:</p><p>(1) PPPPPP signiicantly improves the CCTs. In simulation using the FB trace, the average CCT is improved by 1.51× over the prior art, Aalo. Individual CCT speedups are 1.78× in the median case (P90 = 9.58×). For the Mantri-like trace, the average CCT is improved by 1.36× and individual CCT speedups are 1.75× in the median case (P90 = 12.0×).</p><p>(2) The CCT improvement mainly stems from the reduction in the learning overhead (in terms of latency and amount of data sent) in determining the right queue for the cooows. Compared to Aalo, median reduction in the absolute latency in nding the right queue for cooows in PPPPPP is 19.0×, and in absolute amount of data sent is 20.0× ( §8.2).</p><p>(3) PPPPPP improvements are consistent when varying the skew among the ow sizes in a cooow ( §8.5).</p><p>(4) PPPPPP improvements are consistent when varying its parameters ( §8.6).</p><p>(5) The PPPPPP coordinator is much more scalable than that of Aalo ( §9.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Simulation</head><p>We present detailed simulation results in this section, and the testbed evaluation of our prototype in §9.</p><p>Experimental setup: Our simulated cluster uses the same number of nodes (sending and receiving network ports) as in the trace. As in <ref type="bibr" target="#b17">[19]</ref>, we assume full bisection bandwidth is available, and congestion can happen only at network ports.</p><p>The default parameters for Aalo and PPPPPP in the experiments are: starting queue threshold (Q hi 0 ) is 10MB, exponential threshold growth factor (E) is 10, number of queues (K) is set to 10, the weights assigned to individual priority queues decrease exponentially by a factor of 10, and the new schedule calculation interval δ is set to 8ms for the 150-node cluster 2 , the default suggested in its publicly available simulator <ref type="bibr" target="#b17">[19]</ref>. In PPPPPP, a new schedule is calculated on demand, upon arrival of a new cooow, completion of a cooow, or completion of all pilot ows of a cooow. Finally, in PPPPPP the threshold for thinLimit (T) is set to 7, the number of pilot ows assigned to wide cooows are max(1, 0.05 · S), where S is the number of senders, and the default inter-cooow scheduling policy in PPPPPP is Least length-weighted total-port contention.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.1">Pilot ow selection policies</head><p>We start by evaluating the impact of diierent policies in choosing the pilot ows for a cooow in PPPPPP. Aalo and average error in size estimation normalized to the actual cooow size, when varying the pilot ow selection policy while keeping other parameters as the default in PPPPPP, using the FB trace.</p><p>Unsurprisingly, the estimation accuracy increases when increasing the number of pilot ows across the three selection schemes: constant, fraction of senders, and fraction of total ows. However, as the number of pilot ows increases (over the range of parameter choices), the CCT speedup (P50 and P90 of individual cooow CCT speedups) decreases. This is because the beneet from size estimation accuracy improvement from using additional pilot ows does not ooset the added overhead from completing the additional pilot ows and the delay they incur to other cooows.</p><p>We nd sampling 5% of the number of senders per cooow strikes a good trade-oo between piloting overhead and size estimation accuracy leading to the best CCT reduction. We thus set it (0.05 · S) as the default pilot ow selection policy. Next, using the default pilot selection policy, we evaluate PPPPPP's eeectiveness in estimating cooow sizes by sampling pilot ows. <ref type="figure" target="#fig_4">Fig. 3</ref> shows a scatter plot of the actual cooow size vs. estimated size from running PPPPPP under the default settings. We observe that PPPPPP cooow's size estimation is highly accurate except for a few outliers. Overall, the average and standard deviation of relative estimation error are 0.06 and 0.15, respectively, and for the top 99% and 95% cooows (in terms of estimation accuracy), the average (standard deviation) of relative error are only 0.05 (0.12) and 0.03 (0.07) respectively. Interestingly, a few cooows experience large estimation errors, and we found they all have very high skew in their ow lengths; the mean standard deviation in ow lengths, normalized by the average length, of the bottom 1% (in terms of accuracy) ranges between 4.6 and 6.8. <ref type="figure" target="#fig_0">Fig. 1</ref> shows the cost of estimating the correct queue for each cooow in PPPPPP and Aalo, measured as the time in learning the cooow size as a fraction of the cooow's CCT in PPPPPP and Aalo. We see that under PPPPPP, about 63% of the cooows spent less than 1% of their CCT in the learning phase, while under Aalo, 63% cooows reached the correct priority queue after spending up to 22% of their CCT moving across other queues. Compared to Aalo, PPPPPP in the median case sends 20× less data in determining the right queue and reduces the latency in determining the right queue by 19×.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2">Piloting overhead and accuracy</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.3">Inter-cooow scheduling policies</head><p>PPPPPP diiers from Aalo in two ways: online size estimation and inter--ow scheduling policy. Here, we evaluate the eeectiveness of the four inter-cooow scheduling policies of PPPPPP discussed in §4.4, keeping the remaining parameters as the default. Such evaluation allows us to decouple the contribution of sampling-based learning from the eeect of scheduling policy diierence. <ref type="table" target="#tab_3">Table 3</ref> shows the CCT improvement of PPPPPP under the four inter--ow scheduling policies over Aalo. We make the following observations. First, PPPPPP with the purely sized-based policy, Smallest job rst (A), which uses the same inter-queue and intraqueue scheduling policy as Aalo and only diiers from Aalo in cooow size estimation, reduces the average CCT (P50) of Aalo by <ref type="bibr">1.40x (1.48x)</ref>.</p><p>In contrast, the default PPPPPP uses Least lengthweighted total-port contention (D), which uses the sum of size-weighted port contention to assign cooows to priority queues, and slightly outperforms the size-based policy A; it reduces the average CCT (P50) of Aalo by <ref type="bibr">1.51x (1.78x)</ref>. This is because it captures the diversity of contention at diierent ports, which happens often in real distributed settings, and at the same time accounts for the cooow size by using lengthweighted sum of the port-wise contention. The above results for policy A and policy D indicate that the primary improvement in PPPPPP comes from its sampling-based cooow size estimation scheme.</p><p>Shortest remaining time rst (B) performs similarly as smallest job rst. This is because the preemptive nature of SRTF will kick in only on arrival of new cooows. Also, although SRTF is advantageous for small cooows, since PPPPPP already schedules thin cooows at high priority, many thin and thus small cooows are anyways being scheduled at high priority under both policies A and B, and as a result they perform similarly.</p><p>Finally, Least contention rst (C) performs poorly. This is because contention for a cooow is deened as the unique number of other cooows that share ports, and as a result such a policy completely ignores the size (length) of the cooows. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.4">Average CCT improvement</head><p>We now compare the CCT speedups of PPPPPP against 5 wellknown cooow scheduling policies: (1) Aalo, (2) Aalo-Oracle, which is an oracle version of Aalo where the scheduler knows the nal queue of a cooow upon its arrival time and directly starts the cooow from that queue, (3) SEBF in Varys <ref type="bibr" target="#b19">[21]</ref> which assumes the knowledge of cooow sizes apriori and uses the Shortest EEective Bottleneck First policy, where the cooow whose slowest ow will nish rst is scheduled rst. (4) FIFO, which is a single queue FIFO based cooow scheduler, and (5) FAIR, which uses per--ow fair sharing. We do not include Saath <ref type="bibr" target="#b28">[30]</ref> in the comparison as it does not provide the same liveliness guarantees as PPPPPP which as discussed in §4.3 can obscure the comparison result. All experiments use the default parameters discussed in the setup, including K, E, S, unless otherwise stated. The results are shown in <ref type="figure">Fig. 4(a)</ref>. We make the following observations. First, we compare CCT under PPPPPP against under AaloOracle, where Aalo-Oracle starts all cooows at the correct priority queues (i.e., no learning overhead). PPPPPP improves the average CCT by 1.18× and P50 CCT by 1.40×, respectively. Since Aalo-Oracle pays no overhead for cooow size estimation, its worse performance suggests that using length-weighted total-port contention in assigning cooows to the priority queues in PPPPPP outperforms Aalo's sizebased, contention-oblivious policy in assigning cooows to the queues.</p><p>Second, PPPPPP improves the average CCT over Aalo by 1.51× (median) and P50 by 1.78. The signiicant additional improvement on top of the gain over Aalo-Oracle comes from fast and accurate estimation of the right queues for the cooows <ref type="figure" target="#fig_0">(Fig. 1)</ref>.</p><p>Third, PPPPPP, which requires no cooow size knowledge a priori, achieves comparable performance as SEBF <ref type="bibr" target="#b19">[21]</ref>; it reduces the average CCT by 1.16×. Again this is because its total-port contention policy outperforms the contentionoblivious SEBF.</p><p>Finally, PPPPPP signiicantly outperforms the single-queue FIFO-based cooow scheduler, with a median (P90) CCT speedup of 3.00 (77.96)× and average CCT speedup of 3.16×, and the un-coordinated ow-level fair-share scheduler, with a median (P90) CCT speedup of 70.82× (1947×) and average CCT speedup of 5.66×.</p><p>To gain insight into how diierent cooows are aaected by PPPPPP over Aalo, we group the cooows in the trace into Figure 4: CCT speedup using PPPPPP compared to using other cooow schedulers on diierent traces. In <ref type="figure">Fig. 4(c)</ref>, the x-axis denotes the minimum skew in the 5 Low-skew--ltered traces.</p><p>Bin-1 Bin-2 Bin-3 Bin-4  <ref type="table" target="#tab_5">Table 4</ref>.  four bins deened in <ref type="table" target="#tab_5">Table 4</ref>, and show in <ref type="figure">Fig. 5</ref> the CCT speedups for each bin. We see that PPPPPP improves CCT for all cooows in bin 1 and 3 and for large fraction in bin-4. Most of the underperforming cooows fall in bin-2. Cooows in bin-2 have width &gt; 7 and size &lt; 100MB, i.e., the ows are short but wide. Because the width exceeds the thinLimit, PPPPPP schedules the pilot ows to estimate the cooow size rst ( §4). Thus, although the remaining ows are short, they get delayed until the completion of the pilot ows, which results in CCT increase. Finally, since thin cooows beneet from PPPPPP's scheme of bypassing probing for thin cooows, we also compare PPPPPP with other schemes using the Wide-cooows-only trace which consists of all cooows wider than the default thinLimit <ref type="formula">(7)</ref> in PPPPPP. <ref type="figure">Fig. 4(b)</ref> shows that PPPPPP continues to perform well, reducing the average CCT by 1.54×, 1.15×, and 1.12× over Aalo, Aalo-Oracle, and SEBF, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Bins</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.5">Robustness to cooow data skew</head><p>Next, we evaluate PPPPPP's robustness to ow size skew by comparing it against Aalo using traces with varying degrees of skew. First, we evaluate PPPPPP using the Mantri-like trace. <ref type="figure">Fig. 4(d)</ref> shows that PPPPPP consistently outperforms prior-art cooow schedulers. In particular, PPPPPP reduces the average CCT by 1.36x compared to Aalo. Second, we evaluate PPPPPP using the Low-skew--ltered traces which have low skew cooows ltered out. <ref type="figure">Fig. 4(c)</ref> shows that PPPPPP performs better than Aalo even with highly skewed traces and reduces the average CCT by 1.45×, 1.44×, 1.44×, 1.40× and 1.38× for the ve Low-skew--ltered traces containing cooows with skew of at least 1, 2, 3, 4 and 5, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.6">Sensitivity analysis</head><p>Compared to Aalo, PPPPPP has only two additional paramaters: thinLimit and ow sampling rate. We already discussed the choice of sampling rate in §8.1. Below, we evaluate the sensitivity of PPPPPP to thinLimit and other design parameters common to Aalo by varying one parameter at a time while keeping the rest as the default.</p><p>Thin cooow bypassing limit (T ) In this experiment, we vary thinLimit (T) in PPPPPP for bypassing cooows from the probing phase. The result in <ref type="figure" target="#fig_7">Fig. 7(a)</ref> shows that the average CCT remains almost the same as T increases. This is because the average CCT is dominated by wide and large cooows, which are not aaected by thinLimit. However, the P50 speedup increases till T = 7 and tapers oo after T = 7. The reason for the CCT improvement until T = 7 is that all ows of thin cooows (with width ≤ 7) are scheduled immediately upon arrival which improves their CCT, and the number of thin cooows is signiicant.</p><p>Start queue threshold (Q hi 0 ) We next vary the threshold for the rst priority queue from 2 MB to 64 MB. <ref type="figure" target="#fig_7">Fig. 7(b)</ref> shows the average CCT of PPPPPP over Aalo. Overall, PPPPPP is not very sensitive to the threshold of rst priority queue and the CCT speedup over Aalo is within 8% of the default PPPPPP (10 MB). The speedup appears to oscillate with a periodicity of 5x to 10x. For example, the speedups for 2 MB and 64 MB are close to that of the default (10 MB), while for 4 MB and 32 MB are lower. This can be explained by the impact of the rst queue threshold on job segregation; with the default queue threshold growth factor of 10, every time the rst queue threshold changes by close to 10x, the distribution of jobs across the queues become similar.</p><p>Multiplication factor (E) In this experiment, we vary the queue threshold growth factor from 2 to 64. Recall that the queue thresholds are computed as Q hi q = Q hi q−1 · E. Thus, as E grows, the number of queues decreases. As shown in <ref type="figure" target="#fig_7">Fig. 7(c)</ref>, smaller queue threshold multiplication factor which leads to more queues performs better because of ne-grained priority segregation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Testbed Evaluation</head><p>Next, we deployed PPPPPP in a 150-machine Azure cluster and a 900-machine cluster to evaluate its performance and scalability.</p><p>Testbed setup: We rerun the FB trace on a Spark-like framework on a 150-node cluster in Microsoft Azure <ref type="bibr">[5]</ref>. The coordinator runs on a Standard DS15 v2 server with 20-core 2.4 GHz Intel Xeon E5-2673 v3 (Haswell) processor and 140GB memory. The local agents run on D2v2 with the same processor as the coordinator with 2-core and 7GB memory. The machines on which local agents run have 1 Gbps network bandwidth. Similarly as in simulations, our testbed evaluation keeps the same ow lengths and ow ports in trace replay. All the experiments use default parameters K, E, S and the default pilot ow selection policy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.1">CCT Improvement</head><p>In this experiment, we measure CCT improvements of PPPP compared to Aalo. <ref type="figure" target="#fig_6">Fig. 6</ref> shows the CDF of the CCT speedup of individual cooows under PPPPPP compared to under Aalo. The average CCT improvement is 1.50× which is similar to the results in the simulation experiments. We also observe 1.63× P50 speedup and 8.00× P90 speedup.</p><p>We also evaluated PPPPPP using the Wide-cooow-only trace. <ref type="table" target="#tab_6">Table 5</ref> shows that PPPPPP achieves 1.52× improvement in average CCT over Aalo, similar to that using the full FB trace. This is because the improvement in average CCT is dominated by large cooows, PPPPPP is speeding up large cooows, and the Wide-cooow-only trace consists of mostly large cooows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.2">Job Completion Time</head><p>Next, we evaluate how the improvement in CCT aaects the job completion time (JCT). In data clusters, diierent jobs  spend diierent fractions of their total job time in data shuue. In this experiment, we used 526 jobs, each corresponding to one cooow in the FB trace. The fraction of time that the jobs spent in the shuue phase follows the same distribution used in Aalo <ref type="bibr" target="#b17">[19]</ref>, i.e., 61% jobs spent less than 25% of their total time in shuue, 13% jobs spent 25-49%, another 14% jobs spent 50-74%, and the remaining spent over 75% of their total time in shuue. <ref type="figure" target="#fig_6">Fig. 6</ref> shows the CDF of individual speedups in JCT. Across all jobs, PPPPPP reduces the job completion time by 1.16× in the median case and 7.87× in the 90 th percentile. This shows that improved CCT translates into better job completion time. As expected, the improvement in job completion time is smaller than the improvement in CCT because job completion time depends on the time spent in both compute and shuue (communication) stages, and PPPPPP improves only the communication stage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.3">Scalability</head><p>Finally, we evaluate the scalability of PPPPPP by comparing its performance with Aalo on a 900-node cluster. To drive the evaluation, we derive a 900-port trace by replicating the FB trace 6 times across ports, i.e., we replicated each job 6 times, keeping the arrival time for each copy the same but assigning sending and receiving ports in increments of 150 (the cluster size for the original trace). We also increased the scheduling interval δ by 6 times to δ = 6×δ. PPPPPP achieved 2.72× (9.78×) speedup in average (P90) CCT over Aalo. The higher speedup compared to the 150-node runs (1.50×) comes from higher scalability of PPPPPP. In 900-node runs, Aalo was not able to nish receiving updates, calculating new rates and updating local agents of new rates within δ in 37% of the intervals, whereas PPPPPP only missed the deadline in 10% of the intervals. For 150-node runs these values are 16% for Aalo and 1% for PPPPPP. The 21% increase in missed scheduling intervals in 900-node runs in Aalo resulted in local agents executing more frequently with outdated rates. As a result, PPPPPP achieved even higher speedup in 900-node runs.</p><p>As discussed in §5, Aalo's poorer coordinator scalability comes from more frequent updates from local agents and more frequent rate allocation, which result in longer coordinator CPU time in each scheduling interval. <ref type="table" target="#tab_7">Table 6</ref> shows the average coordinator CPU usage per interval and its breakdown. We see that (1) on average PPPPPP spends much less time than Aalo in receiving updates from local agents, because PPPPPP does not need updates from local agents at every interval -on average in every scheduling interval PPPPPP receives updates from 49 local agents whereas Aalo receives from 429 local agents, and (2) on average PPPPPP spends much less time calculating new rates and send new rates. This is because rate calculation in PPPPPP is triggered by events and PPPPPP did not have to ush rates in 66% of the intervals.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10">Related Work</head><p>Cooow scheduling: In this paper, we have shown PPPPPP outperforms prior-art non-clairvoyant cooow scheduler Aalo from more eecient learning of cooow sizes online. Saath <ref type="bibr" target="#b28">[30]</ref> and Graviton <ref type="bibr" target="#b27">[29]</ref> also learn cooow sizes online using priority queues and hence suuers the same ineeciency as Aalo. Graviton <ref type="bibr" target="#b27">[29]</ref> uses the number of ports a cooow is present at, as an additional indicator of its size. In <ref type="bibr" target="#b17">[19]</ref>, Aalo was shown to outperform previous non-clairvoyant cooow schedulers Baraat <ref type="bibr" target="#b22">[24]</ref> by using global coordination, and Orchestra <ref type="bibr" target="#b18">[20]</ref> by avoiding head-of-line blocking.</p><p>Clairvoyant cooow schedulers such as Varys <ref type="bibr" target="#b19">[21]</ref> and Sincronia <ref type="bibr" target="#b5">[7]</ref> assume prior knowledge of cooows upon arrival. Varys runs a shortest-eeective-bottleneck--rst heuristic for inter-cooow scheduling and performs per--ow rate allocation at the coordinator. Sincronia improves the scalability of the centralized coordinator of Varys by only calculating the cooow ordering at the coordinator (by solving an LP) and oooading ow rate allocation to individual local agents. Sincronia is orthogonal to PPPPPP; once cooow sizes are learned through sampling, ideas from Sincronia can be adopted in PPPPPP to order cooows and oooad rate allocation to local ports. CODA <ref type="bibr" target="#b42">[44]</ref> tackles an orthogonal problem of identifying ows of individual cooows online.</p><p>However, recent studies <ref type="bibr" target="#b17">[19,</ref><ref type="bibr" target="#b38">40]</ref> have shown various reasons why it is not very plausible to learn ow sizes from applications beforehand. For example, many applications stream data as soon as data are generated and thus the application does not know the ow sizes until ow completion, and learning ow sizes from applications requires changing either the network stack or the applications.</p><p>Flow scheduling: There exist a rich body of prior work on ow scheduling. EEorts to minimize ow completion time (FCT), both with prior information (e.g., PDQ <ref type="bibr" target="#b24">[26]</ref>, pFabric <ref type="bibr" target="#b7">[9]</ref>) and without prior information (e.g., <ref type="bibr">Fastpass [35]</ref>, PIAS <ref type="bibr" target="#b11">[13]</ref>, <ref type="bibr" target="#b12">[14]</ref>), fall short in minimizing CCTs which depend on the completion of the last ow <ref type="bibr" target="#b19">[21]</ref>. Similarly, Hedera <ref type="bibr" target="#b6">[8]</ref> and MicroTE <ref type="bibr" target="#b13">[15]</ref> schedule the ows with the goal of reducing the overall FCT, which again is diierent from reducing the overall CCT of cooows.</p><p>Speculative scheduling Recent works <ref type="bibr" target="#b14">[16,</ref><ref type="bibr" target="#b31">33]</ref> use the idea of online requirement estimation for scheduling in datacenter. In <ref type="bibr" target="#b29">[31]</ref>, recurring big data analytics jobs are scheduled using their history.</p><p>Job scheduling: There have been much work on scheduling in analytic systems and storage at scale by improving speculative tasks <ref type="bibr" target="#b9">[11,</ref><ref type="bibr" target="#b10">12,</ref><ref type="bibr" target="#b41">43]</ref>, improving locality <ref type="bibr" target="#b8">[10,</ref><ref type="bibr" target="#b39">41]</ref>, and end-point exibility <ref type="bibr" target="#b15">[17,</ref><ref type="bibr" target="#b36">38]</ref>. The cooow abstraction is complimentary to these work, and can beneet from them. Combining cooow with these approaches remains a future work.</p><p>Scheduling in parallel processors: Cooow scheduling by exploiting the spatial dimension bears similarity to scheduling processes on parallel processors and multi-cores, where many variations of FIFO <ref type="bibr" target="#b35">[37]</ref>, FIFO with backklling <ref type="bibr" target="#b30">[32]</ref> and gang scheduling <ref type="bibr" target="#b23">[25]</ref> have been proposed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="11">Conclusion</head><p>State-of-the-art online cooow schedulers approximate the classic SJF by implicitly learning cooow sizes and pay a high penalty for large cooows. We propose the novel idea of sampling in the spatial dimension of cooows to explicitly and eeciently learn cooow sizes online to enable eecient online SJF scheduling. Our extensive simulation and testbed experiments show the new design ooers signiicant performance improvement over prior art. Further, the sampling-inspatial-dimension technique can be generalized to other distributed scheduling problems such as cluster job scheduling. We have made our simulator publicly available at https: //github.com/coflowPhilae/simulator <ref type="bibr" target="#b4">[6]</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: CDF of learning overhead per cooow, i.e., the time to reach the correct priority queue as a fraction of CCT, excluding cooows directly scheduled by PPPPPP or nish in Aalo's rst queue.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2</head><label>2</label><figDesc>Fig. 2 shows the PPPPPP architecture. PPPPPP models the entire datacenter as a single big-switch with each computing node as an individual port. The scheduling task in PPPPPP is divided among (1) a central coordinator, and (2) local agents that run on individual ports. A computing framework such as Spark [42] rst registers (removes) a cooow when a job arrives ((nishes). Upon a new cooow arrival, old cooow completion, or pilot ow completion, the coordinator calculates a new cooow schedule, which includes (1) cooows that are to be scheduled in the next time slot, and (2) ow rates for the individual ows of a cooow, and pushes this information to the local agents which use this information to allocate their bandwidth. The local agents will follow the current schedule until they receive a new schedule.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: PPPPPP architecture.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>(C), and a new contention-and-length-based policy (D): (A) Smallest job rst: Cooows are sorted based on cooow size (l · n). (B) Smallest remaining data rst: Cooows are sorted based on remaining data (l · n − d). (C) Least contention rst: Cooows are sorted based on their contention (c). (D) Least length-weighted total-port contention rst: Cooows are sorted based on the sum of port-wise con- tention times estimated ow length ∑ p c p · l.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: PPPPPP cooow size learning accuracy. Cooows that did not go through the piloting phase (48%) are not shown.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>Figure 5: Performance breakdown into bins shown in Table 4.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: [Testbed] Distribution of speedup in CCT and JCT in PPPPPP using the FB trace.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: [Simulation] PPPPPP sensitivity analysis. We vary one parameter of PPPPPP keeping rest same as default and compare it with Aalo.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 : Comparison of frequency of interactions between the coordinator and local agents.</head><label>1</label><figDesc></figDesc><table>Update 
Update of 
Rate 
of data sent ow completion 
calculation 
PPPPPP 
No 
Yes 
Event triggered 
Aalo 
Periodic (δ) 
Yes 
Periodic (δ) 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="true"><head>Table 2 : Performance improvement over Aalo for varying pilot ow selection schemes.</head><label>2</label><figDesc></figDesc><table>Constant 
Proportional to number of senders 
Proportional to number of ows 
2 
5% 
10% 
20% 
50% 
100% 
1% 
10% 
Avg. error 
13.21% 
6.14% 5.42% 4.94% 5.53% 4.25% 4.15% 
2.90% 
Avg. CCT 
1.27x 
1.51x 1.45x 1.50x 1.50x 1.50x 1.43x 
0.49x 
P50 speedup 
1.75x 
1.78x 1.76x 1.71x 1.52x 1.40x 1.33x 
0.69x 
P90 speedup 
9.00x 
9.58x 9.00x 9.15x 8.33x 8.45x 8.23x 
8.23x 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 sum</head><label>2</label><figDesc>- marizes the improvement in average CCT of PPPPPP over 2 8ms is the time to send 1MB of data.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 : CCT speedup in PPPPPP under diierent inter-cooow scheduling policies ( §4.4) over Aalo.</head><label>3</label><figDesc></figDesc><table>Priority estimation metric 
P50 
P90 
Avg. CCT 
Estimated size (A) 
1.48x 8.27x 
1.40x 
Remaining size (B) 
1.54x 8.34x 
1.37x 
Global Contention (C) 
0.75x 8.26x 
0.13x 
Length-weighted total-port contention (D) 1.78x 9.58x 
1.51x 
(PPPPPP) 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Bins based on total cooow size and width (number 
of ows). The numbers in brackets denote the fraction of 
cooows in that bin. 

width ≤ 7(thin) width &gt; 7(wide) 
size ≤ 100MB (small) 
bin-1 (44.3%) 
bin-2 (24.1%) 
size &gt; 100MB (large) 
bin-3 (4.5%) 
bin-4 (27.1%) 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 5 : [Testbed] CCT improvement in PPPPPP as compared to Aalo.</head><label>5</label><figDesc></figDesc><table>P50 
P90 
Avg. CCT 
FB Trace 
1.63× 8.00× 
1.50× 
Wide-cooow-only 1.05× 2.14× 
1.49× 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table>[Testbed] Average (standard deviation) coordinator 
CPU time (ms) per scheduling interval in 900-port runs. PPPP 
did not have to calculate and send new rates in 66% of 
intervals, which contributes to its low average. 

Rate Calc. New Rate Send Update Recv. 
Total 
PPPPPP 2.99 (5.35) 4.90 (11.25) 
6.89 (17.78) 14.80 (28.84) 
Aalo 4.28 (4.14) 17.65 (20.9) 
10.97 (19.98) 32.90 (34.09) 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" validated="false"><head>Table 7 : [Testbed] Percentage of scheduling intervals where synchronization and rate calculation took more than δ for 150-port and δ (= 6 × δ) for 900-port runs.</head><label>7</label><figDesc></figDesc><table>150 ports 900 ports 
PPPPPP 
1% 
10% 
Aalo 
16% 
37% 

</table></figure>

			<note place="foot" n="1"> A challenge that has also been faced by previous work on cooow scheduling such as [19, 27, 29, 44].</note>
		</body>
		<back>

			<div type="acknowledgement">
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Apache</forename><surname>Hadoop</surname></persName>
		</author>
		<ptr target="http://hadoop.apache.org" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Apache spark</title>
		<ptr target="http://spark.apache.org" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Apache</forename><surname>Tez</surname></persName>
		</author>
		<ptr target="http://tez.apache.org" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Cooow trace from facebook datacenter</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philae</forename><surname>Simulator</surname></persName>
		</author>
		<ptr target="https://github.com/coflowPhilae/simulator" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Sincronia: Near-optimal network design for cooows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saksham</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akshay</forename><surname>Shijin Rajakrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rachit</forename><surname>Narayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amin</forename><surname>Shmoys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vahdat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the ACM Special Interest Group on Data Communication, SIGCOMM &apos;18</title>
		<meeting>the 2018 Conference of the ACM Special Interest Group on Data Communication, SIGCOMM &apos;18<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="16" to="29" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Hedera: Dynamic ow scheduling for data center networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Al-Fares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sivasankar</forename><surname>Radhakrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barath</forename><surname>Raghavan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nelson</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amin</forename><surname>Vahdat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th USENIX Conference on Networked Systems Design and Implementation, NSDI&apos;10</title>
		<meeting>the 7th USENIX Conference on Networked Systems Design and Implementation, NSDI&apos;10<address><addrLine>Berkeley, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="19" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">pfabric: Minimal near-optimal datacenter transport</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Alizadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuang</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milad</forename><surname>Sharif</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sachin</forename><surname>Katti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nick</forename><surname>Mckeown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Balaji</forename><surname>Prabhakar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Shenker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGCOMM 2013 Conference on SIGCOMM, SIGCOMM &apos;13</title>
		<meeting>the ACM SIGCOMM 2013 Conference on SIGCOMM, SIGCOMM &apos;13<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="435" to="446" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Coping with skewed content popularity in mapreduce clusters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Ganesh Ananthanarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srikanth</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert</forename><surname>Kandula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ion</forename><surname>Greenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duke</forename><surname>Stoica</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ed</forename><surname>Harlan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Harris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Scarlett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth Conference on Computer Systems, EuroSys &apos;11</title>
		<meeting>the Sixth Conference on Computer Systems, EuroSys &apos;11<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="287" to="300" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">EEective straggler mitigation: Attack of the clones</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ganesh</forename><surname>Ananthanarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Ghodsi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Shenker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ion</forename><surname>Stoica</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th USENIX Conference on Networked Systems Design and Implementation, nsdi&apos;13</title>
		<meeting>the 10th USENIX Conference on Networked Systems Design and Implementation, nsdi&apos;13<address><addrLine>Berkeley, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="185" to="198" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Reining in the outliers in map-reduce clusters using mantri</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srikanth</forename><surname>Ganesh Ananthanarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert</forename><surname>Kandula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ion</forename><surname>Greenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Stoica</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bikas</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Saha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Harris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th USENIX Conference on Operating Systems Design and Implementation, OSDI&apos;10</title>
		<meeting>the 9th USENIX Conference on Operating Systems Design and Implementation, OSDI&apos;10<address><addrLine>Berkeley, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="265" to="278" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Pias: Practical information-agnostic ow scheduling for data center networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongsu</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weicheng</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th ACM Workshop on Hot Topics in Networks, HotNets-XIII</title>
		<meeting>the 13th ACM Workshop on Hot Topics in Networks, HotNets-XIII<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="1" to="25" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Information-agnostic ow scheduling for commodity data centers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongsu</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">12th USENIX Symposium on Networked Systems Design and Implementation (NSDI 15)</title>
		<meeting><address><addrLine>Oakland, CA</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="455" to="468" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Microte: Fine grained traac engineering for data centers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theophilus</forename><surname>Benson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashok</forename><surname>Anand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Akella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh COnference on Emerging Networking EXperiments and Technologies, CoNEXT &apos;11</title>
		<meeting>the Seventh COnference on Emerging Networking EXperiments and Technologies, CoNEXT &apos;11<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Creditscheduled delay-bounded congestion control for datacenters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Inho</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keon</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongsu</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference of the ACM Special Interest Group on Data Communication, SIGCOMM &apos;17</title>
		<meeting>the Conference of the ACM Special Interest Group on Data Communication, SIGCOMM &apos;17<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="239" to="252" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Leveraging endpoint exibility in data-intensive clusters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mosharaf</forename><surname>Chowdhury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srikanth</forename><surname>Kandula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ion</forename><surname>Stoica</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGCOMM 2013 Conference on SIGCOMM, SIGCOMM &apos;13</title>
		<meeting>the ACM SIGCOMM 2013 Conference on SIGCOMM, SIGCOMM &apos;13<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="231" to="242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Cooow: A networking abstraction for cluster applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mosharaf</forename><surname>Chowdhury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ion</forename><surname>Stoica</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th ACM Workshop on Hot Topics in Networks, HotNets-XI</title>
		<meeting>the 11th ACM Workshop on Hot Topics in Networks, HotNets-XI<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="31" to="36" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">EEcient cooow scheduling without prior knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mosharaf</forename><surname>Chowdhury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ion</forename><surname>Stoica</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 ACM Conference on Special Interest Group on Data Communication, SIGCOMM &apos;15</title>
		<meeting>the 2015 ACM Conference on Special Interest Group on Data Communication, SIGCOMM &apos;15<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="393" to="406" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Managing data transfers in computer clusters with orchestra</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mosharaf</forename><surname>Chowdhury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matei</forename><surname>Zaharia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ion</forename><surname>Stoica</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGCOMM 2011 Conference, SIGCOMM &apos;11</title>
		<meeting>the ACM SIGCOMM 2011 Conference, SIGCOMM &apos;11<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="98" to="109" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Efcient cooow scheduling with varys</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mosharaf</forename><surname>Chowdhury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ion</forename><surname>Stoica</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 ACM Conference on SIGCOMM, SIGCOMM &apos;14</title>
		<meeting>the 2014 ACM Conference on SIGCOMM, SIGCOMM &apos;14<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="443" to="454" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Khaled Elmeleegy, and Russell Sears. Mapreduce online</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tyson</forename><surname>Condie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil</forename><surname>Conway</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Alvaro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><forename type="middle">M</forename><surname>Hellerstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th USENIX Conference on Networked Systems Design and Implementation, NSDI&apos;10</title>
		<meeting>the 7th USENIX Conference on Networked Systems Design and Implementation, NSDI&apos;10<address><addrLine>Berkeley, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="21" to="21" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Mapreduce: Simpliied data processing on large clusters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeerey</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjay</forename><surname>Ghemawat</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008-01" />
			<publisher>ACM</publisher>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="107" to="113" />
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Decentralized task-aware scheduling for data center networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fahad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Dogar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hitesh</forename><surname>Karagiannis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antony</forename><surname>Ballani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rowstron</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 ACM Conference on SIGCOMM, SIGCOMM &apos;14</title>
		<meeting>the 2014 ACM Conference on SIGCOMM, SIGCOMM &apos;14<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="431" to="442" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Improved utilization and responsiveness with gang scheduling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Dror</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Morris</forename><forename type="middle">A</forename><surname>Feitelson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jette</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Job Scheduling Strategies for Parallel Processing, IPPS &apos;97</title>
		<meeting>the Job Scheduling Strategies for Parallel Processing, IPPS &apos;97<address><addrLine>London, UK, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1997" />
			<biblScope unit="page" from="238" to="261" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Finishing ows quickly with preemptive scheduling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi-Yao</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Caesar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">Brighten</forename><surname>Godfrey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGCOMM 2012 Conference on Applications, Technologies, Architectures, and Protocols for Computer Communication, SIGCOMM &apos;12</title>
		<meeting>the ACM SIGCOMM 2012 Conference on Applications, Technologies, Architectures, and Protocols for Computer Communication, SIGCOMM &apos;12<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="127" to="138" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Sunnow: EEcient optical circuit scheduling for cooows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sunny</forename><surname>Xin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoye</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S Eugene</forename><surname>Steven Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th International on Conference on Emerging Networking EXperiments and Technologies, CoNEXT &apos;16</title>
		<meeting>the 12th International on Conference on Emerging Networking EXperiments and Technologies, CoNEXT &apos;16<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="297" to="311" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Dryad: Distributed data-parallel programs from sequential building blocks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Isard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Budiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Birrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dennis</forename><surname>Fetterly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2Nd ACM SIGOPS/EuroSys European Conference on Computer Systems 2007, EuroSys &apos;07</title>
		<meeting>the 2Nd ACM SIGOPS/EuroSys European Conference on Computer Systems 2007, EuroSys &apos;07<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="59" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Graviton: Twisting space and time to speed-up cooows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akshay</forename><surname>Jajoo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rohan</forename><surname>Gandhi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">Charlie</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">8th USENIX Workshop on Hot Topics in Cloud Computing (HotCloud 16)</title>
		<meeting><address><addrLine>Denver, CO</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Saath: Speeding up cooows by exploiting the spatial dimension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akshay</forename><surname>Jajoo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rohan</forename><surname>Gandhi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">Charlie</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengkok</forename><surname>Koh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Conference on Emerging Networking EXperiments and Technologies, CoNEXT &apos;17</title>
		<meeting>the 13th International Conference on Emerging Networking EXperiments and Technologies, CoNEXT &apos;17<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="439" to="450" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Network-aware scheduling for data-parallel jobs: Plan when you can</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Virajith</forename><surname>Jalaparti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Bodik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishai</forename><surname>Menache</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sriram</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantin</forename><surname>Makarychev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Caesar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 ACM Conference on Special Interest Group on Data Communication, SIGCOMM &apos;15</title>
		<meeting>the 2015 ACM Conference on Special Interest Group on Data Communication, SIGCOMM &apos;15<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="407" to="420" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">The anl/ibm sp scheduling system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">A</forename><surname>Lifka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Job Scheduling Strategies for Parallel Processing, IPPS &apos;95</title>
		<meeting>the Workshop on Job Scheduling Strategies for Parallel Processing, IPPS &apos;95<address><addrLine>London, UK, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1995" />
			<biblScope unit="page" from="295" to="303" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Trumpet: Timely and precise triggers in data centers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masoud</forename><surname>Moshref</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minlan</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramesh</forename><surname>Govindan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amin</forename><surname>Vahdat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 ACM SIGCOMM Conference, SIGCOMM &apos;16</title>
		<meeting>the 2016 ACM SIGCOMM Conference, SIGCOMM &apos;16<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="129" to="143" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Sampling of Populations: Methods and Applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><forename type="middle">S</forename><surname>Stanley Lemeshow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Levy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012-06" />
			<publisher>Wiley</publisher>
		</imprint>
	</monogr>
	<note>4 edition</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Fastpass: A centralized &quot;zero-queue&quot; datacenter network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Perry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amy</forename><surname>Ousterhout</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hari</forename><surname>Balakrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devavrat</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans</forename><surname>Fugal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 ACM Conference on SIGCOMM, SIGCOMM &apos;14</title>
		<meeting>the 2014 ACM Conference on SIGCOMM, SIGCOMM &apos;14<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="307" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Dandelion: A compiler and runtime for heterogeneous systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">J</forename><surname>Rossbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jon</forename><surname>Currey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeanphilippe</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dennis</forename><surname>Fetterly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Fourth ACM Symposium on Operating Systems Principles, SOSP &apos;13</title>
		<meeting>the Twenty-Fourth ACM Symposium on Operating Systems Principles, SOSP &apos;13<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="49" to="68" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Analysis of rst-come--rst-serve parallel job scheduling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Uwe</forename><surname>Schwiegelshohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramin</forename><surname>Yahyapour</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth Annual ACM-SIAM Symposium on Discrete Algorithms, SODA &apos;98</title>
		<meeting>the Ninth Annual ACM-SIAM Symposium on Discrete Algorithms, SODA &apos;98<address><addrLine>PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Philadelphia</publisher>
			<date type="published" when="1998" />
			<biblScope unit="page" from="629" to="638" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Performance isolation and fairness for multi-tenant cloud storage</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Shue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Freedman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anees</forename><surname>Shaikh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th USENIX Conference on Operating Systems Design and Implementation, OSDI&apos;12</title>
		<meeting>the 10th USENIX Conference on Operating Systems Design and Implementation, OSDI&apos;12<address><addrLine>Berkeley, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="349" to="362" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Process Scheduling. Operating System Concepts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abraham</forename><surname>Silberschatz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><forename type="middle">B</forename><surname>Galvin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Gagne</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<publisher>John Wiley &amp; Sons</publisher>
		</imprint>
	</monogr>
	<note>8 edition</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Is advance knowledge of ow sizes a plausible assumption?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vojislav</forename><surname>Ðukić</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abdu</forename><surname>Sangeetha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bojan</forename><surname>Jyothi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhsen</forename><surname>Karlas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ce</forename><surname>Owaida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ankit</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Singla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">16th USENIX Symposium on Networked Systems Design and Implementation (NSDI 19)</title>
		<meeting><address><addrLine>Boston, MA</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="565" to="580" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Delay scheduling: A simple technique for achieving locality and fairness in cluster scheduling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matei</forename><surname>Zaharia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruba</forename><surname>Borthakur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joydeep</forename><forename type="middle">Sen</forename><surname>Sarma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Khaled</forename><surname>Elmeleegy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Shenker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ion</forename><surname>Stoica</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th European Conference on Computer Systems, EuroSys &apos;10</title>
		<meeting>the 5th European Conference on Computer Systems, EuroSys &apos;10<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="265" to="278" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Spark: Cluster computing with working sets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matei</forename><surname>Zaharia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mosharaf</forename><surname>Chowdhury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Franklin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Shenker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ion</forename><surname>Stoica</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2Nd USENIX Conference on Hot Topics in Cloud Computing, HotCloud&apos;10</title>
		<meeting>the 2Nd USENIX Conference on Hot Topics in Cloud Computing, HotCloud&apos;10<address><addrLine>Berkeley, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="10" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Improving mapreduce performance in heterogeneous environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matei</forename><surname>Zaharia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andy</forename><surname>Konwinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><forename type="middle">D</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Randy</forename><surname>Katz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ion</forename><surname>Stoica</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th USENIX Conference on Operating Systems Design and Implementation, OSDI&apos;08</title>
		<meeting>the 8th USENIX Conference on Operating Systems Design and Implementation, OSDI&apos;08<address><addrLine>Berkeley, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="29" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Coda: Toward automatically identifying and scheduling cooows in the dark</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bairen</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mosharaf</forename><surname>Chowdhury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanhui</forename><surname>Geng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 ACM SIGCOMM Conference, SIG-COMM &apos;16</title>
		<meeting>the 2016 ACM SIGCOMM Conference, SIG-COMM &apos;16<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="160" to="173" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
