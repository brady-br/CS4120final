<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2020-09-29T02:51+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">When is the Cache Warm? Manufacturing a Rule of Thumb</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Dept. of Computer Science</orgName>
								<orgName type="department" key="dep2">Computer Science Department</orgName>
								<orgName type="institution" key="instit1">Emory University</orgName>
								<orgName type="institution" key="instit2">Carnegie Mellon University ‡ Indigo Ag † Akamai Inc Facebook Inc</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juncheng</forename><surname>Yang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Dept. of Computer Science</orgName>
								<orgName type="department" key="dep2">Computer Science Department</orgName>
								<orgName type="institution" key="instit1">Emory University</orgName>
								<orgName type="institution" key="instit2">Carnegie Mellon University ‡ Indigo Ag † Akamai Inc Facebook Inc</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Blasiak</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Dept. of Computer Science</orgName>
								<orgName type="department" key="dep2">Computer Science Department</orgName>
								<orgName type="institution" key="instit1">Emory University</orgName>
								<orgName type="institution" key="instit2">Carnegie Mellon University ‡ Indigo Ag † Akamai Inc Facebook Inc</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Mccall</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Dept. of Computer Science</orgName>
								<orgName type="department" key="dep2">Computer Science Department</orgName>
								<orgName type="institution" key="instit1">Emory University</orgName>
								<orgName type="institution" key="instit2">Carnegie Mellon University ‡ Indigo Ag † Akamai Inc Facebook Inc</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ymir</forename><surname>Vigfusson</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Dept. of Computer Science</orgName>
								<orgName type="department" key="dep2">Computer Science Department</orgName>
								<orgName type="institution" key="instit1">Emory University</orgName>
								<orgName type="institution" key="instit2">Carnegie Mellon University ‡ Indigo Ag † Akamai Inc Facebook Inc</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">When is the Cache Warm? Manufacturing a Rule of Thumb</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>The plethora of parameters and nuanced configuration options that govern complex, large-scale caching systems restrict their designers and operators. We analyze cache warmup times that can arise in failure handling, load balancing, and cache partitioning of large-scale distributed memory and storage systems. Through simulation on traces from production CDN and storage systems, we derive rules of thumb formulas for designers and operators to use when reasoning about caches.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Today's caching systems, including storage systems, distributed databases, and content-delivery networks (CDN), are large and abound with configuration options that can be opaque not only to the engineers operating these systems, but also to their designers <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b25">25]</ref>. Two tendencies are to either ignore the complexity and set parameters from ignorance and experience, or to treat the system as such a complex black box that it requires another black box, such as machine learning models, to interpret the potential impact of changes. Between these extremes are simple and intuitive approximate models, or rules of thumb, that are invaluable in many engineering fields to create intuitive and sufficiently correct understanding of the system.</p><p>Here, we derive a rule of thumb expression for cache warmup times, specifically how long caches in storage systems and CDNs need to be warmed up before their performance is deemed to be stable. They are important in several contexts. In distributed storage systems or CDNs, operators may wish to discern how quickly after downtime or maintenance the server becomes useful again for serving content. They may wish to reason about how long to duplicate cache traffic to a new or recently restarted node before it can serve real clients at an acceptable hit rate. During recovery or reconfiguration of cache nodes, they may also wish to estimate how long the back-end storage servers must sustain additional load. In this manner, warmup time estimation allows CDN operators to compute the required redundancy and extra capacity to maintain a level of service in failure scenarios. In a shared memory or storage system, as another example, dynamic cache partitioning is often used to allocate storage resources to different processes or tenants. Here, when the partitioning controller decides to allocate more space to a tenant, it takes a period of time until the steady-state cache performance catches up. The controller needs to be cognizant of this delay to avoid instability whereby the partition keeps changing based on incomplete feedback gathered before steady-state has converged.</p><p>We first provide a concrete definition of cache warmup time, that is, a cache server has warmed up when its cache hit rate over time is and stays comparable (within ε error) to that of an identical cache service that processed the same workload but suffered no downtime. We then analyze dozens of traces across workloads collected from diverse systems, ranging from block accesses of virtual machines in storage systems to cache accesses of large CDN providers. We derive the following rule of thumb expression for operators to estimate warmup time of an LRU-style cache:</p><formula xml:id="formula_0">warmup-time(s, ε) ∝ s p s e −p e ε ,</formula><p>where s represents the cache size, and ε &gt; 0 controls how closely hit rate should match that of a hypothetical cache server which was continuously running. Our experiments show that the p s and p e parameters concentrate at specific values for each type of workload. Our simulation results indicate that the formula provides an accurate expression for operators to estimate their cache server warmup time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Motivation and Background</head><p>Distributed memory caches are the cornerstone of today's content distribution networks (CDNs) and cloud storage systems for improving web service performance. A common architecture for a distributed cache is a collection of highmemory servers which is interposed between client nodes (sometimes actual end-users), and a storage service that interfaces with slower media, such as a disk-bound key-value database. When the server memory (or the memory dedicated to the tenant on a shared cache server) is exhausted, the server makes space by evicting older data according to a replacement policy, which in practice is normally a variant of LRU-evict the least-recently used key-value pair <ref type="bibr" target="#b0">[1]</ref>. A central feature of the distributed cache design is the complete independence of servers from one another. Independence reduces operation and implementation complexity, facilitates scalability, and allows reasoning about each cache server in isolation. Operational dynamics. Most research on caches assumes they operate in steady-state. Yet understanding the cache behavior under exceptional circumstances is often crucial.</p><p>Failure recovery. First, distributed caches can comprise a vast number of servers <ref type="bibr" target="#b16">[17]</ref>, where individual server failures are common. Accurate assessment of recovery time becomes increasingly important for operators to decide when servers are ready for serving clients without imposing significant load on the storage layer or end-user perceived latency. We assume that the cache memory on the server is empty (cold) after recovery because stale cache data can produce application-level inconsistencies, even with sophisticated application-specific cache invalidation pipelines <ref type="bibr" target="#b14">[15]</ref>.</p><p>Load balancing. Second, consistent hashing does not account for key popularity, so some cache servers can become heavily loaded relative to others <ref type="bibr" target="#b11">[12]</ref>. Manual or automatic adjustment of hash ranges to balance load <ref type="bibr" target="#b9">[10]</ref> implies that some cache servers are responsible for key-value pairs they have not encountered before, thus impacting cache hit rate.</p><p>Cache sharing. Third, large cache installations are often shared between multiple applications or tenants to improve efficiency and quality of service, either implicitly <ref type="bibr" target="#b0">[1]</ref> or explicitly <ref type="bibr" target="#b4">[5]</ref>. Explicit sharing is implemented via cache space partitioning mechanisms <ref type="bibr" target="#b7">[8]</ref> which means cache space allocation for tenants may change over time. Operators must estimate how regularly cache space can be re-partitioned, which in turn depends on how quickly the enlarged cache space for tenants becomes useful and indicative of the tenant's cache hit rate performance under steady-state <ref type="bibr" target="#b5">[6]</ref>. Cache dynamics. Operators facing these scenarios would benefit from a rule of thumb to estimate when partially full cache memory has reached a "useful" steady-state and when applications can use the cache without burdening the storage layer or imposing miss latency on clients. Yet, quantifying cache warmup time is challenging due to several factors.</p><p>Cache hit rate performance is determined by the workload. Decades of effort has been spent on characterizing cache workloads, but historically focused on programmatic workloads (such as CPU caches) rather than in the context of human-driven behavior (such as web or CDN workloads) <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b19">20]</ref>.</p><p>Cache workloads are not static. As mentioned earlier, considering a cache server to be warmed up when a particular fixed hit rate threshold is reached ignores temporal popularity dynamics <ref type="bibr" target="#b26">[26]</ref> and diurnal variability exhibited in CDN traces <ref type="bibr" target="#b21">[21]</ref>, among others. Even defining hit rate relative to the start of a trace embodies the same problems.</p><p>Cache performance depends crucially on the cache size. Recent attention on efficiently computing so-called hit rate curves -hit rate as a function of cache space -has illuminated how the relationship tends to be nuanced and volatile in realworld workloads <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b27">27]</ref>. Bonfire <ref type="bibr" target="#b33">[33]</ref> uses temporal and spatial behaviors for doing proactive cache warmup, but does not take cache size into account when defining warmup time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Understanding Cache Warmup</head><p>Interval hit ratio. Warmup time must capture the notion of a cache "being useful", which in turn is related to its hit rate. But the classical notion of "hit rate", defined as the number of hits received over a number of accesses in a trace, relies on requests since the beginning of measurement being predictive of upcoming request-a degree of stability not present when cache workloads change dynamically.</p><p>To address variability in workloads, we measure cache performance by the interval hit ratio (IHR), defined as the ratio of cache hits in a relatively short past time window divided by the total number of requests in that window. This focus on the recent past adapts the metric to measure current performance with the ongoing dynamics. The IHR can be considered over subtraces of the full cache trace. The added flexibility allows us to also consider cache downtime, represented by a specific interval during the workload. We use IHR(st, et, s) to denote the hit ratio computed for a short interval between start time st and end time et at cache size s. Below, each interval spans 1/1000 of the trace length.</p><p>Our analysis shows that even within the same workload type, workloads usually behave differently in terms of smoothness of the IHR curve. <ref type="figure" target="#fig_0">Figure 1</ref> depicts the IHR curves of four workloads, two from Storage1 workloads and the other two from CDN1 (see description in Section 4). We can see that the IHRs of CDN1-a and Storage1-a workloads remain high in most intervals, but CDN1-b and Storage1-b workloads are generally more fluctuated, even considering the periodic processes as a multi-day trace in the Storage1-b workload. We note that in our analysis, we internally compute hit rate curves, or hit rate as a function of cache size, which can be efficiently generated through spatial sampling of the cache trace <ref type="bibr" target="#b27">[27,</ref><ref type="bibr" target="#b32">32]</ref>. Spatial sampling could be used for online computation of the warmup time if needed.</p><p>Cache warmup time. We are now ready to define cache "warmup" time using the interval hit ratio. At a high-level, we declare a particular moment in the trace as when the server comes up (with an empty cache) after downtime. We then compare the IHR of that server (a downcache) to that of a server that did not go down at all (an upcache) while processing the exact same workload. When the IHRs of these two caches are sufficiently close, they have converged (as shown in <ref type="figure" target="#fig_1">Figure 2</ref>). This two-cache comparison overcomes the dynamical issues from above: a cache is consider warmed up if it behaves practically like one that did not go down.</p><p>Formally, we measure the difference in performance of a downcache that resumed operations at time st and an upcache by measuring the difference |IHR(st,t, s) − IHR(0,t, s)| at time t. To capture the IHR of the upcache and downcache staying close, we define a tolerance parameter ε to express the maximum percentage difference we accept after warmup. Definition 1. For cache size s and tolerance level ε &gt; 0, a downcache that recovers at time st is considered warmed up at time t if for any end time et &gt; t, we have</p><formula xml:id="formula_1">|IHR(0, et, s) − IHR(st, et, s)| &lt; ε.</formula><p>Cache warmup time therefore depends on static factors, including cache size and tolerance levels, and dynamic factors dependent on the trace-based characteristics.  Comparing cache warmup to fill up times. The definition further highlights that downcache need not necessarily be filled for the cache to be considered warmed up: the rate of requests to items to which only the upcache was privy may simply be sufficiently limited that the downcache already contains the current working set and can be considered warm. An example is shown in <ref type="figure" target="#fig_3">Figure 3</ref>. Here we define cache is filled up when the cache capacity is fully occupied after a restart, whereas warmed up refers to the definition with ε = 1%. Across all our traces, the cache warms up faster than it fills up, with on average 39.1% and 36.8% for CDN1 and CDN2 workloads, and 16.6% and 23.8% for Storage1 and Storage2 workloads. These results underscore the opportunity for reconsidering cache warmup times in practice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Deriving the Rule of Thumb</head><p>We analyze cache warmup time on several workloads to derive a useful estimation formula. Specifically, we look for a rule of thumb that embodies the following attributes.</p><p>1 Simplicity. Contain only a small number of parameters and as few as possible to capture the dependencies while being intuitive and practical to compute.  a wide variety of different content types, including streaming media, file downloads, and typical web content such as HTML, images, JavaScript, and CSS. CDN2 are traces from the Wikipedia CDN servers <ref type="bibr" target="#b23">[23]</ref>. Storage1 comprises 106 week-long hypervisor-observed disk access traces in production storage systems <ref type="bibr" target="#b27">[27]</ref>. Storage2 consists of 32 file system traces released by MSR Cambridge <ref type="bibr" target="#b15">[16]</ref>. Implementation. We implement the warmup analysis tool on top of Mimircache <ref type="bibr" target="#b31">[31]</ref>, an open source Python cache profiler that helps to calculate IHRs of traces, making the simulation process lightweight. We use an Intel Xeon CPU E5-2670 v3 2.30GHz system for our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Step 1: Relaxing Dynamic Factors</head><p>Our problem space is still large and unwieldy for operators to navigate in practice. Rather than capturing the full range of the workload's dynamic characteristics, captured by the start time st parameter, we simplify the definition to compute the maximum warmup time over all possible start times.</p><p>Definition 2. Given cache size s and tolerance degree ε, the warmup time of a cache server, warmup-time(s, ε), is the smallest t such that for every start time st and any et &gt; t,</p><formula xml:id="formula_2">|IHR(0, et, s) − IHR(st, et, s)| &lt; ε.</formula><p>The above definition is the expression for which we will derive a rule of thumb. Simplifying is critical to minimize the number of parameters and create a practical formula.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Step 2: Approximating Static Factors</head><p>Armed with a compact definition, we can now analyze how cache size and tolerance degree affect cache warmup time on our traces. In search for a simple representation, we apply loglinear regression to model the relationship between warmup time, the cache size and the tolerance degree. We observed that the cache warmup time has a piece-wise linear relationship to size until it reaches a plateau at larger sizes. There, the cache takes longer to warm up, but only until the working set of the trace is captured. The relationship between cache warmup time and tolerance is approximately log-linear; plotting warm-up time on a log-scale vs. tolerance on a linear scale produced a straight line. Larger tolerance degrees produce shorter warmup times as expected.</p><p>These observations suggest the following relationship, where C, p e , and p s are free parameters:</p><formula xml:id="formula_3">warmup-time(s, ε) = C · e −p e ε · s p s .</formula><p>(1)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Evaluation</head><p>We now consider our proposed rule of thumb and how it measures up against our desired attributes.</p><p>1 Simplicity. The equation above says it all: there are only three free variables and one term.</p><p>2 Accuracy. To determine accuracy of the model fit we use a standard R 2 likelihood test. The R 2 distribution is shown in <ref type="figure" target="#fig_4">Figure 4</ref>. We consider 80% as R 2 -threshold of a significance fit, so passing the test means the formula is accurate for use. As shown in the result, most of our CDN traces passed the R 2 likelihood test, together with a branch of storage traces. The accuracy is higher when considering both parameters together.</p><p>3 Generality. Because C is a normalization parameter driven by time resolution, we investigate the ranges of parameters p e and p s as shown in <ref type="table" target="#tab_1">Table 1</ref>. Note that here we only consider the traces that passed the test. These results meet our generality goal for the proposed method.</p><p>Applying the rule. A recent set of papers focused on offline optimal analysis of caches have shown that workload characteristics and object features are helpful for quantifying cache behaviors and further improving cache algorithms <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b32">32]</ref>. In line with those ideas, the warmup time of a workload can be estimated in a two-step process. First, we calculate the warmup times through an offline simulator on workloads, or a sampled workloads for efficiency. This step could be implemented through a simple API like:</p><p>offline-results = SIMULATE(workload, params) Here the parameters s and ε are varied in a wide range. We then apply regression over the offline results to optimize a simple model to express warmup time over these parameters, for instance using the following API:</p><p>warmup-time = ANALYZE(offline-results, params)</p><p>A key problem is how to make this process efficient. We have shown that cache warmup time can be successfully estimated with a lightweight method, and that simple regression can provide sufficiently accurate results. With a rule of thumb formula, operators and designers can estimate warmup time with only a few parameters. We note that warmup time is calculated for each workload and reflects the internal characteristics and behavior of that workload, so a system operator may only need to follow this process if the workload behavior changes drastically. Also, we found that workloads that share similar behaviors also yield similar parameters for their rule of thumb formulas. For instance, two CDN workloads for the same service are likely to share the rule of thumb parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Extension: Enlarging a Cache</head><p>We have assumed thus far that a downcache starts off empty, which is reasonable in cases where a failure occurred since items may be stale, expired or awaiting invalidation. When a cache is resized, however, such as during cache partitioning, tenants retain existing content in the cache after it is enlarged. How would growing the capacity of a cache that already contains useful data affect the warmup time?</p><p>To define warmup time in the context of cache enlargement, we want to compare a "downcache" (to be resized) with the state of the "upcache" (fully resized). We augment the interval hit ratio definition to IHR <ref type="bibr">(st, et, s, rt, m)</ref>, where rt expresses the time when the cache is to be resized, and m ≥ 1 expresses a multiple of its current cache size s. Chronologically over a request stream, a cache of size s begins at time st, its capacity is grown at time rt to a new size m · s and ends at time et. Now:</p><p>Definition 3. Given cache size s, size multiple m, and tolerance degree ε, assume a cache server is initially run at size s and then resized at time rt to m · s. The resized cache server is consider to be warmed up at time t if for every resize time rt and all et &gt; t,</p><formula xml:id="formula_4">|IHR(0, et, m · s) − IHR(0, et, s, rt, m)| &lt; ε.</formula><p>Here, the warmup time is driven primarily by the starting size, multiple, and tolerance level. Focusing on the first two parameters that relate directly to the cache size change, we fix tolerance level to 1% in the following experiments.</p><p>A primary difference between the recovery and resizing cases is that a cache that went down will be fully able to serve content after collecting all s items, whereas (m − 1) · s items are missing in the resized cache. We therefore consider whether there is a log-linear relationship between warm-uptime in the resized context and (m − 1) · s, and use the above methodology to obtain (for C, p r as free parameters):</p><formula xml:id="formula_5">resized-warmup-time(s) = C · ((m − 1) · s) p r</formula><p>Our experiments considered m ∈ {2, 3, 4} and varied s. The R 2 distribution <ref type="figure" target="#fig_4">(Figure 4)</ref> shows that most traces passed the R 2 likelihood tests using spatial sampling rate of 1% per trace. Our results also show that the p r exponent parameter still concentrates differently for each workload catalog <ref type="table" target="#tab_1">(Table 1</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related Work</head><p>Warmup is an important component of the systems or frameworks of several recent systems, yet many papers either define a warmup period arbitrarily, discard the first portion of a workload <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b23">23,</ref><ref type="bibr" target="#b28">28]</ref>, or apply a warmup mechanism without quantifying or evaluating such methods <ref type="bibr" target="#b22">[22,</ref><ref type="bibr" target="#b24">24,</ref><ref type="bibr" target="#b29">29,</ref><ref type="bibr" target="#b30">30]</ref>. <ref type="bibr">Zhang et al. [33]</ref> provided a cache warmup mechanism based on cache recency and is closest to our work. Their method does not consider workload dynamics. To the best of our knowledge, our work is the first to provide a practical method for estimating cache warmup time, and derive a simple expression for engineers and scientists to use.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>There are many scenarios where operators of large distributed caches must implicitly or explicitly reason about warmup time of a cache server. Here, we derive a novel rule of thumb equation based on empirical results on a variety of real-world traces that demonstrates a power-law relationship between warmup time and cache size, coupled with an inverse exponential discount based on the desired tolerance level.</p><p>We build an offline simulator to fit free parameters of the formulas, which is shown to be concentrated within each workload category, to provide a useful expression for backof-the-envelope calculations for the expected warmup time of cache servers without unduly impacting end-user clients or storage servers with miss penalties. We plan to release the code as an open-source Python package to aid the operators and designers of modern large-scale cache systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion Topics</head><p>Our paper sets up a framework to try to understand the process of warming up a cache. This is a question that, to the best of our knowledge, has surprisingly small literature. Understanding where and when the question arises in practice, and what approaches are used would be of interest.</p><p>Original cache state. As discussed above, distributed caches usually contain many storage servers or memory layers, and may encompass many concurrent tenants or classes of workloads. Among these scenarios, a tenant's cache size can be increased or decreased. How do we reason about the original state of the adjusted cache partition? If more cache capacity is allocated during repartitioning, is it more practicable to eagerly clear out the surplus entries (which may belong to a different application or tenant) or to keep those entries loaded? If a cache server is down for a while and restarted, as discussed elsewhere <ref type="bibr" target="#b12">[13]</ref>, is there a practice of keeping possibly stale information around? If some cache capacity is decreased, what content is removed? Is the best choice to remove the least-recently used items? Tracking detailed data placement choices is difficult since distributed caches are hard to trace, but might doing so reveal other factors that could impact the warmup process?</p><p>Cache dynamics. A key idea of this paper is to define Interval Hit Ratio (IHR) to represent dynamic cache workload properties and create opportunities for further analysis. However, as we discussed, distributed cache behaviors are typically workload related. For example, for a specific workload, restarting a cache server at different stages of the trace could result in different warmup times. We observed these patterns in our Storage workloads, where our accuracy is lower than than of CDN workloads. Although we do simplify our warmup time definition to account less for abrupt dynamics and show the efficiency of the result, a richer analysis of cache dynamics could produce a deeper understanding of the warmup process and provide more precise expressions for system developers. This extension would likely be of most interest to the maintainers of specific large-scale distributed cache systems. We look forward to discussions from experienced operators of this kind about how warmup time analysis, and more generally rules of thumb, could be useful in practice.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Examples of Interval Hit Ratio (IHR) Curves. Each interval is 1/1000 of the original trace length.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Cache warmup process, showing convergence of IHRs. Cache size is set to 25% of total unique items for better showing the convergence. Horizontal axis represents virtual time of the trace as a sequence of accesses. The relative start time (st) of a curve, say 0.25 means that it begins at 25% of the entire trace.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Caches warm up faster than they fill up. Comparing warm up and fill up with horizontal axis and four st as per Figure 2. The f and w curves respectively represent fill up and warm up. The left vertical axis shows the convergence between each downcache and the upcache; the right vertical axis shows the rate of cache capacity filled by the newly started cache.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Approximation accuracy, evaluated with R 2 cumulative distribution for p e , p s , combined p e + p s , and p r . We consider 80% as R 2 threshold of a significance (grey dotted vertical line). Results span all workloads except CDN2 which comprises only one trace.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 1 : Proportion of traces whose cache warmup times passed 80% goodness-of-fit-tests within value range for cache size parame- ter p s , tolerance degree parameter p e , and resize parameter p r . Traces with parameter value in range Param Value CDN1 CDN2 Storage1 Storage2</head><label>1</label><figDesc></figDesc><table>p s 
0-2 
58.1% 100% 
49% 
84.2% 
p e 
0.5-1.5 64.5% 100% 
64.3% 
78.9% 
p r 
1-1.5 
84% 
100% 
78.3% 
66.7% 

</table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We are grateful to our shepherd, Deian Stefan, and the IMC 2018 and HotCloud 2020 reviewers for constructive feedback. We also thank Irfan Ahmad, Carl Waldspurger, and Avani Wildani for useful discussions. This work was supported by NSF CAREER Award #1553579.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Workload analysis of a largescale key-value store</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Berk</forename><surname>Atikoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuehai</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eitan</forename><surname>Frachtenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Paleczny</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ACM SIGMETRICS Performance Evaluation Review</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="53" to="64" />
			<date type="published" when="2012" />
			<publisher>ACM</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Towards lightweight and robust machine learning for cdn caching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Berger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th ACM Workshop on Hot Topics in Networks (HotNets 18)</title>
		<meeting>the 17th ACM Workshop on Hot Topics in Networks (HotNets 18)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="134" to="140" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Carver: Finding important parameters for storage system tuning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoff</forename><surname>Kuenning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erez</forename><surname>Zadok</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th USENIX Conference on File and Storage Technologies (FAST 20)</title>
		<meeting>the 18th USENIX Conference on File and Storage Technologies (FAST 20)</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="43" to="57" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Towards better understanding of black-box autotuning: A comparative analysis for storage systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vasily</forename><surname>Tarasov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sachin</forename><surname>Tiwari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erez</forename><surname>Zadok</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 USENIX Annual Technical Conference (USENIX ATC 18)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="893" to="907" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Data caching as a cloud service</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Chockler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guy</forename><surname>Laden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ymir</forename><surname>Vigfusson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th International Workshop on Large Scale Distributed Systems and Middleware (LADIS 10)</title>
		<meeting>the 4th International Workshop on Large Scale Distributed Systems and Middleware (LADIS 10)</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="18" to="21" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Design and implementation of caching services in the cloud</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Chockler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guy</forename><surname>Laden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ymir</forename><surname>Vigfusson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IBM Journal of Research and Development</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="9" to="10" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Cliffhanger: Scaling performance cliffs in web memory caches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asaf</forename><surname>Cidon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Assaf</forename><surname>Eisenman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Alizadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sachin</forename><surname>Katti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">13th USENIX Symposium on Networked Systems Design and Implementation (NSDI 16)</title>
		<meeting><address><addrLine>Santa Clara, CA</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="379" to="392" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Memshare: a dynamic multi-tenant key-value cache</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asaf</forename><surname>Cidon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Rushton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Stephen M Rumble</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Stutsman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 USENIX Annual Technical Conference (USENIX ATC 17</title>
		<meeting>the 2017 USENIX Annual Technical Conference (USENIX ATC 17</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Flashield: a hybrid key-value cache that controls flash write amplification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Assaf</forename><surname>Eisenman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asaf</forename><surname>Cidon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgenya</forename><surname>Pergament</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Or</forename><surname>Haimovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Stutsman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Alizadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sachin</forename><surname>Katti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th USENIX Symposium on Networked Systems Design and Implementation (NSDI 19)</title>
		<meeting>the 16th USENIX Symposium on Networked Systems Design and Implementation (NSDI 19)</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="65" to="78" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Understanding and mitigating the impact of load imbalance in the memory caching tier</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Ju</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mithuna</forename><surname>Thottethodi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th annual Symposium on Cloud Computing (SOCC 13</title>
		<meeting>the 4th annual Symposium on Cloud Computing (SOCC 13</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">An analysis of Facebook photo caching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ken</forename><surname>Birman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robbert</forename><surname>Van Renesse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wyatt</forename><surname>Lloyd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harry C</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th ACM Symposium on Operating Systems Principles (SOSP 13)</title>
		<meeting>the 24th ACM Symposium on Operating Systems Principles (SOSP 13)</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="167" to="181" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Characterizing load imbalance in real-world networked caches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helga</forename><surname>Gudmundsdottir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ymir</forename><surname>Vigfusson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ken</forename><surname>Daniel A Freedman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robbert</forename><surname>Birman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Van Renesse</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th ACM Workshop on Hot Topics in Networks</title>
		<meeting>the 13th ACM Workshop on Hot Topics in Networks</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Ubik: efficient cache sharing with strict QoS for latency-critical workloads</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harshad</forename><surname>Kasture</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Sanchez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGPLAN Notices</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="729" to="742" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Metis: Robustly tuning tail latencies of cloud systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chieh-Jan Mike</forename><surname>Zhao Lucis Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenjia</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lianjie</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenjun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jin</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangzhong</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 USENIX Annual Technical Conference (USENIX ATC 18)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="981" to="992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Existential consistency: measuring and understanding consistency at Facebook</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haonan</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaushik</forename><surname>Veeraraghavan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philippe</forename><surname>Ajoux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jim</forename><surname>Hunt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yee</forename><forename type="middle">Jiun</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wendy</forename><surname>Tobagus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wyatt</forename><surname>Lloyd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th Symposium on Operating Systems Principles (SOSP 15)</title>
		<meeting>the 25th Symposium on Operating Systems Principles (SOSP 15)</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="295" to="310" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Write off-loading: Practical power management for enterprise storage</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dushyanth</forename><surname>Narayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Austin</forename><surname>Donnelly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antony</forename><surname>Rowstron</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Storage (TOS)</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">10</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Scaling Memcache at Facebook</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajesh</forename><surname>Nishtala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans</forename><surname>Fugal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Grimm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herman</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Harry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Mcelroy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Paleczny</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Peek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Saab</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">10th USENIX Symposium on Networked Systems Design and Implementation (NSDI 13)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="385" to="398" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Reliable writeback for client-side flash caches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angela</forename><forename type="middle">Demke</forename><surname>Dai Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashvin</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Goel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 USENIX Annual Technical Conference (USENIX ATC 14)</title>
		<meeting>the 2014 USENIX Annual Technical Conference (USENIX ATC 14)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="451" to="462" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Dynamic performance profiling of cloud caches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trausti</forename><surname>Saemundsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hjortur</forename><surname>Bjornsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Chockler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ymir</forename><surname>Vigfusson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Symposium on Cloud Computing (SOCC 14)</title>
		<meeting>the ACM Symposium on Cloud Computing (SOCC 14)</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Characterizing caching workload of a large commercial content delivery network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M Zubair</forename><surname>Shafiq</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><forename type="middle">X</forename><surname>Amir R Khakpour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th</title>
		<meeting>the 35th</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
				<title level="m">Annual IEEE International Conference on Computer Communications (INFOCOMM 16)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Revisiting caching in content delivery networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><forename type="middle">X</forename><surname>Muhammad Zubair Shafiq</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Amir R Khakpour</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGMETRICS Performance Evaluation Review</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="567" to="568" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Didacache: an integration of device and application for flash-based key-value caching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaoyan</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichen</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zili</forename><surname>Shao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Storage (TOS)</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="32" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Learning relaxed belady for content distribution network caching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenyu</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Berger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wyatt</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lloyd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th USENIX Symposium on Networked Systems Design and Implementation (NSDI 20)</title>
		<meeting>the 17th USENIX Symposium on Networked Systems Design and Implementation (NSDI 20)</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="529" to="544" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Improving flash resource utilization at minimal management cost in virtualized flash-based storage systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianzhe</forename><surname>Tai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengyu</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jack</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ningfang</forename><surname>Mi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Cloud Computing</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="537" to="549" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">ibtune: individualized buffer tuning for large-scale cloud databases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tieying</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feifei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qixing</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Honglin</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the VLDB Endowment</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1221" to="1234" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Popularity prediction of Facebook videos for higher quality streaming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linpeng</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amit</forename><surname>Puntambekar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ymir</forename><surname>Vigfusson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wyatt</forename><surname>Lloyd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 USENIX Annual Technical Conference (USENIX ATC 17</title>
		<meeting>the 2017 USENIX Annual Technical Conference (USENIX ATC 17</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Efficient MRC Construction with SHARDS</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nohhyun</forename><surname>Carl A Waldspurger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">T</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irfan</forename><surname>Garthwaite</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ahmad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th USENIX Conference on File and Storage Technologies (FAST 15)</title>
		<meeting>the 13th USENIX Conference on File and Storage Technologies (FAST 15)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="95" to="110" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Cascade mapping: Optimizing memory efficiency for flash-based key-value caching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kefei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Symposium on Cloud Computing (SOCC 18)</title>
		<meeting>the ACM Symposium on Cloud Computing (SOCC 18)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="464" to="476" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Nvmcached: An nvm-based key-value cache</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingbo</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fan</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yandong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yufei</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Hack</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zili</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th ACM SIGOPS Asia-Pacific Workshop on Systems (ApSys 16)</title>
		<meeting>the 7th ACM SIGOPS Asia-Pacific Workshop on Systems (ApSys 16)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Storage workload isolation via tier warming: How models can help</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ji</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alma</forename><surname>Riska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgenia</forename><surname>Smirni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proeedings of the 11th International Conference on Autonomic Computing (ICAC 14)</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juncheng</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mimircache</surname></persName>
		</author>
		<ptr target="http://mimircache.info/" />
		<imprint>
			<date type="published" when="2018-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Irfan Ahmad, and Ymir Vigfusson. Optimal data placement for heterogeneous cache, memory, and storage systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reza</forename><surname>Karimi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Measurement Analysis of Computer Systems (POMACS/SIGMETRICS)</title>
		<meeting>the ACM Measurement Analysis of Computer Systems (POMACS/SIGMETRICS)</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Warming up storage-level caches with Bonfire</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiying</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gokul</forename><surname>Soundararajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Mark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Storer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Lakshmi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sethuraman</forename><surname>Bairavasundaram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><forename type="middle">C</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Remzi H Arpaci-Dusseau</forename><surname>Arpaci-Dusseau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th USENIX Conference on File and Storage Technologies (FAST 13)</title>
		<meeting>the 11th USENIX Conference on File and Storage Technologies (FAST 13)</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="59" to="72" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
