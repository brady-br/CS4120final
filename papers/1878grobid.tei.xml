<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2020-09-29T02:15+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">SplitJoin: A Scalable, Low-latency Stream Join Architecture with Adjustable Ordering Precision SplitJoin: A Scalable, Low-latency Stream Join Architecture with Adjustable Ordering Precision</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>June 22-24. 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammadreza</forename><surname>Najafi</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Sadoghi</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammadreza</forename><surname>Najafi</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Technical University Munich ‡ IBM T.J. Watson Research Center § Middleware Systems Research Group</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Sadoghi</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans-Arno</forename><surname>Jacobsen</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="laboratory">IBM T. J. Watson Research Center; Hans-Arno Jacobsen, Middleware Systems Research Group</orgName>
								<orgName type="institution">Technische Universität München</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">SplitJoin: A Scalable, Low-latency Stream Join Architecture with Adjustable Ordering Precision SplitJoin: A Scalable, Low-latency Stream Join Architecture with Adjustable Ordering Precision</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2016 USENIX Annual Technical Conference (USENIX ATC &apos;16)</title>
						<meeting>the 2016 USENIX Annual Technical Conference (USENIX ATC &apos;16) <address><addrLine>Denver, CO, USA</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page">493</biblScope>
							<date type="published">June 22-24. 2016</date>
						</imprint>
					</monogr>
					<note>This paper is included in the Open access to the Proceedings of the 2016 USENIX Annual Technical Conference (USENIX ATC &apos;16) is sponsored by USENIX. https://www.usenix.org/conference/atc16/technical-sessions/presentation/najafi USENIX Association</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>There is a rising interest in accelerating stream processing through modern parallel hardware, yet it remains a challenge as how to exploit the available resources to achieve higher throughput without sacrificing latency due to the increased length of processing pipeline and communication path and the need for central coordination. To achieve these objectives, we introduce a novel top-down data flow model for stream join processing (arguably, one of the most resource-intensive operators in stream processing), called SplitJoin, that operates by splitting the join operation into independent storing and processing steps that gracefully scale with respect to the number of cores. Furthermore, SplitJoin eliminates the need for global coordination while preserving the order of input streams by rethinking how streams are channeled into distributed join computation cores and maintaining the order of output streams by proposing a novel distributed punctuation technique. Throughout our experimental analysis, SplitJoin offered up to 60% improvement in throughput while reducing latency by up to 3.3X compared to state-of-the-art solutions.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Scalable stream processing is an integral part of a growing number of data management applications such as real-time data analytics <ref type="bibr" target="#b0">[1]</ref>, algorithmic trading <ref type="bibr" target="#b1">[2]</ref>, intrusion detection <ref type="bibr" target="#b2">[3]</ref>, and targeted advertising <ref type="bibr" target="#b3">[4]</ref>. These latency-sensitive and throughput-intensive applications have motivated database research to seek new avenues for accelerating data management operations in general and stream processing in particular. These new approaches have adopted heterogeneous architectures (e.g., GPUs and Cell processors) <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b7">8]</ref>, multi-core architectures <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b12">13]</ref>, and Field Programmable Gate Arrays (FPGAs) <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b19">20]</ref> for stream processing acceleration.</p><p>Besides leveraging hardware acceleration, coping with the high-velocity of unbounded incoming streams has forced the stream operation model to shift away from the traditional "store and process" model that has been prevalent in database systems for decades. However, the mindset of sequential stream join processing (or constructing lengthy processing pipelines) and, essentially, thinking of a stream as a sliding window (or a long chain of sequentially incoming tuples to resemble database relations) has continued to shape the way stream processing is carried out today, even on low-latency and high-throughput stream processing platforms.</p><p>Stream Join Challenges: To mitigate the challenges imposed by unbounded streams, with respect to both processing and space constraints, data streams are conceptually seen as bounded sliding windows of tuples (i.e., simulating a relation). Sliding windows are defined as a function of time or as a fixed number of tuples. Once the sliding window abstraction is set (i.e., tuples are admitted for processing), the stream join semantics over the windows are identical to the traditional join semantics in relational database systems.</p><p>Although the sliding window provides a robust abstraction to deal with the unboundedness of data streams <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b18">19]</ref>, it remains a challenge to improve parallelism within stream join processing, especially, when leveraging many-core systems. For example, a single sliding window could conceptually be divided into many smaller sub-windows, where each sub-window could be assigned to a different join core. <ref type="bibr" target="#b0">1</ref> However, distributing a single logical stream into many independent cores introduces a new coordination challenge: to guarantee that each incoming tuple in one stream is compared exactly once with all tuples in the other stream.</p><p>The coordination challenge is addressed by handshake join <ref type="bibr" target="#b8">[9]</ref> that transforms the stream join into a bi-directional data flow problem: tuples flow from left-to-right (for S stream) and from right-to-left (for R stream) <ref type="bibr" target="#b1">2</ref> and pass through each join core. The bi-directional data flow ensures that every tuple is compared exactly once by design (shown in <ref type="figure" target="#fig_0">Figure 1</ref>). This new data flow model offers greater processing throughput by increasing parallelism, yet suffers from latency increase since the processing of a single incoming tuple requires a sequential flow through the entire processing pipeline. To improve latency, yet another central coordination is introduced to fast-forward tuples through the linear chain of join cores in the low-latency handshake join <ref type="bibr" target="#b9">[10]</ref> (the coordination module is depicted in <ref type="figure" target="#fig_0">Figure 1</ref>). For each stream, in order to reduce latency, once a tuple reaches a join core, the tuple is replicated and forwarded to the next core before the join computation is carried out <ref type="bibr" target="#b9">[10]</ref>.</p><p>Generally speaking, any central coordination prohibitively limits the scalability of processing as the degree of parallelism is increased (cf. Amdahl's Law); and, central coordination is required in <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b18">19]</ref>. For example, the coordinator must explicitly send expiration messages to each join core as new tuples enter and old tuples leave each sub-window assigned to a join core. Furthermore, the flow of new and expired tuples in and out of cores is further complicated if tuples are additionally replicated and fast-forwarded <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b9">10]</ref>. Consequently, the neighboring cores must explicitly communicate (in addition to communicating with the global coordinator) and, in fact, all tuples from both streams actually pass through this communication channel <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b9">10]</ref>. Moreover, an explicit knowledge of the underlying hardware is required (that may not even be available in virtual machine settings), and one must rely on a complex optimal assignment of the join cores to physical cores to reduce the NUMA-effect by reducing the size of communication paths between neighboring cores <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b9">10]</ref>.</p><p>Problem Statement: In this paper, we tackle two main shortcomings of existing stream join processing architectures: the sequential operation model (i.e., "store" and "process") and the linear data flow model (i.e., "left-to-right" and "right-to-left" flows). We propose SplitJoin, the first step in re-thinking the stream join operation model, which is built on the implicit assumption that storage of newly incoming data, whether stored in a relation or a memory buffer, must always precede processing. Instead, we abstract the computation steps as two independent and concurrent steps, namely, (i) "storage" and (ii) "processing". <ref type="bibr" target="#b2">3</ref> This new splitting <ref type="bibr" target="#b2">3</ref> In relational databases, tuples are first stored in relations prior to being processed (e.g., performing a join) while in a stream join, the incoming tuples are first processed and subsequently stored in sliding windows <ref type="bibr" target="#b20">[21]</ref>. abstraction of join cores enables unprecedented scalability by allowing the system to distribute the execution across many independent storage cores 4 and processing cores. Second, we change the way tuples enter and leave the sliding windows, namely, by dropping the need to have separate left and right data flows (i.e., bi-directional flow). SplitJoin introduces a novel top-down data flow (i.e., a single flow), where incoming tuples (from both streams) are simply arriving via the same path downstream (preserving input stream order), while the join results are further pushed and merged downstream using a novel relaxed adjustable punctuation (RAP) technique (preserving the output stream order). Unlike recent advances in stream join processing <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b9">10]</ref>, SplitJoin does not rely on central coordination for propagating and ordering the input/output streams.</p><p>SplitJoin's top-down data flow trivially satisfies the ordering of incoming tuples and eliminates the in-flight race condition between the left and right streams as tuples travel from one core to the next. Unlike existing approaches <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b9">10]</ref>, the top-down flow also eliminates the need for communication between the join cores. In SplitJoin, the top-down flow is realized using a distribution tree for routing incoming tuples into their corresponding sub-window that addresses the scaling issues of adding new join cores. The adopted distribution mechanism nicely fits into the coordination-free protocol of SplitJoin for distributing new tuples to both storage and processing cores. For example, all join cores receive the newly incoming tuples (achieving the desired expedited delivery, without the linear forwarding used in <ref type="bibr" target="#b9">[10]</ref>), while only one storage core stores the new tuple. Both the storage and eviction of tuples to and from cores are done in a round-robin fashion; thus, naturally, in the same order that cores store a new tuple, they evict their oldest tuple (again, without any explicit coordination). This can be generalized to batches of tuples instead of a single tuple as well.</p><p>SplitJoin has provably lower runtime complexity as compared to state-of-the-art parallel distributed join algorithms <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b9">10]</ref>. SplitJoin exhibits an overall system latency of O(log b k), where k is the number of join cores and b is the branching factor of the distribution tree. In contrast, the state-of-the-art handshake join has O(k), while the original version resulted in an O(n) latency, where n is the number of tuples a window can hold (k 񮽙n) <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b9">10]</ref>.</p><p>SplitJoin's coordination-free distribution also lends itself to a simpler resiliency against failures; for example, core failures do not halt or disrupt the entire join computation and affect only the failed nodes (the loss is limited to only failed nodes). In contrast, in a linear left-to-right data flow, if any cores fails, then, on average, half of the cores may not receive any data.</p><p>SplitJoin is comprised of the following core components: a distribution network, a set of independent join cores, and a  <ref type="table">Tuple   New Tuple   Tuple   Tuple  Tuple   Window   Window   Tuple  New Tuple   Tuple  Tuple  Tuple   Condition  Condition</ref>  result gathering network. The distribution network broadcasts incoming tuples to the set of join cores in a scalable way. The actual join computation is carried out by each join core independently, and subsequently, the joined tuples are pushed down to the result gathering network. The result gathering network is further responsible to ensure the correct ordering of the joined tuples by using the punctuation marks produced by the join cores. In this paper, we make the following contributions:</p><p>(1) we propose SplitJoin, a novel scalable stream join architecture that is highly parallelizable and removes inter-core communications and dependencies, (2) we introduce a new splitting abstraction in SplitJoin to "process" and "store" incoming data streams concurrently and independently, (3) we propose a top-down data flow model to achieve a coordination-free protocol for distributing and parallelizing stream join processing, (4) we develop a distribution tree with logarithmic accesslatency for routing of incoming data to storage and processing cores, while preserving the ordering of incoming tuples, (5) we design a coordination-free protocol that does not rely on global knowledge to produce ordered join output streams by proposing a relaxed adjustable punctuation (RAP) technique with tunable precision, and (6) we conduct an extensive analytical and experimental study of SplitJoin as compared to existing state-of-the-art solutions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Preliminaries</head><p>The relational join (theta join) between two non-stream relations R and S, defined as R 񮽙񮽙 θ S, produces the set of all resulting pairs (r, s), which satisfy the join condition θ(r,s) and r ∈ R, s ∈ S. Extending this definition to stream join implies the same join processing semantics with the exception that streams, unlike relations, are unbounded. To mitigate the challenge of unbounded streams, with respect to both processing and storage limitations, streams are conceptually seen as bounded sliding windows of tuples, as shown in <ref type="figure" target="#fig_2">Figure 2</ref>. The size of these windows are defined as a function of time or number of tuples, referred to as time-based or count-based windows, respectively. operator that receives Tuple-R and Tuple-S from streams R and S, respectively. JC stands for join core, which performs the join operation. To process the tuples shown in the figure, Tuple-R is inserted into Window-R, then it is evaluated against all existing tuples in Window-S and the join results are returned. Similarly, Tuple-S is inserted into Window-S and the same join procedure is applied.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Related Work</head><p>Work related to our approach can be broadly classified into stream join algorithms <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b21">22]</ref>, or more generally speaking, stream processing in software <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b24">25]</ref>, approaches to performance-optimize stream processing through emerging hardware mechanisms <ref type="bibr" target="#b25">[26]</ref>, in particular, through FPGA-based acceleration <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b16">17]</ref>, but also, through GPUs and processor-based I/O processing innovations <ref type="bibr" target="#b7">[8]</ref>.</p><p>The survey <ref type="bibr" target="#b26">[27]</ref> covers other related work and topics including concepts such as ordering in stream join. SplitJoin can be incorporated in any of the existing streaming engines (i.e., <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b29">30]</ref>).</p><p>Stream Join Algorithms -An early stream join was formalized by Kang's three-step procedure <ref type="bibr" target="#b20">[21]</ref>. Subsequently, Gedik et al. <ref type="bibr" target="#b5">[6]</ref> introduced the parallel CellJoin, designed for a heterogeneous architecture, aiming to substantially improve stream join processing performance. However, CellJoin requires a re-partitioning task for each newly incoming tuple, which limits its scalability <ref type="bibr" target="#b5">[6]</ref>. The problem of distributed stream join processing has also been studied with respect to elasticity and reduction of memory footprint, applicable to cloud computing <ref type="bibr" target="#b21">[22]</ref>.</p><p>Teubner et al. introduced a bi-direction data flow-oriented stream join processing approach, called the handshake join <ref type="bibr" target="#b8">[9]</ref>. To reduce delay in the linear chaining, Teubner et al. <ref type="bibr" target="#b9">[10]</ref> introduced a low-latency handshake join that uses a fast forwarding mechanism to expedite tuple delivery to all sub-windows by replicating every tuple k times, where the stream is split over k join cores. This mechanism is illustrated in <ref type="figure" target="#fig_0">Figure 10</ref>. Furthermore, the bi-directional flow complicates the logic for serializing the two pipes connecting consecutive join cores that is necessary in order to avoid race conditions due to concurrent in-flight tuples (i.e., tuples traveling between neighboring processing cores).</p><p>Stream Processing Acceleration -Stream processing has received much attention over the past few years. Many viable research prototypes and products have been developed, such as NiagaraCQ <ref type="bibr" target="#b23">[24]</ref>, TelegraphCQ <ref type="bibr" target="#b22">[23]</ref>, and Borealis <ref type="bibr" target="#b24">[25]</ref>, to just name a few. Most existing systems are fully software-based and support a rich query language, but stream join acceleration has not been the main focus of these approaches.</p><p>Since the inception of stream processing, the development of optimizations both at the query-level and at the engine-level have been widely explored. For example, co-processor-based solutions utilizing GPUs <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b5">6]</ref> and more recently hardware-based solutions employing FPGAs have received attention <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b30">31]</ref>. For example, Tumeo et al. demonstrated how to use GPUs to accelerate regular expression-based stream processing language constructs <ref type="bibr" target="#b7">[8]</ref>. The challenge in utilizing GPUs lies in transforming a given algorithm to use the highly parallel GPU architecture that has primarily been designed to perform high-throughput matrix computations and not, foremost, low latency processing.</p><p>Past work showed that FPGAs are a viable option for accelerating certain data management tasks in general and stream processing in particular <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b32">33]</ref>. For example, Hagiescu et al. <ref type="bibr" target="#b14">[15]</ref> identify compute-intensive nodes in the query plan of a streaming computation. To increase performance in the hardware design that realizes the streaming computation, these nodes are replicated, which, due to the stateless nature of the query language considered, poses few issues. A main difference from our work is the restriction to stateless operations and the lack of a capability to flexibly update the streaming computation. Similarly, Mueller et al. <ref type="bibr" target="#b16">[17]</ref> present Glacier, a component library and compiler, that compiles streaming queries into logic circuits on an operator-level basis. Both approaches are characterized by the goal of hardware-aware acceleration of streams, yet our solution is also applicable to non-FPGA parallel hardware.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">SplitJoin</head><p>In this section, we describe SplitJoin and highlight two of its key properties, namely, the top-down data flow and the splitting of the join computation into independent storage and processing steps. Together, these properties remove any need for coordination and dependencies among join cores, which enables a high-degree of parallelism for SplitJoin without sacrificing latency. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">SplitJoin Overview</head><p>SplitJoin diverts from the bi-directional data flow-oriented processing of existing approaches <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b9">10]</ref>. As illustrated in <ref type="figure" target="#fig_0">Figure 1</ref>, SplitJoin introduces a single top-down data flow that fundamentally changes the overall tuple processing architecture. First, the join cores are no longer chained linearly (i.e., avoiding linear latency overhead). In fact, they are now completely independent (i.e., also avoiding inter-core communication overhead). Second, both streams travel through a single path entering each join core; thus, eliminating all complexity due to potential race conditions caused by in-flight tuples and complexity due to ensuring the correct tuple-arrival order, namely, the FIFO property is trivially satisfied by using a single (logical) path. Third, the communication path can be fully utilized to sustain the maximum throughput and each tuple no longer needs to pass every join core.</p><p>Another important aspect of SplitJoin is the simplification and decomposition of join processing itself. SplitJoin splits the dominant join abstraction that enforces the "storing" and "processing" steps to be coupled and done in a serial order. SplitJoin views these steps as two independent steps, namely, (i) "storing" and (ii) "processing". In fact, SplitJoin goes one step further and shows that not only these steps could be done in parallel, they can also be distributed to independent join cores. Therefore, unlike traditional parallel join processing that divides a single window into a set of sub-windows, where each is assigned to a core, SplitJoin introduces separate storage and processing cores that operate independently of each other as shown in <ref type="figure" target="#fig_4">Figure 4</ref>. The storage core is responsible for storing new tuples, while the processing core is responsible for the actual join operation of a new tuple in one stream with the existing tuples in the other stream. The splitting line in <ref type="figure" target="#fig_4">Figure 4</ref> conceptually divides our join processing architecture into two separate parts, in which a region represents a stream's window and the associated buffer. We use the term right-region when referring to Window-R and left-region for Window-S. For each incoming tuple, a region either does processing or storing. The split mechanism is illustrated in <ref type="figure">Figure 5</ref>, where the incoming tuples are fed to SplitJoin one after another. In the first step, Tuple-R is inserted into both regions. The right-region is responsible for storing Tuple-R in its sliding window, while the left-region is responsible for the processing of the replicated copy of Tuple-R (i.e., the join comparison). The temporary tuple replication eliminates all inter-region communication among storage and processing cores. The replicated tuples are simply discarded once the processing is completed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">SplitJoin Parallelism</head><p>In SplitJoin, we parallelize the stream join computation by dividing each sliding window into a set of disjoint sub-windows. Each sub-window is assigned independently to a join core as shown in <ref type="figure" target="#fig_6">Figure 6</ref> (i.e., acting as a local buffer for each core). Each join core (JC) consists of a left-and a right-region. The division of the sliding window among join cores is accompanied by a Distributor unit to transmit incoming tuples to the join cores.</p><p>In the parallelized version of SplitJoin, all join cores receive the new incoming tuple. In each join core, depending on the tuple origin i.e., whether R or S stream, the processing and storage steps are orchestrated. For example, if the incoming tuple belongs to the R stream, Tuple-R, then all processing cores dedicated to the left-region compare Tuple-R against all the tuples in the S stream sub-windows. Simultaneously, Tuple-R is also stored in the storage core of exactly one right-region. The assignment of Tuple-R follows an arbitration of the tuple to a storage core based on a round-robin selection. In other words, each region, based on its position number <ref type="bibr" target="#b4">5</ref> and the number of seen tuples, independently determines its turn to store an incoming tuple. The proposed assignment model eliminates the need for a central coordinator for tuple assignment, which is a key contributor for achieving scalability in SplitJoin architecture. Notably, transmitting an incoming tuple to each join core translates into writing a tuple to the join core's local buffer (independent of any other join cores) that resembles a simple queue with a single producer and a single consumer, in which the producer is the Distributor and the consumer is join core itself.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Scalable Distribution Tree</head><p>The decoupling of storage and processing in SplitJoin simplifies parallelization by distributing sub-windows among many independent join cores. To fully leverage potential parallelism, we also need an efficient tuple distribution and routing mechanism.</p><p>In SplitJoin, to distribute the stream's transmission load in a balanced and scalable manner, we use a k-ary tree as the distribution network. As the network grows in size, the Distributor is replicated and its replicas are placed in the tree's inner nodes to achieve the desired scalability. As the number of SplitJoin join cores increases, we increase the fanout of each Distributor before increasing the depth of the distribution tree.</p><p>By applying replication recursively, we scale the distribution network as well as the number of join cores for SplitJoin. The resulting system, including the input data distribution network, SplitJoin's join cores, and the output data gathering network (similar in structure to the input network), is shown in <ref type="figure" target="#fig_0">Figure 11</ref>, where the horizontal bars illustrate the input distribution and output gathering networks.</p><p>The distribution network is the same for both count-based and time-based sliding window joins. However, in the time-based version each tuple carries an extra field for its timestamp. This field is to keep track of the lifespan of each tuple to realize the time-based sliding window semantic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Expiration &amp; Replacement Policies</head><p>Tuple expiration is a crucial step to ensure the correctness of the stream join semantic. In the count-based sliding window, the number of tuples in each window is specified explicitly while in the time-based sliding window a lifespan l (e.g., l =10 minutes) defines when a tuple must be expired.</p><p>SplitJoin supports both passive and active expiration techniques. The passive approach is primarily intended for the count-based sliding window, in which the incoming tuples simply overwrite the oldest tuples in the window. The expiration is done implicitly and mimics the functionality of a FIFO buffer. Once a window is full, the stored tuples are expired in order of their arrival. In the active expiration, geared towards the time-based sliding window, each join core locally manages the expiration of tuples from its sub-window. The expiration task for each sub-window is postponed until a tuple from the opposing stream with timestamp of t is received for processing. Then, in the region responsible for processing, just prior to the join computation, for each tuple with a timestamp t i , if (t−t i )&gt;l, then the tuple is expired. Basically, tuples are expired when they fall off the user-defined lifespan (l) of the time-based window size.</p><p>Note the expiration is a local operation within a region and does not involve global coordination because tuples arrive with monotonically increasing timestamps and order is preserved when they are added and stored in a sub-window. The expiration task starts from the end (with the oldest tuple) of each sub-window and ends when a tuple younger than the user-defined lifespan is found. In other words, instead of sending explicit expiry messages with a timestamp, we rely on the timestamp of tuples in the input streams that must Figure 7: SplitJoin data distribution and processing example. be routed to all nodes anyway. Therefore, the expiration messages are implicitly piggybacked on the incoming tuples as a way to broadcast the synchronized time without the need for global coordination. In <ref type="figure">Figure 7</ref>, we illustrate how tuples are stored and processed in SplitJoin join cores. Assuming that we have a sequence of tuples as shown in the upper part of the figure, each tuple is transferred by the distribution tree to all join cores. Each Tuple-R is stored in exactly one right-region while processed by the left-region of all join cores. Likewise, for tuples from the S stream, they are stored in the left-regions and are processed by the right-regions.</p><p>As we can see in <ref type="figure">Figure 7</ref>, the tuples are distributed in-order. The tuples reach the storage cores through the same path (i.e., the top-down flow), and the expiration procedure is preformed based on the order of incoming tuples (for both count-based and time-based sliding windows). Thus, unlike the bi-directional model used in <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b9">10]</ref>, neither the concurrency nor the race condition issues arise.</p><p>During processing, each region emits resulting tuples to be collected by the result gathering network (cf. Section 5). The processing step for each tuple in each region is completed by emitting an end notice from that region, referred to as a star punctuation mark. These marks serve to preserve the order of join results as we describe in detail in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">SplitJoin Algorithms</head><p>Tuple distribution in SplitJoin is specified in Algorithm 1. Upon arrival of a new tuple, regardless of its source stream, the tuple is broadcast to all join cores (Line 3).</p><p>In each join core, as presented in Algorithm 2, depending on the tuple's source (Lines 2 and 11), from R or S stream, the tuple is sent to the right-region for storage and to the left-region for processing or vice versa.</p><p>Finally, in the expiration process specified in Algorithm 4, the tuples that are too old to be considered for the join are expired from the end of the sub-window by computing their lifespan using their timestamp and the timestamp of the new tuple.</p><p>The pseudo code for the processing core (i.e., the join comparison) is specified in Algorithm 3. An incoming tuple is compared with all tuples in the opposite sub-window (Lines 2-4). More importantly, this step is executed concurrently for each sub-window in every region. After processing (Lines 5-6), based on the chosen ordering precision, the star marker is produced and emitted. Also note that the goal of SplitJoin is to provide an efficient and coordination-free architecture for performing stream joins, and the particular choice of join algorithm is orthogonal. In this work, we adopted a simple variation of nested-loop join; however, within each core, one may choose any join algorithms such as hash-or index-based join.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Punctuated Result Collection</head><p>In SplitJoin, we employ a result gathering network (similar to our data distribution network) and a punctuation technique to preserve the ordering for the join result output. The full architecture of SplitJoin, that includes the distribution network, join cores (JCs), and the collection network, is illustrated in <ref type="figure" target="#fig_0">Figure 11</ref>.</p><p>In SplitJoin, we utilized a 2-ary collection tree to gather and merge join results as depicted in <ref type="figure" target="#fig_7">Figure 8</ref>. The result Algorithm 2: A join core in SplitJoin. tuples of each processing core are gathered from the leaves of the collection tree. Each core has its own dedicated FIFO buffer. The collection tree employs a Merger unit and a FIFO buffer in each of its intermediate nodes (except in the root).</p><p>Moving toward the tree's root (from top to bottom), at each node, the data in the two input buffers is merged into the buffer of that node. Merging continues up to the root, which contains the last buffer emitting the gathered join results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Punctuation-based Ordering</head><p>SplitJoin architecture preserves the ordering of result tuples.</p><p>The precision of the output order can be determined by a tunable system parameter, without significant changes in the processing architecture. To realize this flexibility in our design, we developed a relaxed adjustable punctuation (RAP) strategy. We define two levels of ordering guarantees for join results: the outer and inner ordering. Our proposed relaxation enables us to maintain strict outer ordering while adjusting the precision of the inner ordering (essentially, not maintaining the inner ordering) in order to substantially reduce the overall cost of ordering. Furthermore, our technique supports strict outer and inner ordering as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 1 The outer ordering of join results ensures that</head><p>In RAP, we define a simple punctuation emission rule for each core (the same simple rule applies to all cores), that is, the emission of a punctuation at the end of the processing of every newly inserted tuple (preserving the outer ordering and relaxing the inner ordering). In other words, each join core emits a punctuation after the end of processing a newly inserted tuple with all tuples in the other window. We Algorithm 4: Expiring old tuples for time-based version.</p><p>1 Expiration Process(t, sub-window X) begin 2 i← the end of sub-window X; 3 while t i .timestamp -t.timestamp &gt; Time Window Size do 4 omit t i from sub-window X; SplitJoin cores insert both the join results and punctuation marks to collection tree leaves. The punctuation acts as a border between the join results of two consecutively inserted tuples (outer order). As join results and punctuations are pushed down the collection tree towards the root, at each node of the tree, the join results and their corresponding punctuation marker (stars) from the two buffers are merged into the FIFO buffer of their parent node. When the Merger in the parent node receives a star from one of its inputs, it disables that input and continues to receive resulting tuples from the other buffer until it receives a star from that buffer as well. The Merger merges two punctuations (stars) into one and pushes it to its FIFO buffer. This scenario repeats until the star reaches the output of the collection tree.</p><formula xml:id="formula_0">5 i←i−1; R0-S2 S1-R8 R S S1-R4 S2-R8 S2-R3 S2-R9 S2-R4 S3-R8 S2-R7 R1-S4 R2-S6 R3-S3 R2-S4 R3-S8 S S R R R0-S2 S1-R8 S1-R4 S2-R8 S2-R3 S2-R9 S2-R4 S3-R8 S2-R7 R1-S4 R2-S6 R3-S3 R2-S4 R3-S8</formula><p>Since join results are pushed down in the order in which the newly inserted tuple arrives, the outer ordering for each core is trivially satisfied due to the single top-down FIFO flow of SplitJoin that starts from the root of the distribution tree (for inserting new tuples) and ends at the root of the collection tree (for merging the join results). This flow is shown in <ref type="figure" target="#fig_8">Figure 9</ref>.</p><p>The final step in the result gathering network employs a Combiner rather than a Merger. On the right side of the split are the punctuated results, ordered by the tuples from the S stream, while on the left side, the punctuation is based on the arrival sequences of tuples from the R stream. These two sets of punctuated result tuples are consumable as separate streams. However, to emit only one stream as output, we use a Combiner which simply fetches the resulting tuples and punctuations from their input and puts them into the output buffer. The Combiner keeps track of the origin of punctuations (whether from the right-or left-regions) by flagging the stars with R and S, as shown in <ref type="figure" target="#fig_8">Figure 9</ref>.</p><p>In <ref type="figure" target="#fig_8">Figure 9</ref>, the upper flow is the result stream from the right-regions, punctuated by the order of S stream tuples, while the middle one is the result stream from the left-regions, punctuated by the order of R stream tuples. The lower flow demonstrates the combined result stream that includes all result tuples in addition to punctuations. For example, R1-X is specified by two R punctuations and includes the result tuples which start with R1.</p><p>Adjusting the punctuation interval is straightforward and only requires us to tune the punctuation emission rate in SplitJoin's cores. Each core can simply change the frequency at which a punctuation is generated. For example, each core can be tuned to produce a punctuation after joining one newly inserted tuple (strict outer ordering) or after every five tuples (relaxed outer ordering). We could also adjust the precision of inner ordering by increasing the frequency of punctuation generation. For example, to produce a strict inner ordering, each incoming tuple is compared with tuples in the opposite window (starting from the oldest to the most recently inserted one), followed by outputs for both the join result and the punctuation marker for every comparison. Therefore, if each core has a window size of w, then up to w punctuation markers (i.e., stars) are produced for every newly inserted tuple. For a relaxed inner ordering, only one punctuation is produced after joining the incoming tuples with all the tuples in the opposite window. At the other extreme, when no ordering is required, we could simply disable the punctuation generation altogether.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Ordering Algorithm</head><p>For the result gathering network, we utilized a k-ary tree. Algorithm 5 specifies the pseudo-code for an N-ary (e.g., 2-ary) Merger given an N-ary result gathering tree. The Merger is connected to the output FIFO buffer of N regions and collects the resulting tuples and punctuations into its own output FIFO buffer, which is subsequently fed to the next intermediate node (its parent) in the tree. This is repeated up to the root of the tree, where result tuples are punctuated by tuple arrival order from the two stream types (either R or S).</p><p>The Merger connects to the output buffers of the same source, either left or right regions (cf. Line 2 of Algorithm 5). Each Merger collects the results in the same order as the join cores store the new incoming tuples. For example, assuming that the first Tuple-R is stored in the left most join core in its right-region, as shown in <ref type="figure">Figure 7</ref>. The Merger then begins the collection of results from the comparison of Tuple-S with the R sub-window in the left most right-region as well.</p><p>In the result gathering, the Merger fetches tuples from the first region's buffer and stores them in its own output buffer until it reaches the first star in (Line 3∼Line 5). Then it repeats the same procedure for the next region's buffer until it receives a star from there too.</p><p>After receiving a punctuation mark from the last region, the Merger forwards the punctuation to its output buffer (cf. Line 6). Note that each Merger emits only one punctuation mark for every pair of punctuation (i.e., one punctuation mark from each join core). Using a higher ordering precision increases the number of punctuation marks between result tuples of each region. For example, instead of having one punctuation mark after comparison of a tuple with the whole sub-window, we can have one punctuation after each 10 comparisons. Since tuples in the sub-window are already stored in the order of their arrival, the intermediate punctuations preserve the result ordering while gathering the results from all the join cores. For obtaining a higher precisions, Mergers follow the same procedure as before.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Runtime Complexity</head><p>In this section, we present a brief analytical model to study the runtime complexity of SplitJoin relative to related techniques <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b9">10]</ref>. In the analysis, we use the following definitions.</p><p>Definition 3 We define the processing latency (PL) as the time from when a tuple arrives at the join operator until the tuple is compared and joined with all tuples in the other window and all the matching results are produced.</p><p>Definition 4 We define the visiting latency (VL) as the time required for two tuples from both streams to be compared with each other.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Low-latency Handshake Join Analysis</head><p>The processing latency for low-latency handshake join (cf. <ref type="figure" target="#fig_0">Figure 10</ref>) is given as follows:</p><formula xml:id="formula_1">PL=T CL +((k−1)×(T CL +T ML ))+(w×T P )+T Col (1)</formula><p>where T CL represents the communication time between cores and k the number of processing cores. T ML accounts for the tuple monitoring time in both streams, required to prevent missing results between tuples in the fast-forwarding buffers (i.e., race conditions). Therefore, the cost of propagating a single tuple to all cores by replication and fast-forwarding is captured by ((k − 1) × (T CL + T ML )). The size of each sub-window in each core is denoted by w. T P represents the processing time to perform the join operation between each pair of tuples. To simplify the analysis, we assume that all join cores are working in parallel. Finally, T Col presents the time required to collect all the matching results. In <ref type="bibr" target="#b9">[10]</ref> the authors rely on a linear collector method for gathering the results that has the potential to break the strict neighbor-toneighbor communication model of handshake join.</p><p>In theory, assuming a fixed-size sub-window, we can increase the number of processing cores to support larger windows. Therefore, the join's latency scales linearly in the number of processing cores, i.e., as O(k), -optimistically assuming that central coordination would not become a bottleneck while ignoring the effect of the result collection method.</p><p>To calculate the visiting latency, we assume that the number of in-flight tuples from the two streams that must be compared (i.e., the monitoring time T ML ) is negligible. While this assumption renders the model less realistic (which was also implicitly assumed in <ref type="bibr" target="#b9">[10]</ref>), it simplifies the visiting latency analysis.</p><p>Any pair of tuples from both streams meet each other in, at most, one location; let this location be α as shown in <ref type="figure" target="#fig_0">Figure 10</ref>. α could be in any core. If α happens to be on the first core, then the latency is lower, while if it is on the last core, then the latency is higher. Thus, we define the average visiting latency as follows:</p><formula xml:id="formula_2">VL avg =T CL +(񮽙 (k−1) 2 񮽙×(T CL +T ML ))+(( w 2 )×T P ) (2) (񮽙 (k−1) 2 񮽙 × (T CL + T ML )</formula><p>) determines the average time to reach location α (essentially, reaching the mid-point of core chain) and ( w 2 ) × T P captures the processing time for half the tuples at α. The visiting latency scales linearly with the number of processing cores O(k), assuming (T CL +T ML ) is constant, irrespective of the number of cores.</p><p>To simplify the analysis, we ignore the overhead of central coordination in low-latency handshake join <ref type="bibr" target="#b9">[10]</ref>. The coordinator requires sending an explicit expiry message for every tuple <ref type="bibr" target="#b9">[10]</ref>. On average, these messages double the communication traffic between the central coordinator and each join core, significantly affecting the performance as observed in our experimental evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">SplitJoin Analysis</head><p>SplitJoin utilizes a distribution tree to deliver incoming tuples to each join core in O(log b k) time, where k is the number of join cores and b is the branching factor of the distribution tree. We define Path 1···k as a distribution route that a tuple must travel to reach the join cores 1···k, respectively. Let T C Path i ,Depth j be the communication cost (duration) of transferring a tuple to the i th path at depth j. We define the processing latency for SplitJoin as follows:</p><formula xml:id="formula_3">PL= max i=1···k ( ∑ j=1···log b k T C Path i ,Depth j +(w×T P i ))+T Col (3)</formula><p>where T P i is the processing time to perform the join operation between each pair of tuples for the i th core. Assuming the communication times, T C Path i ,Depth j , are roughly equal, then it follows that:</p><formula xml:id="formula_4">PL= max i=1···k (T C Path i ×log b k)+(w×T P i ))+T Col<label>(4)</label></formula><p>If we further assume homogeneous join cores and homogeneous distribution routes within the tree and also decompose T Col into smaller units of work, then it follows that:</p><formula xml:id="formula_5">PL=(T CL ×log b k)+(w×T P )+(T CL ×log c k)<label>(5)</label></formula><p>where log c k defines the depth of the result gathering tree with the branching factor of c (from root to leaves). Assuming a fixed-size sub-window, as we increase the number of join cores, latency increases logarithmically, O(log b k) (assuming b&lt;c), for SplitJoin as opposed to the linear increase (O(k)) observed in <ref type="bibr" target="#b9">[10]</ref>. Supposing two consecutive tuples from both streams meet at the point α, as shown in <ref type="figure" target="#fig_0">Figure 11</ref>, then their communication times in the distribution tree mostly overlap with each other because they are pushed to the distribution tree one after another. They travel together (using the FIFO strategy) to reach the targeted join core. As above, here, we also assume homogeneous join cores and communication costs within the distribution tree. Then, the average visiting latency of SplitJoin is given by:</p><formula xml:id="formula_6">VL avg =(T CL ×log b k)+( w 2 ×T P )<label>(6)</label></formula><p>Thus, the average visiting latency is also logarithmic in the number of join cores, compared to the linear order in <ref type="bibr" target="#b9">[10]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Experimental Results</head><p>In this section, we experimentally evaluate our SplitJoin implementation. All experiments are performed on a 32-core system. Our system is a Dell PowerEdge R820 featuring 4 × Intel E5-4650 processors and 32 × 16GB DDR3 memory (RDIMM, 1600 MHz, Low Volt, Dual Rank, x4  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Experimental Setup</head><p>We adopted the benchmark used in recent stream join approaches <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b9">10]</ref>. In this benchmark two streams R = In our evaluations, we used the low-latency (referred to as LH vs. SplitJoin (SJ)) and the original handshake join libraries that were kindly provided by the authors of <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b9">10]</ref>. Also in line with related approaches, integers and floats were generated following a uniform distribution in the range of 1−10 4 , unless otherwise stated.</p><p>The results cover the end-to-end evaluation, including data distribution network, SplitJoin storage and processing cores, the result gathering network, and also the proposed punctuated ordering mechanism. The punctuation precision is based on the outer tuple ordering as shown in <ref type="figure" target="#fig_8">Figure 9</ref>, unless otherwise stated.</p><p>In our time-based window realization, we generated timestamps on-the-fly using the system call clock gettime(). Using a synthetic timing mechanism, as we experimented, further improves the overall performance by about 15% by relieving the overhead incurred by system calls.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Performance &amp; Scalability</head><p>We evaluate SplitJoin performance by measuring latency and throughput metrics as we scale the level of parallelism. In general, key factors that influence the stream join performance are how the input streams are flowing through the join cores and how the joined results are collected and flow to the output.</p><p>In <ref type="figure" target="#fig_0">Figure 12</ref>, we demonstrate throughput results of SplitJoin in comparison with <ref type="bibr" target="#b9">[10]</ref>. As we scale the number of join cores, we observe that both solutions scale gracefully; however, SplitJoin outperforms the low-latency handshake join by up to 60% (comparison between 15-min sliding windows). Theoretically, the performance of both approaches should be similar, as both utilize all join cores in parallel to process incoming tuples. However, the core-to-core communication and mandatory expiry messages in low-latency handshake join (necessary for both time-based and count-based join versions) impose a noticeable penalty.</p><p>In <ref type="figure" target="#fig_0">Figure 12</ref>, we also observe how the two approaches perform for different time-based window sizes. When the join core count is 32, we observe a drop in performance in both of the approaches. This is due to the existence of extra threads to perform other (non-processing) tasks such as stream distribution and result gathering in case of SplitJoin, and tuple assignment, expiry message generation, and result gathering in case of the low-latency handshake join. Since our system has only 32 processing cores, by instantiating 32 join cores, the operating system is forced to perform context switches, resulting in system saturation and performance drop.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3">Latency Evaluations</head><p>In <ref type="figure" target="#fig_0">Figure 14</ref>, we present an abstract model of our end-to-end processing pipeline stages. The grayed parts show intermediate and pipeline buffers. In the measurements, we are reporting the latency of the distribution stage (dis), which also includes the time that tuples are waiting in the pipeline stage between the distribution and execution stages. The latency of the execution stage (exe) is the latency attributed to the time that it takes a tuple to pass through the processing and storage steps in the join core, which also includes the tuple expiration process for the time-based sliding window. The latency for the last stage includes the time that resulting tuples are waiting in the pipeline stage between the execution and result gathering stages and also the time for the Merger and the Collector units to bring them to the output of SplitJoin. Latency reports for these measurements plus the processing, end-to-end (ete), and latency of SplitJoin, for the time-based sliding window, are presented in <ref type="figure" target="#fig_0">Figure 15</ref>.</p><p>Processing Pipeline Stage Latency: In the distribution network, as we increase the number of join cores, incoming tuples are distributed between larger number of join cores instead of having to pile up in the pipeline buffer for fewer join cores. Therefore, increasing the number of join cores, inherently reduces the waiting time in the distribution stage as shown in <ref type="figure" target="#fig_0">Figure 15</ref>.</p><p>Since our evaluation system has only four processor sockets, the increase in the size of the distribution network has no significant effect on the performance except when the size of the sliding window is small. In the execution stage, the increase in the number of join cores for a given window size translates into smaller sub-windows for each join core and the latency also proportionally decreases.</p><p>Among our three pipeline stages, the result gathering network with punctuation ordering had the highest latency impact. This latency was mainly due to the waiting times of the Mergers on one of their input ports to receive a punctuation mark (star) before starting to read from their next port.</p><p>Visiting Latency: In <ref type="figure" target="#fig_0">Figure 13</ref>, we observe the average visiting latency (T match −max(t r ,t s )) for SplitJoin with 5, 10, and 15 minutes sliding windows, and low-latency handshake join with a 15 minutes sliding window for varying number of join cores. The t r and t s stand for initial timestamp of r and s tuples, respectively.</p><p>As we evaluated the average visiting latency (cf. Section 6), the latency increases logarithmically, O(log b k), for SplitJoin as opposed to linearly, O(k), for the low-latency handshake join <ref type="bibr" target="#b9">[10]</ref>. By comparing the average visiting latency for the 15-min version of SplitJoin and low-latency handshake join, when we use four join cores, the latency is quite similar; however, once the number of join cores increases, the gap between SplitJoin and low-latency handshake join widens drastically by a factor of up to 3.3X <ref type="bibr">(8.1ms vs. 26</ref> Figure 16: Count-based SplitJoin throughput.</p><p>28 join cores).</p><p>We observe an increase in latency while reaching 32 join cores which is again due to the lack of enough resources for the other (non-processing) tasks. Since low-latency handshake join requires to perform additional costly tasks, such as emitting individual expiry message for each tuple, the resource contention shows a more significant impact on latency as seen when instantiating 32 join cores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.4">Count-based Sliding Window</head><p>Although the count-based and time-based versions of SplitJoin behave similarly, there are two key differences: (1) having no space allocated for timestamp values and no on-the-fly generation of timestamps through a costly system call and (2) having a fixed window size for count-based semantics as opposed to the time-based semantics where the window size varies depending on the incoming tuple rate. These differences result in roughly 20% improvement in performance for SplitJoin using a count-based instead of time-based sliding window. For example, SplitJoin instantiated with 28 join cores over a 15-min sliding window (shown in <ref type="figure" target="#fig_0">Figure 12</ref>) sustains an input rate of 4400 tuples/second, which roughly translates to window sizes of 2 21 for each stream. But for the count-based window, if we set the window size to (2 21 ), SplitJoin can process up to 5200 tuples/second, as shown in <ref type="figure" target="#fig_0">Figure 16</ref>.</p><p>In the count-based results shown in <ref type="figure" target="#fig_0">Figure 16</ref>, we observe two effects: (1) larger window sizes result in fewer punctuation marks, assuming the same input throughput, since in the outer tuple ordering each join core produces one punctuation mark at the end of each tuple processing and (2) a larger sub-window per join core additionally increases the processing efficiency by reducing the impact of other (non-processing) pipeline stages. Based on these observations, doubling the window size while fixing the number of join cores reduces the processing throughput.</p><p>For each window size, by increasing the number of join cores (JCs), we observe a relative improvement in the  <ref type="figure" target="#fig_0">Figure 19</ref>: Ordering precision effect (28 JCs, uniform distribution:1−10 4 ).</p><p>throughput except when using 32 join cores. Over-utilizing system resources (i.e., using 32 join cores) has more impact on the throughput for smaller window sizes. Larger windows keep join cores busier, thus, new tuples are processed after longer waits. This relieves other tasks (i.e., distribution), reducing the effect of resource contention.</p><p>In <ref type="figure" target="#fig_0">Figure 18</ref>, we present the latency of the processing pipeline stages, the average processing latency (ete), and visiting (vis) latency for SplitJoin for the count-based sliding window. SplitJoin scales gracefully as we increase the number of join cores; in particular, using 28 join cores, the visiting latency is improved by more than 2.5X and 8.3X as compared to the time-based version of SplitJoin and the low-latency handshake join, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.5">Effect of Selectivity</head><p>The selectivity (also called match probability) is one of the major factors affecting join performance. Often a low selectivity is assumed in most related work <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b9">10]</ref>. However, it is important to analyze the sensitivity of a join algorithm with respect to the selectivity in order to assess the generality of the approach.</p><p>The effect of varying the selectivity on the input throughput is illustrated in <ref type="figure" target="#fig_0">Figure 17</ref>. The key observation is that SplitJoin's latency scales reasonably, and it is robust to changes of selectivity, even for sliding windows as large as 28×2 15 tuples. <ref type="figure" target="#fig_0">Figure 19</ref> demonstrates the effect of the ordering precision on the processing performance. In this diagram, we utilize 28 join cores with varying sub-window sizes (2 12 −2 15 ) per join core. The ordering precision starts from one punctuation per sub-window processing, referred to as relaxed inner ordering, and progressively increases the precision until one punctuation mark (star) is produced after each comparison (represented as 2 1 on the x-axis) within each sub-window, referred to as strict inner ordering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.6">Effect of Punctuation Precision</head><p>The relaxed inner ordering is the same as the strict outer ordering. Therefore, the highest punctuation interval for each window size in <ref type="figure" target="#fig_0">Figure 19</ref> represents the effect of strict outer ordering on the throughput for that window size.</p><p>As we increase the precision (e.g., focusing on a subwindow size of 2 15 ), from 2 11 −2 15 , its effect on the overall performance is negligible, since the number of punctuations produced per each incoming tuple in each join core is relatively low (i.e., 1, 2, 4, 8, and 16 punctuations, respectively) compared to the sub-window size which is 2 15 . However, as we continue to increase the precision from the interval 2 10 down to 2 1 , the number of punctuations becomes comparable to the sub-window size for each join core, and as expected, negatively affects the performance of SplitJoin. This highlights the importance of balancing ordering precision versus overall performance. In fact, since the precision is adjustable, to achieve a desired throughput, SplitJoin could adaptively adjust the precision interval to achieve a sweet spot between the ordering precision and the sustainable input throughput.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusions</head><p>We present SplitJoin, a novel stream join that introduces two unique properties that distinguish it from existing work. First, SplitJoin exhibits a scalable architecture that splits the join computation into two independent "storing" and "processing" steps that can be parallelized using a coordination-free protocol to achieve low-latency join processing. Second, SplitJoin introduces a simplified top-down, flow-oriented join processing that eliminates complex concurrency logic for avoiding race conditions while satisfying input stream ordering semantics. We further propose scalable distribution-and collectiontrees for input stream propagation and output join result gathering, respectively. Lastly, we propose a relaxed adjustable punctuation to guarantee join result ordering and to provide an effective mechanism to balance the trade-offs between the ordering precision and the overall join throughput.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Stream join data flow models (JC stands for join core): (a) bi-directional and (b) top-down.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Sliding window concept in stream join.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 shows</head><label>3</label><figDesc>Figure 3: Traditional stream join architecture.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: SplitJoin concept.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>Figure 5: SplitJoin storing and processing steps.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: SplitJoin parallel architecture.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Punctuations in result gathering.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Punctuated resulting stream. differentiate this punctuation from result tuples by a star, as shown in Figure 8.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 10 :</head><label>10</label><figDesc>Figure 10: Low-latency handshake join overview [10].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 11 :</head><label>11</label><figDesc>Figure 11: SplitJoin complete system.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 14 :</head><label>14</label><figDesc>Figure 12: Throughput comparison.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head></head><label></label><figDesc>(x:int, y:float, z:char[20]) and S = (a:int, b:float, c:double, d:bool) are joined via the two-dimensional band join, as follows: WHERE r.x BETWEEN s.a-10 AND s.a+10 AND r.y BETWEEN s.b-10 AND s.b+10</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>i -tuple in sub-window X do 3 compare t i -tuple with t; if match then 4 emit the matched result; 5 if i≡0 (mod ordering precision) then</head><label></label><figDesc></figDesc><table>1 Join Core(t, source) begin 

2 

if source = Stream R then 
// right-region 

3 

Expiration Process(t, sub-window S); 

4 

Processing Core(t, sub-window S); 

5 

if R store counter = node id then 

6 

Storage Core(t, sub-window R); 

7 

if R store counter = number of join cores then 

8 

R store counter ←0; 

9 

else 

10 

R store counter ←R store counter+1; 

11 

else 
// left-region Algorithm 3: Matches between t and sub-window X. 

1 Processing Core(t, sub-window X) begin 

2 

forall t 6 

emit punctuation star; 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Algorithm 5 : Punctuation-based N-ary merger. 1 N-ary Merger(t) begin 2 foreach right(or left)-region of core 1..N in sequence do 3 while a resulting tuple (t) is available in output buffer till the first star do 4 pop t from join core's output buffer;</head><label>5</label><figDesc></figDesc><table>5 

push t to Merger's output buffer; 

6 

push out the end of result star; 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>504 2016 USENIX Annual Technical Conference</head><label>504</label><figDesc></figDesc><table>USENIX Association 

0 
0.2 
0.4 
0.6 
0.8 
1 

10 1 

10 2 

10 3 

10 4 

10 5 

Selectivity (Match Probability) 
Input Throughput (tuples/second) 

Window Size: 

28×2 12 

28×2 13 

28×2 14 

28×2 15 

Figure 17: Selectivity effect on SplitJoin 
throughput (28 JCs). 

4 8 12 16 20 24 28 32 

10 1 

10 2 

10 3 

10 4 

10 5 

10 6 

Number of Join Cores 
Average Latency (µs) 

dis 
exe 
gat 
ete 
vis 

(Window Size: 1 million tuples) 

Figure 18: Count-based SplitJoin latency 
reports (uniform distribution:1−10 5 ). 

15 
14 
13 
12 
11 
10 
9 
8 
7 
6 
5 
4 
3 
2 
1 

0 

1 

2 

3 

4 

5 

6 

·10 4 

3 
2 
1 

0 

1 

2 

3 

4 
·10 2 

Punctuation Interval (2 x ) 
Input Throughput (tuples/second) 

W:28×( 
2 12 
2 13 
2 14 
2 15 ) 

</table></figure>

			<note place="foot" n="4"> A storage core is an abstraction for an in-memory sliding window, tightly coupled with a join core.</note>

			<note place="foot" n="5"> Position number refers to the logical location of a join core among other join cores.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgment</head><p>This research was supported by the Alexander von Humboldt Foundation.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Enabling real time data analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srivastava</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Golab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Greer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Seidel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shkapenyuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Spatscheck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yates</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
		<imprint>
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Efficient event processing through reconfigurable hardware for algorithmic trading</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sadoghi</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jacobsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-A</forename><surname>Labrecque</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Singh</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename></persName>
		</author>
		<imprint>
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Gigascope: a stream database for network applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cranor</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Spataschek</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename></persName>
		</author>
		<imprint>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Efficiently evaluating complex Boolean expressions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fontoura</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sadanandan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shanmugasundaram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Vassilvitski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Venkatesan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zien</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
		<imprint>
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">CellSort: high performance sorting on the cell processor</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gedik</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Bordawekar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">R</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">U</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">S</forename></persName>
		</author>
		<imprint>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">A parallel stream join operator for the cell processor</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gedik</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Bordawekar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">R</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">U</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">S</forename><surname>Celljoin</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">High performance content-based matching using GPUs. DEBS&apos;11</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Margara</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cugola</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Efficient pattern matching on GPUs for intrusion detection systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tumeo</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Villa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sciuto</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename></persName>
		</author>
		<imprint>
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">How soccer players would do stream joins</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Teubner</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mueller</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename></persName>
		</author>
		<imprint>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Low-latency handshake join</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roy</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Teubner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gemulla</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename></persName>
		</author>
		<imprint>
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Design and evaluation of main memory hash join algorithms for multi-core CPUs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Blanas</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patel</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename></persName>
		</author>
		<imprint/>
	</monogr>
	<note>SIG-MOD&apos;11</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Main-memory hash joins on multi-core CPUs: Tuning to the underlying hardware</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Teubner</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Alonso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Balkesen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ozsu</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">T</forename></persName>
		</author>
		<imprint>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Morseldriven parallelism: A NUMA-aware query evaluation framework for the many-core age</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leis</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Boncz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kemper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neumann</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename></persName>
		</author>
		<imprint>
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Data processing on FPGAs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mueller</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Teubner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alonso</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename></persName>
		</author>
		<imprint>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hagiescu</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-F</forename><surname>Bacon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rabbah</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename></persName>
		</author>
		<title level="m">Folding streams in FPGAs. DAC&apos;09</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Flexible query processor on FPGAs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Najafi</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sadoghi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacobsen</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-A</forename></persName>
		</author>
		<imprint>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Streams on wires: a query compiler for FPGAs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mueller</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Teubner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alonso</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename></persName>
		</author>
		<imprint>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Complex event detection at wire speed with FPGAs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Woods</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Teubner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alonso</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename></persName>
		</author>
		<imprint>
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Multi-query stream processing on FPGAs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sadoghi</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Javed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Tarafdar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Palaniap-Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacobsen</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-A</forename></persName>
		</author>
		<imprint>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Configurable hardware-based streaming architecture using online programmableblocks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Najafi</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sadoghi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacobsen</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-A</forename></persName>
		</author>
		<imprint>
			<biblScope unit="page">15</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Evaluating window joins over unbounded streams</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Naughton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Viglas</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename></persName>
		</author>
		<imprint>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Scalable distributed stream join processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lin</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Ooi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">U</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename></persName>
		</author>
		<imprint>
			<biblScope unit="page">15</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">TelegraphCQ: Continuous dataflow processing for an uncertain world</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chandrasekaran</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">T</forename><surname>Al</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dewitt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Niagaracq</surname></persName>
		</author>
		<title level="m">A scalable continuous query system for internet databases. SIGMOD&apos;00</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">The design of the Borealis stream processing engine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abadi</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">T</forename><surname>Al</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Navigating big data with high-throughput, energy-efficient data partitioning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">U</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Barker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">A</forename></persName>
		</author>
		<imprint>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">A survey of join processing in data streams</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xie</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
		<editor>Data Streams, C. Aggarwal</editor>
		<imprint>
			<date type="published" when="2007" />
			<publisher>Springer US</publisher>
			<biblScope unit="volume">31</biblScope>
		</imprint>
	</monogr>
	<note>of Advances in Database Systems</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">The Dataflow model: A practical approach to balancing correctness, latency, and cost in massive-scale, unbounded, out-of-order data processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akidau</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Bradshaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chambers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chernyak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Fernndez-Moctezuma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Lax</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mcveety</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mills</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Perry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>And Whittle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename></persName>
		</author>
		<imprint>
			<biblScope unit="page">15</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kulkarni</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bhagat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kedigehalli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kel-Logg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Mittal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Ramasamy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Taneja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Twitter Heron</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>Stream processing at scale. SIGMOD&apos;15</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Apache</forename><surname>Storm</surname></persName>
		</author>
		<ptr target="http://storm.apache.org" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Fast, large-scale string match for a 10Gbps FPGA-based network intrusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sourdis</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pnevmatikatos</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename></persName>
		</author>
		<imprint>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Accelerating database workloads by software-hardware-system co-design</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bordawekar</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">R</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sadoghi</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
		<imprint>
			<biblScope unit="page">16</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">The FQP vision: Flexible query processing on a reconfigurable computing fabric</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Najafi</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sadoghi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacobsen</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-A</forename></persName>
		</author>
		<imprint>
			<biblScope unit="page">15</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Docker: Lightweight linux containers for consistent development and deployment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Merkel</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Linux J&apos;</title>
		<imprint>
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
