<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2020-09-29T04:23+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Using Provenance for Repeatability</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quan</forename><surname>Pham</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science 1, § and Computation Institute 2</orgName>
								<orgName type="institution">¶ University of Chicago §, ¶ and Argonne National Laboratory ¶ Chicago</orgName>
								<address>
									<postCode>60637</postCode>
									<region>IL</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tanu</forename><surname>Malik</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science 1, § and Computation Institute 2</orgName>
								<orgName type="institution">¶ University of Chicago §, ¶ and Argonne National Laboratory ¶ Chicago</orgName>
								<address>
									<postCode>60637</postCode>
									<region>IL</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Foster</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science 1, § and Computation Institute 2</orgName>
								<orgName type="institution">¶ University of Chicago §, ¶ and Argonne National Laboratory ¶ Chicago</orgName>
								<address>
									<postCode>60637</postCode>
									<region>IL</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Using Provenance for Repeatability</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We present Provenance-To-Use (PTU), a tool that minimizes computation time during repeatability testing. Authors can use PTU to build a package that includes their software program and a provenance trace of an initial reference execution. Testers can select a subset of the package&apos;s processes for a partial deterministic replay-based, for example , on their compute, memory and I/O utilization as measured during the reference execution. Using the provenance trace, PTU guarantees that events are processed in the same order using the same data from one execution to the next. We show the efficiency of PTU for conducting repeatability testing of workflow-based scientific programs.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Motivation</head><p>Scientific progress relies on novel claims and verifiable results. However, testing claims and results described in research papers can be challenging. Increasingly conference committee and journal editors are encouraging authors to submit their code, data, and software for repeatability testing. Repeatability testing improves peer review by allowing reviewers to: (1) not only read the ideas in the paper, but validate them by running the accompanying software; (2) run the software for different data and parameters to check robustness; and (3) determine the limitations and assumptions in the ideas by testing with more general inputs, or under different conditions and environments. However, as documented by recent experiments, repeatability testing can be arduous and time consuming for both authors and testers <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref>. Authors have to prepare code, document it, and make explicit rendering of all dependencies on compilers, operating systems and hardware. For testers, assessing code and data for repeatability can be challenging since documentation is rarely complete and perfect. But more so, as experiments become data and computation intensive, the testing time can be significant <ref type="bibr" target="#b2">[3]</ref>.</p><p>Recently tools have emerged that aid authors and testers in making their software and thus experiments repeatable. CDE helps authors package the code, data, and environment for Linux programs so that they can be run and deployed on other machines without installation or configuration <ref type="bibr" target="#b3">[4]</ref>. VisTrails provides provenance support for exploratory computational tasks, maintaining detailed history information about the steps followed in during exploration <ref type="bibr" target="#b4">[5]</ref>. RunMyCode.org provides repeatability and workability of computer codes <ref type="bibr" target="#b5">[6]</ref> associated with a publication through a companion website. Finally, SOLE allows an author to associate their code and data directly with text phrases in the publication, obviating the need for detailed documentation, yet improving readability and understandability for testers <ref type="bibr" target="#b6">[7]</ref>.</p><p>While these tools are a step towards simplifying repeatability testing for authors, they do not reduce computation and data processing time for repeatability tests. Testers may want to repeat only selected portions of an experiment without having to go through the (often time-consuming) process of repeating the experiment in its entirety. For instance, they may want to avoid running a compute-intensive process that decodes and splits an MPEG-video, or avoid performing a dataintensive text scan, or avoid network communication or transfers. Similarly, they may want to reuse cached results. However, such selective execution of program components is difficult or impossible for the tester, unless appropriate history and provenance information has been captured in a previous reference run.</p><p>In this paper, we introduce Provenance-To-Use (PTU), a tool that allows authors to assemble code, data, environment, and provenance of an execution into a single package that can be distributed easily. The resulting package allows testers to view the provenance graph and specify, at a process and file level, nodes of the graph that they want to re-execute, thus saving time and effort for repeatability testing (Section 2). As a demonstration, we show how PTU can be used for repeatability testing of workflow-based programs (Section 3). We conclude in Section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">PTU: Provenance-to-use</head><p>Provenance-To-Use (PTU) <ref type="bibr" target="#b7">[8]</ref> is a tool for accelerating and simplifying repeatability testing. Authors can use PTU to accomplish two tasks: (1) build a package of their source code, data, and environment variables, and (2) record process-and file-level details about a reference execution in a database that is included in the package. The resulting package is easily distributed to testers, who are shielded from software deployment issues. Recording a reference execution path and runtime details within the package eases distribution of this vital information that can guide testers during the testing phase. In particular, testers can explore the provenance graph and accompanying run-time details to specify the part of the provenance graph that they want to re-execute or replay: see <ref type="figure">Figures 1, 2</ref>, and 3. PTU uses CDE <ref type="bibr" target="#b3">[4]</ref> to create and run a package. CDE uses Unix ptrace system call interposition to collect code, data files, and environment variables. The ptrace mechanism also allows for auditing file and process information, which can be transformed for storing a provenance graph, independent of the application ptrace. In PTU, we enhance CDE's use of ptrace to store a provenance graph representing a reference runtime execution at the process and file level. We describe how authors and testers can use PTU.</p><p>Authors use PTU to create a self-contained package with a reference execution by prepending the application command with the ptu-audit tool as in the following example, which involves the Java application TextAnalyzer applied to a file news.txt:</p><formula xml:id="formula_0">% ptu-audit java TextAnalyzer news.txt</formula><p>The ptu-audit tool uses ptrace to monitor ~50 system calls including process system calls, such as execve() and sys_fork(), for collecting process provenance; file system calls, such as read(), write(), and sys_io(), for collecting file provenance; and network calls, such as bind(), connect(), socket(), and send() for auditing network activity. Whenever system calls occur, PTU notes the identifier of the process that made the system call so that it can extract more information about the process from the Linux /proc file system. In particular, we obtain process name, owner, group, parent, host, creation time, command line, and environment variables; and file name, path, host, size, and modification time. A separate thread is used to obtain memory footprint, CPU consumption, and I/O activity data for each process from /proc/$pid/stat every three seconds.</p><p>In the case of distributed applications involving multiple compute nodes, network activity is audited independently at each node using ptrace, i.e., without coordination with other nodes. CDE makes all network system blocking during auditing. Thus, the process record is always present and the information extracted will be current and accurate. PTU stores provenance information about processes and files as a graph in an SQLite database. This information can be displayed in a browser in the form of an Open Provenance Model (OPM) <ref type="bibr" target="#b8">[9]</ref> compliant provenance graph.</p><p>Currently, PTU's provenance collector makes two assumptions. First, only network connection information is audited and no network dumps are made. Thus, while a tester can replay a computation between exactly the same set of hosts they cannot do so without conducting network communication. Second, PTU does not audit non-deterministic functions such as ctime() and random(). Relaxing these assumptions to build a general, distributed audit system is part of our ongoing work.</p><p>When a system call (file or network) returns, and if a new file or network does not exist, PTU emulates CDE functionality. In the case of a file, it copies the accessed file into a package directory that consists of all subdirectories and symbolic links to the original file's location. In the case of network communication, it saves a log of the network connection information, including IP and port information, ordered by time. The package directory also contains the SQLite database that stores the provenance information of the test run.</p><p>When the entire reference run finishes, PTU builds a reference execution file consisting of the topological sort of the provenance graph. The nodes of the graph enumerate run-time details, such as process memory consumption, and file sizes. The tester, as described next, can utilize the database and the graph for efficient re-execution.</p><p>Testers can examine the provenance graph contained in a package to study the accompanying reference execution. This graph can be viewed at the granularity of processes and files, and can aid the tester in visually determining parts of the program that they wish to reexecute. For processes, an accompanying bar graph shows CPU and memory consumption. A tester can then request a re-execution, either by specifying nodes in the provenance graph or by modifying a run configuration file that is included in the package. The configuration file initially specifies the provenance graph, corresponding to the reference execution, ordered topologically. A tester can turn flags on or off for each process and file in the provenance graph, to specify if the process needs to be run or if the file needs to be regenerated, respectively.</p><p>To re-run the package, testers prepend the program command with a ptu-exec tool as follows:</p><p>% ptu-exec java TextAnalyzer news.txt</p><p>The ptu-exec tool uses the provenance graph/run configuration file to determine if any additional process(es) must be run or file(s) re-generated. A re-run of a process or a regeneration of a file is mandatory if:</p><p>(1) A process/file is in the descendent sub-graph of another process that is marked for re-running. (2) A process/file is in the descendent sub-graph of another file that is marked for regeneration.</p><p>Re-running these additional processes and regenerating the files is necessary to maintain consistency of the provenance that will be obtained from the test run. To reexecute, ptu-exec obtains run configuration and environment variables for each process from the SQLite database. To re-execute a process, ptu-exec again monitors it via ptrace and re-executes CDE functionality of replacing path argument(s) to refer to the corresponding path within the package cde-package/cde-root/. By doing so, CDE creates a chroot-like sandbox that tricks the target program into 'believing' that it is executing on the original machine <ref type="bibr" target="#b3">[4]</ref>. The following are two of the several ptu-exec command-line options that allow testers to control testing.</p><p>• -time -t1 &lt;t 1 &gt; -t2 &lt;t 2 &gt; implies the tester can reexecute everything between t 1 and t 2 . If t 1 is null or t 2 is null, execution is performed from beginning to t 2 or t 1 till end, respectively. This option avoids the need to modify the run configuration file.</p><p>• -input &lt;p&gt; &lt;f 1 &gt; &lt;f 2 &gt; allows the user to specify input f 1 instead of f 2 for process with id &lt;p&gt;. This option helps user test correctness of the process.</p><p>PTU provides fast audit and re-execution independent of the application. The profiling of processes enables testers to choose the processes to run.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Use Case and Experiments</head><p>To test PTU we took two papers <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b10">11]</ref> in which authors shared data, tools and software. We constructed meaningful testing scenarios and determined if PTU provides performance improvements. In the first paper, Best et. al.</p><p>[10] describes PEEL 0, a three step workflow process implemented as an R-program. The second step, which executes a classification model, is memoryintensive, with a typical run taking a gigabyte of real memory. To reduce memory consumption, testers may want to input a reduced dataset size and/or test a simpler classification model. (The user can specify the classification model used via a command line option.)</p><p>Our second program, TextAnalyzer, is based on the Java-based Unstructured Information Management Architecture (UIMA) and runs a named-entity recognition analysis program using several data dictionaries <ref type="bibr" target="#b10">[11]</ref>. It splits the input file into multiple input files on which it runs a parallel analysis. The tester may want to rerun the program on one input split, but with higher convergence criteria. CDE allows testing without installing R and UIMA, as would normally be required,. The graphs generated at the process and file level in both programs are large. PEEL 0 generates a provenance graph with five process nodes, 10000 exclusive file reads based on the number of files in the dataset, and 422 exclusive file writes for the aggregated dataset. In TextAnalyzer, a single run generates a provenance graph of eight process nodes that in aggregate conduct 616 exclusive file reads, 124 exclusive file writes, and 50 file nodes that are read and written again.</p><p>In our experiment, we measure execution times by modifying the PTU configuration file to specify that different inputs should be used for selected processes. For PEEL 0 , the change involves a different set of input files, and a simplified classification scheme; in the case of TextAnalyzer it is the set of process identifiers to reexecute with a different parameter value. The provenance graphs and configuration files for the programs are available online <ref type="bibr" target="#b7">[8]</ref>.</p><p>Figures 4 and 5 show the performance improvements observed when we thus use PTU to run PEEL 0 and TextAnalyzer, respectively, with different parameters. Note first the slow down incurred during the reference executions: ~35% for PEEL 0 and ~15% for TextAnalyzer. This slowdown is due to additional system call tracing, with in particular many file system calls traced for PEEL 0 . These modest increases in execution times are easily offset during the re-execution phase. TextAnalyzer has a particularly large improvement (&gt;98%) since the entire process is run on a much smaller file.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Conclusion</head><p>PTU is a step toward testing software programs that are submitted to conference proceedings and journals to conduct repeatability tests. Peer reviewers often must review these programs in a short period of time. By providing one utility for packaging the software programs and its reference execution without modifying the application, we have made it easy and attractive for authors to use it and a fine control, efficient way for testers to use PTU. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 . ptu-audit builds a package of prove- nance events and copies application files Figure 2 . The PTU package. The tester chooses to run the sub-graph rooted at /bin/calculate Figure 3 . ptu-exec re-runs part of the applica- tion from /bin/calculate. It uses CDE to re-route file dependencies.</head><label>123</label><figDesc>Figure 1. ptu-audit builds a package of provenance events and copies application files</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 4 .Figure 5 . Time reduction in testing TextAnalyzer using PTU</head><label>45</label><figDesc>Figure 4. Time reduction in testing PEEL 0 using PTU</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Acknowledgements</head><p>We thank Neil Best and Jonathan Ozik for sharing their paper and code. This work was supported by the Center for Robust Decision making on Climate and Energy Policy under NSF grant number 0951576. Contractors of the US Government under contract number DE-AC02-06CH11357 performed the work.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<title level="m">Repeatability and workability evaluation of SIGMOD 2011. SIGMOD Record</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="45" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Computational reproducibility: state-of-the-art, challenges, and DB research opportunities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Freire</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>SIGMOD</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sasha</surname></persName>
		</author>
		<ptr target="http://www.cs.utah.edu/~eeide/archive10/slides/shasha.pd" />
		<title level="m">Repeatability &amp; Workability for the Software Community: Challenges, Experiences, and the Future</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Guo</surname></persName>
		</author>
		<title level="m">CDE: Using System Call Interposition to Automatically Create Portable Software Packages, USENIX</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">VisTrails: enabling interactive multiple-view visualizations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bavoil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Visualization</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Stodden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hurlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Perignon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Runmycode</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Org</surname></persName>
		</author>
		<ptr target="http://www.runmycode.org/CompanionSite/" />
		<title level="m">eSoN</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">SOLE: linking research papers with science objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Pham</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>IPAW</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">PTU: Using Provenance for Repeatability Testing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Pham</surname></persName>
		</author>
		<ptr target="http://www.ci.uchicago.edu/SOLE/PTU.html" />
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">The Open Provenance Model core specification (v1.1). FGCS</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Moreau</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="743" to="756" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Synthesis of a Complete Land Use/Land Cover Dataset for the Conterminous United States</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Best</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
<note type="report_type">RDCEP Working Paper</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Textual Hydraulics: Mining Online Newspapers to Detect Physical, Social, and Institutional Water Management Infrastructure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Murphy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
		<respStmt>
			<orgName>Argonne National Lab</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<title level="m">Runtime (seconds) 3-­-step work?low with 7 classi?ication 3-­-step work?low run with PTU with 1 classi?ication !!&quot; ()*+</title>
		<imprint/>
	</monogr>
	<note>0&quot; 123456&quot;7,6893:;&lt;&quot; =&gt;;?6@&quot;A9BCD9A&quot;AE?F&quot; G&quot;8HI;;EJ8I493;&quot; =&gt;;?6@&quot;A9BCD9A&quot; B6@HIK6:&quot;E3&quot;L0M&quot;AE?F&quot; &apos;&quot;8HI;;EJ8I493&quot;</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
