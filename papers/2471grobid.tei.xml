<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2020-09-29T02:42+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">This paper is included in the Proceedings of the 18th USENIX Conference on File and Storage Technologies (FAST &apos;20) Open access to the Proceedings of the 18th USENIX Conference on File and Storage Technologies (FAST &apos;20) is sponsored by Carver: Finding Important Parameters for Storage System Tuning Carver: Finding Important Parameters for Storage System Tuning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>February 25-27,</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Cao</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Cao</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Stony Brook University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoff</forename><surname>Kuenning</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Harvey Mudd College</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erez</forename><surname>Zadok</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Stony Brook University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="laboratory">Stony Brook University; Geoff Kuenning, Harvey Mudd College; Erez Zadok, Stony Brook University</orgName>
								<address>
									<postCode>2020 •</postCode>
									<settlement>Santa Clara</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">This paper is included in the Proceedings of the 18th USENIX Conference on File and Storage Technologies (FAST &apos;20) Open access to the Proceedings of the 18th USENIX Conference on File and Storage Technologies (FAST &apos;20) is sponsored by Carver: Finding Important Parameters for Storage System Tuning Carver: Finding Important Parameters for Storage System Tuning</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published">February 25-27,</date>
						</imprint>
					</monogr>
					<note>978-1-939133-12-0</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Storage systems usually have many parameters that affect their behavior. Tuning those parameters can provide significant gains in performance. Alas, both manual and automatic tuning methods struggle due to the large number of parameters and exponential number of possible configurations. Since previous research has shown that some parameters have greater performance impact than others, fo-cusing on a smaller number of more important parameters can speed up auto-tuning systems because they would have a smaller state space to explore. In this paper, we propose Carver, which uses (1) a variance-based metric to quantify storage parameters&apos; importance, (2) Latin Hypercube Sampling to sample huge parameter spaces; and (3) a greedy but efficient parameter-selection algorithm that can identify important parameters. We evaluated Carver on datasets consisting of more than 500,000 experiments on 7 file systems, under 4 representative workloads. Carver successfully identified important parameters for all file systems and showed that importance varies with different workloads. We demonstrated that Carver was able to identify a near-optimal set of important parameters in our datasets. We showed Carver&apos;s efficiency by testing it with a small fraction of our dataset; it was able to identify the same set of important parameters with as little as 0.4% of the whole dataset.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Storage systems are critical components of modern computer systems that have significant impact on application performance and efficiency. Most storage systems have many configurable parameters that control and affect their overall behavior. For example, Linux's Ext4 <ref type="bibr">[22]</ref> offers about 60 parameters, representing over 10 37 potential configuration states. The default settings are often sub-optimal; previous research has shown that tuning storage parameters can improve system performance by a factor of as much as 9× <ref type="bibr" target="#b58">[59]</ref>.</p><p>To cope with the vast number of possible configurations, system administrators usually focus on using their domain expertise to tune a few frequently used and well-studied parameters that are believed to significantly impact system performance. However, this manual-tuning approach does not scale well in the face of increasing complexity. Modern storage systems use different file system types <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b55">56,</ref><ref type="bibr" target="#b64">65]</ref>, new hardware (SSDs <ref type="bibr" target="#b23">[26,</ref><ref type="bibr" target="#b45">46]</ref>, SMR <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref>, NVM <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b72">73]</ref>), multi-tier and hybrid storage, and multiple virtualization layers (e.g., LVM, RAID). Storage systems range from one or a few identical nodes to hundreds of highly heterogeneous configurations <ref type="bibr" target="#b21">[23,</ref><ref type="bibr" target="#b56">57]</ref>. Worse, tuning results depend heavily on hardware and the running workloads <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b69">70]</ref>.</p><p>Recently, several optimization methods have been used to auto-tune storage systems, achieving good performance improvements within reasonable time frames <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b39">40]</ref>. These auto-tuning techniques model the storage system as a black box, iteratively trying different configurations, measuring an objective function's value, and-based on previously learned information-selecting new configurations to try. However, many black-box auto-tuning techniques have difficulty scaling to high dimensions and can take a long time to converge on good solutions <ref type="bibr" target="#b60">[61]</ref>. Therefore, the problem of dealing with the vast number of storage-parameter configurations remains largely unsolved.</p><p>In machine learning and information theory, dimensionality reduction is often applied to explosively sized datasets <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b47">48]</ref>. We believe it can also be applied to storage-parameter selection. Previous research has reported that certain storage parameters have greater impact on performance than others <ref type="bibr" target="#b10">[11]</ref>. By eliminating the less important parameters, and ordering parameters by importance, the parameter search space-and thus the number of configurations that need to be considered by either humans or algorithms-can be reduced significantly <ref type="bibr" target="#b26">[28]</ref>.</p><p>Evaluating a single storage configuration is time consuming, and a thorough analysis requires many configurations to be explored; these evaluations can span days or even months. One purpose of a storage parameter-selection algorithm is to be able to pick important parameters by evaluating only a small number of configurations, yet still select the important parameters with high accuracy.</p><p>In this paper, we propose Carver, which efficiently selects a subset of important storage parameters. Carver consists of three components: 1) a variance-based metric to quantify the importance of a storage parameter; 2) a sampling method to intelligently pick a small number of configurations representing the whole parameter space; and 3) a greedy algorithm to select important parameters. Carver outputs a set of selected important parameters; these can be used as pre-selected parameters for auto-tuning algorithms, as well as helping human experts better understand the behaviors of targeted storage systems. As shown in Section 5, the aforementioned three components give Carver the ability to select a near-optimal subset of important parameters by exploring relatively few configurations. With this efficiency, Carver could complete its parameter selection in a relatively short period of time in a real deployment.</p><p>Carver was thoroughly evaluated on (publicly available) experimental data collected from our previous work <ref type="bibr" target="#b10">[11]</ref>, in which we conducted benchmarks on 7 file systems under 4 workloads over a time span of around four years. In that work, for each file system we picked 8-10 frequently tuned parameters and evaluated all possible storage configurations resulting from changing the values of these selected parameters. We collected I/O throughput and latency data throughout the evaluation. The data set consists of more than 500,000 benchmark runs (data points) in total. One advantage of having collected the datasets from the whole configuration space is that they can be used as the ground truth when testing Carver with only a small subset of configurations.</p><p>With the collected datasets, we first confirmed that certain parameters have more impact on system throughput or latency than other parameters, using Carver's proposed importance metric. We found that in all datasets there is always a small set of parameters that have significantly more impact on throughput than all the others. For example, under a Fileserver workload, the two most important parameters for Ext4 were Journal Option and I/O Scheduler. We also observed that the set of important parameters varies with different workloads. In the same Ext4 example, the two most important parameters became Block Size and Inode Size when the workload changed to Dbserver. We also demonstrated that our variance-based metric can always find a near-optimal set of important parameters in these datasets.</p><p>We then demonstrated Carver's efficiency in identifying important parameters by applying it to different measurements, such as I/O throughput and latency. Carver can easily be extended and applied equally well to other quantifiable objectives such as energy consumption, and even composite cost functions <ref type="bibr" target="#b40">[41]</ref>. In our evaluation, Carver uses Latin Hypercube Sampling (LHS) as the sampling method. LHS allows Carver to identify the set of important parameters using a small number of experimental runs that explore only a fraction of all configurations. For instance, among all 1,000 repeated runs, Carver was able to find the two most important parameters for Ext4 using only 0.4% of the evaluation results. We believe Carver's efficiency in finding the most important parameters quickly and accurately is critical and promising, since (1) it can be applied to new storage systems or environments, and (2) the parameters it identifies can then be used by storage administrators or auto-tuning algorithms to further optimize the system.</p><p>The three key contributions of this paper are:</p><p>1. We provide a thorough quantitative analysis of the effects of storage parameters on system performance, for 7 different file systems across 4 representative workloads.</p><p>2. We propose Carver, which uses a variance-based metric of storage-parameter importance and Latin Hypercube Sampling to drive a greedy algorithm that can identify the most important parameters using only a small number of experimental runs.</p><p>3. We thoroughly evaluated Carver's ability to identify important parameters in terms of I/O throughput and latency. We demonstrated that Carver successfully chose a near-optimal set of important parameters for all datasets used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Motivation</head><p>In this paper, we define a storage system as the entire storage stack from file systems to physical devices, including all intermediate layers. Storage systems have many configurable options that affect their performance <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b65">66]</ref>, energy consumption <ref type="bibr" target="#b58">[59]</ref>, reliability <ref type="bibr" target="#b62">[63]</ref>, etc. We define a parameter as one configurable option, and a configuration as a combination of parameter values. For example, Ext4's Journal Option parameter can take three values: data=writeback, data=ordered, and data=journal. Based on this, [journal="data=writeback", block size=4K, inode size=4K] is one configuration with three specific parameter values (Journal Option, Block Size, and Inode Size). The list of all possible (legal) configurations forms a parameter space.</p><p>Storage systems usually come with many configurable parameters that control and affect their overall behavior. An earlier study <ref type="bibr" target="#b58">[59]</ref> showed that tuning even a tiny set of parameters could improve performance and energy efficiency by as much as 9×. However, tuning storage systems is not an easy task; we believe its challenges arise from at least the following four aspects:</p><p>1. Large parameter spaces. Storage systems are complex, incorporating numerous file system types <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b55">56,</ref><ref type="bibr" target="#b64">65]</ref>, devices <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b23">26,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b72">73]</ref>, and intermediate layers <ref type="bibr" target="#b51">[52,</ref><ref type="bibr" target="#b53">54]</ref>. They often span large networks and distributed environments <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b21">23,</ref><ref type="bibr" target="#b28">30,</ref><ref type="bibr" target="#b56">57]</ref>. Modern storage systems have hundreds or even thousands of tunable parameters-and networks are also parameterized. Worse, evaluating a single configuration can take many minutes or even hours, making experimental tuning unusually time-consuming.</p><p>2. Nontransferable tuning results. Evaluation results depend on the specific environment, including the hardware, software, and workload <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b58">59]</ref>. A good configuration for one setup might perform poorly when the environment changes even slightly <ref type="bibr" target="#b59">[60]</ref>.</p><p>discrete and take only a limited set of values. Worse, some are categorical (e.g., the I/O scheduler name or file system type). Many optimization techniques perform poorly on discrete values, and often cannot address categorical values efficiently or at all <ref type="bibr">[24,</ref><ref type="bibr" target="#b48">49]</ref>.</p><p>Given these challenges, manually tuning storage systems becomes nearly impossible, and automatic tuning can be computationally infeasible. Recent efforts have used blackbox optimization techniques to auto-tune storage configurations <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b39">40]</ref>, addressing several of the above challenges and achieving useful performance improvements. However, we believe that the challenge of tuning storage systems is far from being solved. It has been shown that several of these black-box optimization techniques have scalability problems in high-dimensional spaces <ref type="bibr" target="#b60">[61]</ref>. Therefore, directly applying them to tuning systems with hundreds or thousands of parameters would be difficult.</p><p>In machine learning and information theory, dimensionality reduction is a common technique for coping with largesized datasets <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b47">48]</ref>. If it can be applied in storage systems, it will significantly reduce the search space <ref type="bibr" target="#b26">[28]</ref>, making it easier for humans or algorithms to tune storage systems.</p><p>Previous work has reported that not all storage parameters have an equally important performance impact: a few have much greater effect than others <ref type="bibr" target="#b10">[11]</ref>. We observed similar trends from our collected datasets. <ref type="figure" target="#fig_0">Figure 1</ref> demonstrates the impact of the parameters Block Size and I/O Scheduler on the throughput of an Ext4 file systems under a typical file server workload. Each boxplot in the figure represents a median and range of throughput that any Ext4 configuration can produce after fixing the value of one parameter (shown on the X axis). We see that setting the I/O Scheduler to different values (blue bars) makes little difference, resulting in nearly equal medians and ranges of throughput. However, setting the value of Block Size has a greater impact on both the median and the throughput range; specifically, to reach the maximum throughput, Block Size must be set to 4K. Although choosing a large Block Size is a decision that may be obvious to an expert, we have made similar observations in other storage systems and with different workloads. This naturally led us to investigate how we can quantify the impact or importance of each storage parameter, and how we can select important parameters efficiently.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Dimensionality Reduction in a Nutshell</head><p>In this section we briefly discuss some commonly applied approaches to dimensionality reduction, and argue that some metrics are not suitable for quantifying storage parameters' importance. Note that different disciplines might use somewhat different terminology than storage systems. For example, parameters are analogous to features in machine learning, independent variables in regression analysis, and dimensions in mathematics; optimization objectives can be called dependent variables or target variables. When discussing different techniques (Section 3), we use the field-appropriate terms.</p><p>Many approaches have been proposed to address the curse of dimensionality, which refers to the fact that data become sparse in high-dimensional spaces and thus make algorithms designed for low-dimensional spaces less effective. Dimensionality-reduction approaches can be generally summarized into two categories: feature extraction and feature selection <ref type="bibr" target="#b22">[25,</ref><ref type="bibr" target="#b38">39]</ref>.</p><p>Feature extraction refers to projecting high-dimensional data into low-dimensional spaces; the newly constructed features are usually linear or nonlinear combinations of the originals. Common feature-extraction methods include Principal Component Analysis (PCA) <ref type="bibr" target="#b61">[62]</ref>, Independent Component Analysis <ref type="bibr" target="#b27">[29]</ref>, and Linear Discriminant Analysis <ref type="bibr" target="#b46">[47]</ref>. One major drawback of feature extraction is that the physical meaning of each feature is lost by the projection and the nonlinear combination of many dimensions into fewer ones <ref type="bibr" target="#b38">[39]</ref>. Common feature-extraction techniques thus conflict with our goal in this paper, which is to select a few original storage parameters that can be understood and interpreted.</p><p>Conversely, feature selection directly selects a subset of features from the original ones, with the intention of finding only those that are important. Feature-selection methods can be classified as supervised or unsupervised <ref type="bibr" target="#b38">[39]</ref>. Unsupervised feature selection, such as Principle Feature Analysis <ref type="bibr" target="#b42">[43]</ref>, chooses a subset that contains most of the essential information based on relationships among features. It does not consider the impact of features on optimization objectives during the selection phase. In contrast, supervised feature selection chooses a subset that can discriminate between or approximate the target variables. Examples include Lasso <ref type="bibr" target="#b67">[68]</ref> and decision-tree based algorithms <ref type="bibr" target="#b30">[31]</ref>. Since we are interested in finding parameters that have significant impact on our optimization objectives, such as I/O throughput, supervised feature selection best fits our needs.</p><p>Several intrinsic properties of our project also limit our choice of feature-selection methods. Many storage parameters are discrete or categorical (see Sections 2 and 5.1). The performance of storage systems is usually presented as I/O throughput or latency, which are continuous. Therefore, an ideal feature-selection method should work with categorical features and continuous targets. Although there are discretization techniques that can break continuous target variables into discrete sections, feature-selection results depend heavily on the quality of discretization <ref type="bibr" target="#b38">[39]</ref>. One common approach for dealing with categorical features is to transform each of them into dummy binary parameters that take values of 0 or 1. For instance, io scheduler with three possible values (noop, deadline, and cfq) can be converted into three binary features: "io scheduler = noop", "io scheduler = deadline", and "io scheduler = cfq". All the binary features can take on values 0 or 1. This approach is unsatisfactory because it selects the individual binary features instead of the original categorical ones. Moreover, converting a categorical parameter with N values into N separate binary parameters would expand the parameter space exponentially. For this reason, we feel that Lasso <ref type="bibr" target="#b67">[68]</ref> is not suitable for our problem, even though it has been successfully applied to selecting important knobs in databases <ref type="bibr" target="#b69">[70]</ref>. Although Group Lasso has been proposed to partially address this deficiency <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b73">74]</ref>, the computational cost of the Lasso-based methods is still high <ref type="bibr" target="#b38">[39]</ref>.</p><p>Another popular category of feature-selection methods has been built upon information theory <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b38">39]</ref>. These approaches usually define a metric for the homogeneity of the target variable within certain subsets. Commonly used metrics include Gini impurity <ref type="bibr" target="#b38">[39]</ref> and Entropy <ref type="bibr" target="#b4">[5]</ref> for discrete target variables, and Variance <ref type="bibr" target="#b6">[7]</ref> for continuous variables. In this paper we propose Carver, which applies a variancebased metric for parameter importance, as described in Section 4.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Design of Carver</head><p>In this section we detail the design of Carver. Carver consists of three components: 1) a variance-based metric for measuring storage parameters' importance (Section 4.1), 2) a sampling method to select a small number of configurations from huge parameter spaces-in this paper using Latin Hypercube Sampling (Section 4.2), and 3) a greedy algorithm for finding important parameters (Section 4.3). A good sampling method allows Carver to select a near-optimal subset of important parameters while having to evaluate relatively few configurations. In this section we use throughput as an example of the target (objective) variable, but Carver is also applicable to many other metrics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Measuring Parameter Importance</head><p>Carver uses a variance-based metric to quantify storageparameter importance. The variance of a set S of storage configurations is defined as usual:</p><formula xml:id="formula_0">Var(S) = 1 |S| |S| i=1 (y i − µ) 2 ,<label>(1)</label></formula><p>where y i is the throughput of the i-th configuration; |S| is number of configurations in S; and µ is the average throughput within S. Inspired by CART (Classification and Regression Trees) <ref type="bibr" target="#b6">[7]</ref>, we use the reduction in variance to measure parameter importance. We extend CART's original definition to support categorical parameters taking an arbitrary but finite number of values, as compared with only two in CART.</p><p>We define the parameter importance PI of a parameter P that can take a finite number of categorical values, {p 1 , ..., p n }, n &gt; 1, as:</p><formula xml:id="formula_1">PI (P ) = Var(S) − n i=1 |S P =pi | |S| Var(S P =pi ) (2)</formula><p>Here S is the original set of configurations, and S P =pi is the subset of configurations with the parameter P taking the value p i . Intuitively, an important parameter P divides a set S of configurations into multiple subsets, and the weighted sum of variances within each subset should be much smaller than the variance of S. Thus, a high PI indicates a parameter that has a significant effect on performance. The variance-based metric defined in Carver uses a greedy approach, where the next important parameter will be picked by calculating its importance when fixing the values of previously selected parameters. Therefore, for parameter Q with a total of m possible categorical values {q 1 , ..., q m }, m &gt; 1, we define the conditional parameter importance for Q, given P = p as:</p><formula xml:id="formula_2">CPI (Q|P = p) = Var(S P =p ) − m j=1 |S Q=qj ,P =p | |S P =p | Var(S Q=qj |P =p ) (3)</formula><p>where S Q=qj ,P =p denotes the set of configurations with parameters P and Q taking values p and q j , respectively. Similar to Equation 2, given P = p, the next most important parameter Q divides S P =p into multiple subsets, and if Q is important then the weighted sum of variances within each subset will be much smaller than variance of S P =p . To remove the restriction to a given value p, we define CPI (Q|P ) as the maximum of CPI (Q|P = p i ) over all possible values p i ∈ {p 1 , ..., p n } that parameter P can take:</p><formula xml:id="formula_3">CPI (Q|P ) = n max i=1 CPI (Q|p = p i )<label>(4)</label></formula><p>Note that in this paper we use only variance-based metrics to measure parameter importance and select the most critical subset. We leave storage-performance prediction, which requires a large amount of training data <ref type="bibr" target="#b70">[71]</ref>, for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Sampling</head><p>Given the large parameter space and the time needed to evaluate a single storage configuration, we must limit the number of experimental runs required to select important parameters. Therefore, Carver needs an exploratory method that can cover the space uniformly and comprehensively, yet sparsely. In this work, we chose Latin Hypercube Sampling (LHS) <ref type="bibr" target="#b44">[45]</ref>.</p><p>LHS is a stratified sampling method <ref type="bibr" target="#b12">[13]</ref>. In two dimensions, a square grid containing samples is a Latin Square iff there is only one sample in each row and each column. A Latin Hypercube is the generalization of a Latin Square to higher dimensions, where each sample is the only one in each axis-aligned hyperplane containing it <ref type="bibr" target="#b35">[36]</ref>. LHS has been shown to be more effective in exploring parameter spaces than random sampling <ref type="bibr" target="#b44">[45]</ref> and Monte Carlo sampling <ref type="bibr" target="#b14">[15]</ref>. It has been successfully applied in sampling configurations of storage <ref type="bibr" target="#b24">[27]</ref> and cloud systems <ref type="bibr" target="#b41">[42]</ref>.</p><p>Previous work has also applied Plackett-Burman (P&amp;B) Design <ref type="bibr" target="#b52">[53]</ref> to evaluate the impact of parameters in storage benchmarks <ref type="bibr" target="#b50">[51]</ref> and databases <ref type="bibr" target="#b17">[18]</ref>. However, P&amp;B design requires each parameter to have only two possible values, and the target variable must be a monotonic function of the input parameters. Neither requirement holds in our problem.</p><p>We demonstrated that LHS enables Carver to pick important storage parameters with only a small number of evaluations; see Section 5.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Parameter-Selection Algorithm</head><p>Based on our proposed measurements of parameter importance and on Latin Hypercube Sampling (LHS), the pseudocode for Carver's parameter-selection algorithm is as follows: Algorithm 1 Parameter Selection Input: P : set of parameters, S: initial set of configurations; stop(S, selected): user-defined stopping function.</p><formula xml:id="formula_4">selected ← {} S * ← LHS(S) repeat p * ← argmax CPI (p|selected ), p ∈ P selected .insert(p * ) P.remove(p * ) until stop(S, selected ) is true or P is empty Output: selected</formula><p>In this algorithm, Carver takes a set of initial parameters and configurations. It first uses LHS to pick a small number of configurations and evaluates them. Carver then greedily selects the current most important parameters based on the evaluation results for the selected configurations. The mostimportant parameter is selected based on the highest parameter importance value. Carver fixes the value of the most important parameter and calculates the conditional parameter importance (CPI) values for the remaining parameters; the parameter with the highest CPI is selected as the secondmost important. Carver continues evaluating important parameters by fixing the values of previously selected parameters, until the stop function returns true. A na¨ıvena¨ıve stop function could be sizeof (selected) ≥ N , which would select the N most important parameters. An alternative variancebased stopping function might stop when the variances of subsets of configurations (given the current selected parameters) are below a certain threshold ϑ. This stopping condition indicates that by setting the values of the selected parameters, the system throughput already falls into a small enough range that there is little potential gain from additional tuning. In our experiments, we applied this idea and used the Relative Standard Deviation (RSD) <ref type="bibr" target="#b12">[13]</ref>, or Coefficient of Variation, to define our stopping condition. The RSD of a set S of configurations is defined as:</p><formula xml:id="formula_5">RSD(S) = 1 µ Var(S) N − 1 (5)</formula><p>where N is the number of configurations and µ is the mean throughput of configurations within S. We chose RSD because it is normalized to the mean throughput and is represented as a percentage; that way the same threshold can be used across different datasets. We used a threshold of 2% in our experiments; as seen in Section 5, parameters selected by this criterion gave us near-optimal and stable throughput.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Evaluation</head><p>In this section we detail our evaluation of Carver. We first cover the experimental settings we used for collecting datasets in Section 5.1. Section 5.2 provides an overview of storage-parameter importance using our variance-based metric. Section 5.3 demonstrates that the subset of important parameters selected by Carver's importance metric is near-optimal. We show the efficiency of Carver's parameterselection algorithm in Section 5.4, from multiple perspectives.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experiment Settings</head><p>To thoroughly study the problem of storage parameter selection and evaluate Carver, we used datasets originally collected for our previous work <ref type="bibr" target="#b10">[11]</ref>. The whole dataset consists of more than half a million benchmark results on typical storage systems. We describe the experimental settings and collected datasets in this section.</p><p>Hardware. We performed experiments using several Dell PE R710 servers, each with two Intel Xeon quad-core 2.4GHz CPUs, 24GB RAM, and four storage devices: two SAS HDDs, one SATA HDD, and one SSD. Ubuntu 14.04 was installed on all machines with Linux kernel 3.13. We denote this configuration as S1. We also collected several datasets on a slightly different configuration, S2, where we used the GRUB boot loader to limit the available memory to 4GB. We explain the reasons for this change below. We also upgraded the system to Ubuntu 16.04 with kernel 4.15. Experiments on S2 were only conducted on the SSD, given the increasing use of SSDs in production systems.</p><p>Workload. We benchmarked storage configurations with four common macro-workloads generated by Filebench [3, 67]:</p><p>1. Mailserver mimics the I/O workload of a multithreaded email server;</p><p>2. Fileserver emulates a server hosting users' home directories;</p><p>3. Webserver emulates a typical static Web server with a high percentage of reads; and 4. Dbserver mimics the behavior of an Online Transaction Processing (OLTP) database.</p><p>Before each experimental run, we formatted and mounted the storage devices with the selected configuration. In setting S1 we chose Filebench's default workload profiles, limiting the working-set size so we could evaluate more configurations within a practical time period. We call those profiles Mailserver-default, Fileserver-default, etc. Our previous study's goal, which applies to this work as well, was to allow us to explore a large set of parameters and values quickly. By evaluating each configuration once, saving the results, and later looking them up in our database, we could test Carver in seconds instead of waiting for several hours to run the benchmarks selected by Algorithm 1. Clearly, a realworld deployment would not have such a database available and a search for the most important parameters would require running actual benchmark tests, each of which would take significant time. However, as shown in Section 5.4, Carver tests few enough configurations that even these experiments can be completed in a short time, ranging from a few hours to a few days. An additional benefit of the full database is that we were able to compare configurations found by Carver with the true best configuration found by our complete datasets.</p><p>Because we wanted our database to record results of as many experiments as possible, we decided to trade off a smaller working set size in favor of increasing the number of configurations we could explore in a practical time period. Our experiments demonstrated a wide range of performance numbers and are suitable for the purpose of studying storage-parameter importance. As shown in <ref type="table" target="#tab_3">Table 2</ref>, storage parameters do have a wide range of importance under these workloads. We first ran each workload for up to 2 hours to observe its behavior, and then chose a running time long enough for the cumulative throughput to stabilize; we found 100 seconds sufficient for this purpose. In setting S2, we increased the working-set size to 10GB and the running time to 300 seconds, but used relatively fewer total configurations, which we denote Mailserver-10GB, Fileserver-10GB, etc. The RAM size was set to 4GB in S2 so that the benchmark working set could not fit into memory completely, thus forcing more I/Os.</p><p>Parameter space. To evaluate our parameter-selection algorithm, we ideally want our parameter spaces to be large and complex. Considering that evaluating storage systems takes a long time, we decided to experiment with a reasonably sized set of frequently studied and tuned storage parameters. We selected them in close collaboration with several storage experts who have either contributed to storagestack designs or have spent years tuning storage systems in the field. We chose seven Linux file systems that span a wide range of designs and features: <ref type="bibr" target="#b34">[35]</ref>, and Reiserfs <ref type="bibr" target="#b54">[55]</ref>. We experimented with various types of parameters, including file-system formatting and mounting options and some Linux kernel parameters. <ref type="table">Table 1</ref> lists all our file systems, their (abbreviated) parameters, and the number of possible values that each parameter can take. Note that under S1 we conducted benchmarks on four storage devices, and we treat the device as one of the parameters. Under S2 we focused on Ext4 and XFS experiments with an SSD, but evaluated a wider variety of parameters. Cells with "-" mean that the parameters are inapplicable for the given file system. Cells with "dflt" mean we used the default value for that parameter, and so that parameter was not considered during the parameterselection phase. Note that the total number of configurations for each file system does not necessarily equal the product of the number of parameter values, because some parameter combinations are invalid (e.g., in Ext4 the inode size cannot exceed the block size). The total number of configurations across all datasets is 29,544. We ran all configurations in each parameter space under four workloads. We repeated each experiment at least three times to get a stable and representative measurement of performance. Over a time span of more than two years, we collected data from more than 500,000 experimental runs.</p><formula xml:id="formula_6">Ext2 [12], Ext3 [69], Ext4 [21], XFS [65], Btrfs [56], Nilfs2</formula><p>Although we have been collecting benchmarking data over a time span of 4 years, we focused on one dataset at a time, where we benchmarked one file system on the same hardware under the same workload. Each dataset's collection took 1-2 months. Therefore, there may be minor hardware wear-out effects. We repeated each experiment for at least 3 runs, and made sure the variation among the results of these repeated runs were acceptable <ref type="bibr" target="#b9">[10]</ref>. We used the average throughput and latency numbers among repeated runs when evaluating Carver.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Parameter Importance: an Overview</head><p>We have collected experimental data from 9 different parameter spaces <ref type="table">(Table 1)</ref>   <ref type="table" target="#tab_3">3  7  6  - - - - - - - - - - 2  3  dflt dflt  4 2,208  S1 Ext3  3  7  6  3  - - - - - - - - - 2  3  dflt dflt  4 6,624  S1 Ext4  3  7  6  3  dflt dflt  - - - - - - - 2  3</ref>   <ref type="table">Table 1</ref>: Details of parameter spaces. Each cell gives the number of settings we tested for the given parameter and file system; empty cells represent parameters that are inapplicable to the given file system and "dflt" represents those that were left at their default setting. We evaluated 29,544 configurations in total under four workloads, and each experiment was repeated 3+ times.</p><p>culate and evaluate the importance of different storage parameters, which serves as the ground truth when evaluating Carver's parameter-selection algorithm, whose goal is to explore only a small fraction of the parameter space yet find the same subset of important parameters as if we had explored it all. In this section, we first provide an overview of the importance of storage parameters.  <ref type="figure" target="#fig_1">Figure 2</ref> shows the three most important parameters for Ext4 under S1, Fileserver-default. The parameter with the highest importance was evaluated and selected by its Parameter Importance (PI), as defined in Section 4.1. The second most important parameter was chosen by its Conditional Parameter Importance (CPI) given the most important one, in this case CPI (X|journal ). Similarly, the 3 rd most important parameter was evaluated by comparing its CPI (X|journal , device). Note that the Y-axis scales in the three sub-figures are different (but higher is always better). The X axis shows the Ext4 parameters that we experimented with. As shown in the top subfigure in <ref type="figure" target="#fig_1">Figure 2</ref>, Journal Option turns out to be the most important parameter for Ext4 under S1, Fileserver-default. It has the highest variance reduction, 2.7×10 7 . In comparison, the PI of Device is around 10 6 , while all other parameters are under 5 × 10 4 . Similarly, the second and third most important parameters are Device and Block Size, respectively, both with a much higher CPI value than other parameters.</p><p>We discovered that parameter importance depends heavily on file system types and on the running workload. <ref type="table" target="#tab_3">Table 2</ref> lists the top 4 important parameters for Ext4, XFS, and Btrfs under various workload types; the column header #N identifies the N th most important parameter. We also applied the stopping criterion described in Section 4.3. Cells marked as "-" here indicate that no parameter gave a large reduction in variance, and thus no parameter was considered important. To avoid cluttering the paper, we only list 3 file systems under 4 workloads here, and we show only the top 4 ranked parameters under each case.</p><p>As we can see in <ref type="table" target="#tab_3">Table 2</ref>, the important parameters are quite diverse and depend significantly on the file system types and workloads. For Ext4 under S2 and Dbserver-10GB, the top 4 ranked parameters are Block Size, Inode Size, I/O Scheduler, and Journal Option. When the workload changes to Webserver-10GB, the top 4 parameters become Inode Size, Flex BG, Block Size, and Journal Option. For Fileserver-10GB under Ext4, we found only three important parameters, indicating that fixing the values of these three parameters already resulted in quite stable throughputs; we discuss this observation in more detail in Section 5.3. We found similar results on XFS: the values and number of important parameters depended heavily on the workloads. Interestingly, for Btrfs under S1, Webserver-default, we did not find any important parameters. That is because the Webserver-default workload consists primarily of read operations, and the default working-set size used by Filebench is small. All Btrfs configurations actually produce quite similar throughput under Webserver-default. For this reason, we also collected datasets from workloads with a much larger working-set size (10GB), denoted as S2. Webserver-default Btrfs ---- </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>USENIX</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Evaluating The Greedy Algorithm</head><p>In Section 5.2 we used Carver's variance-based metric to pick a set of important parameters for our datasets. However, we must also establish that the selection results are good, i.e., whether there exists another set of parameters, with equal or smaller size, that can lead to an even narrower range of throughput. We demonstrate the effectiveness of Carver's variance-based metric in this section. Figure 3: Impact of parameters on performance and stability (Ext4, S1, Fileserver-default). Each dot represents a set of configurations created by fixing N parameters, where different dot sizes and colors are used for different values of N. Performance is measured by the average throughput (X axis) of all possible configurations within each set; stability is measured by the relative standard deviation (Y axis; lower is better) of the throughput within each set. <ref type="figure">Figure 3</ref> shows the results for Ext4 under S1, Fileserverdefault, where each point represents a set of configurations that fixes the values of N parameters. For N = 1, we have 28 points, which equals the sum of possible value counts for each parameter, as shown in <ref type="table">Table 1</ref>. There are 374 points for N = 2. We use different point colors and sizes for different numbers of parameters. We only plot up to N = 2 here; we extend to N = 4 in set of 2,208 configurations; fixing journal option = ordered, device=ssd reduces that number to 552. In <ref type="figure">Figure 3</ref>, performance is measured by the average throughput within each set of configurations, as presented on the X axis. The Y axis shows the stability of each set, measured by the Relative Standard Deviation (RSD) of throughput within the set. We chose to use the RSD rather than variance because the figure shows sets of varying numbers of configurations; RSD is normalized by the configuration count and the average throughput, and thus is easier to compare. If a set of parameters is important, it should ideally lead to a larger average throughput and lower RSD; therefore the best points should cluster in the bottom-right quadrant of <ref type="figure">Figure 3</ref>. As we can see from that figure, fixing just one parameter value (purple dots) causes the mean throughput to range from 2.5Kops/s to around 15Kops/s, and the RSD ranges from around 7% to 76%. The upper-left purple point (2,500, 76%) represents the configurations achieved by setting Journal Option to journal. The other two points, representing Journal Options of ordered and writeback, turn out to be the best among all purple points. Both are seen near the bottom right with mean throughput of around 15K and (b) Btrfs, Fileserver-default</p><p>Figure 5: Carver's ability to correctly find the top 3 important parameters within small portions of the dataset. The X1 (bottom) axis (log2 scale) shows the percentage of the dataset that was used; for each percentage we ran Carver 1,000 times on different, random LHS-compatible subsets of that size. The X2 (top) axis (log2) shows the running time that would be needed to benchmark the selected configurations. We used the PI calculated from the whole dataset as ground truth. The Y axis shows the percentage of runs that were able to correctly find the important parameters. The solid, dashed, and dotted lines show the results for finding the parameters ranked 1 st , 2 nd , and 3 rd , respectively. Note that although Btrfs required a larger percentage of the dataset, the absolute numbers are similar in both figures, and the running times for Btrfs are shorter (see text).</p><p>an RSD value of 7%. Clearly, the Journal Option parameter has the highest impact on performance; setting it to an improper value could lead to low throughput and high RSD, while setting it correctly provides significant benefits. The points with N = 2 form several clusters. All points with mean throughput less than 9K result from setting Journal Option to journal (and with another parameter set to various valid values). Conversely, all points with mean throughput larger than 14K result from a Journal Option of ordered or writeback. Journal Option is actually the most important parameter selected by Carver (as seen in <ref type="table" target="#tab_3">Table 2</ref>).</p><p>To probe this question further, we zoomed into the bottomright part of <ref type="figure">Figure 3</ref> and added points for N = 3 and N = 4, as shown in <ref type="figure">Figure 4</ref>. The X and Y axes are similar but with narrower ranges (and the X axis starts at 14K). The label "Max" on the X axis, with a small tick mark, shows the global maximum throughput of all Ext4 configurations within the parameter space. For each N , we plotted only the point(s) with the highest average throughput or lowest RSD. The labels around each point show the associated parameter values, ordered by (Journal Option, Device, Block Group, and Inode Size). The black triangle marks the point with highest mean throughput, gotten by fixing the values of the three most important parameters selected by Carver. For N = 1, the best two points resulted from setting Journal Option to either ordered or writeback. These two points overlap with each other in this figure, as they share nearly identical mean throughput and RSD values. Only one point is plotted for N = 2, since the point (journal option=ordered, device=ssd) shows both the highest throughput and the lowest RSD among all N = 2 points; the same is true for N = 3. For N = 4, the left red point shows the lowest RSD value while the right red point shows the highest average throughput. In <ref type="figure">Figure 4</ref>, the top three parameters selected by Carver are Journal Option, Device, and Block Size. By setting the values of these three parameters, the best average throughput (denoted as a triangle in <ref type="figure">Figure 4</ref>) is quite close to the global best average throughput achieved by fixing 3 parameter values (blue point). By comparing the two sets of parameters, we can see that Carver successfully identified the top 2 important parameters; the final average throughput and relative standard deviation achieved by the selected top 3 parameters are quite close to the global optimum. We believe the difference in the 3 rd selection is due to two reasons:</p><p>1. In Carver, the definition of parameter importance focuses on measuring the impact of the parameter on performance, which can be either positive or negative. When discussing "optimality" in <ref type="figure">Figure 4</ref>, we only considered positive impacts.</p><p>2. Carver stops after selecting 3 parameters, as the RSD has already dropped below our 2% threshold at that point. If we removed the stopping criterion, the 4 th parameter that Carver would select would be Block Group, which aligns with the globally optimal set of top 4 parameters, denoted as red dots in <ref type="figure">Figure 4</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Carver: Evaluation</head><p>All evaluations and analysis in Section 5.2 and 5.3 were conducted on the complete dataset of all possible parameter configurations. However, collecting such datasets for storage parameters is usually impractical, given the challenges discussed in Section 2. One design goal of Carver is to select important parameters while evaluating only a small fraction of configurations. Carver does so by utilizing Latin Hypercube Sampling (LHS), which has been effective in exploring system parameter spaces <ref type="bibr" target="#b24">[27,</ref><ref type="bibr" target="#b41">42]</ref>. We demonstrate the effectiveness of Carver's parameter-selection algorithm from the following two perspectives: selecting important parameters for I/O throughput (see Section 5.4.1) and latency (see Section 5.4.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.1">Selecting Important Parameters for Throughput</head><p>A critical question is whether Carver can reliably find the important parameters of a system, and how many experimental runs are necessary to do so. To answer this question, we used our entire dataset of experimental runs on Ext4, Fileserverdefault and Btrfs, Fileserver-default to represent the "ground truth" of which parameters matter. For Ext4, Fileserverdefault, the top 3 important parameters are Journal Option, Device, and Block Size. For Btrfs, Fileserver-default, they are Special Option, Node Size, and Device. We then tested Carver by repeatedly choosing a random subset of the full dataset, simulating a real-world environment in which an experimenter would use LHS to choose configurations to test, and then using the results of those tests to identify important parameters. In all cases we constrained the random subset to be compatible with Latin Hypercube Sampling (LHS), as our hypothetical investigator would do, and tested whether Carver correctly located the first, second, and third most important parameters. We varied the size of the subsets as a percentage of the entire dataset and ran 1,000 iterations of each trial (with different random subsets). <ref type="figure">Figure 5</ref> presents the results of running these experiments. The X1 (bottom) axis shows the percentage of the whole dataset that was used by Carver, and is in log 2 scale. The X2 (top) axis shows the actual running time for benchmarking the selected configurations, and is also in log 2 scale. The Y axis shows the fraction of runs that successfully found the same important parameters as the ground truth. The solid, dashed, and dotted lines show the results of finding the 1 st , 2 nd , and 3 rd most important parameters, respectively. <ref type="figure">Figure 5</ref>(a) shows that even with only 0.1% of the dataset (7 configurations), Carver has a 60% probability of correctly identifying the most important parameter. When using 0.4% (26), Carver was able to find the 1 st and 2 nd ranked parameter in 100% and 99.8% of the 1,000 runs, respectively. Setting the values of the most important two parameters would already produce high average throughput (97% of the global optimum) with high stability (2% of RSD), as shown in <ref type="figure">Fig- ure 4</ref>. The chance of correctly selecting the third most important parameter increases with the percentage of the dataset used by Carver. With 1% (67) of the dataset, the probability of correctly finding the 3 rd parameter is around 50%, while sampling 5% (331) successfully identifies the 3 rd parameter in all 1,000 runs.</p><p>For Btrfs, shown in <ref type="figure">Figure 5</ref>(b), Carver needed a larger fraction of the dataset to make correct selections. This is because Btrfs has only 288 configurations, compared with 6,624 for Ext4. Yet by evaluating only 16% (45) of all configurations, Carver found the 1 st and 2 nd parameters with greater than 80% probability. Carver identified the 3 rd parameter in more than 80% of runs with 31% (90) sampled. Figure 6: Carver's ability to correctly find the top 3 important parameters for the latency metric within small portions of the dataset. Experimental settings, graph axes, and legends are the same as in <ref type="figure">Figure 5</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.2">Selecting Important Parameters for Latency</head><p>To further evaluate Carver's effectiveness in selecting important parameters, we collected datasets with latency metrics. The experimental settings were the same as described in Section 5.1. We ran the Fileserver workload on the Ext4 configuration with S2 settings (see <ref type="table">Table 1</ref>). Instead of using the average I/O throughput reported by Filebench, we now used the average latency. Due to a limitation in Filebench's current implementation, it is difficult to collect and calculate accurate tail latency numbers, such as the 99 th percentile, so we leave parameter selection for tail latency as future work. <ref type="figure">Figure 6</ref> shows the evaluation results of selecting important parameters using the latency metric. The X axis, Y axis, and legends remain the same as in <ref type="figure">Figure 5</ref>. As shown by the red line, with barely 0.2% of all configurations evaluated, Carver was still able to identify the most important parameters in more than 800 out of 1,000 runs. With 1.5% (58 configurations) evaluated, Carver was able to correctly pick the top 2 parameters in almost all the 1,000 runs. Selecting the third most important parameter required a few more evaluation; using 2.5% of the dataset (97 configurations), Carver successfully identified it in 998 runs.</p><p>In sum, Carver is effective in selecting parameters using only a few evaluations. In our experiments, Carver found the top 2 important parameters with higher than 80% probability by evaluating fewer than 50 configurations. Fixing the values of the most important two parameters can already result in high and stable system throughput, as shown in Section 5.3. Carver can find the 3 rd parameter with about 50% probability using only about 50 evaluations. Furthermore, the total running time for these evaluations is tractable: the worst case, in <ref type="figure">Figure 6</ref>, is under 4 days. Moreover, auto-tuning a storage system with an optimization algorithms often requires an initialization phase to explore the whole space <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b41">42]</ref>. Carver can use the data collected during the initialization phase to select parameters; in this case, no extra evaluation needs to be conducted. Integrating Carver with auto-tuning algorithms is part of our future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related Work</head><p>Parameter selection for computer systems. There have been several attempts to select important parameters for various types of software systems. <ref type="bibr">Aken et al. [70]</ref> applied Lasso to choose important knobs for databases. They converted categorical parameters into binary dummy features and included polynomial features to deal with parameter interactions. As discussed in Section 3, Lasso does not scale well when the system has many categorical parameters. Plackett-Burman (P&amp;B) design of experiments <ref type="bibr" target="#b52">[53]</ref> has been applied to evaluating the impact of parameters in storage benchmarks <ref type="bibr" target="#b50">[51]</ref> and databases <ref type="bibr" target="#b17">[18]</ref>. However, P&amp;B assumes that each parameter has only two possible values and that the target variable is a monotonic function of the input parameters; neither assumption holds for storage parameter spaces. Adaptive Sampling <ref type="bibr" target="#b18">[19]</ref> and Probabilistic Reasoning <ref type="bibr" target="#b63">[64]</ref> have been applied to evaluating the impact of database knobs. They either only work for continuous parameters, or have scalability issues in high-dimensional spaces. In comparison, Carver applies variance-based metrics for storage-parameter importance. To the best of our knowledge, we have conducted the first thorough quantitative study of storage-parameter importance by evaluating Carver on datasets collected from a variety of file systems and workloads. Carver also provides insights into the interactions between parameters.</p><p>Auto-tuning storage systems. Several researchers have built systems to automate storage-system tuning. <ref type="bibr">Strunk et al. [63]</ref> applied Genetic Algorithms (GAs) to automate storage-system provisioning. <ref type="bibr">Babak et al. [4]</ref> used GAs to optimize the I/O performance of HDF5 applications. GAs have also been applied to storage-recovery problems <ref type="bibr" target="#b31">[32]</ref>. Deep Q-Networks have been successfully applied in optimizing performance for Lustre <ref type="bibr" target="#b39">[40]</ref>. More recently, Madireddy et al. applied a Gaussian process-based machine learning algorithm to model Lustre's I/O performance and its variability <ref type="bibr" target="#b43">[44]</ref>. Our own previous work <ref type="bibr" target="#b10">[11]</ref> provided a comparative study of applying multiple optimization algorithms to auto-tune storage systems. However, many auto-tuning algorithms have scalability issues in highdimensional spaces <ref type="bibr" target="#b60">[61]</ref>, which is one of the motivations for Carver. Selecting the important subset of parameters could reduce the search space dramatically, which would then benefit either auto-tuning algorithms or manual tuning by experts.</p><p>General feature selection. Many feature-selection techniques have been proposed in various disciplines. <ref type="bibr">Li et al. [39]</ref> provide a thorough summary and comparison for most state-of-the-art feature-selection algorithms. Based on our arguments in Section 3, we chose to use variance-based metrics for storage-parameter selection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions</head><p>Modern storage systems come with many parameters that affect their behavior. Tuning parameter settings can bring significant performance gains, but both manual tuning by experts and automated tuning have difficulty dealing with large numbers of parameters and configurations. In this paper, we propose Carver, which addresses this problem with the following three contributions:</p><p>1. Carver uses a variance-based metric for quantifying storage parameter importance, and proposes a greedy yet efficient parameter-selection algorithm.</p><p>2. To the best of our knowledge, we provide the first thorough study of storage-parameter importance. We evaluated Carver across multiple datasets (chosen from more than 500,000 experimental runs) and showed that there is always a small subset of parameters that have the most impact on performance-but that the set of important parameters changes with different workloads, and that there are interactions between parameters.</p><p>3. We demonstrated Carver's efficiency by testing it on small fractions of the configuration space. This efficiency gives Carver the potential to be easily applied to new systems and environments and to identify important parameters in a short time, with a small number of configuration evaluations.</p><p>In the future, we plan to extend Carver to support other parameter-selection techniques, such as Group Lasso <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b73">74]</ref> and ANOVA <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b71">72]</ref>. We will evaluate and improve Carver with more optimization objectives (e.g., reliability), and even larger storage-parameter spaces. Currently Carver can only measure storage importance for one objective at a time (e.g., throughput, latency). We plan to investigate how to extend Carver's parameter selection algorithm into the problem of multi-objective optimization <ref type="bibr" target="#b16">[17]</ref>. We also plan to integrate Carver with auto-tuning algorithms <ref type="bibr" target="#b10">[11]</ref>.</p><p>Royal Statistical Society: Series B (Statistical Methodology), 68(1): <ref type="bibr">49-67, 2006.</ref> </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Range of throughput after fixing the value of one parameter. Red bars represent setting the block size to 1K, 2K, or 4K, respectively, while blue bars represent setting the I/O scheduler to noop, cfq, or deadline.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Top 3 most important Ext4 parameters under S1, Fileserver-default. The most important parameter is measured by its PI; the second and third parameters are evaluated by their CPI given higher-ranked parameters. The Y-axis scales in the three subfigures are different.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .Figure 4 :</head><label>44</label><figDesc>Figure 3 shows the results for Ext4 under S1, Fileserverdefault, where each point represents a set of configurations that fixes the values of N parameters. For N = 1, we have 28 points, which equals the sum of possible value counts for each parameter, as shown in Table 1. There are 374 points for N = 2. We use different point colors and sizes for different numbers of parameters. We only plot up to N = 2 here; we extend to N = 4 in Figure 4. Larger points are used for smaller N values, since fixing fewer parameter values would result in a larger number of usable configurations. For example, fixing journal option = ordered in our datasets leads to a</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head></head><label></label><figDesc>under 4 representative workload types. Having the complete datasets allowed us to accurately cal-</figDesc><table>Set-
ting 

File 
System 

Blk 
Size 

Inode 
Size 

Block 
Grp 

Jour-
nal 

Flex 
Grp 

Read-
ahead 

XFS 
Sctr 
Size 

Allc 
Grp 
Cnt 

Log 
Buf 
Cnt 

Log 
Buf 
Size 

Allc 
Size 

Node 
Size 

Spec 
Opt 

Atime 
Opt 

I/O 
Schd 

Drty 
Bg 
Ratio 

Drty 
Ratio 
Dev Total 

S1 Ext2 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 2 : Top-ranked important parameters for various file systems. The column header #N identifies the N th most important parameter.</head><label>2</label><figDesc></figDesc><table></table></figure>

			<note place="foot" n="50"> 18th USENIX Conference on File and Storage Technologies USENIX Association</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank the anonymous FAST reviewers and our shepherd, Bill Bolosky, for their valuable comments. This work was made possible in part thanks to <ref type="bibr">Dell-EMC, NetApp, and IBM support;</ref><ref type="bibr">and NSF awards CCF-1918225, CNS- 1900706, CNS-1729939, and CNS-1730726.</ref> </p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Skylight-a window on shingled disk operation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abutalib</forename><surname>Aghayev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mansour</forename><surname>Shafaei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Desnoyers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trans. Storage</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">28</biblScope>
			<date type="published" when="2015-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Evolving ext4 for shingled disks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abutalib</forename><surname>Aghayev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theodore</forename><surname>Ts&amp;apos;o</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Garth</forename><surname>Gibson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Desnoyers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th USENIX Conference on File and Storage Technologies (FAST)</title>
		<meeting>the 15th USENIX Conference on File and Storage Technologies (FAST)</meeting>
		<imprint>
			<biblScope unit="page" from="105" to="120" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Filebench github repository</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Amvrosiadis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vasily</forename><surname>Tarasov</surname></persName>
		</author>
		<ptr target="https://github.com/filebench/filebench/wiki" />
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Taming parallel I/O complexity with auto-tuning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Babak</forename><surname>Behzad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huong</forename><surname>Vu Thanh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Luu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Surendra</forename><surname>Huchette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Byna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruth</forename><surname>Prabhat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quincey</forename><surname>Aydt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Koziol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Snir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on High Performance Computing, Networking, Storage and Analysis, SC &apos;13</title>
		<meeting>the International Conference on High Performance Computing, Networking, Storage and Analysis, SC &apos;13<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013" />
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="page" from="1" to="68" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">M</forename><surname>Bishop</surname></persName>
		</author>
		<title level="m">Pattern Recognition and Machine Learning</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruba</forename><surname>Borthakur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">HDFS architecture guide. Hadoop Apache Project</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Classification and regression trees</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leo</forename><surname>Breiman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jerome</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><forename type="middle">J</forename><surname>Stone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">A</forename><surname>Olshen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1984" />
			<publisher>CRC press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Conditional likelihood maximisation: A unifying framework for information theoretic feature selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gavin</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Pocock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Jie</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikel</forename><surname>Luján</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="27" to="66" />
			<date type="published" when="2012-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Robust tests for the equality of variances</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Morton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">B</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Forsythe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="issue">346</biblScope>
			<biblScope unit="page" from="364" to="367" />
			<date type="published" when="1974" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">On the performance variation in modern storage stacks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vasily</forename><surname>Tarasov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hari</forename><surname>Raman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dean</forename><surname>Hildebrand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erez</forename><surname>Zadok</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th USENIX Conference on File and Storage Technologies (FAST)</title>
		<meeting>the 15th USENIX Conference on File and Storage Technologies (FAST)<address><addrLine>Santa Clara, CA</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2017-03" />
			<biblScope unit="page" from="329" to="343" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Towards better understanding of black-box auto-tuning: A comparative analysis for storage systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vasily</forename><surname>Tarasov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sachin</forename><surname>Tiwari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erez</forename><surname>Zadok</surname></persName>
		</author>
		<ptr target="http://download.filesystems.org/auto-tune/ATC-2018-auto-tune-data.sql.gz" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual USENIX Technical Conference</title>
		<meeting>the Annual USENIX Technical Conference<address><addrLine>Boston, MA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Design and implementation of the second extended filesystem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Card</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ts&amp;apos;o</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tweedie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings to the First Dutch International Symposium on Linux</title>
		<meeting>to the First Dutch International Symposium on Linux<address><addrLine>Amsterdam, Netherlands</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Statistical Inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Casella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roger</forename><forename type="middle">L</forename><surname>Berger</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="volume">2</biblScope>
			<pubPlace>Duxbury Pacific Grove, CA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Some theoretical results on the grouped variables Lasso</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christophe</forename><surname>Chesneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Hebiri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematical Methods of Statistics</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="317" to="326" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Reliability based optimization with metaheuristic algorithms and Latin hypercube sampling based surrogate models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liu</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduardo</forename><surname>Souza De Cursi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abdelkhalak</forename><forename type="middle">El</forename><surname>Hami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Eid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied and Computational Mathematics</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="462" to="468" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Falling off the cliff: When systems go nonlinear</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yvonne</forename><surname>Coady</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Russ</forename><surname>Cox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Detreville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Druschel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Hellerstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Hume</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kimberly</forename><surname>Keeton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thu</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Small</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lex</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Warfield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th Conference on Hot Topics in Operating Systems (HOTOS &apos;05)</title>
		<meeting>the 10th Conference on Hot Topics in Operating Systems (HOTOS &apos;05)</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Multi-objective optimization using evolutionary algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kalyanmoy</forename><surname>Deb</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
			<publisher>John Wiley &amp; Sons</publisher>
			<biblScope unit="volume">16</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">SARD: A statistical approach for ranking database tuning parameters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Biplob</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">J</forename><surname>Debnath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><forename type="middle">F</forename><surname>Lilja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mokbel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 24th International Conference on Data Engineering Workshop (IDEW)</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="11" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Tuning database configuration parameters with iTuned</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vamsidhar</forename><surname>Songyun Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shivnath</forename><surname>Thummala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Babu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. VLDB Endow</title>
		<meeting>VLDB Endow</meeting>
		<imprint>
			<date type="published" when="2009-08" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1246" to="1257" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Normalized mutual information feature selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pablo</forename><forename type="middle">A</forename><surname>Estévez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Tesmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claudio</forename><forename type="middle">A</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacek</forename><forename type="middle">M</forename><surname>Zurada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="189" to="201" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ext4</surname></persName>
		</author>
		<ptr target="http://ext4.wiki.kernel.org/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">The Google file system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Gobioff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">T</forename><surname>Leung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th ACM Symposium on Operating Systems Principles (SOSP &apos;03)</title>
		<meeting>the 19th ACM Symposium on Operating Systems Principles (SOSP &apos;03)<address><addrLine>Bolton Landing, NY</addrLine></address></meeting>
		<imprint>
			<publisher>ACM SIGOPS</publisher>
			<date type="published" when="2003-10" />
			<biblScope unit="page" from="29" to="43" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">An introduction to variable and feature selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isabelle</forename><surname>Guyon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">André</forename><surname>Elisseeff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1157" to="1182" />
			<date type="published" when="2003-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">The tail at store: A revelation from millions of hours of disk and SSD deployments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingzhe</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gokul</forename><surname>Soundararajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deepak</forename><surname>Kenchammana-Hosekote</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">A</forename><surname>Chien</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haryadi</forename><forename type="middle">S</forename><surname>Gunawi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">14th USENIX Conference on File and Storage Technologies (FAST 16)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="263" to="276" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Reducing file system tail latencies with Chopper</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duy</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><forename type="middle">C</forename><surname>Arpaci-Dusseau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Remzi</forename><forename type="middle">H</forename><surname>Arpaci-Dusseau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th</title>
		<meeting>the 13th</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
				<title level="m">USENIX Conference on File and Storage Technologies, FAST&apos;15</title>
		<meeting><address><addrLine>Berkeley, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="119" to="133" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Adaptation in natural and artificial systems: An introductory analysis with applications to biology, control, and artificial intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Holland</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1975" />
			<publisher>Michigan Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Independent component analysis: Algorithms and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aapo</forename><surname>Hyvärinen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erkki</forename><surname>Oja</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">4-5</biblScope>
			<biblScope unit="page" from="411" to="430" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Decentralized user authentication in a global file system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kaminsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Savvides</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mazieres</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">F</forename><surname>Kaashoek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th</title>
		<meeting>the 19th</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
				<title level="m">ACM Symposium on Operating Systems Principles (SOSP &apos;03)</title>
		<meeting><address><addrLine>Bolton Landing, NY</addrLine></address></meeting>
		<imprint>
			<publisher>ACM SIGOPS</publisher>
			<date type="published" when="2003-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Variable importance using decision trees</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jalil</forename><surname>Kazemitabar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arash</forename><surname>Amini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Bloniarz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ameet</forename><surname>Talwalkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">;</forename><forename type="middle">I</forename><surname>Guyon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><forename type="middle">V</forename><surname>Luxburg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wallach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vishwanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Garnett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 30</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="426" to="435" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">On the road to recovery: Restoring data after disasters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kimberly</forename><surname>Keeton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ernesto</forename><surname>Brau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arif</forename><surname>Merchant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cipriano</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st ACM SIGOPS/EuroSys European Conference on Computer Systems</title>
		<meeting>the 1st ACM SIGOPS/EuroSys European Conference on Computer Systems<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="235" to="248" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Evaluating phase change memory for enterprise storage systems: A study of caching and tiering approaches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Seshadri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Dickey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Chiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th USENIX Conference on File and Storage Technologies</title>
		<meeting>the 12th USENIX Conference on File and Storage Technologies<address><addrLine>Berkeley, CA</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="33" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Tree-guided group Lasso for multi-task regression with structured sparsity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seyoung</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="543" to="550" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">The Linux implementation of a log-structured file system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryusuke</forename><surname>Konishi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshiji</forename><surname>Amagai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koji</forename><surname>Sato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hisashi</forename><surname>Hifumi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seiji</forename><surname>Kihara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Satoshi</forename><surname>Moriai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGOPS Operating Systems Review</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="102" to="107" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sampling</forename><surname>Latin Hypercube</surname></persName>
		</author>
		<ptr target="https://en.wikipedia.org/wiki/Latinhypercubesampling" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">F2FS: A new file system for flash storage</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changman</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongho</forename><surname>Sim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jooyoung</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sangyeun</forename><surname>Cho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th USENIX Conference on File and Storage Technologies (FAST)</title>
		<meeting>the 13th USENIX Conference on File and Storage Technologies (FAST)<address><addrLine>Santa Clara, CA</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2015-02" />
			<biblScope unit="page" from="273" to="286" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Robust tests for equality of variances. Contributions to Probability and Statistics. Essays in Honor of Harold Hotelling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Howard</forename><surname>Levene</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1961" />
			<biblScope unit="page" from="279" to="292" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Feature selection: A data perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jundong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kewei</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suhang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fred</forename><surname>Morstatter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiliang</forename><surname>Trevino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huan</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys (CSUR)</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">94</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Capes: Unsupervised system performance tuning using neural network-based deep reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenneth</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oceane</forename><surname>Bel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ethan</forename><forename type="middle">L</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Darrell</forename><forename type="middle">D E</forename><surname>Long</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis, SC &apos;17</title>
		<meeting>the International Conference for High Performance Computing, Networking, Storage and Analysis, SC &apos;17</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">On the importance of evaluating storage systems&apos; $costs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mukker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Zadok</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th USENIX Conference on Hot Topics in Storage and File Systems, HotStorage&apos;14</title>
		<meeting>the 6th USENIX Conference on Hot Topics in Storage and File Systems, HotStorage&apos;14</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Metis: robustly optimizing tail latencies of cloud systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chieh-Jan Mike</forename><surname>Zhao Lucis Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenjia</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lianjie</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenjun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jin</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangzhong</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 USENIX Conference on Usenix Annual Technical Conference</title>
		<meeting>the 2018 USENIX Conference on Usenix Annual Technical Conference</meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="981" to="992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Feature selection using principal feature analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yijuan</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ira</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><forename type="middle">Sean</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th ACM international conference on Multimedia</title>
		<meeting>the 15th ACM international conference on Multimedia</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="301" to="304" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Machine learning based parallel i/o predictive modeling: A case study on lustre file systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandeep</forename><surname>Madireddy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prasanna</forename><surname>Balaprakash</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Carns</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Latham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Ross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shane</forename><surname>Snyder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><forename type="middle">M</forename><surname>Wild</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on High Performance Computing</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="184" to="204" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">A comparison of three methods for selecting values of input variables in the analysis of output from a computer code</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Mckay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Beckman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">J</forename><surname>Conover</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Technometrics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="239" to="245" />
			<date type="published" when="1979" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">A large-scale study of flash memory failures in the field</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Meza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjev</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Onur</forename><surname>Mutlu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 ACM International Conference on Measurement and Modeling of Computer Systems (SIGMETRICS 2015)</title>
		<meeting>the 2015 ACM International Conference on Measurement and Modeling of Computer Systems (SIGMETRICS 2015)<address><addrLine>Portland, OR</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015-06" />
			<biblScope unit="page" from="177" to="190" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Bernhard Scholkopf, and Klaus-Robert Mullers. Fisher discriminant analysis with kernels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Mika</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gunnar</forename><surname>Ratsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Signal Processing Society Workshop on Neural Networks for Signal Processing</title>
		<meeting>the IEEE Signal Processing Society Workshop on Neural Networks for Signal Processing</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1999" />
			<biblScope unit="page" from="41" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><forename type="middle">P</forename><surname>Murphy</surname></persName>
		</author>
		<title level="m">Machine Learning: A Probabilistic Perspective</title>
		<imprint>
			<publisher>MIT press</publisher>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">A simplex method for function minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">A</forename><surname>Nelder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roger</forename><surname>Mead</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Computer Journal</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="308" to="313" />
			<date type="published" when="1965" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Applied Linear Statistical Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Neter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">H</forename><surname>Kutner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">J</forename><surname>Nachtsheim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Wasserman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="volume">4</biblScope>
			<pubPlace>Irwin Chicago</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">A statistical evaluation of the impact of parameter selection on storage system benchmarks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nohhyun</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijun</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyubaik</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">J</forename><surname>Lilja</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th IEEE International Workshop on Storage Network Architecture and Parallel I/Os (SNAPI)</title>
		<meeting>the 7th IEEE International Workshop on Storage Network Architecture and Parallel I/Os (SNAPI)</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">A case for redundant arrays of inexpensive disks (RAID)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Patterson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gibson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Katz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGMOD</title>
		<meeting>the ACM SIGMOD<address><addrLine>Chicago, IL</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1988-06" />
			<biblScope unit="page" from="109" to="116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">The design of optimum multifactorial experiments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robin</forename><forename type="middle">L</forename><surname>Plackett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Peter Burman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="page" from="305" to="325" />
			<date type="published" when="1946" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Page</forename><surname>Lvm2 Resource</surname></persName>
		</author>
		<ptr target="http://sources.redhat.com/lvm2/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Reiser</surname></persName>
		</author>
		<ptr target="http://web.archive.org/web/20031015041320/http://namesys.com/" />
		<title level="m">ReiserFS v.3 whitepaper</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">BTRFS: The Linux B-tree filesystem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ohad</forename><surname>Rodeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Bacik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Mason</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trans. Storage</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">32</biblScope>
			<date type="published" when="2013-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">GPFS: A shared-disk file system for large computing clusters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Schmuck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Haskin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First USENIX Conference on File and Storage Technologies (FAST &apos;02)</title>
		<meeting>the First USENIX Conference on File and Storage Technologies (FAST &apos;02)<address><addrLine>Monterey, CA</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2002-01" />
			<biblScope unit="page" from="231" to="244" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">Linear Regression Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">F</forename><surname>George</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">J</forename><surname>Seber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lee</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>John Wiley &amp; Sons</publisher>
			<biblScope unit="volume">329</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Evaluating performance and energy in file system server workloads</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Priya</forename><surname>Sehgal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vasily</forename><surname>Tarasov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erez</forename><surname>Zadok</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the USENIX Conference on File and Storage Technologies (FAST)</title>
		<meeting>the USENIX Conference on File and Storage Technologies (FAST)<address><addrLine>San Jose, CA</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2010-02" />
			<biblScope unit="page" from="253" to="266" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Optimizing energy and performance for server-class file system workloads</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Priya</forename><surname>Sehgal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vasily</forename><surname>Tarasov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erez</forename><surname>Zadok</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Storage (TOS)</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2010-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">Taking the human out of the loop: A review of Bayesian optimization. Proceedings of the IEEE</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bobak</forename><surname>Shahriari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziyu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ryan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nando De</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Freitas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="page" from="148" to="175" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">A tutorial on principal component analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1404.1100</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Using utility to provision storage systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">D</forename><surname>Strunk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eno</forename><surname>Thereska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christos</forename><surname>Faloutsos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><forename type="middle">R</forename><surname>Ganger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th USENIX Conference on File and Storage Technologies, FAST&apos;08</title>
		<meeting>the 6th USENIX Conference on File and Storage Technologies, FAST&apos;08<address><addrLine>Berkeley, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="313" to="328" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m" type="main">Using probabilistic reasoning to automate software tuning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">G</forename><surname>Sullivan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Margo</forename><forename type="middle">I</forename><surname>Seltzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avi</forename><surname>Pfeffer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<publisher>ACM</publisher>
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Scalability in the XFS file system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sweeney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Doucette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nishimoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Peck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual USENIX Technical Conference</title>
		<meeting>the Annual USENIX Technical Conference<address><addrLine>San Diego, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1996-01" />
			<biblScope unit="page" from="1" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Benchmarking file system benchmarking: It *IS* rocket science</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vasily</forename><surname>Tarasov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saumitra</forename><surname>Bhanage</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erez</forename><surname>Zadok</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Margo</forename><surname>Seltzer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of HotOS XIII:The 13th USENIX Workshop on Hot Topics in Operating Systems</title>
		<meeting>HotOS XIII:The 13th USENIX Workshop on Hot Topics in Operating Systems<address><addrLine>Napa, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">Filebench: A flexible framework for file system benchmarking. ;login: The USENIX Magazine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vasily</forename><surname>Tarasov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erez</forename><surname>Zadok</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Spencer</forename><surname>Shepler</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016-03" />
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="6" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Regression shrinkage and selection via the lasso</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Tibshirani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society. Series B (Methodological)</title>
		<imprint>
			<biblScope unit="page" from="267" to="288" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Ext3, journaling filesystem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Tweedie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Ottawa Linux Symposium</title>
		<imprint>
			<date type="published" when="2000-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Automatic database management system tuning through large-scale machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dana</forename><surname>Van Aken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Pavlo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">J</forename><surname>Gordon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bohan</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 ACM International Conference on Management of Data, SIGMOD &apos;17</title>
		<meeting>the 2017 ACM International Conference on Management of Data, SIGMOD &apos;17</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1009" to="1024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Storage device performance prediction with CART models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengzhi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kinman</forename><surname>Au</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anastassia</forename><surname>Ailamaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>Brockwell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christos</forename><surname>Faloutsos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><forename type="middle">R</forename><surname>Ganger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Computer Society&apos;s 12th Annual International Symposium on Modeling, Analysis, and Simulation of Computer and Telecommunications Systems. (MASCOTS)</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="588" to="595" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">On the comparison of several mean values: An alternative approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Welch</forename><surname>Bernard Lewis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">3/4</biblScope>
			<biblScope unit="page" from="330" to="336" />
			<date type="published" when="1951" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Phase change memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-S. Philip</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simone</forename><surname>Raoux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sangbum</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiale</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">P</forename><surname>Reifenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bipin</forename><surname>Rajendran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><surname>Asheghi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenneth</forename><forename type="middle">E</forename><surname>Goodson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2201" to="2227" />
			<date type="published" when="2010-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Model selection and estimation in regression with grouped variables</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
