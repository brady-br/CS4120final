<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2020-09-29T04:12+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Open access to the Proceedings of the 29th USENIX Security Symposium is sponsored by USENIX. Justinian&apos;s GAAvernor: Robust Distributed Learning with Gradient Aggregation Agent Justinian&apos;s GAAvernor: Robust Distributed Learning with Gradient Aggregation Agent</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>August 12-14, 2020</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xudong</forename><surname>Pan</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mi</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duocai</forename><surname>Wu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qifan</forename><surname>Xiao</surname></persName>
							<email>qfxiao16@fudan.edu.cn</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xudong</forename><surname>Pan</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mi</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duocai</forename><surname>Wu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qifan</forename><surname>Xiao</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shouling</forename><surname>Ji</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">Zhejiang University</orgName>
								<address>
									<country>‡ Ant Financial</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Yang</surname></persName>
							<email>m_yang@fudan.edu.cn</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Fudan University</orgName>
								<address>
									<addrLine>Shouling Ji</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Zhejiang University/Ant Financial</orgName>
								<address>
									<addrLine>Min Yang</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution" key="instit1">Fudan University</orgName>
								<orgName type="institution" key="instit2">Fudan University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Open access to the Proceedings of the 29th USENIX Security Symposium is sponsored by USENIX. Justinian&apos;s GAAvernor: Robust Distributed Learning with Gradient Aggregation Agent Justinian&apos;s GAAvernor: Robust Distributed Learning with Gradient Aggregation Agent</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 29th USENIX Security Symposium</title>
						<meeting>the 29th USENIX Security Symposium						</meeting>
						<imprint>
							<date type="published">August 12-14, 2020</date>
						</imprint>
					</monogr>
					<note>This paper is included in the 978-1-939133-17-5</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>The hidden vulnerability of distributed learning systems against Byzantine attacks has been investigated by recent researches and, fortunately, some known defenses showed the ability to mitigate Byzantine attacks when a minority of workers are under adversarial control. Yet, our community still has very little knowledge on how to handle the situations when the proportion of malicious workers is 50% or more. Based on our preliminary study of this open challenge, we find there is more that can be done to restore Byzantine robust-ness in these more threatening situations, if we better utilize the auxiliary information inside the learning process. In this paper, we propose Justinian&apos;s GAAvernor (GAA), a Gradient Aggregation Agent which learns to be robust against Byzantine attacks via reinforcement learning techniques. Basically , GAA relies on utilizing the historical interactions with the workers as experience and a quasi-validation set, a small dataset that consists of less than 10 data samples from similar data domains, to generate reward signals for policy learning. As a complement to existing defenses, our proposed approach does not bound the expected number of malicious workers and is proved to be robust in more challenging scenarios. Through extensive evaluations on four benchmark systems and against various adversarial settings, our proposed defense shows desirable robustness as if the systems were under no attacks, even in some case when 90% Byzantine workers are controlled by the adversary. Meanwhile, our approach shows a similar level of time efficiency compared with the state-of-the-art defenses. Moreover, GAA provides highly interpretable traces of worker behavior as by-products for further mitigation usages like Byzantine worker detection and behavior pattern analysis. Justinian I, an emperor of Byzantium, reorganized the imperial government to revive the empire&apos;s greatness in a dark time. Gradient Aggregation Agent, a new GAAvernor (pronounced as governor) of distributed learning system, bases its learning policy on historical and auxiliary information to fight against Byzantine attacks.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Over the past few decades, deep learning has achieved abundant breakthroughs driven by big data <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b51">52]</ref>. To deal with the fast scaling-up of data volume, many efficient distributed learning algorithms have been proposed in the past decade <ref type="bibr" target="#b1">[3,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b28">29]</ref>, yet their hidden vulnerability to Byzantine attacks <ref type="bibr" target="#b36">[37]</ref> have also been observed by a series of recent works <ref type="bibr" target="#b9">[11,</ref><ref type="bibr" target="#b14">16,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b61">62]</ref>.</p><p>In a typical distributed learning system <ref type="bibr" target="#b1">[3,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b63">64]</ref>, a group of workers participate in building a global learning model under the coordination of one parameter server. In each round, the server first distributes current parameters of the global learning model to each worker, requiring them to compute the corresponding gradient based on their local data. Once receiving all the submissions from the workers, the server then applies certain Gradient Aggregation Rule (GAR) to yield the next weight update. As an optimal choice in theory <ref type="bibr" target="#b10">[12,</ref><ref type="bibr" target="#b46">47]</ref>, most existing distributed learning algorithms implemented their GAR simply by averaging over the whole set of submitted gradients <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b55">56,</ref><ref type="bibr" target="#b62">63]</ref>.</p><p>However, the behaviors of real-world workers are far from ideal. As is suggested in <ref type="bibr" target="#b61">[62]</ref>, a worker may probably submit abnormal gradients due to various causes such as biased batch sampling, computation error, network instability or even malicious attacks. In <ref type="bibr" target="#b9">[11]</ref>, a worker with the aforementioned abnormal behavior is usually referred to as a Byzantine worker. As first observed by Blanchard et al., the classical GAR (i.e., GAR by averaging) is so fragile that even a single Byzantine worker can have a catastrophic effect on the whole learning process, from degraded prediction accuracy <ref type="bibr" target="#b30">[31]</ref> to total stagnation <ref type="bibr" target="#b9">[11]</ref>. These facts highly emphasize the urgency and significance of effective defense against this type of adversarial behavior, namely Byzantine attack.</p><p>To fight against Byzantine attacks, most previous studies implement alternative GARs to the classical one <ref type="bibr" target="#b2">[4,</ref><ref type="bibr" target="#b9">11,</ref><ref type="bibr" target="#b14">16,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b61">62]</ref>. These methods view gradients abstractly as highdimensional vectors to apply robust statistical methods such as clustering <ref type="bibr" target="#b9">[11]</ref>, median <ref type="bibr" target="#b30">[31]</ref> or geometric median <ref type="bibr" target="#b2">[4,</ref><ref type="bibr" target="#b14">16,</ref><ref type="bibr" target="#b61">62]</ref>.</p><p>Although it allows previous methods to be highly decoupled with the underlying learning systems, the simplicity is accompanied with several weaknesses: First, as previous GARs computes the weight update direction as the only product, they are unable to provide interpretable information of the workers' behaviors for further mitigation; Second, due to the theoretical bottleneck of robust statistics <ref type="bibr" target="#b47">[48]</ref>, most known defenses expect that only a minority of workers are compromised. As a result, they are inadequate and cannot be directly extended to cover more challenging scenarios where the adversary has gained control over a majority of workers and iteratively manipulates an uncertain ratio of workers to play the Byzantine roles. Our Work. In this paper, we propose the design of Justinian's GAAvernor (GAA), a Gradient Aggregation Agent which serves as a novel server-side defense that leverages Reinforcement Learning (RL) techniques to learn to be Byzantinerobust from interactions with the workers and from the auxiliary information on the server. Our defense aims at restoring the robustness of distributed learning in more challenging scenarios characterized by the existence of the malicious majority.</p><p>By viewing the historical interactions with the workers as its experience and the relative decrease of loss on a quasivalidation set as its reward, GAA searches over a simplex as its policy space for the optimal policy. Intuitively, each coordinate of a policy of GAA can be interpreted as its current credit on the corresponding worker. By proposing the weight update at each iteration as a linear combination of the received gradients weighted with its credits, GAA receives the reward signal after the global learning model is updated with the current weight update and it then optimizes its current policy by RL techniques <ref type="bibr" target="#b53">[54]</ref>. It is worth to notice, we introduce the notion of a quasi-validation set to denote a collection of data samples that follows a similar but not necessarily identical distribution as the true sample distribution. In practice, when a golden-labeled validation set (i.e., a set of samples from the true sample distribution) is available during the learning process, GAA can utilize it as its quasi-validation set. Otherwise, GAA randomly collects a small number of data samples (empirically, less than 10 samples) from similar data domains to form its quasi-validation set.</p><p>With extensive experiments, we evaluate GAA's robustness on four diverse case studies (i.e., MNIST <ref type="bibr" target="#b38">[39]</ref>, CIFAR-10 <ref type="bibr" target="#b34">[35]</ref>, Yelp reviews <ref type="bibr">[1]</ref> and CMS public healthcare records <ref type="bibr" target="#b0">[2]</ref>), against various attacking settings. We find our proposed approach shows near-optimal Byzantine robustness in most cases, whenever the ratio of Byzantine workers (i.e., Byzantine ratio) is below or over 50% or fluctuates unboundedly. Meanwhile, GAA shows comparable time efficiency to known defenses. We also evaluate GAA's robustness against several adaptive attacks on this novel defense mechanism. Moreover, we present the application of GAA to Byzantine worker detection, which shows high accuracy, and to behavior pattern analysis of Byzantine attacks, which demonstrates high interpretability of its traces.</p><p>Contributions. In summary, we mainly make the following contributions.</p><p>• We propose the design of GAA, a novel RL-based defense against Byzantine attacks which requires no upper bound on the Byzantine ratio ( §4).</p><p>• We implement and evaluate our proposed defense on four diverse case studies, against various adversarial settings.</p><p>Empirical results suggest in most cases, GAA with an easily accessible quasi-validation set helps the distributed learning systems achieve almost indistinguishable performance as if the systems were under no attacks ( §5 &amp; §6).</p><p>• We also provide a number of analytic results on GAA's robustness in different settings as theoretical evidences ( §4.4).</p><p>• Additionally, we demonstrate the interpretability of GAA's traces with visualizations and with applications to Byzantine worker detection and behavior analysis ( §4.5), which we hope will facilitate future mitigation studies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background and Preliminaries</head><p>Gradient-based Distributed Learning and GAR. In this paper, we focus on the data-parallel distributed learning system with one parameter server (abbrev. the server) and n workers. This system model is widely used as one of the commonest implementations of distributed learning algorithms <ref type="bibr" target="#b1">[3,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b63">64]</ref>. We denote the loss function to be minimized as f (θ, D), where θ ∈ R d collects all the free parameters of the underlying model (e.g., a deep neural network) and D denotes the sample distribution. Usually, the true loss function f (θ, D) is the expectation over the sample distri-</p><formula xml:id="formula_0">bution, i.e. f (θ, D) := E z∼D [ f (θ, z)]</formula><p>where D is unknown to the server. In practice, the optimization happens on the empirical version of the loss f (θ,</p><formula xml:id="formula_1">D) := 1 |D| ∑ z∈D f (θ, z),</formula><p>where D is a collection of training samples. For simplicity, we denote the true loss function as f and the empirical loss function calcuated on dataset D asˆfasˆ asˆf D .</p><p>The distributed learning process starts with an initial guess θ 0 on parameters. At iteration t, the server first sends the current parameter θ t to each worker. Ideally, a worker i then computes the estimated gradient V t i of loss f at parameter θ t based on its local data and submits V t i back to the server.</p><p>Once the server receives the candidate set of gradients Q t :=</p><formula xml:id="formula_2">{V t 1 , . . . ,V t n }, it executes certain GAR F : (R d ) n → R d to</formula><p>aggregate the received gradients into a single weight update direction. Such a procedure is executed in iterations until a provided termination condition is reached. Formally, the update rule at iteration t follows θ t+1 = θ t − λF (V t 1 , . . . ,V t n ), where λ is the learning rate.</p><p>In the literature of distributed learning, the following GARs are the common choices for implementation of F <ref type="bibr" target="#b1">[3,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b60">61]</ref>, while their vulnerability to Byzantine attacks have been studied in a series of recent works <ref type="bibr" target="#b9">[11,</ref><ref type="bibr" target="#b14">16,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b61">62]</ref>.</p><formula xml:id="formula_3">Definition 1 (Classical GAR). F (V 1 , . . . ,V n ) = 1 n ∑ n i=1 V i</formula><p>Definition 2 (Linear GAR). As a generalization of classical GAR, a linear GAR F with parameter α ∈ S n is defined as</p><formula xml:id="formula_4">F (V 1 , . . . ,V n ) = ∑ n i=1 α i V i , where S n := {α ∈ R n : α i ≥ 0, ∑ n i=1 α i = 1} is called an n-dimension simplex.</formula><p>Benign Workers vs. Byzantine Workers. In order to have a precise understanding of what a Byzantine worker is, we start from a formal definition of benign worker.</p><p>As is discussed, at iteration t, each worker is expected to estimate the true gradient</p><formula xml:id="formula_5">g t = E z [∇ θ f (θ t , z)] based on its local data set D. Optimally, it computes V t := 1 |D| ∑ z∈D ∇ θ f (θ t , z)</formula><p>as its submission, due to the well-known fact that V t is an unbiased estimator of g t if D is i.i.d. sampled from D <ref type="bibr" target="#b10">[12]</ref>.</p><p>Generally, it inspires us to make the following definition.</p><p>Definition 3 (Benign Worker). A worker which submits a gradient V t at iteration t is said to be benign if V t is an unbiased estimator of the true gradient g t , i.e., EV t = g t .</p><p>With such a definition of benign worker, it is rather simple to define a Byzantine worker as its opposition.</p><p>Definition 4 (Byzantine Worker). Otherwise, a worker is said to be Byzantine at iteration t if V t is biased, i.e., EV t − g t = 0.</p><p>A well-established theorem from statistics states that classical SGD is guaranteed to converge if the gradient estimation at each descent step is unbiased <ref type="bibr" target="#b10">[12,</ref><ref type="bibr" target="#b12">14]</ref>. If the system is ideally correct, classical GAR is almost the optimal choice. However, it is usually not the case in real-world settings <ref type="bibr" target="#b61">[62]</ref>. In fact, as first noticed by <ref type="bibr" target="#b9">[11]</ref>, classical GAR and its variants are so fragile that even a single Byzantine worker can totally break the whole learning process, as is stated by the following lemma. Proposition 1. [11, Lemma 1] For any linear GAR F with fixed parameter α, the adversary with only one single Byzantine worker can fool F into yielding any arbitrary weight update continually regardless of other submissions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Security Settings</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Threat Model</head><p>Throughout this paper, we consider the same threat model as in previous studies <ref type="bibr" target="#b2">[4,</ref><ref type="bibr" target="#b9">11,</ref><ref type="bibr" target="#b14">16,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b61">62]</ref>. Generally speaking, this threat model assumes that, the adversary compromises a proportion β (s.t. β ∈ (0, 1)) of all workers throughout the learning process and he/she commands the compromised workers to present arbitrary behaviors at each iteration. In other words, the adversary is able to choose the submitted gradients of each manipulated worker. Noteworthily, at iteration t, the Byzantine ratio can be also smaller than β if some  <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b47">48]</ref> </p><formula xml:id="formula_6">n ≥ 2m + 1 O( n m (n − m)d) O( n m + nd) GeoMed [16, 62] n ≥ 2m + 1 O(n 2 d) O(n 2 d) Krum [11] n ≥ 2m + 3 O(n 2 d + n 2 log n) O(n 2 d) Bulyan [31] n ≥ 4m + 3 O(n 2 d) O(n 2 + nd) GAA (ours) n ≥ m + 1 O(n 3 d) O(n 2 + nd)</formula><p>Byzantine workers pretend benign. To provide a finer-grained description on the threat model, we introduce the following notions.</p><p>Role Function. As is discussed, each worker behaves either benignly or maliciously at iteration t. Therefore, we introduce the notion of the role function of worker i to characterize its temporal behaviors. Formally, the role function is defined as a binary-valued function on Z + , i.e., the timeline. Intuitively, r i (t) = 1 means worker i behaves normally at iteration t and otherwise, worker i is a Byzantine worker. Tampering Algorithm. Byzantine workers can choose different tampering algorithms to produce malicious gradients. In previous studies, several realizations of tampering algorithms have been used for evaluation of defenses, such as random fault <ref type="bibr" target="#b9">[11]</ref> (More details can be found in Section 5.1). In general, we denote the tampering algorithm as T , which, with the estimated gradient as the input, outputs the tampered gradient for submission. As in previous studies, we assume the identity of the tampering algorithm for each malicious worker. With the notions above, the behavior of the manipulated worker i at iteration t can be described as 1. First, the adversary selects the current role of the worker i as r i (t). 2. If the role is benign, i.e., r i (t) = 1, then the worker honestly computes the gradient on its local data, that is, V t i . 3. Otherwise, i.e., r i (t) = 0, it tampers the gradient V t i with certain tampering algorithm T (e.g., random fault) and produces T (V t i ). 4. Finally, the produced gradient is sent back to the server.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Previous Defenses</head><p>In order to fight against the aforementioned threat model, previous works proposed several alternative GARs to classical GAR and its linear variants. We briefly review the state-ofthe-art defenses as follows, where m out of n workers are assumed to be Byzantine at certain iteration, s.t. m/n ≤ β. For an overview, please refer to <ref type="table" target="#tab_0">Table 1</ref>. Brute-Force <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b47">48]</ref> is based on a brute-force search for an optimal subset C * in Q of size n − m with the minimal maximum pairwise distance. Formally, the optimal set can be</p><formula xml:id="formula_7">written as C * = arg min C ∈R max (V i ,V j )∈C ×C V i −V j , where R := {C ⊂ Q : |C | = n − m}. Then the proposed weight up-date direction is calculated as F (V 1 , . . . ,V n ) = 1 n−m ∑ V ∈C * V .</formula><p>It was proved to be perfectly robust when n ≥ 2m + 1 <ref type="bibr" target="#b47">[48]</ref>, while it is almost intractable in highly distributed learning systems.</p><p>GeoMed <ref type="bibr" target="#b14">[16,</ref><ref type="bibr" target="#b61">62]</ref> computes the geometric median of Q as the proposed estimator, which assumes the Byzantine ratio satisfies n ≥ 2m + 1 <ref type="bibr" target="#b14">[16,</ref><ref type="bibr" target="#b61">62]</ref>. In consideration of the computational complexity of geometric median when n is large <ref type="bibr" target="#b16">[18]</ref>, recent works on Byzantine robustness proposed to approximate it with the vector in Q which has the smallest sum of distance with other gradients, i.e.,</p><formula xml:id="formula_8">F (V 1 , . . . ,V n ) := arg min V i ∑ j =i V i −V j .</formula><p>Krum <ref type="bibr" target="#b9">[11]</ref> was recently proposed in <ref type="bibr" target="#b9">[11]</ref> as an approximate algorithm to Brute GAR, which assumes the Byzantine ratio satisfies n ≥ 2m + 3. It first finds the n − m − 2 closest vectors in Q for each V i , which is denoted as i → j in their original work. Next, it computes a score for each vector V i with the formula s(V i ) = ∑ i→ j V i −V j 2 . Finally, it proposes the vector V i with the smallest score as the next update step,</p><formula xml:id="formula_9">i.e., F (V 1 , . . . ,V n ) = arg min V i ∈Q s(V i ).</formula><p>Bulyan <ref type="bibr" target="#b30">[31]</ref> was originally designed for Byzantine attacks that concentrate on a single coordinate. First, it runs Krum over Q without replacement for n − 2m time and collect the n − 2m gradients to form a selection set. It then computes F coordinate-wise: the i-th coordinate of F is equal to the average of the n − 4m closest i-th coordinates to the median i-th coordinate of the selection set. Bulyan has the strictest assumption as n ≥ 4m + 3 (and otherwise it is not executable), which significantly limits its practical usage.</p><p>As we can see, the aforementioned approaches only considered the limited situation when β is expected to be smaller than 1/2. In more general cases, e.g., when there is no explicit upper bound on the Byzantine ratio in the system, merely no defenses above could remain robust any longer. The following proposition provides a typical failure case.</p><p>Proposition 2. Consider the submitted gradients at iteration t as (V 1 , . . . ,V n−m , B 1 , . . . , B m ) where {B i } m i=1 are Byzantine gradients. For the slightest violations in each case, i.e., n = 2m for Brute GAR, GeoMed and n = 2m + 2 for Krum, the adversary can simply take B 1 = B 2 = . . . = B m = E to tempt these GARs to always yield E, any arbitrary direction specified by the adversary.</p><p>In practice, this more challenging situation could happen for distributed learning systems in open network environments <ref type="bibr" target="#b60">[61]</ref>. When the adversary has already compromised a majority of workers at the beginning or continuously gains malicious control over each worker during the learning process, the Byzantine ratio in system could go over 1/2 or even fluctuate with uncertainty. In either cases, the system robustness is no longer under guard with the above defenses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Defense with Gradient Aggregation Agent</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Overview</head><p>In order to restore robustness in a more general scenario, we suggest the defender to be combined more tightly with the underlying learning process, by utilizing some auxiliary information inside the distributed learning system for mitigation purposes. Before providing an overview of our methodology, we first clarify our security assumptions and present our goals of defense. 4.1.1 Security Assumptions. We make the following assumptions on the distributed learning system where GAA is to be deployed. Assumption 1. The server is secure. Assumption 2. There is one worker that is never controlled by the adversary.  Here, Assumptions 1 &amp; 3 are commonly adopted in previous studies <ref type="bibr" target="#b2">[4,</ref><ref type="bibr" target="#b9">11,</ref><ref type="bibr" target="#b14">16,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b61">62]</ref>. As GAA is deployed on the server, Assumption 1 guarantees its correct execution. Noticeably, Assumption 2 relaxes the known slightest requirements on the tolerable Byzantine ratio to 1 − 1/n. As a trade-off, we require Assumption 4 to introduce an additional condition on the availability of a quasi-validation set that follows a similar but not necessarily identical distribution as the true sample distribution. In theory we prove the lower the divergence, the better the model performance will be (Thm. <ref type="bibr">1 &amp; 2)</ref>. Through empirical evidences, we show this assumption can be easily satisfied with the quasi-validation set that consists of few samples from similar data domains, if there is no provided golden validation set <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b60">61]</ref>. 4.1.2 Defender's Goals. Towards Byzantine robustness, the defender's primary goal is to guarantee the distributed learning process can minimize the loss function f to an acceptable threshold, usually compared to the global minimum of the loss function <ref type="bibr" target="#b30">[31]</ref>. In practice, it is also reasonable to measure the robustness of certain defense by the gaps among the model's utility (e.g., the accuracy of an image classifier) when the defense is equipped, unequipped with or without attacks. We will provide more details in Section 5. 4.1.3 Methodology Overview. Before detailing the implementations, we provide an overview of our proposed approach ( <ref type="figure" target="#fig_2">Fig. 1)</ref>. Robust distributed learning with GAA follows the following procedures: First, on receiving the submitted gradients from each worker, GAA, an additional module deployed on the server, executes certain policy to pose credit on each worker. Intuitively, GAA has limited credit in total and it will pose higher credit on the worker it trusts more (Step 1). Next, GAA aggregates the gradients based on the credit and then proposes the weight update decision to the underlying learning process (Step 2). Finally, the learning process produces a reward signal based on the quasi-validation set, which is used to indicate the quality of the update direction (Step 3) and can further help GAA adjust its policy dynamically (Step 4). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Distributed Learning as a Markov Decision Process</head><p>Following the conventions of Reinforcement Learning (RL) <ref type="bibr" target="#b52">[53]</ref>, we first define the notion of environment, with which an agent interacts. Standardly, the environment of a Markov Decision Process (MDP) is represented as a tu-</p><formula xml:id="formula_10">ple (S , A,R, p 0 , p, γ)</formula><p>, where S,A are respectively the set of states and of actions, R : S → R is the reward function, p 0 : S → R + is the initial probability density over states and p : S × A × S → R + is the transition probability density, with γ ∈ (0, 1] the discount factor. In the context of distributed learning, our specifications for these components are stated as follows. <ref type="figure" target="#fig_3">Fig. 2</ref> shows an overview of our MDP settings.</p><p>Set of States S. In the terminology of MDP, a state usually has the intuitive meaning as a context, based on which the agent makes a decision. Naturally, our GAA at iteration t refers to the tuple s t := (Q t , θ t , ˆ f B (θ t )) as the current state to decide the next weight update direction. Recall θ t , Q t are respectively the parameter and the received gradients at iteration t, whilêwhilê f B (θ t ) is defined as the loss at θ t estimated by the server on the quasi-validation set B.</p><p>Set of Actions A. Taking advantage of the simplicity of linear GAR, we propose to define the action space as an n-dimension simplex, where n is the number of workers. Generally speaking, our motivation here is to regularize the action space with prior knowledge and therefore the cost on searching the optimal policy can be largely scaled down. By restricting the feasible action to the space of linear GARs, GAA at each iteration chooses a candidate internal action α t ∈ S n based on the current state s t and the previous action α t−1 . Intuitively, this process can be considered as GAA's posing credit on each worker. Based on α t , GAA then proposes the current update step as</p><formula xml:id="formula_11">θ t+1 = θ t − λ(∑ n i=1 α (i) t V t n ).</formula><p>It is worth to notice, although the aggregation rule of GAA is linear in its form, it largely differs from linear GARs in that the coefficient α t is chosen by a sophisticated agent adaptively at each iteration rather than predefined, which therefore makes our model immune to the vulnerability innate to linear GARs <ref type="bibr" target="#b9">[11]</ref>. Reward Function R. Reward function is usually defined as a function from each state s to a scalar value, which provides heuristics for policy learning. In our context, we set the reward at iteration t as</p><formula xml:id="formula_12">R t := ˆ f B (θ t ) − ˆ f B (θ t+1 )</formula><p>, namely the relative loss decrease on the quasi-validation set B. Intuitively, if KL(P m ||D) is 0, the reward R t highly reflects the changes in the true loss f <ref type="bibr" target="#b46">[47]</ref> and thus provides a good guidance for GAA's policy learning. For other situations when P m is similar but not necessarily identical with the true distribution, empirical studies show the reinforcement learning techniques still work well, probably due to its innate tolerance of noises in rewards <ref type="bibr" target="#b52">[53]</ref>. Initial and Transition Probability Density p 0 , p. Usually, these terms are partially unknown to an agent, which could only be estimated implicitly from observed trajectories <ref type="bibr" target="#b56">[57]</ref>. Similarly, our GAA only has the partial knowledge regarding θ andˆfandˆ andˆf B (θ) of p 0 , with random initialization of parameters, and of p, with the updating rule above, but totally ignorant of the initial distribution of Q 0 and its transition. In fact, the learning of GAA is exactly paralleled with an incrementally accurate estimation of p 0 and p, which equivalently means a better knowledge of the undertaking Byzantine attacks. Discount Factor γ. Discount factor as a constant in <ref type="bibr">(0,</ref><ref type="bibr">1]</ref> describes how the rewards in history influence the current decision, the value of which is determined by different application scenarios. Our configurations can be found in the evaluation parts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Learning Optimal Policy for GAA</head><p>In the MDP setting above, our GAA is required to search for certain optimal policy π(α|s) to maximize the expectation of accumulated reward <ref type="bibr" target="#b53">[54]</ref>, where π(α|s) denotes a parametrized distribution over the action space A, conditioned on the currently observed state s. Formally, the optimization objective for training GAA is defined as</p><formula xml:id="formula_13">max π E s 0 ,a 0 ,...,s T ,a T [∑ T t=0 γ t R(s t )], where (s 0 , a 0 , . . . , s T , a T )</formula><p>is called a trajectory (or, experience) of length T + 1, which has the joint probability density p(s 0 , α 0 , . . . , s T , α T ) = </p><formula xml:id="formula_14">p 0 (s 0 ) ∏ T t=1 p(s t |s t−1 , α t−1 )π(α t−1 |s t−1 ).</formula><p>In the context of RL, the objective above has been intensively studied and various mature algorithms such as policy gradient descent <ref type="bibr" target="#b53">[54]</ref> or Q-learning <ref type="bibr" target="#b56">[57]</ref> have been proposed to solve it. We expect our GAA can be seamlessly fused into the learning process of the underlying model with a similar behavior as statistical GARs. Therefore, we propose to approximately model the chained term ∏ T t=1 p(s t |s t−1 , α t−1 )π(α t−1 |s t−1 ) in the joint probability density with a general Recurrent Neural Network (RNN <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b58">59]</ref>). The full computational graph of our proposed implementation is illustrated in <ref type="figure" target="#fig_0">Fig. 3</ref>. Starting from the initial state s 0 ∼ p 0 and initial action α 0 := ( 1 n , . . . , 1 n ), we formulate the auxiliary RNN as follows ∀t ∈ {0, . . . , T − 1}, α t+1 = h ψ (s t+1 , α t ), where h ψ denotes certain recurrent unit with parameter ψ, with its range as a subset of S n . Practically, such a condition can be easily realized with a softmax layer <ref type="bibr" target="#b8">[10]</ref>. For details, please see Section 5.1.</p><p>Therefore, the optimization objective of GAA is refor-</p><formula xml:id="formula_15">mulated as min ψ E s 0 ∼p 0 [∑ T −1 t=0 γ t ( ˆ f B (θ t+1 ) − ˆ f B (θ t ))]</formula><p>, where θ t is uniquely determined with the update rule conditioned on α t−1 and θ t−1 . By expansion ofˆfofˆ ofˆf B , we can formulate the final optimization objective of GAA in episode i as min ψ</p><formula xml:id="formula_16">1 S ∑ T −1 t=0 γ t ∑ z∈B f (θ t+1 , z) − f (θ t , z)</formula><p>, where θ 0 is initialized randomly while α 0 in episode i always inherits value from α T in episode i − 1. Our learning algorithm is listed in Algorithm 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Analytical Results</head><p>In this part, we present theoretical evidence on Byzantine robustness of distributed learning with GAA when the Byzantine ratio is fixed or fluctuates with uncertainty. Please note in the following analysis we focus on the empirical version of f on the training set, as the omitted leap from our proved results to f is guaranteed by standard results in generalization theory <ref type="bibr" target="#b57">[58]</ref>. For the same reason, we maintain the notation f for its empirical version. We assume the loss function f is convex and η-smooth with pointwise bounded gradient ∇ f 2 ≤ M. For non-convex objective, our results can be exAlgorithm 1: Robust Distributed Learning against Byzantine attacks with GAA <ref type="bibr">1</ref> Initialize parameters of recurrent unit h ψ randomly ;</p><formula xml:id="formula_17">2 Initialize α old = α 0 = ( 1 n , . . . , 1 n ) ∈ S n ; 3 for i ∈ {1, . . . , N} do 4</formula><p>Initialize parameters of f as θ 0 randomly ;</p><formula xml:id="formula_18">5 for k ∈ {1, . . . , K} do 6 α 0 ← α old , GAA ← 0; 7 for t ∈ {0, . . . , T − 1} do 8</formula><p>Send the current parameters θ t to each worker ;</p><formula xml:id="formula_19">9 Receive submitted gradients Q t := (V t 1 , . . . ,V t n ) ; 10 θ t+1 ← θ t − λ(∑ n i=1 α i t V t i ) ; 11 GAA ← GAA + 1 S γ t ∑ z∈B f (θ t+1 , z) − f (θ t , z) ; 12 α t+1 ← h ψ (s t+1 , α t ) 13 end 14</formula><p>Update ψ with a step of gradient descent on GAA ; tended with quadratic approximations <ref type="bibr" target="#b11">[13]</ref>. Due to the page limit, we provide the detailed proofs for the results in this part at the website pertaining to this paper 1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.1">Provable Robustness with a Fixed Byzantine Ratio.</head><p>Theorem 1. After t steps of gradient descent with GAA when the Byzantine ratio is fixed as β, Algorithm 1 yields a parameter θ t s.t.</p><formula xml:id="formula_20">f (θ t ) − f (θ * ) &lt; 2RM (1 − β)nt + SηR 2 t + √ 2 f ∞ KL(P m ||D) + O(e −t ) (1)</formula><p>where R is the diameter of parameter space.</p><p>Corollary 1. As long as β is smaller than 1 and P m = D a.e., Algorithm 1 in the above setting will asymptotically converge to the global optimum with rate O(1/ √ t).</p><p>Intuitively, Theorem 1 suggests, when the Byzantine ratio is fixed over time, GAA is proved to help the underlying system attain a sub-optimal parameter with error ε + O(</p><formula xml:id="formula_21">KL(P m ||D)) in O( 1 (1−β)ε 2 ) steps.</formula><p>It suggests a lower KLdivergence bound (at the scale of 10 −2 in our case studies with a quasi-validation set constructed from similar data domains) and a smaller Byzantine ratio will lead to a more accurate sub-optimum. When the quasi-validation set is from the true distribution, Corollary 1 further guarantees the convergence of the learning process with rate O(1/ √ t), which is relatively larger than the optimal rate O(1/t) in Byzantium-free learning case <ref type="bibr" target="#b12">[14]</ref>. We provide a more detailed explanation on the meaning of each term and an empirical validation of Theorem 1 in Appendix A.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.2">Provable Robustness with a Fluctuated Byzantine</head><p>Ratio.</p><p>Theorem 2. After t steps of gradient descent with GAA when the Byzantine ratio fluctuates randomly other than 1, Algorithm 1 yields a parameter θ t s.t.</p><formula xml:id="formula_22">f (θ t ) − f (θ * ) &lt; 2RM + M √ t + SηR 2 t + √ 2 f ∞ KL(P m ||D)<label>(2</label></formula><p>) where R is the diameter of parameter space.</p><p>Corollary 2. Specifically, if P m = D a.e., the learning process will asymptotically converge to the global optimum with convergence rate O(1/ √ t).</p><p>Intuitively, Theorem 2 suggests, although there is still a guarantee for GAA to attain the sub-optimum in this case, the error term on the right of <ref type="formula" target="#formula_22">(2)</ref> is independent from β and is slightly larger than the one in (1). It is mainly because GAA in this case would pose all its credit on one single worker that is never compromised and therefore the distributed learning system degrades to a single-noded version when Byzantine ratio fluctuates. Similarly, Corollary 2 proves the convergence of GAA in this more challenging case when a golden-labeled validation set is available.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Byzantine Worker Detection &amp; Behavior Analysis</head><p>In principle, when a policy is learned on how to determine an optimal action α t according to the current state s t and the historical information, our GAA is expected to master a good knowledge of the undertaking Byzantine attacks. Generally speaking, since the action proposed by our GAA is always constrained in S n , it is therefore reasonable to view each component of α t as the credit on the corresponding worker. Specifically, we present its application in detection and behavioral pattern analysis of Byzantine workers below. 4.5.1 Byzantine Worker Detection. When the Byzantine ratio is fixed, accurate detection of Byzantine workers can help accelerate the learning process by eliminating potential Byzantine workers at an early stage. Therefore, we suggest detection algorithms should aim at selecting K most suspicious workers at iteration t. Although most statistical GARs are not directly applicable for detection tasks, we find one exception is GeoMed, for which we provide a straightforward extension as follows.</p><p>Procedure 1 (GeoMed+). Given Q t = {V t 1 , . . . ,V t n },</p><formula xml:id="formula_23">Step 1. Initialize O t = {} Step 2. O t ← i * := arg max i∈{1,...,n} ∑ V t j ∈Q t V t i −V t j</formula><p>Step 3. Q t ← Q t \{V t i * }</p><p>Step 4. If |O t | = K, output O t . Otherwise, go to Step 2.</p><p>As a comparison, Byzantine worker detection with GAA can be conducted in a more natural way.</p><p>Procedure 2 (GAA+).</p><p>Step 1. Find K smallest coordinate of α t .</p><p>Step 2. Output the corresponding index set as O t 4.5.2 Byzantine Behavior Analysis. When the Byzantine ratio fluctuates with unknown patterns, detecting temporal characteristics is a much more challenging task compared with the aforementioned case. Barely any previous statistical GARs can be adapted for addressing this task due to their lack of interpretability, while our proposed GAA can be applied directly for Byzantine behavior analysis with visualizations. In this case, we can visualize the policy sequence {α t } to understand the temporal patterns of Byzantine attacks. A concrete demonstration on a situation when the Byzantine ratio fluctuates periodically is presented in Section 6.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Overview of Evaluations</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Overall Settings</head><p>5.1.1 Benchmark Systems. We build GAA into the distributed learning process of four benchmark systems for text and image classification listed in <ref type="table" target="#tab_1">Table 2</ref>. On MNIST and CIFAR-10, each worker shares a copy of the training set, while on Yelp and Healthcare, each worker has its local dataset. In all the cases, the loss function f is set as the cross entropy loss between the prediction of classifier g and the ground-truth. More details are provided in Appendix A.3. • Static Attack: All the βn compromised workers play the role of Byzantine workers during the whole learning process.</p><p>• Pretense Attack: In this case, the βn manipulated workers pretend to be benign in the first L rounds and start the attack from the (L + 1)-th round.</p><p>• Randomized Attack: At beginning, each compromised worker (βn in total) is assigned with its role r i (0) by the adversary. During the learning process, it changes its role with a probability q at a period of p rounds.</p><p>It is worth to notice, the first pattern is a realization for the case in Section 4.4.1, when the Byzantine ratio is fixed over time, while the pretense and randomized attacks correspond to the setting in Section 4.4.2 when the Byzantine ratio fluctuates with or without uncertainty. Moreover, the latter two patterns are designed as adaptive attacks on the RL mechanism adopted by GAA. Both randomized attack and pretense attack attempt to mislead GAA into making wrong credit assignments, by letting the manipulated workers pretend to be benign and submit normal gradients in a certain time span of the learning process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.3">Tampering Algorithms.</head><p>In experiments, we evaluate the impact of two realizations of the tampering algorithm T .</p><p>• Random Fault (RF) <ref type="bibr" target="#b9">[11]</ref>. For RF, Byzantine workers submit noisy gradients sampled from a multi-dimensional Gaussian N (µ, σ 2 I). In our experiments, we take µ = (0.5, . . . , 0.5) ∈ R d and σ = 2 × 10 −6 .</p><p>• Adaptive Fault (AF). For AF, we consider an adversary has some knowledge of the quasi-validation set, which allows the manipulated workers to submit well-crafted gradients that can tempt GAA to assign them with high credits and meanwhile maximize the overall training loss. We provide the details on the implementation of this fault in Section 6.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.4">Implementation Details of GAA.</head><p>We implement the recurrent unit h ψ of GAA in the following experiments as a fully connected, feed-forward neural network with no hidden layer, with an input layer of size (3n + 2) × d (i.e., the dimension of concatenation of s t and α t ) and an output layer of size d with softmax activation. For other common hyperparameter settings in Algorithm 1, we set the learning rate λ as 0.05, discount factor γ as 0.9, the episode length T as 5, the number of episode N as 5. Each benign worker computes the gradient on randomly sampled mini-batch of size 64 for MNIST &amp; CIFAR-10 and 256 for Yelp &amp; Healthcare.</p><p>5.1.5 Choice of the Quasi-Validation Set B. For MNIST and CIFAR-10, we set the quasi-validation set as a random mini-batch of training samples. For Yelp and Healthcare, we implement the quasi-validation set as a small subset of samples from similar data domains. On Yelp, each worker holds 20k restaurants' reviews (randomly selected from the raw restaurant reviews) from one of the 10 US states with the most recorded Yelp reviews (including Arizona, Illinois and so on). We randomly sampled 1k reviews from South California, which is not in the top-10 states, as the full quasi-validation set. On Healthcare, each worker holds 20k treatment descriptions from local hospitals in one of the 50 different states, while we use a subset of descriptions from Alaska as the full quasi-validation set, which contains 1k records in total. For all our experiments on Yelp and Healthcare, we use less than 10 random samples from the full quasi-validation set as the working quasi-validation set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Summary of Results</head><p>We highlight some experimental findings below.</p><p>• Robustness -GAA effectively defends the 4 benchmark systems against 3 attacking patterns and 2 tampering algorithms, with a wide range of configurations. It helps the underlying systems achieve comparable performance in limited rounds as if the systems were not under attacks.</p><p>• Efficiency -The time efficiency of GAA is on a similar scale with previous statistical defenses.</p><p>• Interpretablity -A well-trained GAA provides informative and interpretable traces that can be used for Byzantine worker detection and behavior pattern visualization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Results &amp; Analysis</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Robustness against Static Attacks</head><p>Figure 4: Test accuracy of the benchmark systems under static attacks when different defenses are applied up to a fixed round.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.1">Comparison with Baselines.</head><p>We compare the Byzantine robustness of our proposed GAA with 6 baselines under static attacks with RF: (A) Classical GAR (B) Brute-Force (C) GeoMed (D) Krum (E) Bulyan and (F) Classical GAR without attack. We include the last baseline for measuring the degradation of each method under attacks. We set the Byzantine ratio β in the static attack as 0.2, 0.5, 0.7, where 0.2 is a tolerable Byzantine ratio for all the baselines and 0.5 corresponds to the breaking point of the baselines. <ref type="figure" target="#fig_1">Fig. 4</ref> shows the final test accuracy of the four benchmark systems with different defenses equipped, up to 5k, 10k, 20k, 40k rounds respectively. As Bulyan is not executable when n ≥ 4m + 3, the corresponding result is not collected when β ≥ 0.5. Moreover, Brute-Force on MNIST, CIFAR-10 &amp; Healthcare and Bulyan on CIFAR-10 fail to finish the learning in 10 days due to the high time complexity (we provide evaluations in Section 6.1.2 and Table 1), the corresponding results are not reported.</p><p>Results &amp; Analysis. As we can see from <ref type="figure" target="#fig_1">Fig. 4</ref>, when the Byzantine ratio is as small as 0.2, each baseline method is observed to be Byzantine robust, which conforms to the reported results in previous works <ref type="bibr" target="#b30">[31]</ref>. In this case, our GAA also helps the underlying model achieve a similar test accuracy. Noticeably, the robustness of our GAA is strongly demonstrated by its comparable performance to classical GAR without attack, when the Byzantine workers are in majority. For example, as the β = 0.5 cases represent the breaking point of Brute-Force, Krum and GeoMed, on Yelp the benchmark systems with the baseline defenses perform no better than a random guesser, while GAA helps the system achieve over 80% accuracy, which is very close to the 84.5% accuracy when the system is under no attack. A similar phenomenon was observed even when we further enlarge the Byzantine ratio to 0.7. These results imply GAA does complement the existing defenses when the Byzantine ratio is larger than 0.5. 6.1.2 Time Efficiency. We measure the time cost of our defense and provide a tentative comparison with previous defenses. We run the four benchmark systems with different defenses under the same static attack in the previous part and record the time cost of 100 iterations with 10 repetitions in the same environment described in Appendix A.1. <ref type="table" target="#tab_2">Table 3</ref> lists the running time of different defenses in each case. As the results imply, GAA brings computation overheads on a similar scale compared with previous defenses, which roughly corresponds to the theoretical complexity listed in <ref type="table" target="#tab_0">Table 1</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Robustness against Adaptive Attacks on the RL mechanism</head><p>In this part, we evaluate the robustness of GAA when the adversary attempts to mislead the credit assignment by letting the manipulated workers pretend to be benign. shows GAA helps the benchmark system on MNIST achieve about 90% accuracy on average, which is close to the 96.4% accuracy of the system under no attack. As a comparison, the systems equipped with the baseline defenses either has final performance much lower than the expected or totally stagnate. Moreover, from <ref type="figure" target="#fig_6">Fig. 5</ref>(e)-(h), we find no fluctuation happens when the manipulated workers begin to attack after 1K rounds, which implies the RL mechanism of GAA is robust against pretense. Below, we present a more careful evaluation of GAA under a wide range of attack configurations. 6.2.2 GAA under Adaptive Attacks with Varied Configurations. Besides, we further evaluate GAA's robustness against the randomized attacks and the pretense attacks with diverse configurations on Yelp and Healthcare. <ref type="figure" target="#fig_8">Fig. 6</ref> presents the learning curves of the underlying benchmark systems under attacks of varied configurations listed in the legends, where the shaded part of the curves denotes the variance of the accuracy within 10 repetitions.</p><p>Results &amp; Analysis. As we can see from <ref type="figure" target="#fig_8">Fig. 6</ref>, under randomized Byzantine attacks of most configurations, GAA helps the benchmark systems on Yelp and Healthcare achieve desirable performance, compared with the accuracy of systems without Byzantine attacks. For example, in most configurations for Yelp, the final accuracy is around 83%, which is close to the optimal accuracy 84.5%. Although from <ref type="figure" target="#fig_8">Fig. 6(b)</ref> we notice the q = 0.0 case on Yelp has a larger variance, the average final accuracy is only about 10% lower compared with the optimal accuracy, which is still acceptable considering the high Byzantine ratio up to 0.7. Similarly, from Fig. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Robustness against Adaptive Attacks on the Quasi-Validation Set</head><p>Although Assumption 1 and the randomness in the composition of the Quasi-Validation set (abbrev. QV set) imply the exact samples in the QV set is hard to be known by the adversary, we further examine the following two worst-case leakages of the QV set, which may allow the adversary to submit carefully crafted gradients (or called Adaptive Fault (AF)) based on the knowledge of the QV set to attempt to mislead GAA.</p><p>• Case A. The adversary knows the distribution where the QV set is sampled.</p><p>• Case B. Some classes are missing in the QV set and the malicious worker can target on the missing classes. Intuitively, Case A is possible when the adversary expects GAA would use samples from similar data domains as the QV set, while Case B is possible when the QV set is too small to cover all different classes. It is worth to notice, for the adversary in Case A, the probability of determining the exact samples in the QV set is very low in theory, as the QV set contains less than 10 samples that are chosen independently by the server while the sample space of the distribution known to the adversary, practically the local dataset held by the manipulated worker, can contain as large as 10 3 samples when deep learning models are deployed.</p><p>In both cases, we consider the AF follows the same principle: it minimizes the loss on a dataset D 0 , which is chosen based on the knowledge about the QV set, to tempt GAA to assign the manipulated worker with high credit. In the meanwhile, the AF maximizes the overall loss on D 1 , (a subset of) its own training set, to compromise the whole distributed learning process. Accordingly, we formulate the gradient V t i submitted by a malicious worker (i.e., Worker i) at iteration t with AF by</p><formula xml:id="formula_24">V t i ∝ ∇ θ ((θ t , D 0 ) − α(θ t , D 1 )),</formula><p>where α is a hyperparameter that controls the stealthiness of the adaptive fault. , we find in most cases the final accuracy of the benchmark systems remains close to the optimal accuracy. For example, under the combo adaptive attack on both the RL mechanism and the QV set (i.e., Config. b in <ref type="figure" target="#fig_10">Fig. 7(a)&amp;(b)</ref>), GAA achieves respectively about 82% and 65% accuracy on Yelp and Healthcare, which is close to the performance of the system under no attack. The results imply that, GAA is robust against the adaptive adversary knowing the distribution where the QV set is sampled. From our perspective, lacking the knowledge of the exact QV set would let the adversary only count on his/her own inexact guess on the QV set. Hence, combining with the malice on maximizing the loss on the local training set, the gradient directions crafted by the malicious workers would be less effective in minimizing the loss on the QV set than the benign workers and therefore would be less trusted by GAA. However, when the adversary somehow knows the exact QV set the server uses, he/she would craft gradients that always minimize the loss on the QV set and mislead GAA to fully trust the manipulated worker, while this case would be rare, if not impossible, depending on the randomness of sampling and the security of the server. 6.3.2 Adaptive Attacks in Case B. In this setting, the manipulated worker can target on the missing classes by maximizing the loss on samples belonging to these missing classes, which forms the D 0 , while minimizing the loss of samples from other existing classes, which forms D 1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.1">Adaptive</head><p>Experimental Settings. We first sample 10 records from the full QV set on Healthcare (Yelp) to cover all the classes. For Healthcare, we reduce the number of classes from 9 to 1 with stride 2 by eliminating the samples belonging to the missing classes that we specify. For Yelp, we consider the case when the QV set contains only positive or only negative samples. With the QV sets with missing classes, we conduct the GAA defense against three typical attack patterns listed in the legends and titles of <ref type="figure" target="#fig_10">Fig. 7</ref>(c)-(f), which present the learning curves of the benchmark systems under the considered adaptive attack on the QV set.</p><p>Results &amp; Analysis. As we can see from <ref type="figure" target="#fig_10">Fig. 7</ref>(c)-(f), even when the adversary targets on the missing classes in the QV set, GAA is still able to guarantee the benchmark systems to reach satisfying performance. For example, under static Byzantine attacks on Healthcare (in <ref type="figure" target="#fig_10">Fig. 7(d)</ref>), the final performance with 5 missing classes in the QV set is around 75%, even better than the 73.1% accuracy of the system under no attack. Also, Config. c in <ref type="figure" target="#fig_10">Fig. 7</ref>(c) and <ref type="figure" target="#fig_10">Fig. 7</ref>(f) demonstrates GAA remains robustness under combo attacks on the RL mechanism and the missing classes. Furthermore, we notice the number of missing classes has minor influence on GAA's defense quality, which strongly demonstrates the robustness of GAA against the adaptive adversary knowing the missing classes in the QV set. 6.3.3 GAA vs. Different Attacks. Despite the robustness of GAA against various attacks, the empirical performance does show subtle differences when GAA is against different attacks. For example, comparing <ref type="figure" target="#fig_6">Fig. 5</ref> and <ref type="figure" target="#fig_1">Fig. 4</ref>, we find that the final accuracy of the benchmark systems under randomized and pretense attacks, two attacks exploiting the knowledge that GAA uses the RL mechanism to learn credit, is overall no better than that under static attacks. Similarly, as we can see from the corresponding results in <ref type="figure" target="#fig_10">Fig. 7</ref> and <ref type="figure" target="#fig_1">Fig. 4</ref>, adaptive attacks that exploits the knowledge on the QV set are relatively more threatening than static attacks, where the threat is not further enlarged when the adversary exploits both the knowledge on the RL mechanism and the QV set, if comparing Config. b &amp; c in <ref type="figure" target="#fig_10">Fig. 7</ref>(a) &amp; (b) with the corresponding results in <ref type="figure" target="#fig_6">Fig. 5</ref>. These phenomena interestingly show, the more knowledge the adversary has of the deployed defense, the more threatening the attack could be against GAA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Byzantine Worker Detection</head><p>In this part, we report the accuracy of Byzantine worker detection when the system is under static Byzantine attacks via our proposed GAA+ in Proc. 2, compared with the baseline method the GeoMed+ algorithm in Proc. 1. </p><formula xml:id="formula_25">β = 0.7 K=1</formula><p>99.9%/2.85% 0.0%/0.0% K =10 99.9%/28.5% 0.0%/0.0% K =35 99.9%/99.9% 57.1%/57.1%</p><p>Experimental Settings. By choosing Byzantine ratio β = 0.3, 0.7, we apply two detection algorithms on MNIST with the total number of workers as 50. Since we have defined the task of Byzantine worker detection as a top-K classification task, we report precision/recall in <ref type="table" target="#tab_3">Table 4</ref>. Both precision and recall are calculated as an average over 1 × 10 3 randomly subsequent iterations after 1 × 10 4 iterations of distributed learning with GAA.</p><p>Results &amp; Analysis. As we can see from above, with small Byzantine ratio, both GeoMed+ and our method achieve near perfect detection of each Byzantine worker. These empirical results not only justify that GeoMed+ is indeed a strong baseline, but also validates GAA+'s comparable performance with statistical counterparts in slight Byzantium. However, when the Byzantine ratio β is set up to 0.7, GeoMed+ fails to detect Byzantine workers any longer, while our method still detects each Byzantine worker perfectly, regardless of its majority in total.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.5">Visualizing Byzantine Attack Patterns</head><p>In the final part of experiments, we present several interesting visualizations on the policy curve of GAA after learning under randomized attacks of q = 1.0, that is, each manipulated worker inverses its role periodically. Experimental Settings. We consider two specific randomized attacks on MNIST with the following configurations: (a) n = 10, q = 1.0, p = 1k with initial β = 0.9 and (b) n = 10, q = 1.0, p = 400 with initial β = 0.5. In other words, we consider the cases when all workers are manipulated and invert their role periodically. We collect GAA's action sequence in each configuration up to 40k rounds and plot the policy curves of each worker over a representative slice of iterations in <ref type="figure" target="#fig_11">Fig. 8</ref> after normalization, where the policy curves for the initially Byzantine workers are warm-toned and the initially benign workers cool-toned.</p><p>Results &amp; Analysis. First, in both cases the periodic characteristic of the undertaking Byzantine attack is captured well by our GAA, as its policy curve presents a period close to the ground-truth. To analyze with more care, we notice, in <ref type="figure" target="#fig_11">Fig.  8(b)</ref>, as GAA's decision on Byzantine workers appears to be correct initially, its policy curve mainly evolves vertically. In other words, GAA tends to behave stable after an optimal policy is attained. Differently in <ref type="figure" target="#fig_11">Fig.8(a)</ref>, although a low credit is assigned to the only initially benign worker in the first half period, GAA wisely skips the other half and swiftly adjust its policy in the subsequent period by heuristics of reward. The phenomenon is highlighted by the slashed region in <ref type="figure" target="#fig_11">Fig. 8(a)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Discussion</head><p>On Assumptions 1 &amp; 2. Assumption 1 is used to guarantee the correct execution of Algorithm 1 and GAA itself would not be compromised by the adversary, while Assumption 2 is used to guarantee GAA has at least one worker to trust. We claim both assumptions are reasonable. On one hand, the former assumption is commonly assumed in previous studies of Byzantine robustness <ref type="bibr" target="#b2">[4,</ref><ref type="bibr" target="#b9">11,</ref><ref type="bibr" target="#b13">15,</ref><ref type="bibr" target="#b14">16,</ref><ref type="bibr" target="#b18">20,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b61">62]</ref>, which serves as a standing point of most published defenses, since otherwise the adversary could easily tamper the global model itself. On the other hand, the security level of the central server in real world distributed systems is always on a much higher level than working nodes, due to, e.g., rigorous access control mechanisms <ref type="bibr" target="#b54">[55]</ref>. Therefore, the cost of attacks on central server is much higher than that on workers.</p><p>Moreover, we find it is quite straightforward to satisfy Assumption 2 if Assumption 1 is valid. For instance, the parameter server can spare certain computation resources to simulate one worker node on its own devices. Therefore, falling back on the properness of Assumption 1, we could claim the simulated worker is an always benign worker and thus satisfies the second assumption. On Assumptions 3 &amp; 4. These two assumptions regularize the range of learning tasks which GAA can help. Assumption 3 is again a commonly adopted assumption in most known defenses <ref type="bibr" target="#b2">[4,</ref><ref type="bibr" target="#b9">11,</ref><ref type="bibr" target="#b13">15,</ref><ref type="bibr" target="#b14">16,</ref><ref type="bibr" target="#b18">20,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b61">62]</ref>. On one hand, if the workers share a copy of the same training set as in many conventional distributed learning systems (including the MNIST &amp; CIFAR-10 cases) <ref type="bibr" target="#b1">[3,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b63">64]</ref>, both Assumptions 3 &amp; 4 can be naturally satisfied due to the availability of a validation set from the same data source. For some newly proposed distributed learning systems (e.g., federated learning <ref type="bibr" target="#b33">[34]</ref>) when the workers have their local datasets (including the Yelp &amp; Healthcare cases), we demonstrate with the experimental results in <ref type="figure" target="#fig_12">Fig. 9</ref>, where we control the size of the QV set on Yelp and Healthcare to be 1 and 10, 100, · · · , 1000 by sampling from the full QV set, that the requirement on the QV set is relatively easy to be satisfied with only a small number of samples from similar data domains. For example, from <ref type="figure" target="#fig_12">Fig.  9(b)</ref>, we find the final accuracy on Yelp under randomized attacks is both close to the bottleneck accuracy whenever the QV set size is 1 or 1k, despite a slightly larger variance of performance and a lower convergence rate when the QV set is smaller. Moreover, experiments in Section 6.3 has proved that a small QV set is not likely to be exploited as a weak spot of the system whenever it may have missing classes or share a similar distribution with the local datasets of the manipulated workers. Despite this, we admit the QV set may be a weak spot for GAA if it is fully known by the adversary, while this case would be rare, if not impossible, in practice due to the randomness in preparing the QV set by the server and the security of the server.</p><p>For a validation of the requirement on the QV set in Assumption 4, we numerically estimate the average KL divergence among the local datasets and the full QV set on Healthcare. We find the empirical value is about 0.1. By inserting the empirical values of the KL divergence and the other terms in Section 4.4, we find the convergence rate predicted by Theorem 1 is quite close to the empirical learning curves. We provide more details in Appendices A. <ref type="bibr">2 &amp; A.4</ref>. However, GAA could have certain limitations to guarantee Assumption 4 when the server has no knowledge about the data domain of the undergoing distributed learning process or the learning protocol may have privacy requirements <ref type="bibr" target="#b60">[61]</ref>, which we leave as an interesting future work. On Threat Model. Does the real world distributed learning environment really show such malice that the Byzantine ratio has no explicit upper bound or even fluctuate? It may not the case for current distributed learning systems in stable local network environments <ref type="bibr" target="#b51">[52]</ref>. Existing real world cases are, for example, distributed systems in unstable network environment with low-specification working machines, where a majority of nodes would send faulty gradients due to network or computation errors in an unpredictable manner. In this situation, GAA turns out to be a promising tool to help the underlying learning process converge to a near-optimal solution. Other possible use cases of GAA can be found in federated learning systems <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b60">61]</ref>, where end users are allowed to build a global learning model in cooperation. From our perspective, we suggest the threat model in this case should be formulated as malicious as possible, since the reliability of end users can be hardly guaranteed, similar to the case of DDoS attack <ref type="bibr" target="#b44">[45]</ref>. Limitations and Future Directions. In one repetitive test of GAA, we observed a fluctuated test result on MNIST, which, based on our detailed analysis in Appendix A.5, could probably occur when the reward distribution of malicious workers is almost indistinguishable from that of benign workers. This may weaken the defense capability of GAA against attacks that aim at misclassification of targeted data samples instead of the overall accuracy we focus on in the current work. This kind of targeted attacks can be highly stealthy in terms of worker behavior <ref type="bibr" target="#b6">[8]</ref> and remains an open challenge in building robust distributed learning systems <ref type="bibr" target="#b23">[24]</ref>.</p><p>Due to the limited access to distributed learning systems in industry, we have tried our best to cover typical use cases in image classification, sentiment analysis and intelligent healthcare, where the latter two are based on datasets from real-world applications and are minimally preprocessed to reflect the characteristics of data in practice. Nevertheless, more research efforts are required to provide a more thorough evaluation of GAA's security and performance in more application domains within industrial environments, which is very meaningful to be pursued as a future work. Although the distributed learning paradigm we study remains a mainstream techniques, there do exist other distributed learning paradigms such as second-order optimization based paradigms <ref type="bibr" target="#b49">[50]</ref> or model-parallel paradigms <ref type="bibr" target="#b32">[33]</ref>. To generalize GAA to more distributed learning paradigms will also be an interesting direction to follow.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">More Related Work</head><p>Byzantine Robustness of Gradient-Based Distributed Learning Systems. Recent years, distributed learning systems under Byzantine attacks have aroused emerging research interests. Mainstream works in this field mainly focus on Byzantine robustness of the distributed learning protocol we introduce in Section 2. As we have reviewed in Section 3.2, most previous works are more interested in the defense side and usually utilize statistical approaches towards Byzantine robustness <ref type="bibr" target="#b2">[4,</ref><ref type="bibr" target="#b9">11,</ref><ref type="bibr" target="#b14">16,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b61">62]</ref>. At the attack side, two very recent works <ref type="bibr" target="#b4">[6,</ref><ref type="bibr" target="#b24">25]</ref> have devised carefully-crafted attacks against Krum and GeoMed, while the attack techniques are highly dependent on the target defense and are hard to be generalized to GAA. Correspondingly, we in turn investigate the robustness of GAA under adaptive attacks on its own mechanism in Sections 6. <ref type="bibr">2 &amp; 6.3</ref>. During our paper preparation, we notice one recent work that also attempts to break the β = 0.5 bound <ref type="bibr" target="#b59">[60]</ref>. The work is not learning-based and uses the loss decrease at the current iteration on the training set to rank the workers' credibility, which can be viewed a special case of our algorithm when the workers share the same training set and T = 1 in Algorithm 1. Moreover, the work only considers a 4-layer convolutional network on CIFAR-10 as the only benchmark system, while we provide more comprehensive evaluations in four typical scenarios, including the case they studied. Byzantine Problem in Other Contexts. Aside from the aforementioned works on gradient-based distributed learning, there also exist some researches on other distributed learning protocols. For example, Chen et al. proposed a robust distributed learning protocol by requiring workers submitting redundant information <ref type="bibr" target="#b13">[15]</ref>; Damaskinos et al. studied the Byzantine robustness of asynchronous distributed learning <ref type="bibr" target="#b18">[20]</ref>; another thread of works exploited the vulnerability of distributed learning protocols where a worker is directly allowed to submit the local model to the master <ref type="bibr" target="#b3">[5,</ref><ref type="bibr" target="#b5">7,</ref><ref type="bibr" target="#b27">28]</ref>. In this paper, we focus on the gradient-based distributed learning system model as studied by the mainstream defenses and therefore none of the aforementioned works are directly related to this paper.</p><p>Besides the Byzantine robustness in the context of machine learning, it has also been studied in many other contexts, like the multi-agent systems <ref type="bibr" target="#b45">[46]</ref> and file systems <ref type="bibr" target="#b20">[21]</ref>, and was first studied in the seminal work by Lamport <ref type="bibr" target="#b36">[37]</ref>. From a higher viewpoint on adversarial machine learning, challenges like adversarial example <ref type="bibr" target="#b29">[30]</ref>, data poisoning <ref type="bibr" target="#b7">[9]</ref> and privacy issues <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b50">51]</ref> remain open problems and require future research efforts on building more robust and reliable machine learning systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Conclusion</head><p>In this paper, we have proposed the design of a novel RLbased defense GAA against Byzantine attacks, which learns to be Byzantine robust from interactions with the distributed learning systems. Due to the interpretability of its policy space, we have also successfully applied our method to Byzantine worker detection and behavioral pattern analysis. With theoretical and experimental efforts, we have proved GAA, as a promising defense and a strong complement to existing defenses, is effective, efficient and interpretable for guaranteeing the robustness of distributed learning systems in more general and challenging use cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Other Details</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Experimental Environments</head><p>All the defenses and experiments are implemented with Torch <ref type="bibr" target="#b17">[19]</ref>, which is an open-source software framework for numeric computation and deep learning. All our experiments are conducted on a Linux server running Ubuntu 16.04, one AMD Ryzen Threadripper 2990WX 32-core processor and 2 NVIDIA GTX RTX2080 GPUs. We simulate the distributed learning setting by sequential computation of gradients on randomly sampled mini-batches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Estimate KL-divergence</head><p>We design the following procedures to estimate the pairwise KL-divergence between datasets D i and D j on Healthcare, which consist of samples of form (x, y) s.t. x ∈ R n , y ∈ [K], where n = 1024 and K = 10. <ref type="figure" target="#fig_2">Fig. 10</ref> shows the heatmap of the KL-divergence among the local datasets on each worker and the full QV set. </p><formula xml:id="formula_26">KL(D i ||D j ) = 1 K × N N ∑ k=1 K ∑ c=1 p i (x k |y = c) log p i (x k |y = c) p j (x k |y = c)<label>(3)</label></formula><p>Figure 10: Estimated KL-divergence among local datasets and the prepared validation set on Healthcare.</p><p>However, it is true that it is challenging to estimate the KL-divergence when the QV set is very small. To leverage the above algorithm for estimation, ideally we require the knowledge of the distribution where the QV set is sampled, so that we can estimate the conditional distribution p(y|x) via learning-based approaches. Intuitively, if QV set contains more samples, the estimated conditional distribution is less biased and thus the error of estimating the KL-divergence is smaller. To be concrete, the minimum requirement for conducting the estimation is, the QV set should contain at least one sample from each class and thus we can estimate the conditional distribution with support vector classifier or KNearest Neighbor (KNN). As a future work, it would be a meaningful direction to study how to guarantee a low KLdivergence in a distributed learning protocol that may have privacy requirements <ref type="bibr" target="#b60">[61]</ref>. which produces the curve of the predicted training loss in <ref type="figure" target="#fig_2">Fig. 11(d)</ref>. Compared with the empirical training loss curve, we find the prediction from Theorem 1 roughly conforms to GAA's empirical behavior in this case.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.5 Analysis of a Fluctuated Phenomenon on MNIST under Randomized Attacks</head><p>In one repetitive test of GAA, we noticed a fluctuated test result on MNIST under randomized attacks of p = 0.5, q = 5, initially β = 26/50, which we report below in <ref type="figure" target="#fig_2">Fig. 12</ref>. In fact, through a larger number of repetitive experiments, we have observed this phenomenon only on MNIST but not on other three benchmarks. We would like to clarify that this <ref type="figure" target="#fig_2">Figure 11</ref>: Empirical values of the theoretical terms in Theorem 1, alongside the predicted training loss curves.</p><p>phenomenon is not a common case in repetitive tests and we reported this result here mainly because we think this singular phenomenon may help the readers understand the behavior of GAA more thoroughly. Below, we further investigate the possible causes of this phenomenon. As we can see from <ref type="figure" target="#fig_2">Fig. 12</ref>, the policy curve of GAA is more unstable than that in other cases, which in other words means GAA's credit on each worker fluctuates a lot. This phenomenon indicates that GAA somehow could not recognize the always benign worker in this situation. As a hypothesis, we speculate the reason as the low complexity of the MNIST task <ref type="bibr" target="#b15">[17,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b48">49]</ref>, which makes the reward from the workers' gradient on MNIST is not as distinguishable as in other cases. To validate this point, we plot the distribution of the rewards (i.e., the relative loss decrease) yielded by the benign workers and the randomized Byzantine workers on each benchmark as follows.</p><p>In detail, we set the worker number as 2 and set their roles respectively as benign and Byzantine with the RF tampering algorithm. We execute the classical distributed learning protocol for 10 epochs over the corresponding training set and collect the yielded reward (calculated on the quasi-validation set of the same settings in Section 5.1) respectively from the benign and Byzantine workers for every 1k iterations. We then plot the histogram of rewards on MNIST and CIFAR-10 in <ref type="figure" target="#fig_0">Fig. 13</ref>.</p><p>As we can see from <ref type="figure" target="#fig_0">Fig. 13</ref>, on CIFAR-10 the Byzantine worker always yields zero reward, which is highly divergent from that of the benign worker. Differently, on MNIST the Byzantine worker and the benign worker yield rewards that follow similar distributions, which thus may bring difficulties for GAA to distinguish one from the other. A noticeable point is the Byzantine worker tends to yield rewards that distribute in a slightly wider range than the benign one, which could be another cause of the instability in GAA's learning curve on MNIST. This speculation is also supported by the MNIST case under static Byzantine attacks of ratio over 0.5 &amp; 0.7 (in <ref type="figure" target="#fig_1">Fig. 4)</ref>, where the baseline methods were observed to perform slightly stronger than the random-guess, while on other datasets they did not. This phenomenon suggests that the model on MNIST still learns something from even incorrect gradients.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Assumption 3 .</head><label>3</label><figDesc>The local datasets on workers are i.i.d. sam- pled from the unknown distribution D.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Assumption 4 .</head><label>4</label><figDesc>GAA has access to a quasi-validation set B of size S, which consists of i.i.d. samples from a sample distribution P m s.t. KL(P m ||D) &lt; ∞, i.e., the KL-divergence between P m and D is upper bounded by a constant.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Overview of our proposed defense.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Distributed learning as an MDP.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Implementation of GAA's policy as a general recurrent neural network.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>15 α</head><label>15</label><figDesc>old ← α T ; 16 end 17 end</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Learning curves of GAA against randomized attacks and pretense attacks.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>6 . 2 .</head><label>62</label><figDesc>1 Comparison with Baselines. First, we evaluate the four benchmark systems under the randomized attack of q = 0.5, p = 5 and the pretense attack of β = 0.7, L = 1000, when GAA and other baseline defenses are equipped. Each worker is assumed to play the Byzantine role with RF. For random- ized attacks, 24 out of 49 compromised workers are initially malicious on MNIST, CIFAR-10 &amp; Healthcare and 4 out of 9 on Yelp. Fig. 5 plots learning curves of the benchmark sys- tems when different defenses are equipped, where the shaded part of the curves denotes the variance of the accuracy within 10 repetitions. Results &amp; Analysis. As we can see from Fig. 5, , GAA is the only defense that is robust against both randomized and pretense attacks. For example, Fig. 5(a)&amp;(e)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Learning curves of the benchmark systems on Yelp and Healthcare when GAA is applied for defending against randomized attacks with varied role-change period (the first column), role-change probability (the second column), initial Byzantine ratio (the third column) and against pretense attacks with varied pretense rounds (the last column). The legend describes the detailed configurations. 6(d)&amp;(g), we also find the different configurations of the pretense attacks has very limited influence on GAA's defense quality.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>Faults in Case A. We choose the D 0 as the full QV set, and the D 1 as the local training set of the ma- nipulated workers. The parameter α in AF is set as 10. We conduct the GAA defense under three typical attack patterns listed in the legends of Fig. 7(a)&amp;(b), which show the learn- ing curves of the benchmark systems under the considered adaptive attack on the QV set. Results &amp; Analysis. From Fig. 7(a)&amp;(b)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Learning curves of the benchmark systems on Yelp and Healthcare when GAA is applied for defending against adaptive faults in two cases of varied configurations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Capture periodic information of randomized Byzantine attack with GAA.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Learning curves on Yelp and Healthcare when GAA is equipped with varied size of the quasi-validation set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>1 K</head><label>1</label><figDesc>ln K, which is about 0.23 for K = 10 on Healthcare), while the estimated KL divergence term is about 0.16 from Fig. 10. Therefore, on Healthcare under static Byzantine attacks with β = 0.7, n = 50, the numeric form of Theorem 1 writes as f (θ t ) − f (θ * )</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 12 :</head><label>12</label><figDesc>Figure 12: An observed fluctuated run of GAA defense on MNIST under the randomized attack: (a) its learning curve and (b) its policy curves.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Figure 13 :</head><label>13</label><figDesc>Figure 13: Distribution of rewards from benign workers and from randomized Byzantine workers on MNIST and CIFAR-10.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 : Comparisons among different defenses against Byzantine attacks. Constraint Time Complexity Space Complexity Brute-Force</head><label>1</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="true"><head>Table 2 : Summary of the benchmark systems.</head><label>2</label><figDesc></figDesc><table>MNIST 
CIFAR-10 
Yelp [1] 
Healthcare [2] 

Model 
MLP 
ResNet-18 
MLP 
MLP 

Task 
Hand-Written Digits 
(10-class) 

Objects 
(10-class) 

Sentiment 
(2-class) 

Disease 
(10-class) 

# Samples 
60k 
(Shared) 

60k 
(Shared) 

20k per worker 
(Local) 

20k per worker 
(Local) 

# Parameters 
25, 450 
11, 173, 962 
10, 272 
33, 130 

# Workers 
50 
50 
10 
50 

5.1.2 Attacking Patterns. We consider the following three 
attack patterns of the adversary. 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Time cost of distributed learning with each defense 
(sec. / 100 iterations), where -means the 100 iterations have 
not finished in one hour. 

Classical 
GAA 
GeoMed Krum Bulyan Brute-Force 

MNIST 
6.32 
8.14 
15.85 
15.79 
698 
-

CIFAR-10 
116.85 
129.50 
118.73 
118.69 
-
-

Yelp 
1.45 
2.40 
1.76 
1.85 
13.16 
4.76 

Healthcare 
8.77 
11.15 
17.70 
18.57 
1877 
-

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Precision-recall of Byzantine worker detection meth-
ods. 

GAA+ 
GeoMed+ 

β = 0.3 

K=1 
99.7%/6.65% 100%/6.67% 
K =5 99.7%/33.2% 100%/33.3% 
K =15 99.8%/99.8% 100%/100% 

</table></figure>

			<note place="foot" n="1"> https://bit.ly/2wjR2bb</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgement</head><p>We sincerely appreciate the shepherding from Yuan Tian. We would also like to thank the anonymous reviewers for their constructive comments and input to improve our paper. This work was supported in part by the National Natural Science Foundation of China (61972099, U1636204, U1836213, U1836210, U1736208, 61772466, U1936215, and U1836202), the National Key Research and Development Program of China (2018YFB0804102), the Natural Science Foundation of <ref type="bibr">Shanghai (19ZR1404800)</ref> </p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 Details of the Benchmark Systems</head><p>1. MNIST: The first case is training a fully connected feedforward neural network for the hand-written digital classification task on the MNIST dataset <ref type="bibr" target="#b38">[39]</ref>, with 50 workers. This public dataset contains 60000 28 × 28 images of 10 digits for training and 10000 for testing. Each worker shares a copy of the training set. The model consists of 784 inputs, 10 outputs with soft-max activation and one hidden layer with 30 rectified linear units (ReLu <ref type="bibr" target="#b35">[36]</ref>). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4 An Empirical Validation of the Analytic Results</head><p>Without loss of generality, we take Theorem 1 as an example. First, we explain the terms R, M, α and S one by one with more care and give the empirical values on Healthcare for demonstration. In general, our terminology follows the conventions in <ref type="bibr" target="#b12">[14]</ref>, a standard text on optimization theory.</p><p>• Diameter R: The diameter R of a parameter space Θ (i.e., the feasible set of parameters of the underlying learning model) is defined as the maximal 2-norm of an element θ ∈ Θ. Formally, R = sup{{θ 2 : θ ∈ Θ}. On Healthcare, we estimate the 2-norm of the flattened parameter of the neural network during the learning process to estimate as the scale of R, which is plotted in <ref type="figure">Fig. 11(a)</ref>. The average value of R is around 11.05.</p><p>• Upper bound of gradient norm M: The term M is used to denote the upper bound of the gradient norm. Formally, M = sup θ∈Θ ∇ θ ˆ f (θ, D train ) 2 . On Healthcare task, we compute the 2-norm of the gradient submitted by the always-benign worker during the learning process to estimate the scale of M, which is plotted in <ref type="figure">Fig. 11(b)</ref>. The average value of M is around 0.36.</p><p>• Smoothness factor η: The term η occurs in our assumption that the loss function f is η-smooth. Formally, the loss function f is said to be η-smooth if</p><p>We estimate the empirical scale of α by calculating the expressions at both sides of the definition during the learning process, which is plotted in <ref type="figure">Fig. 11(c)</ref>. The average value of η is around 0.50.</p><p>• Size of mini-batch S: The term S denotes the training size of the mini-batch on which the always-benign worker calculates the gradient. In addition, S is required to be no less than 1 (i.e., the training set contains at least one sample) or otherwise the theorem is invalid. On Healthcare, S is set as 256.</p><p>• Finally, the max-norm of the loss function (which is implemented as a cross-entropy) is upper bound by the maximal entropy of the K-class classification task (i.e., f ∞ ≤</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<ptr target="https://www.cms.gov/Research-Statistics-Data-and-Systems/" />
		<title level="m">Statistics-Trends-and-Reports/MedicareProvider-Charge-Data/Physician-and-OtherSupplier2016.html. Accessed</title>
		<imprint>
			<biblScope unit="page" from="2019" to="2028" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Tensorflow: a system for large-scale machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martín</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianmin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andy</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Devin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjay</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Irving</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Isard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">OSDI</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Byzantine stochastic gradient descent</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Alistarh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeyuan</forename><surname>Allen-Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jerry</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Yiqing Hua, Deborah Estrin, and Vitaly Shmatikov. How to backdoor federated learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Bagdasaryan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Veit</surname></persName>
		</author>
		<idno>1807.00459</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A little is enough: Circumventing defenses for distributed learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moran</forename><surname>Baruch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gilad</forename><surname>Baruch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<biblScope unit="page">6156</biblScope>
			<date type="published" when="1902" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Analyzing federated learning through an adversarial lens</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Supriyo</forename><surname>Arjun Nitin Bhagoji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chakraborty</surname></persName>
		</author>
		<idno>1811.12470</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint/>
	</monogr>
	<note>Prateek Mittal, and Seraphin Calo</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Prateek Mittal, and Seraphin B. Calo. Analyzing federated learning through an adversarial lens</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Supriyo</forename><surname>Arjun Nitin Bhagoji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chakraborty</surname></persName>
		</author>
		<idno>1811.12470</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Poisoning attacks against support vector machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Battista</forename><surname>Biggio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Blaine</forename><surname>Nelson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><surname>Laskov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Pattern recognition and machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nasser</forename><forename type="middle">M</forename><surname>Bishop</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nasrabadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Electronic Imaging</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Machine learning with adversaries: Byzantine tolerant gradient descent</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peva</forename><surname>Blanchard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rachid</forename><surname>Guerraoui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Stainer</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Online learning and stochastic approximations. On-line learning in neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Convex optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Boyd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lieven</forename><surname>Vandenberghe</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<publisher>Cambridge university press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sébastien</forename><surname>Bubeck</surname></persName>
		</author>
		<title level="m">Convex optimization: Algorithms and complexity. Foundations and Trends® in Machine Learning</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Draco: byzantine-resilient distributed training via redundant gradients</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingjiao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Charles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitris</forename><surname>Papailiopoulos</surname></persName>
		</author>
		<idno>1803.09877</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Distributed statistical machine learning in adversarial settings: Byzantine gradient descent</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yudong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lili</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaming</forename><surname>Xu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>POMACS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Emnist: Extending mnist to handwritten letters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saeed</forename><surname>Afshar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Tapson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">André</forename><surname>Van Schaik</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Geometric median in nearly linear time</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yin Tat</forename><surname>Michael B Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gary</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakub</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Pachocki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sidford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">STOC</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Torch: a modular machine learning software library</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johnny</forename><surname>Mariéthoz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Asynchronous byzantine machine learning (the case of sgd)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios</forename><surname>Damaskinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>El Mahdi El</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rachid</forename><surname>Mhamdi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rhicheek</forename><surname>Guerraoui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mahsa</forename><surname>Patra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Taziki</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Arxiv</surname></persName>
		</author>
		<idno>1802.07928</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Practical byzantine fault tolerance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miguel Oom Temudo De</forename><surname>Castro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">OSDI</title>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Large scale distributed deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajat</forename><surname>Monga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Devin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Senior</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Tucker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno>1810.04805</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Advances and open problems in federated learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Kairouz</surname></persName>
		</author>
		<idno>1912.04977</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Local model poisoning attacks to byzantine-robust federated learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minghong</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyu</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinyuan</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil</forename><forename type="middle">Zhenqiang</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="1911" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Model inversion attacks that exploit confidence information and basic countermeasures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Fredrikson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Somesh</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Ristenpart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CCS</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Approximation of dynamical systems by continuous time recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ken-Ichi</forename><surname>Funahashi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuichi</forename><surname>Nakamura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural networks</title>
		<imprint>
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Mitigating sybils in federated learning poisoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clement</forename><surname>Fung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Chris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Beschastnikh</surname></persName>
		</author>
		<idno>1808.04866</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Large-scale matrix factorization with distributed stochastic gradient descent</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rainer</forename><surname>Gemulla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><surname>Nijkamp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><forename type="middle">J</forename><surname>Haas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yannis</forename><surname>Sismanis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Explaining and harnessing adversarial examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<idno>1412.6572</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">The hidden vulnerability of distributed learning in byzantium</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rachid</forename><surname>Guerraoui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sébastien</forename><surname>Rouault</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Gpipe: Efficient training of giant neural networks using pipeline parallelism</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanping</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonglong</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dehao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyoukjoong</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiquan</forename><surname>Ngiam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Chen</surname></persName>
		</author>
		<idno>1811.06965</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Federated learning: Strategies for improving communication efficiency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakub</forename><surname>Konečn`konečn`y, H Brendan Mcmahan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><forename type="middle">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Richtárik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ananda</forename><forename type="middle">Theertha</forename><surname>Suresh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dave</forename><surname>Bacon</surname></persName>
		</author>
		<idno>1610.05492</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In NeurIPS</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">The byzantine generals problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leslie</forename><surname>Lamport</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Shostak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marshall</forename><surname>Pease</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TOPLAS</title>
		<imprint>
			<date type="published" when="1982" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE</title>
		<meeting>the IEEE</meeting>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Measuring the intrinsic dimension of objective landscapes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunyuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heerad</forename><surname>Farkhoor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rosanne</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Yosinski</surname></persName>
		</author>
		<idno>1804.08838</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Communication efficient distributed machine learning with the parameter server</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">J</forename><surname>Andersen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yu</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Asynchronous parallel stochastic gradient for nonconvex optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangru</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yijun</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuncheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ji</forename><surname>Liu</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Communication-efficient learning of deep networks from decentralized data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eider</forename><surname>H Brendan Mcmahan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seth</forename><surname>Ramage</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hampson</surname></persName>
		</author>
		<idno>1602.05629</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Exploiting unintended feature leakage in collaborative learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Melis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Congzheng</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emiliano</forename><surname>De Cristofaro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vitaly</forename><surname>Shmatikov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">S &amp; P</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">A taxonomy of ddos attack and ddos defense mechanisms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jelena</forename><surname>Mirkovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Reiher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGCOMM Computer Communication Review</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Consensus computation in unreliable networks: A system theoretic approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabio</forename><surname>Pasqualetti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Bicchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francesco</forename><surname>Bullo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Automatic Control</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">A stochastic approximation method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herbert</forename><surname>Robbins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sutton</forename><surname>Monro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Herbert Robbins Selected Papers</title>
		<imprint>
			<date type="published" when="1985" />
			<biblScope unit="page" from="102" to="109" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Multivariate estimation with high breakdown point</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Peter J Rousseeuw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Mathematical statistics and applications</title>
		<imprint>
			<date type="published" when="1985" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Updates-leak: Data set inference and reconstruction attacks in online learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmed</forename><surname>Salem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Apratim</forename><surname>Bhattacharyya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Backes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mario</forename><surname>Fritz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="1067" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Communication-efficient distributed optimization using an approximate newton-type method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ohad</forename><surname>Shamir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nati</forename><surname>Srebro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Membership inference attacks against machine learning models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reza</forename><surname>Shokri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Stronati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Congzheng</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vitaly</forename><surname>Shmatikov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Mastering the game of go with deep neural networks and tree search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aja</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><forename type="middle">J</forename><surname>Maddison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><surname>Guez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Sifre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Driessche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ioannis</forename><surname>Schrittwieser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Veda</forename><surname>Antonoglou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Panneershelvam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lanctot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Reinforcement learning: An introduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">G</forename><surname>Richard S Sutton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francis</forename><surname>Barto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bach</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Policy gradient methods for reinforcement learning with function approximation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">A</forename><surname>Richard S Sutton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mcallester</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Satinder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yishay</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mansour</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">Distributed systems: principles and paradigms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maarten</forename><surname>Tanenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Van Steen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<publisher>PrenticeHall</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Distributed asynchronous deterministic and stochastic gradient optimization algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">N</forename><surname>Tsitsiklis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitri</forename><forename type="middle">P</forename><surname>Bertsekas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Athans</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1984" />
			<publisher>American Control Conference</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">Q-learning. Machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jch</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Watkins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dayan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">Weak convergence and empirical processes: with applications to statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jon</forename><surname>Wellner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<publisher>Springer Science &amp; Business Media</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Backpropagation through time: what it does and how to do it</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Paul J Werbos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE</title>
		<meeting>the IEEE</meeting>
		<imprint>
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Zeno: Distributed stochastic gradient descent with suspicion-based fault-tolerance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cong</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oluwasanmi</forename><surname>Koyejo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Indranil</forename><surname>Gupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">Federated machine learning: Concept and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianjian</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongxin</forename><surname>Tong</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>TIST</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yudong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kannan</forename><surname>Ramchandran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Bartlett</surname></persName>
		</author>
		<idno>1803.01498</idno>
		<title level="m">Byzantine-robust distributed learning: Towards optimal statistical rates. ArXiv</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Deep learning with elastic averaging sgd</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sixin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Choromanska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m" type="main">Parallelized stochastic gradient descent</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Zinkevich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Weimer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lihong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
