<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2020-09-29T02:34+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Unioning of the Buffer Cache and Journaling Layers with Non-volatile Memory</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eunji</forename><surname>Lee</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Ewha University</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyokyung</forename><surname>Bahn</surname></persName>
							<email>bahn@ewha.ac.kr</email>
							<affiliation key="aff0">
								<orgName type="institution">Ewha University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><forename type="middle">H</forename><surname>Noh</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Hongik University</orgName>
								<address>
									<settlement>http</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Unioning of the Buffer Cache and Journaling Layers with Non-volatile Memory</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Journaling techniques are widely used in modern file systems as they provide high reliability and fast recovery from system failures. However, it reduces the performance benefit of buffer caching as journaling accounts for a bulk of the storage writes in real system environments. In this paper, we present a novel buffer cache architecture that subsumes the functionality of caching and journaling by making use of non-volatile memory such as PCM or STT-MRAM. Specifically, our buffer cache supports what we call the in-place commit scheme. This scheme avoids logging, but still provides the same journaling effect by simply altering the state of the cached block to frozen. As a frozen block still performs the function of caching, we show that in-place commit does not degrade cache performance. We implement our scheme on Linux 2.6.38 and measure the throughput and execution time of the scheme with various file I/O benchmarks. The results show that our scheme improves I/O performance by 76% on average and up to 240% compared to the existing Linux buffer cache with ext4 without any loss of reliability.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Non-volatile memory such as PCM (phase-change memory) and STT-MRAM (spin torque transfer magnetic RAM) is being considered as a replacement for DRAM memory <ref type="bibr" target="#b0">[1]</ref><ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref><ref type="bibr" target="#b7">[8]</ref>. Though currently unfit for complete replacement due to cost, non-volatile memory has become a viable component that may be added to current systems to enhance performance <ref type="bibr">[9]</ref>. Temporary non-volatile memory solutions in the form of supercapacitor-supported DRAM are also finding its place in the server market <ref type="bibr">[10]</ref>. As non-volatile memory is expected to provide performance competitive to DRAM while retaining non-volatile characteristics, studies on exploiting these dual characteristics have recently been catching interest <ref type="bibr" target="#b0">[1]</ref><ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref><ref type="bibr" target="#b7">[8]</ref>. This paper also exploits the nonvolatile characteristic of these new memory technologies through marriage of the buffer cache and journaling layers. We believe, to the best of our knowledge, that our work is the first to propose such a union.</p><p>In traditional systems, as main memory is volatile, the file system may enter an inconsistent and/or out-of-date state upon sudden system crashes <ref type="bibr" target="#b8">[11]</ref>. To relieve this problem, journaling, which is a technique that logs the updates to non-volatile storage within a short time period for high reliability and fast system recovery, is widely adopted in modern file systems <ref type="bibr" target="#b9">[12]</ref>. However, journaling is a serious impediment to high performance due to its frequent storage accesses. For example, a recent study has shown that synchronous writes due to journaling dominates storage traffic in mobile handheld devices leading to severe slowdown of flash storage <ref type="bibr" target="#b10">[13]</ref>. In cloud storage systems, even though there is a consensus that journaling is necessary, it is not deployed due to the high cost of network accesses involved in journaling <ref type="bibr" target="#b11">[14]</ref>. In this study, we present a novel buffer cache architecture that removes almost all storage accesses due to journaling without any loss of reliability by intelligently adopting non-volatile memory as the buffer cache.</p><p>At first glance, simply adopting a non-volatile buffer cache may seem to be enough to provide a highly reliable file system. However, this is not the case as there are two requirements that are needed to support reliability in file systems: durability and consistency. A nonvolatile buffer cache, simply as is, ensures durability as it maintains data even after a power failure. However, consistency cannot be guaranteed upon system crashes just by providing non-volatility to the buffer cache. Take, for example, a typical situation where a write operation requires both data and metadata updates but the system crashes after updating only metadata. Then, the data in the buffer cache loses consistency, eventually leading to an inconsistent file system state.</p><p>We propose a new buffer cache architecture, called UBJ (Union of Buffer cache and Journaling), that resolves this problem by providing the functionality of journaling without frequent storage accesses. Specifically, we propose In-place Commit, which changes the state of updated cache blocks to frozen (i.e., write protected) and manages them as a transaction right at where it is currently located. This scheme does not perform additional logging but simply reaps the same effect just by changing a state. Furthermore, as the block in the frozen state can still be used as a cache block, the effectiveness of the buffer cache is not deteriorated. <ref type="figure" target="#fig_0">Figure 1</ref> shows the commit process of our buffer cache compared to that of the existing buffer cache in conjunction with journaling.</p><p>Previous work most closely related to this study also attempts to relieve journaling overhead by adopting non-volatile memory for file system and database management <ref type="bibr" target="#b12">[15,</ref><ref type="bibr" target="#b13">16,</ref><ref type="bibr" target="#b14">17]</ref>. They improve performance by adding non-volatile memory as a separate journal area or as a write buffer of log files. However, in these schemes, the non-volatile memory cannot function as a cache and is kept separately from the buffer cache. Our scheme is different in that we intelligently union the journaling functionality into the buffer cache architecture, thereby minimizing additional memory copy and space overhead.</p><p>We have implemented a prototype of our buffer cache with in-place commit in Linux 2.6.38. Measurement results with various storage benchmarks show that our scheme improves file system performance by 76% on average and up to 240% compared to the existing Linux buffer cache with ext4 set to the journal mode.</p><p>The remainder of this paper is organized as follows. Section 2 investigates the effect of journaling on the write traffic of storage. Section 3 describes our buffer caching architecture and algorithm in detail. In Section 4, we discuss cache performance issues inherent in our scheme. Section 5 presents a brief description of the implementation and discusses the experimental results of the implementation. Section 6 concludes this paper. <ref type="figure" target="#fig_1">Figure 2</ref> shows the amount of write traffic from the buffer cache to storage when journaling is employed relative to when it is not for various workloads. <ref type="figure" target="#fig_1">As Fig- ure 2</ref> shows, write traffic increases dramatically when journaling is used; on average the data stored with journaling is 2.7 times more than that without journaling. When we do not use journaling, storage writes occur only when dirty blocks are evicted from the cache or when there is an explicit sync operation. However, with journaling, there are two more cases that cause storage writes. The first case is when a commit to the journal area occurs. The second case is when checkpointing, which writes the updated data to permanent file system locations, occurs. Checkpointing is triggered periodically and is also activated when the amount of free space in the journal area drops below a certain threshold.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Analysis of Storage Write Traffic</head><p>As we can see, journaling accounts for a considerable portion of storage writes for all workloads, and thus, is a potential source of performance degradation. As <ref type="figure" target="#fig_1">Fig- ure 2</ref> shows, however, our UBJ scheme performs journaling but eliminates most of its storage writes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Buffer Cache with In-place Commit</head><p>In UBJ, the buffer cache and the journal area share the same allocated space. Every block in this space functions either as a cache block, a log block, or a cache and log block at the same time when the block has dualpurpose. We can represent the state of each block as a combination of three state indicators: frozen/normal state, dirty/clean state, and up-to-date/out-of-date state (Refer to <ref type="figure">Figure 3</ref>). The frozen/normal state distinguishes whether the block is a (normal) cache block or a (frozen) log block. The dirty/clean state indicates whether the block has been modified since it entered the cache. The up-to-date/out-of-date state indicates whether the block is the most recent version or not. This last distinction is necessary as multiple blocks for the same data may exist in the buffer/journal space.</p><p>In the following, we use these states and the transitions between these states to describe the workings of UBJ. The scheme is described as three distinct operations: the read/write operations, the commit operation, and the checkpointing operation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Read/Write Operations</head><p>Reaction to a write request depends on the state of the block. If the block is normal, it is simply updated. Otherwise, that is, if it is frozen (a log block), a copy is made to a new location and the updated data is written to the copy. The copy then becomes up-to-date, while the original becomes out-of-date. This allows logged data to remain safe against system failures.</p><p>Read requests, on the other hand, are serviced irrespective of block state and do not alter the states of the block. This is because reading data does not affect the consistency of blocks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Commit Operations</head><p>As part of transaction management, UBJ periodically commits data by changing the state of normal dirty blocks to frozen dirty blocks. This is done by keeping and manipulating transactions maintained as lists. There are three types of transaction as shown in <ref type="figure" target="#fig_2">Figure 4</ref>. The first is a running transaction that maintains a list of normal dirty blocks that became dirty after the previous commit operation. When a commit operation is issued, this running transaction is converted to a commit transaction. At this point, the blocks on the commit transaction, which are in normal state, are committed in-place (hence, the name In-place Commit) simply by converting their state to frozen. New block writes arriving during this conversion process is simply added to a new running transaction created for the next commit period. During the state conversion process, UBJ also checks if the same data block had been committed before, and if so, keeps track of the previous block as an old-commit block. For efficient space management, these oldcommit blocks may be released immediately at this point. When all dirty data blocks in the commit transaction become frozen, we change the state of the transaction to a checkpoint transaction. The checkpoint transactions are maintained in the buffer cache until they are reflected onto the file system via checkpointing. Should a system crash occur, they are the ones used to recover the file system into a consistent and up-to-date state.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Checkpoint Operations</head><p>The checkpoint operation updates the file system with committed data. UBJ scans the checkpoint transaction lists and reflects them on to their permanent locations in the file system. When a single data block has been committed multiple times, only the last commit block is checkpointed in order to reduce checkpointing overhead. After a transaction checkpoint is completed, cache space occupied by frozen blocks is reclaimed. During this process, if the block is up-to-date, we reuse it as a buffer cache block by changing its state to normal and clean, and updating its associated metadata. On the other hand, if the block is out-of-date, the space is reclaimed as a free block.</p><p>While the commit operation is performed frequently to reduce the vulnerability window of reliability, checkpointing may be done less frequently as it does not directly affect system reliability. Nevertheless, excessive delay in checkpointing may have negative effects. As the interval between checkpointing grows, more and more cache space will be occupied by frozen blocks effectively reducing the buffer cache, potentially leading to degradation of buffer cache performance. To prevent this situation, our scheme triggers checkpointing   when the number of frozen blocks becomes larger than a certain threshold as is done with conventional journaling. Checkpointing is also triggered by the page reclamation daemon when it evicts dirty blocks from the cache. <ref type="figure">Figure 5</ref> shows the workings of UBJ in contrast to a typical buffer cache scheme. In this example, the commit and checkpointing periods are set to 30 and 90 seconds, respectively. The initial content of block A is D0. At time 10, a write request modifies the content of block A to D1, converting it into a dirty block. 20 seconds later, a commit occurs. To service the commit, UBJ simply changes the state of block A to frozen, whereas a typical buffer cache would incur a write to storage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Example</head><p>Suppose another write to block A occurs at time 40. UBJ at this point copies block A into another location A', and then writes the new data to location A'. Block A, then becomes out-of-date, while block A' is now up-todate. (We quantify the effect of having multiple copies of the same data block later.) Subsequent writes (write at time 50, in this example) are performed on block A' until it is committed and hence, frozen (at time 60). When checkpointing occurs at time 90, UBJ reflects only the latest version of block A', that is D3, into the file system eliminating unnecessary writes (D1 and D2). After checkpointing, space occupied by block A is reclaimed, while the up-to-date version of block A' is reused as normal buffer cache data.</p><p>In this example, we see that UBJ writes to storage only once when checkpointing, while a typical buffer cache scheme generates storage writes every time it commits or checkpoints. This results in writes of blocks that are eventually overwritten and did not need to be saved. In practice, as commits are much more frequent than checkpoints, the reduction in the number of storage writes can become substantial.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. System Recovery</head><p>System crashes incur inconsistency problems as data may remain partially updated in the buffer cache, the  journal area, and the file system. Hence, upon reboot from an abnormal termination, UBJ goes through the following steps for recovery. First, the running transaction list is checked. This list holds blocks that are residing in the buffer cache and may have been partially updated. However, since these are uncommitted data and thus, not reflected on the file system, we simply invalidate these blocks.</p><p>Next, we consider the commit transaction list. When a crash occurs in the middle of committing a transaction, the commit transaction list may be in a partially committed state containing a mixture of committed and stilluncommitted blocks. In this case, as the commit operation did not complete properly, UBJ simply invalidates the data in the same way as it did with the running transaction list. Finally, the system state is made consistent by making use of the checkpointing transactions. Even though the file system may be corrupted if a crash occurs while executing checkpoint operations, the system can be restored to a consistent state simply by redoing the operation as all the checkpoint transactions still reside in the buffer cache.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Cache Performance</head><p>As our scheme holds log blocks in the buffer cache, a single data block may occupy multiple cache blocks, degrading the space efficiency of the buffer cache. To investigate this effect, we compare the buffer cache miss ratio of the original buffer cache that is used only for caching and with no log blocks (BF-no) and UBJ, where cache and journal space is in union. In addition, for comparison purposes, we also observe the miss ratio of a hypothetical scheme that uses half of its allocated memory space as a dedicated buffer cache and the other half as a dedicated journal area. We will call this scheme buffer caching with in-memory journaling <ref type="bibr">(BF- Jm)</ref>. This scheme works just like conventional journaling, except for the fact that the journal area is not in storage but in memory, possibly non-volatile memory. <ref type="figure" target="#fig_4">Figure 6</ref> plots the cache miss ratio of the three buffer cache schemes for the Filebench benchmark, which is a representative file system benchmark. <ref type="table" target="#tab_1">Table 1</ref> summarizes the characteristics of the Filebench workloads used in this paper.</p><p>We vary the cache size from 0.1 (10%) to 2.0 (200%) relative to the I/O footprint. Generally, the cache size of 1.0 is identical to infinite cache capacity since the cache will simultaneously accommodate all block references of the trace. However, as UBJ and BF-Jm use a certain portion of the buffer cache space for the journal area, cache size of 1.0 may be insufficient to accommodate all the requests. For BF-Jm, which dedicates half of the total space to the buffer cache and the other half to the journal area, a cache size of 2.0 is equivalent to infinite cache capacity. Moreover, to monitor the worst case performance degradation of UBJ, we delay checkpointing of frozen log blocks until they are selected as victims by the cache replacement policy.</p><p>The results shown in <ref type="figure" target="#fig_4">Figure 6</ref> reveals that the cache performance of UBJ exhibits only marginal degradation compared to that of BF-no, while performance of BFJm degrades significantly. To understand this more clearly, we also plot in <ref type="figure" target="#fig_5">Figure 7</ref> the portion of the buffer/journal space occupied by frozen blocks when the cache size is 0.7 (70%) of the workload footprint, which is where the performance gap between UBJ and BF-Jm is largest.</p><p>We observe that UBJ uses a substantial portion of the buffer/journal space for the journal area for all workloads. This results in read requests being serviced by these frozen blocks. As <ref type="figure">Figure 8</ref> shows, roughly 16% to 48% of all hits occur in the journal area for UBJ. In contrast, schemes like BF-Jm that simply dedicate (nonvolatile) journal space cannot take advantage of the data that resides there. <ref type="figure">Figure 9</ref> plots the ratio of journal </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Performance Evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Implementation</head><p>We implemented a UBJ prototype on Linux 2.6.38. We compare our scheme with ext4 that runs on the original Linux (BF-ext4). We set the journaling option of ext4 to journal-mode, which logs both data and metadata, to provide the same consistency semantics as UBJ. According to conventional configurations, the commit period is set to five seconds for both schemes; checkpointing is triggered when a fourth of the journal area is filled or five minutes have elapsed since the last checkpointing time. For better space efficiency, we adopt the early reclamation policy that releases old versions of frozen log blocks, that is, old-commit blocks, immediately when a recent commit version of the same data block is generated.</p><p>Our experimental platform consists of the Intel Core i3-2100 CPU running at 3.1GHz and 4GB of DDR2-800 memory. Though our design assumes non-volatile main memory like PCM or STT-MRAM, as it is not yet commercially available, we simply use a portion of the DRAM as buffer/journal space. We measure the performance with three representative storage benchmarks: Filebench <ref type="bibr" target="#b15">[18]</ref>, IOzone <ref type="bibr" target="#b16">[19]</ref>, and Postmark <ref type="bibr" target="#b17">[20]</ref>. <ref type="figure" target="#fig_0">Figure 10</ref> shows the execution time and the throughput of UBJ compared to BF-ext4 for the Filebench workloads. As shown in the figure, UBJ performs better than BF-ext4 for all workloads. The execution time and throughput of UBJ is better than BF-ext4 by 30.7% and 59.8% on average. Specifically, the performance improvement of varmail is the largest among the four workloads, which is 60% and 240%, respectively, in execution time and throughput. The reason behind such large improvements is that varmail contains a large number of write requests, thus incurring frequent commits (though checkpointing is not performed frequently due to its small memory footprint). Moreover, varmail issues read and write requests concurrently. Though our scheme does not have an explicit policy to improve read performance, eliminating frequent storage writes relieves the contention to hardware resources like the memory bus and DMAs, leading to improvements in I/O performance in general. Even for read-intensive workloads like webserver and proxy, UBJ improves performance by 23% and 11%, respectively, due to this reason. For fileserver, which is write-intensive, the improvement of our scheme is relatively small compared to varmail. This is because most write requests in file-  server are large and sequential writes, which leads to frequent checkpointing. <ref type="figure" target="#fig_0">Figure 11</ref> shows the throughput of UBJ and BF-ext4 for the IOzone benchmark. IOzone measures file I/O performance by generating particular types of operations in batches. It creates a single large file and performs a series of operations on that file. We measure the performance with two IOzone scenarios, random write and sequential write, varying the total fileset sizes ranging from 100MB to 300MB.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Experimental Results</head><p>As the figure shows, UBJ outperforms BF-ext4 in all configurations. Specifically, the performance improvement is 2.1 times on average. The source of this enhancement is the large reduction in storage writes achieved by in-place commit. Note also that UBJ performs better relative to BF-ext4 as the fileset size is reduced. This is because with smaller fileset size checkpointing is done less frequently leading to reduced storage accesses. Unlike UBJ, BF-ext4 is less sensitive to the fileset size. This is because the performance of BFext4 is dominated by the number of commits, which is independent of the fileset size.</p><p>Another observation that can be made with IOzone is that UBJ is more sensitive to the fileset size for random writes. This is because random writes are largely affected by seek times as checkpointing for random accesses incur large seek overhead to move the disk head to the requested location. <ref type="figure" target="#fig_0">Figure 12</ref> shows the throughput for the Postmark benchmark. Postmark emulates an email server that concurrently performs read and write operations. The benchmark reports separate performance numbers for read and write operations. We vary the number of Postmark transactions from 2,000 to 10,000 on 1,000 files, whose average size is 500KB. As shown in the figure, UBJ exhibits 109% better throughput than BFext4 on average. Note that read operation throughput also improves due to the reduced storage writes. We also observe that the performance improvement of UBJ decreases as the number of transactions increases. Similarly to IOzone, this is because with a larger number of transactions UBJ increases checkpointing, while keeping other factors constant. Hence, the relative performance gap between UBJ and BF-ext4 is reduced.</p><p>Finally, we see how the performance of UBJ is affected as the commit period changes. <ref type="figure" target="#fig_0">Figure 13</ref> shows the latency per operation for the varmail workload. As we can see, the latency of BF-ext4 becomes small as the commit period changes from 1 to 5 seconds. This is because storage writes become less frequent. This, of course, increases the window of vulnerability for BFext4. In contrast, the latency of UBJ is not sensitive to the commit period as the overhead of commit is very small in UBJ. This result indicates that UBJ can shorten the window of vulnerability without sacrificing performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>In this paper, we presented a novel buffer cache architecture that subsumes the function of caching and journaling in a unified non-volatile memory space. Specifically, blocks in the buffer cache are converted to journal logs through what we call In-place Commit. Inplace Commit simply changes the state of cached block from a normal state to a frozen state. By so doing, it reaps the same effect as journaling. Furthermore as the block in frozen state can still be used as a cache block the effectiveness of the buffer cache is not deteriorated. Based on In-place Commit, we implement UBJ (Union of Buffer cache and Journaling) on Linux 2.6.38. Measurement studies showed that UBJ significantly improves file I/O performance compared to the existing Linux ext4 journaling scheme without any loss of reliability. The effectiveness of UBJ will increase in environments such as cloud storage and networked storage systems where storage access cost are higher. We are planning to extend our scheme to this area in the near future. (No.10041608, Embedded System Software for Newmemory based Smart Devices.) Hyokyung Bahn is the corresponding author of this paper. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Commit process of our buffer cache compared to the original buffer cache with journaling.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Write traffic with journaling and our proposed scheme (UBJ) relative to when journaling is not used (denoted nojournal) for various workloads.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4</head><label>4</label><figDesc>Fig. 4 Data structures for UBJ.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Fig. 5 Comparison of our UBJ scheme and the original buffer cache with journaling</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 6</head><label>6</label><figDesc>Fig. 6 Cache miss ratio as a function of the cache size.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Ratio of journal area for each Filebench workload Fig. 8. Hit counts for frozen blocks for the Filebench workload. Fig. 9. Change of the journal area size as time progresses for the fileserver workload</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. Throughput and execution time of the Filebench workloads. Fig. 11. Throughput of IOzone as the fileset size is varied. Fig. 12. Throughput of Postmark as the number of transactions is varied.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 13 .</head><label>13</label><figDesc>Fig. 13. Latency of varmail varying the commit period</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 1 .</head><label>1</label><figDesc></figDesc><table>Summary of workload characteristics 

workload 
avg. 
file 
size 

# of 
files 

avg. 
op. 
size 

# of 
ops. 
r:w 
ratio 

Varmail 
16KB 
1,000 
4KB 
6,638K 
1:1 

Proxy 
16KB 
10,000 
5KB 
6,723K 
5:1 

Webserver 
16KB 
1,000 
14KB 
6,432K 
10:1 

Fileserver 
128KB 1,000 
72KB 
6,843K 
1:2 

</table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We would like to thank our shepherd Anna Povzner and the anonymous reviewers for their insight and suggestions for improvement. </p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Operating system support for NVM+DRAM hybrid main memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Mogul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Argollo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Faraboschi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th USENIX Workshop on Hot Topics in Operating Systems (HotOS)</title>
		<meeting>the 12th USENIX Workshop on Hot Topics in Operating Systems (HotOS)</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Scalable high performance main memory system using phase-change memory technology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">K</forename><surname>Qureshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Rivers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th ACM/IEEE International Symposium on Computer Architecture (ISCA)</title>
		<meeting>the 36th ACM/IEEE International Symposium on Computer Architecture (ISCA)</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Phase change memory architecture and the quest for scalability</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">C</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ipek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Mutlu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Burger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="99" to="106" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Characterizing memory write references for efficient management of hybrid PCM and DRAM memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">H</forename><surname>Noh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th IEEE International Symposium on Modeling, Analysis, and Simulation of Computer and Telecommunication Systems (MASCOTS)</title>
		<meeting>the 19th IEEE International Symposium on Modeling, Analysis, and Simulation of Computer and Telecommunication Systems (MASCOTS)</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="168" to="175" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A durable and energy efficient main memory using phase change memory technology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th ACM/IEEE International Symposium on Computer Architecture (ISCA)</title>
		<meeting>the 36th ACM/IEEE International Symposium on Computer Architecture (ISCA)</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Architecting phase change memory as a scalable DRAM alternative</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">C</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ipek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Mutlu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Burger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th ACM/IEEE International Symposium on Computer Architecture (ISCA)</title>
		<meeting>the 36th ACM/IEEE International Symposium on Computer Architecture (ISCA)</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Dynamically replicated memory: building reliable systems from nanoscale resistive memories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ipek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Condit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">B</forename><surname>Nightingale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Burger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Moscibroda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th ACM International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS)</title>
		<meeting>the 15th ACM International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS)</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Better I/O through byte-addressable, persistent memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Condit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">B</forename><surname>Nightingale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Frost</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ipek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Burger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Coetzee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM Symposium on Operating Systems Principles (SOSP)</title>
		<meeting>the 22nd ACM Symposium on Operating Systems Principles (SOSP)</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The Rio file cache: Surviving Operating System Crashes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">T</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chandra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Aycock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Rajamani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lowell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th ACM International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS)</title>
		<meeting>the 7th ACM International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS)</meeting>
		<imprint>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Analysis and evolution of journaling file systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Prabhakaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Arpaci-Dusseau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">H</forename><surname>Arpaci-Dusseau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the USE-NIX Annual Technical Conference (ATC)</title>
		<meeting>the USE-NIX Annual Technical Conference (ATC)</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Revisiting storage for smartphones</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ungureanu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th USENIX File and Storage Technologies (FAST)</title>
		<meeting>the 10th USENIX File and Storage Technologies (FAST)</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Linux Foundation Collaboration Summit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rubin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
	<note>File systems in the Cloud</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Zumastor linux storage server</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Phillips</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Linux Symposium</title>
		<meeting>the Linux Symposium</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="135" to="143" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">High performance database logging using storage class memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hsiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Mohan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th IEEE International Conference on Data Engineering (ICDE)</title>
		<meeting>the 27th IEEE International Conference on Data Engineering (ICDE)</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="11" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Design and Implementation of Transactional Write Buffer Cache with Storage Class Memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">H</forename><surname>Doh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">H</forename><surname>Noh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Korean Institute of Information Scientists and Engineers</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="247" to="251" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Norcutt</surname></persName>
		</author>
		<ptr target="http://www.iozone.org/" />
		<title level="m">IOzone Filesystem Benchmark</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Postmark: a new file system benchmark</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Katcher</surname></persName>
		</author>
		<idno>TR-3022</idno>
	</analytic>
	<monogr>
		<title level="j">Network Appliances</title>
		<imprint>
			<date type="published" when="1997" />
		</imprint>
	</monogr>
<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Filebench</surname></persName>
		</author>
		<ptr target="http://www.solarisinternals.com/wiki/index.php/FileBench" />
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
