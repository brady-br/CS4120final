<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2020-09-29T02:58+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Reinforcement Learning-Based SLC Cache Technique for Enhancing SSD Write Performance</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sangjin</forename><surname>Yoo</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Sungkyunkwan University</orgName>
								<address>
									<settlement>Samsung Electronics</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongkun</forename><surname>Shin</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Sungkyunkwan University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Reinforcement Learning-Based SLC Cache Technique for Enhancing SSD Write Performance</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Although quad-level-cell (QLC) NAND flash memory can provide high density, its lower write performance and endurance compared to triple-level-cell (TLC) flash memory are critical obstacles to the proliferation of QLC flash memory. To overcome such drawbacks of QLC flash memory, hybrid architectures, which program a part of QLC blocks in the single-level-cell (SLC) mode and utilize the blocks as a cache of remaining QLC blocks, are widely adopted in the commercial solid-state disks (SSDs). However, it is challenging to optimize various parameters of hybrid SSDs such as the SLC cache size and the hot/cold separation threshold. In particular, the parameters must be adjusted dynamically by monitoring the change on I/O workloads. However, current techniques use fixed parameters determined heuristically. This paper proposes a reinforcement learning-based SLC cache management technique. By observing workload pattern and internal status of hybrid SSD, it determines the optimal SLC cache parameters maximizing the efficiency of hybrid SSD. Experimental results show that the proposed technique improves write throughput and write amplification factor by 77.6% and 20.3% on average, respectively, over the previous techniques.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Recently, quad-level-cell (QLC) NAND flash memory, which can store four bits per cell, is becoming a mainstream storage medium of solid-state drives (SSDs). QLC flash memory has a higher density, and lower cost compared to single-level-cell (SLC) or triple-level-cell (TLC) flash memories. However, QLC flash memory has slower performance and lower endurance than its previous generation memories, as shown in <ref type="table" target="#tab_0">Table 1</ref>. In order to hide the slow performance of QLC flash memory, most recent QLC-based SSDs adopt a hybrid SSD architecture which has a partitioned SLC region. The flash blocks in the SLC region are programmed in the SLC mode (i.e., they store only one bit per cell.), and thus they provide a shorter access latency than QLC blocks. The SLC region is utilized as a cache space of the remaining QLC region. By writing frequently-updated data at the SLC region, the overall performance of hybrid SSD can be improved.</p><p>In order to design a hybrid SSD, two important factors must be determined. The first is the size of the SLC region, which must be determined considering the trade-off between capacity loss and SLC-to-QLC block migration overhead. Since the capacity of an SLC block is smaller than that of a QLC block, the total capacity of SSD is reduced as more flash blocks are allocated to the SLC region. On the contrary, a too small SLC region will result in high migration costs while increasing the latency of write requests and the write amplification ratio. This is because the data in the SLC region must be migrated to the QLC region when the free blocks in the SLC region are insufficient.</p><p>The second factor is the hot/cold separation threshold. Considering the SLC-to-QLC migration cost, it is better to write only frequently-updated data (hot data) at the SLC region. Other cold data need to be sent directly to the QLC region. To discriminate between hot data and cold data, the hybrid SSD needs to observe several factors of write requests such as data size, target address, and update frequency. A widely used simple heuristic approach is to use the data size since small data tend to be frequently-updated <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b9">10]</ref>. If the data size is smaller than a threshold, the data can be regarded as hot data. As a lower threshold is used, the write traffic to the SLC region decreases, and thus the SLC-to-QLC migration cost also decreases. However, more number of write requests will be sent to the QLC region, resulting in the overall write performance degradation. Therefore, the SLC cache size and the hot/cold separation threshold must be determined by considering the workload patterns and the internal behavior of hybrid SSD such as migration cost. Besides, these factors must be adjusted according to the system state change.</p><p>However, the existing techniques use heuristicallydetermined fixed design factors and do not adjust the factors at run time. In this paper, we propose a reinforcement learning (RL)-based SLC cache management technique for hybrid SSDs. To the best of our knowledge, our technique is the first </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">BACKGROUND AND MOTIVATION</head><p>2.1 Hybrid SSD Architecture <ref type="figure" target="#fig_0">Figure 1</ref> shows a typical hybrid SSD architecture. As mentioned before, the flash blocks are divided into an SLC region and a QLC region. The key parameters, which have a strong influence on the write performance, are the hot/cold separation threshold (θ) and the SLC region size. The write requests with the data size not larger than θ are sent to the SLC region, whereas other requests are sent to the QLC region. Some old data in the SLC region can be migrated into the QLC region when the free space in the SLC region is insufficient. According to the SLC region management scheme, there are two types of hybrid SSDs: static scheme and dynamic scheme. While the static scheme maintains a fixed size of SLC region and a fixed hot/cold threshold <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b7">8]</ref>, the dynamic scheme can adjust the SLC region parameters depending on the system states such as amount of stored data, I/O access pattern, and garbage collection cost <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b12">13]</ref>.</p><p>Recently, several QLC SSD products began to adopt the dynamic scheme-based hybrid SSD architecture <ref type="bibr" target="#b0">[1]</ref><ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref>. They use a simple technique to adjust the SLC cache size. A proper SLC region size for a given storage utilization is investigated at offline with representative workloads. At run time, the SLC region size is adjusted by referring to the offline result as the storage utilization changes. Therefore, their performance can be degraded under unexamined or variable workloads.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Motivation</head><p>To observe the problem of the current dynamic hybrid SSDs, we performed experiments with our own trace-driven hybrid SSD simulator. Two real-world workloads were used: PC and YCSB-A. The PC workload trace was collected at Windows  10-based desktop, and it includes a larger number frequentlyupdated data compared to the YCSB-A database workload <ref type="bibr" target="#b4">[5]</ref>.</p><p>The total capacity of the SSD was set to 32 GB. We examined the hybrid SSD performance with two different SLC cache setting policies, as shown in <ref type="table" target="#tab_1">Table 2</ref>, each of which uses different SLC cache sizes at different storage utilizations. The data of Setting 1 are originated from a commercial SSD <ref type="bibr" target="#b2">[3]</ref>. Setting 1 (S1) utilizes the SLC cache more aggressively than Setting 2 (S2). The hot/cold separation thresholds (θ) of Setting 1 and Setting 2 are 64KB and 16KB, respectively. <ref type="figure" target="#fig_1">Figure 2</ref> compares the total I/O execution times under different policies and different space utilization values. The execution time is divided into four parts based on write type: host writes to SLC cache (SLC), host writes to QLC region (QLC), SLC-to-QLC migrations (SLC-to-QLC), and garbage collections within QLC region (QLC-to-QLC). From the results, we can know that the better policy between Setting 1 and Setting 2 is different depending on the workload and the storage utilization. For example, in the PC workload, when the initial storage is empty (i.e., the utilization is 0%), Setting 1 shows a better result than Setting 2 since many write requests are serviced at the SLC region without significant SLC-to-QLC migration overhead. However, when the utilization is high, Setting 1 shows a worse result due to high migration cost. In the YCSB-A workload, Setting 1 shows a worse result at low utilization. Since Setting 1 allocates more flash blocks to the SLC region, the capacity of the QLC region is small. Therefore, the QLC garbage collection cost increases.</p><p>Consequently, we need a more intelligent algorithm to adjust the SLC cache configuration considering the dynamically changing system states. The traditional adaptive control algorithms could be a solution. However, it is hard to design and tune an algorithm which can effectively handle the various system states of hybrid SSD under dynamically changing user workloads. We adopt a reinforcement learning (RL)-based method. Without any prior knowledge about user workload or storage characteristics, the RL-based approach can learn how to find the optimal management policy. Therefore, it can be used for any user scenarios and any storage products.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Reinforcement Learning and its Applicability to Dynamic SLC Cache</head><p>In reinforcement learning, an agent learns to act optimally through observations and rewards from the environment. The purpose of reinforcement learning is to choose the action that maximizes cumulative reward. We employ Q-learning, which is a widely used reinforcement technique <ref type="bibr" target="#b10">[11]</ref>. In Q-learning, the agent calculates Q-values that tell the agent which action is right in a given state. The agent chooses an action a in any given state s, and observes the reward r and the next state s . Then, the Q-value is updated as follows:</p><formula xml:id="formula_0">Q(s, a) = Q(s, a) + α(r + γ max a Q(s , a ) − Q(s, a)) (1)</formula><p>where α and γ are the learning rate and the discount factor, respectively, a is the action in the next state s . The Q-learning maintains a key data structure, called Q-table, to store Q(s, a).</p><p>The size (# of entries) of Q-table is # of states × # of actions. We employ the ε-greedy algorithm for exploration that can maximize the total reward in the long time interval. In Equation (2), ε is a probability between 0 and 1. The agent mostly selects the action a * in a given state s by exploiting the learned policy. At a low probability of ε, the agent selects a random action to explore the optimal policy of the changing environment. We set ε to 0.07 in our experiments. <ref type="figure" target="#fig_2">Figure 3</ref> shows how the reinforcement learning can be applied to the dynamic SLC cache. At each time step, the agent, i.e., the SLC cache manager, selects an action A t including the changes of the SLC cache size and the hot/cold separation threshold. The environment defines the state S t based on the workload characteristics and the internal status of the SSD, and estimates the reward R t for the previous action. 3 RL-based Dynamic SLC Cache</p><formula xml:id="formula_1">π(s) = a * = arg max a Q(s, a), 1 − ε a = a * , ε<label>(2)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Overall Algorithm</head><p>The proposed RL-based technique takes an action at every time step. Each time step is defined as a predetermined cumulative amount of host write requests. The size of time step interval determines the sensitivity of the agent's reaction. If the interval is too short, the agent cannot observe meaningful changes on the system states. On the contrary, the agent will miss state changes when the interval is too long. To observe the change on SLC-to-QLC migration cost, each time step is configured to the size of eight SLC blocks in our implementation. Algorithm 1 shows the pseudo-code of the proposed SLC cache management, which is called at every time step. The current state S t , the previous state S t−1 , and the previous action A t−1 are inputs. The algorithm chooses the action A t for the current state S t by calling GetAction(), which returns the action A which maximizes Q(S t , A) for the given S t , by referring to the Q-table. The selected action A t includes the adjustment on SLC cache size and hot/cold separation threshold. After performing the action A t , the agent checks the reward of the previous action A t−1 in GetReward() function. Finally, the agent updates Q(S t−1 , A t−1 ) in the Q-table by using Equation 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 SLC Cache Management</head><p>Input: State (S t ), State (S t−1 ), Action (A t−1 ) Output: Action (A t ) 1: A t = GetAction(S t ) 2: Perform A t 3: R t = GetReward( ) 4: Update Q-value (S t−1 , A t−1 ) with Equation 1</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">States</head><p>For the agent to learn the optimal policy for the SLC cache management, several states must be observed to know the change of environment, which includes both the host and the SSD subsystem. <ref type="table" target="#tab_2">Table 3</ref> shows the selected states, each of which is divided into multiple bins to limit the total number of different states of the environment. The SLC cache size is the main state of hybrid SSD. It has a strong influence on garbage collection and SLC-to-QLC migration costs. The SLC cache size is also the target of the action. We use nine intervals to represent the SLC cache size. The space utilization is the ratio between the size of valid data and the total capacity of the SSD. As the space utilization becomes higher, the garbage collection cost at the QLC region increases. The agent will learn to restrain itself from increasing the SLC cache when the space utilization is high. The previous action includes the recent decision of the agent and the recent system states. By considering the previous action, the agent can determine a history-aware current action.</p><p>For host workload states, we use the demand for SLC writes and the update frequency in the SLC cache. The first one represents how much hot data the host generates, and the second one means the intensity of hotness of the host data written in the SLC cache. If the demand for SLC writes increases, the agent needs to increase the SLC cache or reduce the amount of data to the SLC cache by decreasing the hot/cold separation threshold. The decision must also consider the garbage collection cost in the QLC region. If the update frequency of the data stored in the SLC cache is high, the SLC-to-QLC migration cost will decrease due to many invalidated data in the SLC cache. Therefore, it is also an important factor to determine the SLC cache size suitable for the host workload.</p><p>From the number of bins of each state in <ref type="table" target="#tab_2">Table 3</ref>, the total number of environment states is 1,296 (= 9×4×9×2×2), and the Q-table size is 5,186 bytes, which can be stored at an SLC flash page with the size of 16 KB. The small Q-table can be cached in the internal DRAM of SSD. If we increase the number of bins of each state, the agent could act more correctly. If the memory space for caching Q-table is insufficient, an on-demand loading technique can be used. However, too many states will require too long training time, and thus the agent cannot be agile. Therefore, considering the trade-off, the number of bins of each state must be determined.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Reward</head><p>The main goal of our algorithm is to improve the overall write performance. The latency of a write request will be different depending on the program mode, i.e., SLC mode or QLC mode. In addition, the host write request to the SLC region can be delayed by SLC-to-QLC migration operations, which can also be delayed by QLC garbage collection operations.</p><p>The host write request to the QLC region can also be delayed by QLC garbage collection. Therefore, we need to consider all the costs to calculate the reward of the previous action.</p><p>Algorithm 2 shows the pseudo-code of the proposed reward function. It gets several write-related costs and space utilization as inputs. It first calculates the reclaim cost and the host write cost. The reclaim cost is the sum of SLC-to-QLC migration cost (T SLC−to−QLC ) and QLC garbage collection cost (T QLC−to−QLC ). The host write cost is the sum of SLC cache write cost (T SLCwrite ) and QLC region write cost (T QLCwrite ), each of which does not include the waiting time due to SLCto-QLC migration or QLC garbage collection. The total write cost is the weighted sum of the host write cost and the reclaim cost. As the space utilization is higher, a higher weight is given to the reclaim cost and a lower weight to the host write cost. This is because the effect of reclaim cost on the overall performance is more significant at a higher space utilization. By giving a higher weight to the reclaim cost, the reduction on the SLC cache size can be accelerated when the utilization is high. The final reward value is determined to be positive or negative depending on the comparison result to the average total write cost. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 2 Reward function</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>To evaluate the efficiency of the proposed method, we implemented a trace-driven hybrid SSD simulator. The simulator estimates the latency of each write request by counting the numbers of SLC or QLC flash read, program, and erase operations required to handle the request. Several flash memory parameters were configured, as shown in <ref type="table" target="#tab_0">Table 1</ref>. To simplify the analysis, we assumed that the SSD has only one 32GB NAND QLC flash memory chip which consists of 2,138 blocks. However, the proposed algorithm can be applied to more complex SSD architectures by designing a proper write cost model. The page size is 16 KB, and a block has 256 pages and 1024 pages at SLC mode and QLC mode, respectively. The over-provision area for garbage collection is 3% of total capacity. The SSD has 144 KB of write buffer for handling host writes and garbage collection. The hybrid SSD simulator includes a flash translation layer (FTL), which manages 4KB page-level logical-to-physical address mapping. We assumed that the address mapping table is fully cached at DRAM, and thus there are no additional flash operations to access the mapping table. When the number of free blocks of each region is below 5 blocks, SLC-to-QLC migration or garbage collection are invoked.</p><p>Since the RL agent runs within the hybrid SSD, it will consume some amount of CPU cycles and DRAM space to maintain Q-table, which may delay the host IO request handling. However, the CPU and DRAM overheads are much smaller compared to the cost of flash memory operations. Therefore, we ignored the overhead of the agent in the simulation.</p><p>We used six workloads for simulator inputs collected with the blktrace or the diskmon tool. The PC trace was extracted from a Windows 10-based desktop while running web browsers and compiler. The Phone trace was collected from a smartphone under multiple applications <ref type="bibr" target="#b13">[14]</ref>. The TPC-C trace was extracted while executing TPCC-MySQL tool with 160 warehouses on MySQL for 10 minutes. The OLTP trace and Linkbench trace were collected by running Sysbench and Linkbench benchmark on MySQL, respectively. The YCSB-A trace is the workload type A of YCSB running on RocksDB with 16 million keys. <ref type="table" target="#tab_3">Table 4</ref> shows the characteristics of the traces.</p><p>We compared the proposed RL-based technique with two previous dynamic SLC techniques: utilization-aware selftuning (UST) <ref type="bibr" target="#b12">[13]</ref> and dynamic write accelerator (DWA) <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b5">6]</ref>. The UST allocates a different number of SLC or QLC physical blocks to each logical block depending on its locality. At maximum, MAX SLC number of SLC blocks can be allocated to a logical block. In order to observe data locality, all write requests are first sent to SLC blocks. When there is no sufficient space in the SLC blocks, the garbage collection for the SLC blocks moves hot data within SLC blocks (SLC-to-SLC), and moves cold data to QLC blocks (SLC-to-QLC). Therefore, as the number of hot logical blocks increases, many SLC blocks will be allocated. So, the total number of SLC blocks will change depending on workloads. The value of MAX SLC is 6 blocks in our experiment. DWA adjusts the SLC cache size according to the space utilization. Considering the characteristics of the target workloads, we used the Setting 1 in <ref type="table" target="#tab_1">Table 2</ref>. The hot/cold threshold, θ, is fixed to 32 KB in DWA.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Performance Evaluation</head><p>Figure 4 compares write throughputs of different schemes with six workloads. The results are normalized to that of the baseline method, which uses only QLC blocks without the SLC cache. The RL scheme outperforms all other techniques under most workloads except for the case of YCSB-A. Since most of the write requests are large and most of the data are cold in YCSB-A, the SLC cache was little utilized in the RLbased scheme. So, its performance is similar to the baseline performance.</p><p>To analyze the behavior of SLC cache management techniques, we observed the number of allocated SLC blocks and the hot/cold separation threshold (θ) at every 128 MB of host write (episode), as shown in <ref type="figure" target="#fig_5">Figure 5</ref> and <ref type="figure" target="#fig_6">Figure 6</ref>. Compared to DWA and UST, the RL-based technique adjusts more dynamically the SLC cache size and the hot/cold separation threshold. In the PC workload, which has many frequentlyupdated data, the proposed method allocates less number of SLC blocks than UST does, but maintains a large value of θ, i.e., 512 KB, to store as much hot data as possible in the SLC cache. <ref type="figure" target="#fig_7">Figure 7</ref> shows the breakdown of I/O execution time. The RL technique reduced the QLC-to-QLC or SLC-to-SLC garbage collection overhead compared to UST. Note that UST performs the garbage collection within SLC blocks for hot data whereas our hybrid SSD does not have the SLC-to-SLC migration. The migration and garbage collection costs of the RL-based technique are 65.2% lower than that of UST. Compared to DWA, the QLC write overhead is reduced by the RL scheme. From this result, we can know that the RL-based technique can find the optimal SLC cache parameters under various workloads. Since the RL-based technique reduces migration and garbage collection costs, the write amplification factor (WAF) is also improved. The proposed scheme reduced the average WAF by 20.3% over other techniques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Effect of Agent Pre-training</head><p>The proposed RL-based technique requires a long training time for unexamined workloads or SSD subsystems. However, if an agent that has been pre-trained at one system is used at other systems, it can adapt to the new environments in a short time. To check the effect of the trained agent, we first trained an agent with several workloads of PC, Phone, YSCB-A, and LinkBench. And then, we observed the performance  of the agent at other workloads of TPC-C and OLTP. <ref type="figure" target="#fig_8">Figure 8</ref> compares I/O performances of pre-trained agent and untrained agent. The pre-trained agent improves the write performance by up to 12.8% over the untrained agent. Therefore, we can know that the RL-based scheme can be applied quickly to a new system by using a pre-trained agent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>Due to the increased bit density of flash memory, the hybrid SSD technology is becoming more and more important to enhance write performance. In this paper, we proposed an RL-based SLC cache technique for the hybrid SSDs. The proposed method dynamically determines the optimal SLC cache parameters based on the system states, including the characteristics of the workload and the internal status of the SSD. As a result, the write performance is significantly enhanced without any prior knowledge about host workload or storage characteristics.</p><p>As a future work, we have a plan to examine the effect of the proposed RL scheme at a real SSD subsystem. Another work is to apply the technique at multi-stream SSDs <ref type="bibr" target="#b8">[9]</ref>. The host can deliver data separation decisions to a multi-stream SSD via the stream interface. Different streams tend to have different update patterns. Thus, we can utilize the stream information to determine the optimal number of SLC blocks of each stream by observing the data lifetime of the stream.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Typical hybrid SSD architecture.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Write performance under different SLC cache management policies.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: SLC cache management with RL agent.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Input: T SLC−to−QLC , T QLC−to−QLC , T SLCwrite , T QLCwrite , space utilization U Output: Reward (R t ) 1: reclaim cost = T SLC−to−QLC + T QLC−to−QLC 2: host write cost = T SLCwrite + T QLCwrite 3: total write cost = (1-U)×host write cost + U×reclaim cost 4: if total write cost &gt; average total cost then 5: R t = negative reward 6: else 7: R t = positive reward 8: end if 9: Update average total write cost</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Write throughput comparison.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: The change of the number of allocated SLC blocks.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: The change of hot/cold separation threshold (θ) at the RL-based SLC cache scheme.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Write execution time comparison.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Comparison between pre-trained and untrained agents.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="true"><head>Table 1 : Characteristics of SLC, TLC and QLC memories [12]</head><label>1</label><figDesc></figDesc><table>SLC 
TLC 
QLC 
Program time (page) 
160 us 
730 us 3102 us 
Read time (page) 
30 us 
66 us 
140 us 
Erase time (block) 
3 ms 
4.8 ms 
3.5 ms 
Endurance (Max. P/E) 
100,000 
3,000 
1,000 

machine learning-based dynamic approach for hybrid SSD. 
Our RL-based technique defines several states that reflect 
the characteristics of the workload and the internal behavior 
of hybrid SSD. It determines the optimal SLC cache param-
eters using the Q-learning algorithm. Experimental results 
show that the RL-based technique can improve the SSD write 
performance compared to the existing techniques, by dynam-
ically adjusting the SLC cache factors based on the system 
states. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Two example settings on SLC cache size at different 
storage utilizations (%) 

Space 
utilization (%) 

0 
∼20 

20 
∼30 

30 
∼40 

40 
∼50 

50 
∼60 

60 
∼70 

70 
∼100 
Setting 1 
56 
50 
40 
30 
25 
20 
10 
Setting 2 
40 
40 
30 
25 
20 
10 
5 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true"><head>Table 3 : States</head><label>3</label><figDesc></figDesc><table>Category 
Information used for State 
# of bins 
SLC cache size 
9 
SSD 
Space utilization 
4 
Previous action 
9 
Host 
Demand for SLC writes 
2 
Workload Update write frequency in SLC cache 
2 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="true"><head>Table 4 : Workload Characteristic</head><label>4</label><figDesc></figDesc><table>Trace 
PC 
Phone TPC-C 
OLTP 
LinkBench YCSB-A 
Address space (MB) 
1,029 
7,606 
4,622 
5,694 
4,482 
30,241 
Total write amount (MB) 
46,426 81,833 39,506 25,866 
38,391 
97,294 
Avg. request size (KB) 
66.7 
42.8 
34.3 
35.8 
28.2 
896.3 

Write request size distribution (%) 

≤ 128KB 
29.47 
25.22 
53.25 
53.4 
61.76 
0.09 
≤ 256KB 
23.08 
1.47 
2.06 
5.01 
3.21 
0.06 
≤ 512KB 
27.03 
1.76 
16.05 
12.42 
15.58 
3.87 
&gt; 512KB 
20.42 
71.55 
28.64 
29.17 
19.45 
95.98 

</table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P1</forename><surname>Crucial</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ssd</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019-12-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
				<ptr target="https://www.samsung.com/semiconductor" />
		<title level="m">Samsung 860 QVO SSD</title>
		<imprint>
			<date type="published" when="2019-12-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<ptr target="https://www.anandtech.com/show/13078/the-intel-ssd-660p-ssd-review-qlc-nand-arrives" />
		<title level="m">The Intel SSD 660p SSD Review : QLC NAND Arrives For Consumer SSDs</title>
		<imprint>
			<date type="published" when="2019-12-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A hybrid approach to NAND-flash-based solid-state disks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Pin</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computers</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1337" to="1349" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Benchmarking cloud serving systems with YCSB</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Brian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Cooper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erwin</forename><surname>Silberstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raghu</forename><surname>Tam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Russell</forename><surname>Ramakrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sears</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st ACM symposium on Cloud computing</title>
		<meeting>the 1st ACM symposium on Cloud computing</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="143" to="154" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Optimized client computing with dynamic write acceleration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dave</forename><surname>Glen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Micron</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">ComboFTL: Improving performance and lifespan of MLC flash memory using SLC flash buffer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soojun</forename><surname>Im</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongkun</forename><surname>Shin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Systems Architecture</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="641" to="653" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Software controlled cell bit-density to improve NAND flash lifetime</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Jimenez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Novo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Ienne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Design Automation Conference</title>
		<meeting>the 49th Annual Design Automation Conference</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="229" to="234" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The Multi-streamed Solid-State Drive</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeong-Uk</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeeseok</forename><surname>Hyun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyunjoo</forename><surname>Maeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sangyeun</forename><surname>Cho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">6th USENIX Workshop on Hot Topics in Storage and File Systems (HotStorage&apos;14)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">LAST: locality-aware sector translation for NAND flash memory-based storage systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungjin</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongkun</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Young-Jin</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jihong</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGOPS Operating Systems Review</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="36" to="42" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Introduction to reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">G</forename><surname>Richard S Sutton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Barto</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<publisher>MIT press</publisher>
			<biblScope unit="volume">2</biblScope>
			<pubPlace>Cambridge</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Analysis on Heterogeneous SSD Configuration with Quadruple-Level Cell (QLC) NAND Flash Memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshiki</forename><surname>Takai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mamoru</forename><surname>Fukuchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reika</forename><surname>Kinoshita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chihiro</forename><surname>Matsui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ken</forename><surname>Takeuchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE 11th International Memory Workshop (IMW)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1" to="4" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Utilization-aware self-tuning design for TLC flash storage devices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Chang</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan-Hao</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chei-Wei</forename><surname>Tsao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chung-Yu</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Very Large Scale Integration (VLSI) Systems</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="3132" to="3144" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">I/O characteristics of smartphone applications and their implications for eMMC design</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deng</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Symposium on Workload Characterization</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="12" to="21" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
