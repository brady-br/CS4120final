<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2020-09-29T02:20+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">SOCK: Rapid Task Provisioning with Serverless-Optimized Containers SOCK: Rapid Task Provisioning with Serverless-Optimized Containers</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>July 11-13. 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Oakes</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">-Madison † Microsoft Gray Systems Lab</orgName>
								<orgName type="institution" key="instit1">University of Wisconsin</orgName>
								<orgName type="institution" key="instit2">University of Wisconsin-Madison</orgName>
								<orgName type="institution" key="instit3">University of Wisconsin</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leon</forename><surname>Yang</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">-Madison † Microsoft Gray Systems Lab</orgName>
								<orgName type="institution" key="instit1">University of Wisconsin</orgName>
								<orgName type="institution" key="instit2">University of Wisconsin-Madison</orgName>
								<orgName type="institution" key="instit3">University of Wisconsin</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dennis</forename><surname>Zhou</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">-Madison † Microsoft Gray Systems Lab</orgName>
								<orgName type="institution" key="instit1">University of Wisconsin</orgName>
								<orgName type="institution" key="instit2">University of Wisconsin-Madison</orgName>
								<orgName type="institution" key="instit3">University of Wisconsin</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Houck</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">-Madison † Microsoft Gray Systems Lab</orgName>
								<orgName type="institution" key="instit1">University of Wisconsin</orgName>
								<orgName type="institution" key="instit2">University of Wisconsin-Madison</orgName>
								<orgName type="institution" key="instit3">University of Wisconsin</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Madison</forename><forename type="middle">;</forename></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">-Madison † Microsoft Gray Systems Lab</orgName>
								<orgName type="institution" key="instit1">University of Wisconsin</orgName>
								<orgName type="institution" key="instit2">University of Wisconsin-Madison</orgName>
								<orgName type="institution" key="instit3">University of Wisconsin</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Microsoft, GSL;</roleName><forename type="first">Tyler</forename><surname>Harter</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">-Madison † Microsoft Gray Systems Lab</orgName>
								<orgName type="institution" key="instit1">University of Wisconsin</orgName>
								<orgName type="institution" key="instit2">University of Wisconsin-Madison</orgName>
								<orgName type="institution" key="instit3">University of Wisconsin</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><forename type="middle">C</forename><surname>Arpaci-Dusseau</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">-Madison † Microsoft Gray Systems Lab</orgName>
								<orgName type="institution" key="instit1">University of Wisconsin</orgName>
								<orgName type="institution" key="instit2">University of Wisconsin-Madison</orgName>
								<orgName type="institution" key="instit3">University of Wisconsin</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Remzi</forename><forename type="middle">H</forename><surname>Arpaci-Dusseau</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">-Madison † Microsoft Gray Systems Lab</orgName>
								<orgName type="institution" key="instit1">University of Wisconsin</orgName>
								<orgName type="institution" key="instit2">University of Wisconsin-Madison</orgName>
								<orgName type="institution" key="instit3">University of Wisconsin</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Oakes</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">-Madison † Microsoft Gray Systems Lab</orgName>
								<orgName type="institution" key="instit1">University of Wisconsin</orgName>
								<orgName type="institution" key="instit2">University of Wisconsin-Madison</orgName>
								<orgName type="institution" key="instit3">University of Wisconsin</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leon</forename><surname>Yang</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">-Madison † Microsoft Gray Systems Lab</orgName>
								<orgName type="institution" key="instit1">University of Wisconsin</orgName>
								<orgName type="institution" key="instit2">University of Wisconsin-Madison</orgName>
								<orgName type="institution" key="instit3">University of Wisconsin</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dennis</forename><surname>Zhou</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">-Madison † Microsoft Gray Systems Lab</orgName>
								<orgName type="institution" key="instit1">University of Wisconsin</orgName>
								<orgName type="institution" key="instit2">University of Wisconsin-Madison</orgName>
								<orgName type="institution" key="instit3">University of Wisconsin</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Houck</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">-Madison † Microsoft Gray Systems Lab</orgName>
								<orgName type="institution" key="instit1">University of Wisconsin</orgName>
								<orgName type="institution" key="instit2">University of Wisconsin-Madison</orgName>
								<orgName type="institution" key="instit3">University of Wisconsin</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tyler</forename><surname>Harter</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">-Madison † Microsoft Gray Systems Lab</orgName>
								<orgName type="institution" key="instit1">University of Wisconsin</orgName>
								<orgName type="institution" key="instit2">University of Wisconsin-Madison</orgName>
								<orgName type="institution" key="instit3">University of Wisconsin</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><forename type="middle">C</forename><surname>Arpaci-Dusseau</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">-Madison † Microsoft Gray Systems Lab</orgName>
								<orgName type="institution" key="instit1">University of Wisconsin</orgName>
								<orgName type="institution" key="instit2">University of Wisconsin-Madison</orgName>
								<orgName type="institution" key="instit3">University of Wisconsin</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Remzi</forename><forename type="middle">H</forename><surname>Arpaci-Dusseau</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">-Madison † Microsoft Gray Systems Lab</orgName>
								<orgName type="institution" key="instit1">University of Wisconsin</orgName>
								<orgName type="institution" key="instit2">University of Wisconsin-Madison</orgName>
								<orgName type="institution" key="instit3">University of Wisconsin</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">SOCK: Rapid Task Provisioning with Serverless-Optimized Containers SOCK: Rapid Task Provisioning with Serverless-Optimized Containers</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 USENIX Annual Technical Conference (USENIX ATC &apos;18)</title>
						<meeting>the 2018 USENIX Annual Technical Conference (USENIX ATC &apos;18) <address><addrLine>Boston, MA, USA</addrLine></address>
						</meeting>
						<imprint>
							<date type="published">July 11-13. 2018</date>
						</imprint>
					</monogr>
					<note>Open access to the Proceedings of the 2018 USENIX Annual Technical Conference is sponsored by USENIX. This paper is included in the</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Serverless computing promises to provide applications with cost savings and extreme elasticity. Unfortunately, slow application and container initialization can hurt common-case latency on serverless platforms. In this work, we analyze Linux container primitives, identifying scalability bottlenecks related to storage and network isolation. We also analyze Python applications from GitHub and show that importing many popular libraries adds about 100 ms to startup. Based on these findings, we implement SOCK, a container system optimized for serverless workloads. Careful avoidance of kernel scalability bottlenecks gives SOCK an 18× speedup over Docker. A generalized-Zygote provisioning strategy yields an additional 3× speedup. A more sophisticated three-tier caching strategy based on Zygotes provides a 45× speedup over SOCK without Zygotes. Relative to AWS Lambda and OpenWhisk, OpenLambda with SOCK reduces platform overheads by 2.8× and 5.3× respectively in an image processing case study.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The effort to maximize developer velocity has driven many changes in the way programmers write and run their code <ref type="bibr" target="#b41">[43]</ref>. Programmers are writing code at a higher level of abstraction: JavaScript, Python, Java, Ruby, and PHP are now the most popular languages on GitHub (in that order), surpassing lower-level languages such as C and C++ <ref type="bibr" target="#b49">[51]</ref>. Developers also increasingly focus on application-specific logic, reusing existing libraries for general functionality when possible <ref type="bibr" target="#b17">[19,</ref><ref type="bibr" target="#b21">23,</ref><ref type="bibr" target="#b38">40]</ref>.</p><p>New programming paradigms are also liberating developers from the distraction of managing servers <ref type="bibr" target="#b16">[18,</ref><ref type="bibr" target="#b50">52,</ref><ref type="bibr" target="#b52">54]</ref>. In particular, a proliferation of new serverless platforms <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b12">14,</ref><ref type="bibr" target="#b15">17,</ref><ref type="bibr" target="#b18">20,</ref><ref type="bibr" target="#b37">39,</ref><ref type="bibr" target="#b43">45]</ref> allow developers to construct applications as a set of handlers, called lambdas, commonly written in Python (or some other highlevel language), that execute in response to events, such as web requests or data generation. Serverless providers automatically scale the number of handlers up and down to accommodate load so that developers need not worry about the number or configuration of machines serving their workload. Using serverless platforms is often very economical: billing granularity is in fractions of a second, and there is generally no tenant charge for idle time.</p><p>These three strategies (i.e., programming at higher abstraction levels, reusing libraries, and decomposing applications into auto-scaling serverless lambdas) improve developer velocity, but they also create new infrastructure problems. Specifically, these techniques make process cold-start more expensive and frequent. Languages such as Python and JavaScript require heavy runtimes, making startup over 10× slower than launching an equivalent C program <ref type="bibr" target="#b0">[1]</ref>. Reusing code introduces further startup latency from library loading and initialization <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b24">26,</ref><ref type="bibr" target="#b25">27]</ref>. Serverless computing amplifies these costs: if a monolithic application is decomposed to N serverless lambdas, startup frequency is similarly amplified. Lambdas are typically isolated from each other via containers, which entail further sandboxing overheads <ref type="bibr" target="#b29">[31]</ref>.</p><p>Fast cold start is important for both tenants and providers. A graceful reaction to flash crowds <ref type="bibr" target="#b13">[15,</ref><ref type="bibr" target="#b20">22]</ref> requires concurrent low-latency deployment to many workers. From a provider perspective, avoiding cold starts can be quite costly. Most serverless platforms currently wait minutes or hours to recycle idle, unbilled lambda instances <ref type="bibr" target="#b48">[50]</ref>. If cold start is made faster, providers will be able to reclaim idle resources and rebalance load across machines more aggressively.</p><p>In order to better understand the sandboxing and application characteristics that interfere with efficient cold start, we perform two detailed studies. First, we analyze the performance and scalability of various Linux isolation primitives. Among other findings, we uncover scalability bottlenecks in the network and mount namespaces and identify lighter-weight alternatives. Second, we study 876K Python projects from GitHub and analyzing 101K unique packages from the PyPI repository. We find that many popular packages take 100 ms to import, and installing them can take seconds. Although the entire 1.5 TB package set is too large to keep in memory, we find that 36% of imports are to just 0.02% of packages.</p><p>Based on these findings, we implement SOCK (roughly for serverless-optimized containers), a special-purpose container system with two goals: (1) low-latency invocation for Python handlers that import libraries and <ref type="formula">(2)</ref> efficient sandbox initialization so that individual workers can achieve high steady-state throughput. We integrate SOCK with the OpenLambda <ref type="bibr" target="#b18">[20]</ref> serverless platform, replacing Docker as the primary sandboxing mechanism.</p><p>SOCK is based on three novel techniques. First, SOCK uses lightweight isolation primitives, avoiding the performance bottlenecks identified in our Linux primitive study, to achieve an 18× speedup over Docker. Second, SOCK provisions Python handlers using a generalized Zygote-provisioning strategy to avoid the Python initialization costs identified in our package study. In the simplest scenarios, this technique provides an additional 3× speedup by avoiding repeated initialization of the Python runtime. Third, we leverage our generalized Zygote mechanism to build a three-tiered packageaware caching system, achieving 45× speedups relative to SOCK containers without Zygote initialization. In an image-resizing case study, SOCK reduces cold-start platform overheads by 2.8× and 5.3× relative to AWS Lambda and OpenWhisk, respectively.</p><p>The rest of this paper is structured as follows. We study the costs of Linux provisioning primitives ( §2) and application initialization ( §3), and use these findings to guide the design and implementation of SOCK ( §4). We then evaluate the performance of SOCK ( §5), discuss related work ( §6), and conclude ( §7).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Deconstructing Container Performance</head><p>Serverless platforms often isolate lambdas with containers <ref type="bibr" target="#b12">[14,</ref><ref type="bibr" target="#b18">20,</ref><ref type="bibr" target="#b37">39,</ref><ref type="bibr" target="#b43">45]</ref>. Thus, optimizing container initialization is a key part of the lambda cold-start problem. In Linux, containerization is not a single-cohesive abstraction. Rather, general-purpose tools such as Docker <ref type="bibr" target="#b35">[36]</ref> are commonly used to construct containers using a variety of Linux mechanisms to allocate storage, isolate resources logically, and isolate performance. The flexibility Linux provides also creates an opportunity to design a variety of special-purpose container systems. In this section, we hope to inform the design of SOCK and other special-purpose container systems by analyzing the performance characteristics of the relevant Linux abstractions. In particular, we ask how can one maximize density of container file systems per machine? What is the cost of isolating each major resource with namespaces, and which resources must be isolated in a serverless environment? And how can the cost of repeatedly initializing cgroups to isolate performance be avoided? We perform our analysis on an 8-core m510 machine <ref type="bibr" target="#b9">[11]</ref> with the 4.13.0-37 Linux kernel.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Container Storage</head><p>Containers typically execute using a root file system other than the host's file system. This protects the host's data and provides a place for the container's unique dependencies to be installed. Provisioning a file system for a container is a two step procedure: (1) populate a subdirectory of the host's file system with data and code needed by the container, and (2) make the subdirectory the root of the new container, such that code in the container can no longer access other host data. We explore alternative mechanisms for these population and accessdropping steps.</p><p>Populating a directory by physical copying is prohibitively slow, so all practical techniques rely on logical copying. Docker typically uses union file systems (e.g., AUFS) for this purpose; this provides a flexible layered-composition mechanism and gives running containers copy-on-write access over underlying data. A simpler alternative is bind mounting. Bind mounting makes the same directory visible at multiple locations; there is no copy-on-write capability, so data that must be protected should only be bind-mounted as read-only in a container. To compare binds to layered file systems, we repeatedly mount and unmount from many tasks in parallel. <ref type="figure" target="#fig_0">Figure 1</ref> shows the result: at scale, bind mounting is about twice as fast as AUFS.</p><p>Once a subdirectory on the host file system has been populated for use as a container root, the setup process must switch roots and drop access to other host file data. Linux provides two primitives for modifying the filesystem visible to a container. The older chroot operation simply turns a subdirectory of the original root file system into the new root file system. A newer mount-namespace abstraction enables more interesting transformations: an unshare call (with certain arguments) gives a container a new set of mount points, originally identical to the host's set. The container's mount points can then be modified with mount, unmount, and other calls. It is even possible to reorganize the mount namespace of a container such that the container may see file system Y mounted on file system X (the container's root) while the host may see X mounted on Y (the host's root). There are cases where this powerful abstraction can be quite helpful, but overusing mount namespace flexibility "may quickly lead to insanity," as the Linux manpages warn <ref type="bibr" target="#b30">[32]</ref>.</p><p>We measure the scalability of mount namespaces, with results shown in <ref type="figure">Figure 2</ref>. We have a variable number of long-lived mount namespaces persisting throughout the experiment (x-axis). We churn namespaces, concurrently creating and deleting them (concurrency is shown by different lines). We observe that churn performance scales poorly with the number of prior existing namespaces: as the number of host mounts grows large, the rate at which namespaces can be cloned approaches zero. We also evaluate chroot (not shown), and find that using it entails negligible overhead (chroot latency is &lt; 1µs).   access to their own virtual roots, backed by different physical directories in the host. Linux's network namespaces similarly allow different containers to use the same virtual port number (e.g., 80), backed by different physical ports on the host (e.g., 8080 and 8081). In this section, we study the collective use of mount and network namespaces, along with UTS, IPC, and PID namespaces <ref type="bibr">[37]</ref> (user and cgroup namespaces are not evaluated here). The unshare call allows a process to create and switch to a new set of namespaces. Arguments to unshare allow careful selection of which resources need new namespaces. Namespaces are automatically reaped when the last process using them exits. We exercise namespace creation and cleanup performance by concurrently invoking unshare and exiting from a variable number of tasks. We instrument the kernel with ftrace to track where time is going. <ref type="figure">Figure 3</ref> shows the latency of the four most expensive namespace operations (other latencies not shown were relatively insignificant). We observe that mount and IPC namespace cleanup entails latencies in the tens of milliseconds. Upon inspection of the kernel code, we found that both operations are waiting for an RCU grace period <ref type="bibr" target="#b34">[35]</ref>. During this time, no global locks are held and no compute is consumed, so these latencies are relatively harmless to overall throughput; as observed earlier ( §2.1), it is possible to create ∼1500 mount namespaces per second, as long as churn keeps the number of namespaces small over time.</p><p>Network namespaces are more problematic for both creation and cleanup due to a single global lock that is shared across network namespaces <ref type="bibr" target="#b11">[13]</ref>. During creation, Linux iterates over all existing namespaces while holding the lock, searching for namespaces that should be notified of the configuration change; thus, costs increase proportionally as more namespaces are created. As with mount and IPC namespaces, network-namespace cleanup requires waiting for an RCU grace period. However, for network namespaces, a global lock is held during that period, creating a bottleneck. Fortunately, network namespaces are cleaned in batches, so the per-namespace cost becomes small at scale (as indicated by the downwardsloping "net cleanup" line). <ref type="figure" target="#fig_1">Figure 4</ref> shows the impact of network namespaces on overall creation/deletion throughput (i.e., with all five namespaces). With unmodified network namespaces, throughput peaks at about 200 c/s (containers/second). With minor optimizations (disabling IPv6 and eliminating the costly broadcast code), it is possible to churn over 400 c/s. However, eliminating network namespaces entirely provides throughput of 900 c/s.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Performance Isolation: Cgroup Primitives</head><p>Linux provides performance isolation via the cgroup interface <ref type="bibr">[9]</ref>. Processes may be assigned to cgroups, which are configured with limits on memory, CPU, file I/O, and other resources. Linux cgroups are easier to configure dynamically than namespaces. The API makes it simple to adjust the resource limits or reassign processes to different cgroups. In contrast, a mechanism for reassigning a process to a new PID namespace would need to overcome obstacles such as potential PID collisions.</p><p>The flexibility of cgroups makes two usage patterns viable. The first involves (1) creating a cgroup, (2) adding a process, (3) exiting the process, and (4) removing the cgroup; the second involves only Steps 2 and 3 (i.e., the same cgroup is reused for different processes at different times). <ref type="figure" target="#fig_2">Figure 5</ref> compares the cost of these two approaches while varying the numbers of tasks concurrently manipulating cgroups. Reusing is at least twice as fast as creating new cgroups each time. The best reuse performance is achieved with 16 threads (the number of CPU hyperthreads), suggesting cgroups do not suffer from the scaling issues we encountered with namespaces.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Serverless Implications</head><p>Our results have several implications for the design of serverless containers. First, in a serverless environment, all handlers run on one of a few base images, so the flexible stacking of union file systems may not be worth the the performance cost relative to bind mounts. Once a root location is created, file-system tree transformations that rely upon copying the mount namespace are costly at scale. When flexible file-system tree construction is not necessary, the cheaper chroot call may be used to drop access. Second, network namespaces are a major scalability bottleneck; while static port assignment may be useful in a server-based environment, serverless platforms such as AWS Lambda execute handlers behind a Network Address Translator <ref type="bibr" target="#b14">[16]</ref>, making network namespacing of little value. Third, reusing cgroups is twice as fast as creating new cgroups, suggesting that maintaining a pool of initialized cgroups may reduce startup latency and improve overall throughput.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Python Initialization Study</head><p>Even if lambdas are executed in lightweight sandboxes, language runtimes and package dependencies can make cold start slow <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b24">26,</ref><ref type="bibr" target="#b25">27]</ref>. Many modern applications are accustomed to low-latency requests. For example, most Gmail remote-procedure calls are short, completing in under 100 ms (including Internet round trip) <ref type="bibr" target="#b18">[20]</ref>. Of the short requests, the average latency is 27 ms, about the time it takes to start a Python interpreter and print a "hello world" message. Unless serverless platforms provide language-and library-specific cold-start optimizations, it will not be practical to decompose such applications into independently scaling lambdas. In this section, we analyze the performance cost of using popular Python libraries and evaluate the feasibility of optimizing initialization with caching. We ask: what types of packages are most popular in Python applications? What are the initialization costs associated with using these packages? And how feasible is it to cache a large portion of mainstream package repositories on local lambda workers?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Python Applications</head><p>We now consider the types of packages that future lambda applications might be likely to use, assuming efficient platform support. We scrape 876K Python projects from GitHub and extract likely dependencies on packages in the popular Python Package Index (PyPI) repository, resolving naming ambiguity in favor of more popular packages. We expect that few of these applications currently run as lambdas; however, our goal is to identify potential obstacles that may prevent them from being ported to lambdas in the future. <ref type="figure">Figure 6</ref> shows the popularity of 20 packages that are most common as GitHub project dependencies. Skew is high: 36% of imports are to just 20 packages (0.02% of the packages in PyPI). The 20 packages roughly fall into five categories: web frameworks, analysis, communication, storage, and development. Many of these use cases are likely applicable to future serverless applications. Current web frameworks will likely need to be replaced by serverless-oriented frameworks, but computeintense analysis is ideal for lambdas <ref type="bibr" target="#b19">[21]</ref>. Many lambdas will need libraries for communicating with other services and for storing data externally <ref type="bibr" target="#b14">[16]</ref>  libraries may be somewhat less relevant, but lambdabased parallel unit testing is an interesting use case.</p><p>If a package is being used for the first time, it will be necessary to download the package over the network (possibly from a nearby mirror), install it to local storage, and import the library to Python bytecode. Some of these steps may be skipped upon subsequent execution, depending on the platform. <ref type="figure">Figure 7</ref> shows these costs for each of the popular packages. Fully initializing a package takes 1 to 13 seconds. Every part of the initialization is expensive on average: downloading takes 1.6 seconds, installing takes 2.3 seconds, and importing takes 107 ms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">PyPI Repository</head><p>We now explore the feasibility of supporting full language repositories locally on serverless worker machines. We mirror and analyze the entire PyPI repository, which contains 101K unique packages. <ref type="figure">Figure 8</ref> shows the footprint of the entire repository, including every version of every package, but excluding indexing files. The packages are about 1.5 TB total, or ∼0.5 TB compressed.</p><p>Most packages are compressed as .tar.gz files or a zipbased format (.whl, .egg, or .zip). Across all format types, the average package contains about 100 files (e.g., 135K</p><p>.whl packages hold 13M compressed files).</p><p>We wish to understand how many of the PyPI packages could coexist when installed together. PyPI packages that unpack to a single directory can easily coexist with other installed packages, whereas packages that modify shared files may break other packages. We attempt to install every version of every PyPI package in its own Docker Ubuntu container (using a 1-minute timeout) and identify file creations and modifications. We ignore changes to temporary locations. <ref type="figure">Figure 9</ref> shows the results for .tar.gz, .whl, and .zip distributions (.egg libraries are used directly without a prior installation, so we skip those). While fewer than 1% timed out, 18% simply failed to install in our container. 66% of succeeding installs only populate the local Python module directory (the module dirs category). Another 31% of succeeding installs modified just the module directories and the local bin directory (Python modules are sometimes bundled with various utilities). We conclude it is possible for 97% of installable packages to coexist in a single local install.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Serverless Implications</head><p>Downloading and installing a package and its dependencies from a local mirror takes seconds; furthermore, import of installed packages takes over 100 ms. Fortunately, our analysis indicates that storing large package repositories locally on disk is feasible. Strong popularity skew further creates opportunities to pre-import a subset of packages into interpreter memory <ref type="bibr" target="#b7">[8]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">SOCK with OpenLambda</head><p>In this section, we describe the design and implementation of SOCK, a container system optimized for use in serverless platforms. We integrate SOCK with the OpenLambda serverless platform, replacing Docker containers as the primary sandboxing mechanism for OpenLambda workers and using additional SOCK containers to implement Python package caching. We design SOCK to handle high-churn workloads at the worker level. The local churn may arise due to global workload changes, rebalancing, or aggressive reclamation of idle resources.</p><p>SOCK is based on two primary design goals. First, we want low-latency invocation for Python handlers that import libraries. Second, we want efficient sandbox initialization so that individual workers can achieve high steady-state throughput. A system that hides latency by maintaining pools of pre-initialized containers (e.g., the LightVM approach <ref type="bibr" target="#b29">[31]</ref>) would satisfy the first goal, but not the second. A system that could create many containers in parallel as part of a large batch might satisfy the second goal, but not the first. Satisfying both goals will make a serverless platform suitable for many applications and profitable for providers.</p><p>Our solution, SOCK, takes a three-pronged approach to satisfying these goals, based on our analysis of Linux containerization primitives ( §2) and Python workloads ( §3). First, we build a lean container system for sandboxing lambdas ( §4.1). Second, we generalize Zygote provisioning to scale to large sets of untrusted packages ( §4.2). Third, we design a three-layer caching system for reducing package install and import costs ( §4.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Lean Containers</head><p>SOCK creates lean containers for lambdas by avoiding the expensive operations that are only necessary for general-purpose containers. Creating a container involves constructing a root file system, creating communication channels, and imposing isolation boundaries. <ref type="figure" target="#fig_0">Figure 10</ref> illustrates SOCK's approach to these three tasks.</p><p>Storage: Provisioning container storage involves first populating a directory on the host to use as a container root. Bind mounting is faster using union file systems ( §2.1), so SOCK uses bind mounts to stitch together a root from four host directories, indicated by the "F" label in <ref type="figure" target="#fig_0">Figure 10</ref>. Every container has the same Ubuntu base for its root file system ("base"); we can afford to back this by a RAM disk as every handler is required to use the same base. A packages directory used for package caching ("packages") is mounted over the base, as described later ( §4.3). The same base and packages are readonly shared in every container. SOCK also binds handler code ("λ code") as read-only and a writable scratch directory ("scratch") in every container.</p><p>Once a directory has been populated as described, it should become the root directory. Tools such as Docker accomplish this by creating a new mount namespace, then restructuring it. We use the faster and simpler chroot operation ( §2.1) since it is not necessary to selectively expose other host mounts within the container for serverless applications. SOCK containers always start with two processes ("init" and "helper" in <ref type="figure" target="#fig_0">Figure 10)</ref>; both of these use chroot during container initialization, and any children launched from these processes inherit the same root.</p><p>Communication: The scratch-space mount of every SOCK container contains a Unix domain socket (the black pentagon in <ref type="figure" target="#fig_0">Figure 10</ref>) that is used for communication between the OpenLambda manager and processes inside the container. Event and request payloads received by OpenLambda are forwarded over this channel.</p><p>The channel is also used for a variety of control operations ( §4.2). Some of these operations require privileged access to resources not normally accessible inside a container. Fortunately, the relevant resources (i.e., namespaces and container roots) may be represented as file descriptors, which may be passed over Unix domain sockets. The manager can thus pass specific capabilities over the channel as necessary.</p><p>Isolation: Linux processes may be isolated with a combination of cgroup (for performance isolation) and namespace primitives (for logical isolation). It is relatively expensive to create cgroups; thus, OpenLambda creates a pool of cgroups (shown in <ref type="figure" target="#fig_0">Figure 10</ref>) that can be used upon SOCK container creation; cgroups are returned to the pool after container termination.</p><p>The "init" process is the first to run in a SOCK container; init creates a set of new namespaces with a call to unshare. The arguments to the call indicate that mount and network namespaces should not be used, because these were the two namespaces that scale poorly ( §2.1 and §2.2). Mount namespaces are unnecessary because SOCK uses chroot. Network namespaces are unnecessary because requests arrive over Unix domain socket, not over a socket attached to a fixed port number, so port virtualization is not required.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Generalized Zygotes</head><p>Zygote provisioning is a technique where new processes are started as forks of an initial process, the Zygote,  <ref type="figure" target="#fig_0">Figure 12</ref>. Serverless Caching that has already pre-imported various libraries likely to be needed by applications, thereby saving child processes from repeatedly doing the same initialization work and consuming excess memory with multiple identical copies. Zygotes were first introduced on Android systems for Java applications <ref type="bibr" target="#b7">[8]</ref>. We implement a more general Zygote-provisioning strategy for SOCK. Specifically, SOCK Zygotes differ as follows: (1) the set of pre-imported packages is determined at runtime based on usage, (2) SOCK scales to very large package sets by maintaining multiple Zygotes with different pre-imported packages, (3) provisioning is fully integrated with containers, and (4) processes are not vulnerable to malicious packages they did not import.</p><p>As already described, SOCK containers start with two processes, an init process (responsible for setting up namespaces) and a helper process. The helper process is a Python program that listens on the SOCK communication channel; it is capable of (a) pre-importing modules and (b) loading lambda handlers to receive subsequent forwarded events. These two capabilities are the basis for a simple Zygote mechanism. A Zygote helper first preimports a set of modules. Then, when a lambda is invoked requiring those modules, the Zygote helper is forked to quickly create a new handler helper, which then loads the lambda code to handle a forwarded request.</p><p>We assume packages that may be pre-imported may be malicious <ref type="bibr" target="#b46">[48]</ref>, and handlers certainly may be malicious, so both Zygote helpers and handler helpers must run in containers. The key challenge is using Linux APIs such that the forked process lands in a new container, distinct from the container housing the Zygote helper. <ref type="figure" target="#fig_0">Figure 11</ref> illustrates how the SOCK protocol provisions a helper handler ("helper-H" in "Container H") from a helper Zygote ("helper-Z" in "Container Z"). <ref type="formula">(1)</ref> The manager obtains references, represented as file descriptors (fds), to the namespaces and the root file system of the new container. (2) The fds are passed to helper-Z, which (3) forks a child process, "tmp". (4) The child then changes roots to the new container with a combination of fchdir(fd) and chroot(".") calls. The child also calls setns (set namespace) for each namespace to relocate to the new container. (5) One peculiarity of setns is that after the call, the relocation has only partially been applied to all namespaces for the caller. Thus, the child calls fork again, creating a grandchild helper ("helper-H" in the figure) that executes fully in the new container with respect to namespaces. (6) The manager then moves the grandchild to the new cgroup. <ref type="formula">(7)</ref> Finally, the helper listens on the channel for the next commands; the manager will direct the helper to load the lambda code, and will then forward a request to the lambda.</p><p>The above protocol describes how SOCK provisions a handler container from a Zygote container. When OpenLambda starts, a single Zygote that imports no modules is always provisioned. In order to benefit from preimporting modules, SOCK can create additional Zygotes that import various module subsets. Except for the first Zygote, new Zygotes are provisioned from existing Zygotes. The protocol for provisioning a new Zygote container is identical to the protocol for provisioning a new handler container, except for the final step 7. Instead of loading handler code and processing requests, a new Zygote pre-imports a specified list of modules, then waits to be used for the provisioning of other containers.</p><p>Provisioning handlers from Zygotes and creating new Zygotes from other Zygotes means that all the interpreters form a tree, with copy-on-write memory unbroken by any call to exec. This sharing of physical pages between processes reduces memory consumption <ref type="bibr" target="#b1">[2]</ref>. Initialization of the Python runtime and packages will only be done once, and subsequent initialization will be faster.</p><p>If a module loaded by a Zygote is malicious, it may interfere with the provisioning protocol (e.g., by modifying the helper protocol so that calls to setns are skipped). Fortunately, the Zygote is sandboxed in a container, and will never be passed descriptors referring to unrelated containers, so a malicious process cannot escape into arbitrary containers or the host. SOCK protects innocent lambdas by never initializing them from a Zygote that has pre-imported modules not required by the lambda.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Serverless Caching</head><p>We use SOCK to build a three-tier caching system, shown in <ref type="figure" target="#fig_0">Figure 12</ref>. First, a handler cache maintains idle handler containers in a paused state; the same approach is taken by AWS Lambda <ref type="bibr" target="#b47">[49]</ref>. Paused containers cannot consume CPU, and unpausing is faster than creating a new container; however, paused containers consume memory, so SOCK limits total consumption by evicting paused containers from the handler cache on an LRU basis. Second, an install cache contains a large, static set of pre-installed packages on disk. Our measurements show that 97% of installable PyPI packages could coexist in such a installation. This installation is mapped read-only into every container for safety. Some of the packages may be malicious, but they do no harm unless a handler chooses to import them.</p><p>Third, an import cache is used to manage Zygotes. We have already described a general mechanism for creating many Zygote containers, with varying sets of packages pre-imported ( §4.2). However, Zygotes consume memory, and package popularity may shift over time, so SOCK decides the set of Zygotes available based on the import-cache policy. Import caching entails new decisions for handling hits. In traditional caches, lookup results in a simple hit or miss; in contrast, SOCK always hits at least one cache entry and often must decide between alternative Zygotes. Eviction is also complicated by copy-on-write sharing of memory pages between Zygotes, which obfuscates the consumption of individuals. We now describe SOCK's selection and eviction policies.</p><p>Import-Cache Selection: Suppose (in the context of <ref type="figure" target="#fig_0">Figure 13</ref>) that a handler is invoked that requires packages A and B. Entry 4 is a tempting choice to use as the template for our new interpreter; it would provide the best performance because all requisite packages are already imported. However, if package C is malicious, we expose the handler to code that it did not voluntarily import. We could potentially vet a subset of packages to be deemed safe, but we should generally not use cache entries that pre-import packages not requested by a handler. This leaves cache Entries 2 and 3 as reasonable candidates. The import cache decides between such alternatives by choosing the entry with the most matching packages, breaking ties randomly. When SOCK must use an entry X that is not an exact match, it first replicates X to a new entry Y , imports the remaining packages in Y , and finally replicates from Y to provision for the handler.</p><p>Import-Cache Eviction: The import cache measures the cumulative memory utilization of all entries; when utilization surpasses a limit, a background process begins evicting entries. Deciding which interpreters to evict is challenging because the shared memory between interpreters makes it difficult to account for the memory used by a particular entry. The import cache relies on a simple runtime model to estimate potential memory reclamation; the model identifies the packages included by an interpreter that are not included by the parent entry. The model uses the on-disk size of the packages as a heuristic for estimating memory cost. The import cache treats the sum of these sizes as the benefit of eviction and the number of uses over a recent time interval as the cost of eviction, evicting the entry with highest benefit-to-cost ratio.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Evaluation</head><p>We now evaluate the performance of SOCK relative to Docker-based OpenLambda and other platforms. We run experiments on two m510 machines <ref type="bibr" target="#b9">[11]</ref> with the 4.13.0-37 Linux kernel: a package mirror and an OpenLambda worker. The machines have 8-core 2.0 GHz Xeon D-1548 processors, 64 GB of RAM, and a 256 GB NVMe SSD. We allocate 5 GB of memory for the handler cache and 25 GB for the import cache. We consider the following questions: What speedups do SOCK containers provide OpenLambda ( §5.1)? Does built-in package support reduce cold-start latency for applications with dependencies ( §5.2)? How does SOCK scale with the number of lambdas and packages ( §5.3)? And how does SOCK compare to other platforms for a real workload ( §5.4)?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Container Optimizations</head><p>SOCK avoids many of the expensive operations necessary to construct a general-purpose container (e.g., network namespaces, layered file systems, and fresh cgroups). In order to evaluate the benefit of lean containerization, we concurrently invoke no-op lambdas on OpenLambda, using either Docker or SOCK as the container engine. We disable all SOCK caches and Zygote preinitialization. <ref type="figure" target="#fig_0">Figure 14</ref> shows the request throughput and average latency as we vary the number of concurrent outstanding requests. SOCK is strictly faster on both metrics, regardless of concurrency. For 10 concurrent re-   quests, SOCK has a throughput of 76 requests/second (18× faster than Docker) with an average latency of 130 milliseconds (19× faster). Some of the namespaces used by Docker rely heavily on RCUs ( §2.2), which scale poorly with the number of cores <ref type="bibr" target="#b33">[34]</ref>. <ref type="figure" target="#fig_0">Figure 14</ref> also shows Docker performance with only one logical core enabled: relative to using all cores, this reduces latency by 44% for concurrency = 1, but throughput no longer scales with concurrency. SOCK also improves performance by using Zygotestyle preinitialization. Even if a lambda uses no libraries, provisioning a runtime by forking an existing Python interpreter is faster than starting from scratch. <ref type="figure" target="#fig_0">Figure 15</ref> compares SOCK throughput with and without Zygote preinitialization. Using Zygotes provides SOCK with an additional 3× throughput improvement at scale.</p><p>OpenLambda, like AWS Lambda <ref type="bibr" target="#b47">[49]</ref>, keeps recently used handlers that are idle in a paused state in order to avoid cold start should another request arrive. We now compare the latency of SOCK cold start to the latency of unpause, as shown in <ref type="figure" target="#fig_0">Figure 16</ref>. Although Zygotes have reduced no-op cold-start latency to 32 ms (concurrency = 10), unpausing takes only 3 ms. Although SOCK cold-start optimizations enable more aggressive resource reclamation, it is still beneficial to pause idle handlers before immediately evicting them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Package Optimizations</head><p>SOCK provides two package-oriented optimizations. First, SOCK generalizes the Zygote approach so that new containers can be allocated by one of many different Zygote containers, each with different packages pre-imported, based on the current workload (import caching). Second, a large subset of packages are preinstalled to a partition that is bind-mounted read-only in every container (install caching).</p><p>We first evaluate these optimizations together with a simple workload, where a single task sequentially invokes different lambdas that use the same single library, but perform no work. <ref type="figure" target="#fig_0">Figure 17</ref> shows the result. Without optimizations, downloading, installing, and importing usually takes at least a second. The optimizations reduce latency to 20 ms, at least a 45× improvement.</p><p>To better understand the contributions of the three caching layers (i.e., the new import and install caches and the old handler cache), we repeat the experiment in each cache in isolation. For each experiment, 100 different lambdas import django, and a single task sequentially invokes randomly-chosen lambdas. <ref type="figure" target="#fig_0">Figure 18</ref> shows the results. The handler cache has bimodal latency: it usually misses, but is fastest upon a hit. The working set fits in the import cache, which provides consistent latencies around 20 ms; the install cache is also consistent, but slower. Using all caches together provides better performance than any one individually. When import caching is enabled, processes in the handler cache and processes in the import cache are part of the same process tree. This structure leads to deduplication: multiple processes in the handler cache can share the same memory page on a copy-on-write basis with a parent process in the import cache. This allows the handler cache to maintain more cache entries. <ref type="figure" target="#fig_0">Figure 19</ref> illustrates this helpful interaction. We issue 200 requests to many different lambdas, all of which import django, without an import cache (experiment 1) and with an import cache (experiment 2). In the first experiment, the handler cache has 18% hits. In the second, deduplication allows the handler cache to maintain more entries, achieving 56% hits.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Scalability</head><p>We stress test SOCK with a large set of artificial packages (100K). The packages generate CPU load and memory load, similar to measured overheads of 20 popular packages ( §3.1). We create dependencies between packages similar to the PyPI dependency structure. Each handler imports 1-3 packages directly. The packages used are decided randomly based on package popularity; popularity is randomly assigned with a Zipfian distribution, s = 2.5. All packages are pre-installed to the install cache.</p><p>We also vary the number of handlers (100 to 10K). A small working set exercises the handler cache, and a large working set exercises the install cache. The import cache should service mid-sized working sets. Handlers are executed uniformly at random as fast as possible by 10 concurrent tasks. <ref type="figure">Figure 20</ref> shows a latency CDF for each working set size. With 100 handlers, SOCK achieves low latency (39 ms median). For 10K handlers, 88% percent of requests must be serviced from the install cache, so the median latency is 502 ms. For 500 handlers, the import cache absorbs 46% of the load, and the handler cache absorbs 6.4%, resulting in 345 ms latencies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Case Study: Image Resizing</head><p>In order to evaluate a real serverless application, we implement on-demand image resizing <ref type="bibr" target="#b26">[28]</ref>. A lambda reads an image from AWS S3, uses the Pillow package to resize it <ref type="bibr" target="#b8">[10]</ref>, and writes the output back to AWS S3. For this experiment, we compare SOCK to AWS Lambda and OpenWhisk, using 1 GB lambdas (for AWS Lambda) and a pair of m4.xlarge AWS EC2 instances (for SOCK and OpenWhisk); one instance services requests and the other hosts handler code. We use AWS's US East region for EC2, Lambda, and S3.</p><p>For SOCK, we preinstall Pillow and the AWS SDK <ref type="bibr" target="#b42">[44]</ref> (for S3 access) to the install cache and specify these as handler dependencies. For AWS Lambda and OpenWhisk, we bundle these dependencies with the handler itself, inflating the handler size from 4 KB to 8.3 MB. For each platform, we exercise cold-start performance by measuring request latency after re-uploading our code as a new handler. We instrument handler code to separate compute and S3 latencies from platform latency.</p><p>The first three bars of <ref type="figure" target="#fig_0">Figure 21</ref> show compute and platform results for each platform (average of 50 runs). "SOCK cold" has a platform latency of 365 ms, 2.8× faster than AWS Lambda and 5.3× faster than OpenWhisk. "SOCK cold" compute time is also shorter than the other compute times because all package initialization happens after the handler starts running for the other platforms, but SOCK performs package initialization work as part of the platform. The "SOCK cold+" represents a scenario similar to "SOCK cold" where the handler is being run for the first time, but a different handler that also uses the Pillow package has recently run. This scenario further reduces SOCK platform latency by 3× to 120 ms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Related Work</head><p>Since the introduction of AWS Lambda in 2014 <ref type="bibr" target="#b4">[5]</ref>, many new serverless platforms have become available <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b12">14,</ref><ref type="bibr" target="#b15">17,</ref><ref type="bibr" target="#b37">39,</ref><ref type="bibr" target="#b43">45]</ref>. We build SOCK over OpenLambda <ref type="bibr" target="#b18">[20]</ref>. SOCK implements and extends our earlier Pipsqueak proposal for efficient package initialization <ref type="bibr" target="#b36">[38]</ref>.</p><p>In this work, we benchmark various task-provisioning primitives and measure package initialization costs. Prior studies have ported various applications to the lambda model in order to evaluate platform performance <ref type="bibr" target="#b19">[21,</ref><ref type="bibr" target="#b31">33]</ref>. <ref type="bibr">Spillner et al. [46]</ref> ported Java applications to AWS Lambda to compare performance against other platforms, and Fouladi et al. <ref type="bibr" target="#b14">[16]</ref> built a video encoding platform over lambdas. <ref type="bibr">Wang et al. [50]</ref> reverse engineer many design decisions made by major serverless platforms.</p><p>There has been a recent revival of interest in sandboxing technologies. Linux containers, made popular through Docker <ref type="bibr" target="#b35">[36]</ref>, represent the most mainstream technology; as we show herein, the state of the art is not yet tuned to support lambda workloads. OpenWhisk, which uses Docker containers, hides latency by maintaining pools of ready containers <ref type="bibr" target="#b45">[47]</ref>. Recent alternatives to traditional containerization are based on library operating systems, enclaves, and unikernels <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b22">24,</ref><ref type="bibr" target="#b27">29,</ref><ref type="bibr" target="#b29">31,</ref><ref type="bibr" target="#b39">41,</ref><ref type="bibr" target="#b40">42]</ref>.</p><p>The SOCK import cache is a generalization of the Zygote approach first used by Android <ref type="bibr" target="#b7">[8]</ref> for Java processes. Akkus et al. <ref type="bibr" target="#b0">[1]</ref> also leverage this technique to efficiently launch multiple lambdas in the same container when the lambdas belong to the same application. Zygotes have also been used for browser processes (sometimes in conjunction with namespaces <ref type="bibr" target="#b10">[12]</ref>). We believe SOCK's generalized Zygote strategy should be generally applicable to other language runtimes that dynamically load libraries or have other initialization costs such as JIT-compilation (e.g., the v8 engine for Node.js <ref type="bibr" target="#b23">[25]</ref> or the CLR runtime for C# <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b28">30]</ref>); however, it is not obvious how SOCK techniques could be applied to staticallylinked applications (e.g., most Go programs <ref type="bibr" target="#b51">[53]</ref>).</p><p>Process caching often has security implications. For example, HotTub <ref type="bibr" target="#b25">[27]</ref> reuses Java interpreters, but not between different Linux users. Although the Zygote approach allows cache sharing between users, Lee et al. <ref type="bibr" target="#b24">[26]</ref> observed that forking many child processes from the same parent without calling exec undermines address-space randomization; their solution was Morula, a system that runs exec every time, but maintains a pool of preinitialized interpreters; this approach trades overall system throughput for randomization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusion</head><p>Serverless platforms promise cost savings and extreme elasticity to developers. Unfortunately, these platforms also make initialization slower and more frequent, so many applications and microservices may experience slowdowns if ported to the lambda model. In this work, we identify container initialization and package dependencies as common causes of slow lambda startup. Based on our analysis, we build SOCK, a streamlined container system optimized for serverless workloads that avoids major kernel bottlenecks. We further generalize Zygote provisioning and build a package-aware caching system. Our hope is that this work, alongside other efforts to minimize startup costs, will make serverless deployment viable for an ever-growing class of applications.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Storage Primitives. The performance of mount-</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Network Namespace Performance. A given number of containers (x-axis) are created and deleted in parallel with multiple network namespace configurations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. Cgroup Primitives. Cgroup performance is shown for reuse and fresh-creation patterns.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 7 .Figure 8 .Figure 9 .</head><label>789</label><figDesc>Figure 7. Startup Costs. The download, install, and import times are shown for 20 popular Python packages, ordered by total initialization time.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>Figure 10. Lean Containers</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 13 .</head><label>13</label><figDesc>Figure 13. Tree Cache. Numbered circles represent Zygotes in the cache, and sets of letters indicate the packages imported by a process. Arrows represent the parent-child relationships between interpreter processes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 14 .Figure 15 .</head><label>1415</label><figDesc>Figure 14. Docker vs. SOCK. Request throughput (xaxis) and latency (y-axis) are shown for SOCK (without Zygotes) and Docker for varying concurrency.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 17 .</head><label>17</label><figDesc>Figure 17. Pre-Imported Packages. SOCK latency with and without package caches are shown.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 18 .Figure 19 .Figure 20 .Figure 21 .</head><label>18192021</label><figDesc>Figure 18. Individual Caches. Each line shows a latency CDF for a different configuration for the django experiment.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>. Development</head><label>Development</label><figDesc></figDesc><table>Web 
Analysis 
Communication 

Storage 
Development 
Other 

11.5% 

4.7% 
3.1% 
1.9% 
1.8% 
1.5% 
1.5% 
1.2% 
1.1% 
1.1% 
1.0% 
0.8% 
0.7% 
0.7% 
0.7% 
0.7% 
0.6% 
0.6% 
0.6% 
0.6% 

64% 

django 
numpy 
setuptools 
pip 
flask 
matplotlib 
werkzeug 
requests 
sqlalchemy 
jinja2 
scipy 
protobuf 
pandas 
six 
simplejson 
twisted 
PyQt4 
updates 
dnspython 
mock 
Other 

0 

3 

6 

9 

12 

15 

Percent of Imports 

PyPI Package 

Figure 6. Package Popularity. The twenty most used PyPI 

packages are shown. The bar labels represent the percentage of 
all GitHub-to-PyPI dependencies. 

PyPI Package 

Time (s) 

import 
install 
download 

12.8s 

10.4s 
9.8s 
9.8s 

4.4s 
4.0s 
3.8s 
3.7s 
2.9s 
2.5s 
2.4s 
2.3s 
2.1s 
1.8s 
1.7s 
1.5s 
1.3s 
1.2s 
1.0s 
not installable for us 

pandas 
twisted 
scipy 
matplotlib 
sqlalchemy 
django 
flask 
numpy 
simplejson 
protobuf 
jinja2 
updates 
pip 
setuptools 
requests 
mock 
werkzeug 
dnspython 
six 
PyQt4 

</table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We thank the anonymous ATC reviewers, the members of ADSL, and our colleagues at GSL for their valuable input. This material was supported by funding from NSF grant CNS-1421033, DOE grant DESC0014935, and student funding from Microsoft. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and may not reflect the views of NSF, DOE, Microsoft, or other institutions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>USENIX Association</head></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">SAND: Towards High-Performance Serverless Computing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruichuan</forename><surname>Istemi Ekin Akkus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivica</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manuel</forename><surname>Rimac</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andre</forename><surname>Satzke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paarijaat</forename><surname>Beck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Volker</forename><surname>Aditya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hilt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 USENIX Annual Technical Conference (USENIX ATC 18). USENIX Association</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Operating Systems: Three Easy Pieces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Remzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><forename type="middle">C</forename><surname>Arpaci-Dusseau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Arpaci-Dusseau</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015-05" />
		</imprint>
	</monogr>
	<note>Arpaci-Dusseau Books, 0.91 edition</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<ptr target="https://docs.microsoft.com/en-us/dotnet/framework/app-domains/assemblies-in-the-common-language-runtime" />
		<title level="m">Assemblies in the Common Language Runtime</title>
		<imprint>
			<date type="published" when="2018-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">AWS Developer Forums: Java Lambda Inappropriate for Quick Calls?</title>
		<ptr target="https://forums.aws.amazon.com/thread.jspa?messageID=679050" />
		<imprint>
			<date type="published" when="2015-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aws</forename><surname>Lambda</surname></persName>
		</author>
		<ptr target="https://aws.amazon.com/lambda/" />
		<imprint>
			<date type="published" when="2018-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Microsoft Azure Functions</surname></persName>
		</author>
		<ptr target="https://azure.microsoft.com/en-us/services/functions/" />
		<imprint>
			<date type="published" when="2018-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Shielding Applications from an Untrusted Cloud with Haven</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Baumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcus</forename><surname>Peinado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Galen</forename><surname>Hunt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Computer Systems (TOCS)</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Dalvik Virtual Machine Internals. Talk at Google I/O</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Bornstein</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Pillow Python Imaging Library</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Clark</surname></persName>
		</author>
		<ptr target="https://pillow.readthedocs.io/en/latest/" />
		<imprint>
			<date type="published" when="2018-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cloudlab</surname></persName>
		</author>
		<ptr target="https://www.cloudlab.us/" />
		<imprint>
			<date type="published" when="2018-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chromium</forename><forename type="middle">Linux</forename><surname>Docs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sandboxing</surname></persName>
		</author>
		<ptr target="https://chromium.googlesource.com/chromium/src/+/lkcr/docs/linux_sandboxing.md" />
		<imprint>
			<date type="published" when="2018-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Re: net: cleanup net is slow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Dumazet</surname></persName>
		</author>
		<ptr target="https://lkml.org/lkml/2017/4/21/533" />
		<imprint>
			<date type="published" when="2017-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Introducing Functions as a Service (OpenFaaS</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Ellis</surname></persName>
		</author>
		<ptr target="https://blog.alexellis.io/introducing-functions-as-a-service/" />
		<imprint>
			<date type="published" when="2017-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Handling Flash Crowds from Your Garage</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeremy</forename><surname>Elson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jon</forename><surname>Howell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">USENIX 2008 Annual Technical Conference, ATC&apos;08</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="171" to="184" />
		</imprint>
	</monogr>
	<note>USENIX Association</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Encoding, Fast and Slow: Low-Latency Video Processing Using Thousands of Tiny Threads</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sadjad</forename><surname>Fouladi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Riad</forename><forename type="middle">S</forename><surname>Wahby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brennan</forename><surname>Shacklett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karthikeyan</forename><forename type="middle">Vasuki</forename><surname>Balasubramaniam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rahul</forename><surname>Bhalerao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anirudh</forename><surname>Sivaraman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Porter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keith</forename><surname>Winstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">14th USENIX Symposium on Networked Systems Design and Implementation (NSDI 17)</title>
		<meeting><address><addrLine>Boston, MA</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="363" to="376" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Google</forename><surname>Cloud Functions</surname></persName>
		</author>
		<ptr target="https://cloud.google.com/functions/docs/" />
		<imprint>
			<date type="published" when="2018-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Why Do Computers Stop and What Can We Do About It</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jim</forename><surname>Gray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">6th International Conference on Reliability and Distributed Databases</title>
		<imprint>
			<date type="published" when="1987-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A File is Not a File: Understanding the I/O Behavior of Apple Desktop Applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tyler</forename><surname>Harter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dragga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Vaughn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><forename type="middle">C</forename><surname>Arpaci-Dusseau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Remzi</forename><forename type="middle">H</forename><surname>Arpaci-Dusseau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Third ACM Symposium on Operating Systems Principles, SOSP &apos;11</title>
		<meeting>the Twenty-Third ACM Symposium on Operating Systems Principles, SOSP &apos;11</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="71" to="83" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Serverless Computation with OpenLambda</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Hendrickson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Sturdevant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tyler</forename><surname>Harter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Venkateshwaran</forename><surname>Venkataramani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><forename type="middle">C</forename><surname>Arpacidusseau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Remzi</forename><forename type="middle">H</forename><surname>Arpaci-Dusseau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">8th USENIX Workshop on Hot Topics in Cloud Computing</title>
		<meeting><address><addrLine>Denver, CO</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>HotCloud 16</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Occupy the Cloud: Distributed Computing for the 99%</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Jonas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qifan</forename><surname>Pu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shivaram</forename><surname>Venkataraman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ion</forename><surname>Stoica</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Recht</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Symposium on Cloud Computing</title>
		<meeting>the 2017 Symposium on Cloud Computing</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="445" to="451" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Flash Crowds and Denial of Service Attacks: Characterization and Implications for CDNs and Web Sites</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaeyeon</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Balachander</forename><surname>Krishnamurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Rabinovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th International Conference on World Wide Web, WWW &apos;02</title>
		<meeting>the 11th International Conference on World Wide Web, WWW &apos;02</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="293" to="304" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Revisiting Storage for Smartphones</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyojun</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitin</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristian</forename><surname>Ungureanu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th USENIX Conference on File and Storage Technologies, FAST&apos;12</title>
		<meeting>the 10th USENIX Conference on File and Storage Technologies, FAST&apos;12</meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="17" to="17" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Open-Sourcing gVisor, a Sandboxed Container Runtime</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Lacasse</surname></persName>
		</author>
		<ptr target="https://cloudplatform.googleblog.com/2018/05/Open-sourcing-gVisor-a-sandboxed-container-runtime.html" />
		<imprint>
			<date type="published" when="2018-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">How the V8 Engine Works?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thibault</forename><surname>Laurens</surname></persName>
		</author>
		<ptr target="http://thibaultlaurens.github.io/javascript/2013/04/29/how-the-v8-engine-works/" />
		<imprint>
			<date type="published" when="2013-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">From Zygote to Morula: Fortifying Weakened ASLR on Android</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Byoungyoung</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Long</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tielei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taesoo</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenke</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Security and Privacy (SP), 2014 IEEE Symposium on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="424" to="439" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Don&apos;t Get Caught In the Cold, Warm-up Your JVM</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Lion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adrian</forename><surname>Chiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hailong</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikola</forename><surname>Grcevski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ding</forename><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Symposium on Operating Systems Design and Implementation (OSDI &apos;16)</title>
		<meeting>the Symposium on Operating Systems Design and Implementation (OSDI &apos;16)<address><addrLine>Savannah, Georgia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Liston</surname></persName>
		</author>
		<ptr target="https://aws.amazon.com/blogs/compute/resize-images-on-the-fly-with-amazon-s3-aws-lambda-and-amazon-api-gateway/" />
		<title level="m">Resize Images on the Fly with Amazon S3, AWS Lambda, and Amazon API Gateway</title>
		<imprint>
			<date type="published" when="2017-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Unikernels: Library Operating Systems for the Cloud</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anil</forename><surname>Madhavapeddy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Mortier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charalampos</forename><surname>Rotsos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Scott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Balraj</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Gazagnaire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Hand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jon</forename><surname>Crowcroft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS &apos;13)</title>
		<meeting>the International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS &apos;13)<address><addrLine>Houston, Texas</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
				<ptr target="https://docs.microsoft.com/en-us/dotnet/standard/managed-execution-process" />
		<title level="m">Managed Execution Process</title>
		<imprint>
			<date type="published" when="2018-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">My VM is Lighter (and Safer) Than Your Container</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Filipe</forename><surname>Manco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Costin</forename><surname>Lupu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jose</forename><surname>Mendes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Kuenzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Sati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenichi</forename><surname>Yasukata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Costin</forename><surname>Raiciu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felipe</forename><surname>Huici</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th Symposium on Operating Systems Principles, SOSP &apos;17</title>
		<meeting>the 26th Symposium on Operating Systems Principles, SOSP &apos;17</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="218" to="233" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linux</forename><surname>Manpages</surname></persName>
		</author>
		<ptr target="https://www.systutorials.com/docs/linux/man/2-pivot_root/" />
		<title level="m">Linux Man Pages</title>
		<imprint>
			<date type="published" when="2018-02" />
		</imprint>
	</monogr>
	<note>pivot root</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Serverless Computing: Design, Implementation, and Performance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Garrett</forename><surname>Mcgrath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><forename type="middle">R</forename><surname>Brenner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Distributed Computing Systems Workshops</title>
		<imprint>
			<publisher>ICDCSW</publisher>
			<biblScope unit="page">2017</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
				<title level="m">IEEE 37th International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="405" to="410" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Introduction to RCU Concepts: Liberal application of procrastination for accommodation of the laws of physics for more than two decades! In LinuxCon Europe</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Paul E Mckenney</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">RCU Usage in the Linux Kernel: One Decade Later</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silas</forename><surname>Paul E Mckenney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Boyd-Wickizer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Walpole</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Docker: Lightweight Linux Containers for Consistent Development and Deployment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><surname>Merkel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Linux Journal, Issue</title>
		<imprint>
			<biblScope unit="volume">239</biblScope>
			<date type="published" when="2014-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Pipsqueak: Lean Lambdas with Large Libraries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Oakes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leon</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Houck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tyler</forename><surname>Harter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><forename type="middle">C</forename><surname>Arpaci-Dusseau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Remzi</forename><forename type="middle">H</forename><surname>Arpacidusseau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE 37th International Conference on Distributed Computing Systems Workshops (ICDCSW)</title>
		<imprint>
			<date type="published" when="2017-06" />
			<biblScope unit="page" from="395" to="400" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ibm Cloud Functions</surname></persName>
		</author>
		<ptr target="https://www.ibm.com/cloud/functions" />
		<imprint>
			<date type="published" when="2018-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Another Go at Language Design</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Pike</surname></persName>
		</author>
		<ptr target="http://www.stanford.edu/class/ee380/Abstracts/100428.html" />
		<imprint>
			<date type="published" when="2010-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Rethinking the Library OS from the Top Down</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donald</forename><forename type="middle">E</forename><surname>Porter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silas</forename><surname>Boyd-Wickizer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jon</forename><surname>Howell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reuben</forename><surname>Olinsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Galen</forename><forename type="middle">C</forename><surname>Hunt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixteenth International Conference on Architectural Support for Programming Languages and Operating Systems, AS-PLOS XVI</title>
		<meeting>the Sixteenth International Conference on Architectural Support for Programming Languages and Operating Systems, AS-PLOS XVI</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="291" to="304" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Introducing Asylo: an Open-Source Framework for Confidential Computing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nelly</forename><surname>Porter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Garms</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Simakov</surname></persName>
		</author>
		<ptr target="https://cloudplatform.googleblog.com/2018/05/Introducing-Asylo-an-open-source-framework-for-confidential-computing.html" />
		<imprint>
			<date type="published" when="2018-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Ries</surname></persName>
		</author>
		<title level="m">The Lean Startup. Crown Business</title>
		<imprint>
			<date type="published" when="2011-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Amazon Web Services. The AWS SDK for Python</title>
		<ptr target="https://boto3.readthedocs.io/en/latest/" />
		<imprint>
			<date type="published" when="2018-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Announcing Fn: An Open Source Serverless Functions Platform</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaun</forename><surname>Smith</surname></persName>
		</author>
		<ptr target="https://blogs.oracle.com/developers/announcing-fn" />
		<imprint>
			<date type="published" when="2017-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Java Code Analysis and Transformation into AWS Lambda Functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Spillner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serhii</forename><surname>Dorodko</surname></persName>
		</author>
		<idno>abs/1702.05510</idno>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Squeezing the milliseconds: How to make serverless platforms blazing fast! https://medium.com/openwhisk/squeezingthe-milliseconds-how-to-make-serverlessplatforms-blazing-fast-aea0e9951bd0</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Thömmes</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Typosquatting in Programming Language Package Managers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikolai</forename><forename type="middle">Philipp</forename><surname>Tschacher</surname></persName>
		</author>
		<ptr target="http://incolumitas.com/data/thesis.pdf" />
	</analytic>
	<monogr>
		<title level="m">University of Hamburg</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">Bachelor Thesis</note>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Understanding Container Reuse in AWS Lambda</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Wagner</surname></persName>
		</author>
		<ptr target="https://aws.amazon.com/blogs/compute/container-reuse-in-lambda/" />
		<imprint>
			<date type="published" when="2014-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Peeking Behind the Curtains of Serverless Platforms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengyuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinqian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Ristenpart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Swift</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 USENIX Annual Technical Conference (USENIX ATC 18). USENIX Association</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">The 15 Most Popular Programming Languages, According to the &apos;Facebook for Programmers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Weinberger</surname></persName>
		</author>
		<ptr target="http://www.businessinsider.com/the-9-most-popular-programming-languages-according-to-the-facebook-for-programmers-2017-10#1-javascript-15" />
		<imprint>
			<date type="published" when="2017-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Configuration Debugging As Search: Finding the Needle in the Haystack</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Whitaker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">S</forename><surname>Cox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><forename type="middle">D</forename><surname>Gribble</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th Conference on Symposium on Opearting Systems Design &amp; Implementation</title>
		<meeting>the 6th Conference on Symposium on Opearting Systems Design &amp; Implementation</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="6" to="6" />
		</imprint>
	</monogr>
	<note>OSDI&apos;04</note>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Go executables are statically linked</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Williams</surname></persName>
		</author>
		<ptr target="http://matthewkwilliams.com/index.php/2014/09/28/go-executables-are-statically-linked-except-when-they-are-not/" />
		<imprint>
			<date type="published" when="2014-09" />
		</imprint>
	</monogr>
	<note>except when they are not</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">A Smart Hill-Climbing Algorithm for Application Server Configuration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowei</forename><surname>Xi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mukund</forename><surname>Raghavachari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cathy</forename><forename type="middle">H</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th international conference on World Wide Web</title>
		<meeting>the 13th international conference on World Wide Web</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page" from="287" to="296" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
