<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2020-09-29T02:57+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Caching in the Multiverse</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mania</forename><surname>Abdi</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Northeastern University</orgName>
								<orgName type="institution" key="instit2">Boston University</orgName>
								<address>
									<addrLine>‡ State Street</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amin</forename><surname>Mosayyebzadeh</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Northeastern University</orgName>
								<orgName type="institution" key="instit2">Boston University</orgName>
								<address>
									<addrLine>‡ State Street</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><forename type="middle">Hossein</forename><surname>Hajkazemi</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Northeastern University</orgName>
								<orgName type="institution" key="instit2">Boston University</orgName>
								<address>
									<addrLine>‡ State Street</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ata</forename><surname>Turk</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Northeastern University</orgName>
								<orgName type="institution" key="instit2">Boston University</orgName>
								<address>
									<addrLine>‡ State Street</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Orran</forename><surname>Krieger</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Northeastern University</orgName>
								<orgName type="institution" key="instit2">Boston University</orgName>
								<address>
									<addrLine>‡ State Street</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Desnoyers</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Northeastern University</orgName>
								<orgName type="institution" key="instit2">Boston University</orgName>
								<address>
									<addrLine>‡ State Street</addrLine>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Caching in the Multiverse</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>To get good performance for data stored in Object storage services like S3, data analysis clusters need to cache data locally. Recently these caches have started taking into account higher-level information from analysis framework, allowing prefetching based on predictions of future data accesses. There is, however, a broader opportunity; rather than using this information to predict one future, we can use it to select a future that is best for caching. This paper provides preliminary evidence that we can exploit the directed acyclic graph (DAG) of inter-task dependencies used by data-parallel frameworks such as Spark, PIG and Hive to improve application performance, by optimizing caching for the critical path through the DAG for the application. We present experimental results for PIG running TPC-H queries, showing completion time improvements of up to 23% vs our implementation of MRD, a state-of-the-art DAG-based prefetching system, and improvements of up to 2.5x vs LRU caching. We then discuss the broader opportunity for building a system based on this opportunity.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Modern data analytics platforms (e.g. Spark <ref type="bibr" target="#b38">[37]</ref>, PIG <ref type="bibr" target="#b19">[20]</ref>, or Hive <ref type="bibr" target="#b28">[27]</ref>) are often coupled with external data storage on services such as Amazon S3 <ref type="bibr" target="#b2">[3]</ref> and Azure Data Lake Store <ref type="bibr" target="#b16">[17]</ref>, resulting in storage bottlenecks <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b22">23]</ref>.</p><p>Multiple caching solutions have been developed to address this storage bottleneck, e.g. Solutions such as Pacman <ref type="bibr" target="#b4">[5]</ref>, Tachyon/Alluxio <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b15">16]</ref> and Apache:Ignite <ref type="bibr" target="#b5">[6]</ref> allow datasets to be cached within the local cluster. However given finite cache, and often even more limited bandwidth for fetching data into the cache, the performance of this cache depends on its caching policy, and recent studies show that traditional caching policies (e.g. LRU) for this workload perform poorly relative to task-specific ones <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b20">21]</ref>.</p><p>Higher-level analysis frameworks such as PIG <ref type="bibr" target="#b19">[20]</ref>, Hive <ref type="bibr" target="#b28">[27]</ref> and SPARK <ref type="bibr" target="#b38">[37]</ref> compile user programs into an execution plan consisting of multiple, for example, MapReduce <ref type="bibr" target="#b10">[11]</ref>, or Tez <ref type="bibr" target="#b25">[24]</ref> jobs, and a directed acyclic graph <ref type="bibr">(DAG)</ref> of dependencies between these jobs. Jobs are then scheduled in parallel, within the constraints set by these dependencies. Jobs can take minutes to even hours <ref type="bibr" target="#b8">[9]</ref>, resulting in execution plans which identify data accesses far into the future. Exploiting this knowledge of future access patterns results in significant improvements in caching performance vs. LRU and other history-based algorithms, as shown by works such as MemTune <ref type="bibr" target="#b34">[33]</ref>, LRC <ref type="bibr" target="#b37">[36]</ref> and <ref type="bibr" target="#b14">[15]</ref>.</p><p>These existing efforts use application DAG information to predict future data accesses, and then prefetch data into the cache and manage the cache contents based on those predictions. In doing so, they are not taking advantage of a fundamental opportunity. Rather than caching data given a prediction of task execution, can we exploit the information provided by the DAG to influence the order of task execution to enable more effective caching? That is, rather than managing/prefetching the cache based on one prediction of the future universe, can we select a universe for which caching will be more effective?</p><p>This paper provides preliminary evidence that the answer is yes. In a simple, semi automated experiment, we show that by caching can be used to optimize the critical path through the DAG, and present experimental results showing completion time improvements for TPC-H queries of as much as 2.5x over LRU and 23% over MRD <ref type="bibr" target="#b21">[22]</ref>, the state-of-the-art DAGbased approach (and in all cases no worse than MRD).</p><p>We next provide more background on the opportunity, present our initial evidence, and then discuss the research challenges and effort to exploit this opportunity in a systematic way.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background and Motivation</head><p>To explain DAG-guided caching, we consider the PIG workflow management framework, which compiles the user's query into a directed acyclic graph (DAG) of MapReduce <ref type="bibr" target="#b10">[11]</ref>, Spark <ref type="bibr" target="#b38">[37]</ref> or Tez <ref type="bibr" target="#b25">[24]</ref> jobs. In <ref type="figure" target="#fig_1">Figure 1a</ref>   Query 8 in PIG Latin <ref type="bibr" target="#b26">[25]</ref>, which is compiled by PIG into the execution plan DAG in <ref type="figure" target="#fig_1">Figure 1b</ref>. Tasks are then sorted by dependency into stages, and submitted for execution resulting in a timeline such as is seen in <ref type="figure" target="#fig_1">Figure 1c</ref>.</p><p>In this environment, caching policy can use not only information from previous requests, but knowledge of future requests derived from this execution plan 1 , including i) the dependency graph, ii) job type, and iii) job input datasets and sizes. In addition, to predict the execution timeline, we need to iv) predict individual job execution times, which may be done with data from past executions of the same job type (sort/join/etc. in PIG; application executable in some systems), and v) network and storage system bandwidth, which may be known or can be measured.</p><p>In <ref type="table">Table 1</ref> we see the jobs created by the PIG compiler (J 1 , J 2 , .., J 7 ) as well as the inputs to each job (I 1 , I 2 , ...., I 6−2 ) with their respective sizes. Runtime for each job (in arbitrary units) is predicted without cached input ("baseline runtime") as well as for the case where each input dataset is cached (expressed as runtime improvement over baseline). For this example we assume that speedups are additive, and that they are all-or-nothing; i.e. if one block of input for J 2 is fetched (I 2 is 2 units in size), there is no speedup, while it completes in 1 time unit if both units of I 2 are fetched. (We take this simplifying assumption from Pacman <ref type="bibr" target="#b4">[5]</ref>) <ref type="figure">Figure 2</ref>(a) shows the execution plan without prefetching <ref type="bibr" target="#b0">1</ref> We restrict our discussion to PIG; however the same approach may be used with Spark and other systems which expose internal dependencies. and with LRU cache management; completion time is 9 units as there is no input data re-use, and thus all inputs are read from remote storage (purple); at the bottom of the figure we see a timeline of jobs running at each unit of time.</p><p>MRD uses prior runtime information to predict the order and timing of data requests, prefetching data (green blocks) and evicting other data (orange) to improve performance. Prefetching allows job J 6 to run faster, resulting in a completion time of 8 units rather than 9.</p><p>At each point in time, MRD fetches the dataset which will be requested the soonest in the future; ties are broken arbitrarily. Stage 1 requires 10 units of input, but we have 6 units of cache; we show inputs for J 1 and J 2 being prefetched, but only part of the two inputs to J 3 , I 3−1 , so stage 1 ends at t 4 as before. Prefetching of inputs to J 5 begins at t 3 , when the inputs become more valuable than data already in the cache; however input I 5−2 cannot be completely loaded as inputs to J 3 , which is still running, are occupying 3 units of cache, and prefetching I 5−1 gives a speedup of 0 to J 5 . Finally at t 6 we prefetch I 6−1 but not I 6−2 , giving a speedup of 1 to job J 6 and completing the entire workflow one unit sooner.</p><p>By taking speedup information into account, we can do much better as shown in <ref type="figure">Figure 2c</ref>(c). For each stage of job execution, we prefetch the set of inputs (subject to available cache space) which will result in the largest decrease in overall execution time, or nothing if no decrease is possible. Thus inputs to J 1 and J 2 are ignored, as they cannot cause stage 1 to complete in less than 2 time units. However the inputs to 2 2 3_1 3_1 5_2 5_2 6_2 6_2 6_2 2 2 3_1 3_1 5_2 5_2 6_2 6_2 6_2</p><formula xml:id="formula_0">1 1 3_2 3_2 5_1 5_1 6_1 6_1 6_1 1 1 3_1 3_1 5_1 5_1 6_1 6_1 6_1 3_2 3_2 3_2 3_2 3_2 3_2 5_2 5_2 5_2 3_1 3_1 3_1 3_1 3_1 3_1 5_2 5_2 5_2 MRU LRU Time J3 J2 J1 J5 J4 J6 J7 t0 t1 t2 t3 t4 t5 t6 t7 t8 t9</formula><p>(a) LRU 3_2 3_2 3_2 3_2 3_2 5_2 5_2 5_2 2 2 2 5_2 5_2 5_2 5_2 5_2  <ref type="table">Table 1</ref>: Job characteristics and predicted runtime improvement Query #8.</p><formula xml:id="formula_1">1 1 1 5_2 5_1 5_1 5_1 6_2 6_2 1 1 1 5_1 5_1 5_1 5_1 6_1 6_1 3_1 3_1 3_1 3_1 3_1 3_1 6_2 6_2 6_2 3_1 3_1 3_1 3_1 3_1 3_1 6_1 6_1 6_1 Time J3 J2 J1 J5 J4 J6 J7 t0 t1 t2 t3 t4 t5 t6 t7 t8 (b) MRD 3_2 3_2 3_2 6_2 6_2 6_2 6_2 6_2 3_1 3_1 3_1 6_2 6_2 6_2 6_2 6_2 3_1 3_1 3_1 6_1 6_1 6_1 6_1 6_1 3_1 3_1 3_1 6_1 6_1 6_1 6_1 6_1 3_2</formula><p>job J 3 are fetched in their entirety, giving a 2-unit speedup and finishing the job (and thus the stage) by t 2 . There is not enough cache space to prefetch for J 5 , so none of its inputs are prefetched; as a result there is sufficient room to fetch all inputs to J 6 at the beginning of stage 2 (t 3 ), giving a 1-unit speedup and completing the workflow in 6 units of time. Given the above information and assumptions, we can (a) determine the feasibility of any prefetching/eviction schedule (e.g. does it fit in cache) and (b) estimate its completion time. From this, in turn, we can (in theory) determine the optimal prefetching schedule. In theory this problem is no doubt NP-complete; however for practical job schedules (especially with PIG stage-based scheduling) it is likely that good approximations may be found.</p><p>This approach leads to our suggested caching/pre-fetching strategy, which we call Near-Optimal Caching (NOC). NOC pulls DAG information along with job type (e.g. filter, sort, etc.) and input data sets for each job with the DAG and extracts their size from the storage. In addition, we estimate the job performance under two scenario: (1) when data is in the cache, (2) when data is not in the cache. We assume a staged execution model such as used by PIG, where all jobs complete before a stage ends. We use the scheduling information of the Pig execution framework and for each stage, we select the input datasets that could decrease the stage runtime the most by being in cache. Based on prior measurements of external storage throughput, for each to-be-prefetched dataset, we calculate its read latency from backend. This allows us to begin prefetching a dataset in time to have it in the cache when it is required.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Evaluation</head><p>We put together a simple experimental testbed to get a feeling for the performance gains that could be obtained with NOC.  executed all queries with and without caching and recorded the time of execution for each job within the query. In other words, we ran query and gather statistics when query's input is in the cache and when it is out of the cache.</p><p>Also, we modified Pig to output the execution plan (DAG of MapReduce jobs) before launching the query. Following the procedure explained in section 2, we created a I/O plan for which dataset should be prefetched/cached and when the prefetching request should be scheduled. We also modified Pig to provide timing and staging information as the query is executed by the framework 2 .</p><p>We processed the execution plan to create scripts that would run in parallel to the execution of the query. These scripts issue load requests to Alluxio to prefetch data and free requests to evict data from the cache. A separate script was generated that emulated the NOC and MRD algorithms. We compare the performance of these algorithms to LRU, implemented natively by Alluxio. The results of this experiment are shown in <ref type="figure" target="#fig_2">Figure 3</ref>. With this simple experiment, we see that NOC has substantial gains over LRU, achieves at least as good performance as our emulation of MRD and in the best case (i.e., Q19) NOC outperforms MRD by 22.8%. In the queries where NOC and MRD have identical performance, they choose the same datasets to evict and prefetch, while in other cases NOC chooses datasets based on future stages as shown in <ref type="figure">Figure 2</ref> for query 9.</p><p>This experiment suggests that a NOC implementation may well offer significant performance advantages. These results are, we believe, quite pessimistic. NOC will offer significantly more advantages in an environment where the bandwidth to storage is limited. The scheduling by Pig into stages, where jobs whose dependencies are met are not scheduled until all jobs in the previous stage have completed, greatly limits our opportunity to optimize in the current experimental environment. We also believe the degrees of freedom available with NOC will be more valuable when caching intermediate data sets (in these experiments we only cached input data sets) and when multiple tasks are being executed concurrently on the cluster and the cache resources are being shared.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Challenges and Future Work</head><p>What are the challenges in applying near-optimal caching to realistic systems, and what are the longer-term questions in pursuing this approach?</p><p>Runtime and speedup estimation: how can we estimate the speedup due to prefetching an input data set? Inferring speedup is a straightforward extension of the methods (e.g. regression) already in use to estimate job runtime based on job type and input data sets. More information may in fact be available from this data than can be used by current algorithms: e.g. if jobs were found to have partial speedups with partial data (instead of allor-nothing), or if speedups for multiple inputs were not additive.</p><p>It is an open research question as to whether we can actually schedule based on these more realistic models, however. Estimating job runtime with different levels of accuracy has been studied extensively <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b31">30]</ref>. Future work will compute the confidence interval to limit the consequences of inaccurate prediction. If insufficient information is available to predict the runtime accurately, the confidence interval will be wide, the strategy degrades to be the same as MRD.</p><p>Data Locality: Execution engines favor data locality when allocating resources for job execution; cache management decisions (i.e. where to cache a prefetched data item) thus impact scheduler job placement. Is this interaction a problem, and if so how can the execution scheduler and cache manager cooperate?</p><p>Running Concurrent Queries: Workflow management frameworks run multiple queries to reach higher resource utilization. Considering one query at a time does not necessarily lead to an optimum decision or even might degrade the performance of the other queries. A cache management needs to take into account other jobs from other queries and decide which datasets should be fetched to improve overall performance of the system (even though some queries' performance may deteriorate). Since query runtimes can be predicted by NOC, we propose using this information to perform shortest-job-first (SJF) scheduling across multiple queries <ref type="bibr" target="#b32">[31]</ref>.</p><p>Query priorities: Many analysis systems handle both interactive and batch queries. Prefetching for interactive queries is difficult, yet even interactive use often has many repeated patterns, leading to the question of whether we can predict and prefetch for future queries, thus improving interactive performance.</p><p>Writing to Cache: In the discussion above, all data sets have been assumed to be inputs. Writeback caching violates this assumption: intermediate results are kept in cache <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b15">16]</ref> before being written back to external storage. The size of these results is not known, but must be estimated based on job parameters, and write data must be prioritized in the cache until it can be written back.</p><p>Other platforms: It should be possible to apply this strategy to other DAG-based frameworks, such as HIVE, Spark, etc.</p><p>Other job types: Some fraction of jobs (20% in the Alibaba [1] traces) will not use frameworks with DAG information that can be used for prefetching. How can we handle those jobs and the cache they use, without either starving them or the DAG-based jobs? Can we infer dependencies and cache size utilizations for them?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related work</head><p>Cache management policies and prefetching has been studied extensively in different areas of computer system design <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b27">26,</ref><ref type="bibr" target="#b30">29]</ref>. Cache management policies for data analytics have been studied extensively. Traditionally, such work <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b35">34]</ref> exploits job execution history to speculate dataset future access pattern. However, there is also a small number of recent work that attempts to use future information extracted from higher level framework <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b36">35,</ref><ref type="bibr" target="#b37">36]</ref> for dataset caching and prefetching.</p><p>Mithril <ref type="bibr" target="#b35">[34]</ref> proposes a prefetching layer that applies data mining algorithms on block access history to speculate what to prefetch at time. <ref type="bibr">Netco [15]</ref> takes advantage of dataset access history to prefetch the best candidate based on available cache size and network bandwidth to meet deadline SLOs such as maximizing the number of finished jobs. Our approach is different from the enumerated methods as it relies on the future information.</p><p>Among work relying on future information, both SADP [8] and MRD <ref type="bibr" target="#b21">[22]</ref> rely on information from higher-level framework to find and prefetch the nearest dataset used in future. LRC <ref type="bibr" target="#b37">[36]</ref> prioritizes datasets to cache which has the most number of dependent jobs and evict datasets with least number of dependencies. Although all of them take advantage of the future information, they only consider a single dimension i.e., job dependency; however we take into account other dimensions e.g., dataset contribution in total runtime.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>Locally caching data sets is critical for compute clusters that use storage from object storage services. Researchers have started using scheduling information (i.e. job DAGs) from existing analytic environments to manage these caches. The fundamental insight of this work is that, rather than prefetching based on a prediction of job execution based on this information, we can use this information to influence the execution order in order to enable more effective caching. We developed a simple experimental environment that used DAGs extracted from PIG to prefetch data along the critical path of execution through the DAG, and evicted cached data that was no longer required. Even with this very simple experimental environment we obtained up to 22.8% improved performance, providing strong preliminary evidence of the power of this approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Discussion Topics</head><p>• What are the other analytic systems that we can use?</p><p>What changes we need to apply to popular systems such as SPARK to take advantage of NOC?</p><p>• How feasbile is it to apply the same idea to the frameworks such as Hive?</p><p>• What are the other workflow management frameworks that this idea can be applied to?</p><p>• Whe consider the network bandwidth to the backend storage is unlimited, however, in practice the network bandwidth resource is limited. What changes we need to make to deal with this limitation?</p><p>• How can we generate a more realistic workloads (e.g., with concurrent queries) to emphasize the propose idea?</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Execution of Query #8 from TPC-H benchmark using Pig framework. In (a) we see the query script with jobs and inputs identified in purple circles and grey squares, respectively. (b) shows the directed acyclic graph (DAG) produced by the Pig compiler, with the corresponding jobs and inputs; (c) is the Pig schedule of the DAG to the MapReduce framework, with jobs executed in breadth-first stages.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Effect of NOC data prefetching on query execution end-to-end latency.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head></head><label></label><figDesc>The experimental environment included a four node compute cluster and a four node storage cluster. The compute cluster nodes have 2x Intel Xeon CPU E5-2660 2.20GHz (16 total cores, 32 threads), 128GB RAM and 2x 10GbE NICs and the storage cluster nodes have 2x Intel Xeon E5-2660 CPU (28 total cores, 56 threads), 256GB RAM, 12 x 2 TB 7.2K SATA Seagate HDDs and 2x10GbE NICs. On the storage cluster we deployed CEPH [32] 12.2.7. On the compute nodes we deployed PIG [20] 0.17.0 on top of Hadoop [11] 2.8.4 and Alluxio [2] 1.8.0 as an in-memory cache layer. We dedicated 6GB of memory on each node to Alluxio for a total of 24GB of cache. We restricted Hadoop to 50GB of memory on each node. For evaluation, we used a subset of the TPC-H [28] bench- mark transformed into PIG Latin and run on a dataset of 32GB. We ran queries sequentially based on their order and before each query we clear the cache. Before the experiment, we</figDesc><table></table></figure>

			<note place="foot">I 3-2 I 5-1 I 5-2 I 6-1 I 6-2 (a) PIG Latin script</note>

			<note place="foot" n="2"> This required a 300 line patch to the PIG framework.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgment</head><p>We would like to acknowledge the feedback of the anonymous reviewers and our shepherd, Yu Hua, as well as contributions by Larry Rudolph. This work was supported in part by the Mass Open Cloud (massopen.cloud) and its industrial partners.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alibaba</forename><surname>Cloud Traces</surname></persName>
		</author>
		<ptr target="https://github.com/alibaba/clusterdata/tree/master/cluster-trace-v2018" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Alluxio -Open Source Memory Speed Virtual Distributed Storage</title>
		<ptr target="https://www.alluxio.org" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Inc. Amazon Web Services. Amazon Simple Storage Service</title>
		<imprint>
			<biblScope unit="issue">S3</biblScope>
		</imprint>
	</monogr>
	<note>Cloud Storage -AWS. available at aws.amazon.com/s3/</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emr</forename><surname>Amazon</surname></persName>
		</author>
		<ptr target="https://aws.amazon.com/emr/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">PACMan: Coordinated Memory Caching for Parallel Jobs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ganesh</forename><surname>Ananthanarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Ghodsi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Warfield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruba</forename><surname>Borthakur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srikanth</forename><surname>Kandula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Shenker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ion</forename><surname>Stoica</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Presented as part of the 9th USENIX Symposium on Networked Systems Design and Implementation (NSDI 12)</title>
		<meeting><address><addrLine>San Jose, CA</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="267" to="280" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Apache</forename><surname>Ignite</surname></persName>
		</author>
		<ptr target="https://ignite.apache.org/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">AdaptSize: Orchestrating the Hot Object Memory Cache in a Content Delivery Network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><forename type="middle">S</forename><surname>Berger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramesh</forename><forename type="middle">K</forename><surname>Sitaraman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mor</forename><surname>Harchol-Balter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">14th USENIX Symposium on Networked Systems Design and Implementation (NSDI 17)</title>
		<meeting><address><addrLine>Boston, MA</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="483" to="498" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">SchedulingAware Data Prefetching for Data Processing Services in Cloud</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hsia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kuo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE 31st International Conference on Advanced Information Networking and Applications (AINA)</title>
		<imprint>
			<date type="published" when="2017-03" />
			<biblScope unit="page" from="835" to="842" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Interactive Analytical Processing in Big Data Systems: A Cross-industry Study of MapReduce Workloads</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanpei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sara</forename><surname>Alspaugh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Randy</forename><surname>Katz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. VLDB Endow</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1802" to="1813" />
			<date type="published" when="2012-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">CAST: Tiering Storage for Data Analytics in the Cloud</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Safdar Iqbal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aayush</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><forename type="middle">R</forename><surname>Butt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th International Symposium on High-Performance Parallel and Distributed Computing, HPDC &apos;15</title>
		<meeting>the 24th International Symposium on High-Performance Parallel and Distributed Computing, HPDC &apos;15<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="45" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">MapReduce: Simplified Data Processing on Large Clusters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjay</forename><surname>Ghemawat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="107" to="113" />
			<date type="published" when="2008-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">ISP: Using idle SMs in hardware-based prefetching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Falahati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Abdi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Baniasadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hessabi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 17th CSI International Symposium on Computer Architecture Digital Systems (CADS 2013)</title>
		<imprint>
			<date type="published" when="2013-10" />
			<biblScope unit="page" from="3" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Power-efficient prefetching on GPGPUs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Falahati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hessabi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Abdi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Baniasadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Supercomputing</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2808" to="2829" />
			<date type="published" when="2015-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Bridging the Tenantprovider Gap in Cloud Services</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Virajith</forename><surname>Jalaparti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hitesh</forename><surname>Ballani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Costa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Karagiannis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ant</forename><surname>Rowstron</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third ACM Symposium on Cloud Computing, SoCC &apos;12</title>
		<meeting>the Third ACM Symposium on Cloud Computing, SoCC &apos;12<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Netco: Cache and I/O Management for Analytics over Disaggregated Stores</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Virajith</forename><surname>Jalaparti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Douglas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mainak</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashvin</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avrilia</forename><surname>Floratou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srikanth</forename><surname>Kandula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishai</forename><surname>Menache</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><forename type="middle">Seffi</forename><surname>Naor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sriram</forename><surname>Rao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Symposium on Cloud Computing, SoCC &apos;18</title>
		<meeting>the ACM Symposium on Cloud Computing, SoCC &apos;18<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="186" to="198" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Tachyon: Reliable, Memory Speed Storage for Cluster Computing Frameworks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoyuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Ghodsi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matei</forename><surname>Zaharia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Shenker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ion</forename><surname>Stoica</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Symposium on Cloud Computing, SOCC &apos;14</title>
		<meeting>the ACM Symposium on Cloud Computing, SOCC &apos;14<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Microsoft</forename><surname>Datalake</surname></persName>
		</author>
		<ptr target="http://azure.microsoft.com/en-us/solutions/data-lake" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hdinsight</forename><surname>Microsoft Azure</surname></persName>
		</author>
		<ptr target="https://azure.microsoft.com/en-us/services/hdinsight/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Scaling Memcache at Facebook</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajesh</forename><surname>Nishtala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans</forename><surname>Fugal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Grimm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herman</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harry</forename><forename type="middle">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcelroy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Paleczny</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Peek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Saab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Stafford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tony</forename><surname>Tung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Venkateshwaran</forename><surname>Venkataramani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th USENIX Conference on Networked Systems Design and Implementation, nsdi&apos;13</title>
		<meeting>the 10th USENIX Conference on Networked Systems Design and Implementation, nsdi&apos;13<address><addrLine>Berkeley, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="385" to="398" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Pig Latin: A Not-soforeign Language for Data Processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Olston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Utkarsh</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ravi</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Tomkins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2008 ACM SIGMOD International Conference on Management of Data, SIGMOD &apos;08</title>
		<meeting>the 2008 ACM SIGMOD International Conference on Management of Data, SIGMOD &apos;08<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1099" to="1110" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Making Sense of Performance in Data Analytics Frameworks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kay</forename><surname>Ousterhout</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Rasti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sylvia</forename><surname>Ratnasamy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Shenker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Byung-Gon</forename><surname>Chun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th USENIX Conference on Networked Systems Design and Implementation, NSDI&apos;15</title>
		<meeting>the 12th USENIX Conference on Networked Systems Design and Implementation, NSDI&apos;15<address><addrLine>Berkeley, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="293" to="307" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Reference-distance Eviction and Prefetching for Cache Management in Spark</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">G</forename><surname>Tiago</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaobo</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dazhao</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 47th International Conference on Parallel Processing</title>
		<meeting>the 47th International Conference on Parallel Processing<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="page" from="1" to="88" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baskar</forename><surname>Raghu Ramakrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">R</forename><surname>Sridharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavan</forename><surname>Douceur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Balaji</forename><surname>Kasturi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karthick</forename><surname>Krishnamacharisampath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Krishnamoorthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitica</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Spiro</forename><surname>Manu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rogério</forename><surname>Michaylov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil</forename><surname>Ramos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zee</forename><surname>Sharman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youssef</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Barakat</surname></persName>
		</author>
		<imprint>
			<pubPlace>Chris Douglas, Richard</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shrikant</forename><forename type="middle">S</forename><surname>Draves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shankar</forename><surname>Naidu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Atul</forename><surname>Shastry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Sikaria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramarathnam</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Venkatesan</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Azure Data Lake Store: A Hyperscale Distributed File Service for Big Data Analytics</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 ACM International Conference on Management of Data, SIGMOD &apos;17</title>
		<meeting>the 2017 ACM International Conference on Management of Data, SIGMOD &apos;17<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="51" to="63" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Apache Tez: A Unifying Framework for Modeling and Building Data Processing Applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bikas</forename><surname>Saha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hitesh</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siddharth</forename><surname>Seth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gopal</forename><surname>Vijayaraghavan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arun</forename><surname>Murthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlo</forename><surname>Curino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data, SIGMOD &apos;15</title>
		<meeting>the 2015 ACM SIGMOD International Conference on Management of Data, SIGMOD &apos;15<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1357" to="1369" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Savvas</forename><surname>Savvides</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tpch-Pig</surname></persName>
		</author>
		<ptr target="https://github.com/ssavvides/tpch-pig" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">RIPQ: Advanced Photo Caching on Flash for Facebook</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linpeng</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wyatt</forename><surname>Lloyd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th USENIX Conference on File and Storage Technologies, FAST&apos;15</title>
		<meeting>the 13th USENIX Conference on File and Storage Technologies, FAST&apos;15<address><addrLine>Berkeley, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="373" to="386" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Hive -a petabyte scale data warehouse using Hadoop</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Thusoo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Sarma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Chakka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Antony</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Murthy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2010 IEEE 26th International Conference on Data Engineering (ICDE 2010)</title>
		<imprint>
			<date type="published" when="2010-03" />
			<biblScope unit="page" from="996" to="1005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tpch</forename><surname>Benchmark</surname></persName>
		</author>
		<ptr target="http://www.tpc.org/tpch/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Steven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">J</forename><surname>Vanderwiel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lilja</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Prefetch Mechanisms. ACM Comput. Surv</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="174" to="199" />
			<date type="published" when="2000-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Ernest: Efficient Performance Prediction for Large-Scale Advanced Analytics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shivaram</forename><surname>Venkataraman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zongheng</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Franklin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Recht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ion</forename><surname>Stoica</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">13th USENIX Symposium on Networked Systems Design and Implementation (NSDI 16)</title>
		<meeting><address><addrLine>Santa Clara, CA</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="363" to="378" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">CLARINET: WAN-Aware Optimization for Analytics Queries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raajay</forename><surname>Viswanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ganesh</forename><surname>Ananthanarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Akella</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">12th USENIX Symposium on Operating Systems Design and Implementation (OSDI 16)</title>
		<meeting><address><addrLine>Savannah, GA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="435" to="450" />
		</imprint>
	</monogr>
<note type="report_type">USENIX Association</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Ceph: A Scalable, High-performance Distributed File System</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sage</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><forename type="middle">A</forename><surname>Weil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ethan</forename><forename type="middle">L</forename><surname>Brandt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Darrell</forename><forename type="middle">D E</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Maltzahn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th Symposium on Operating Systems Design and Implementation, OSDI &apos;06</title>
		<meeting>the 7th Symposium on Operating Systems Design and Implementation, OSDI &apos;06<address><addrLine>Berkeley, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="307" to="320" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">MEMTUNE: Dynamic Memory Management for In-Memory Data Analytic Platforms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">R</forename><surname>Butt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><forename type="middle">Z</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE International Parallel and Distributed Processing Symposium (IPDPS)</title>
		<imprint>
			<date type="published" when="2016-05" />
			<biblScope unit="page" from="383" to="392" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Mithril: Mining Sporadic Associations for Cache Prefetching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juncheng</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reza</forename><surname>Karimi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trausti</forename><surname>Saemundsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avani</forename><surname>Wildani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ymir</forename><surname>Vigfusson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Symposium on Cloud Computing, SoCC &apos;17</title>
		<meeting>the 2017 Symposium on Cloud Computing, SoCC &apos;17<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="66" to="79" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">LERC: Coordinated Cache Management for Data-Parallel Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">B</forename><surname>Letaief</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">GLOBECOM 2017 -2017 IEEE Global Communications Conference</title>
		<imprint>
			<date type="published" when="2017-12" />
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">LRC: Dependency-aware cache management for data analytics clusters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ben Letaief</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE INFOCOM 2017 -IEEE Conference on Computer Communications</title>
		<imprint>
			<date type="published" when="2017-05" />
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Spark: Cluster Computing with Working Sets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matei</forename><surname>Zaharia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mosharaf</forename><surname>Chowdhury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Franklin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Shenker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ion</forename><surname>Stoica</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2Nd USENIX Conference on Hot Topics in Cloud Computing, HotCloud&apos;10</title>
		<meeting>the 2Nd USENIX Conference on Hot Topics in Cloud Computing, HotCloud&apos;10</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="10" to="10" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
