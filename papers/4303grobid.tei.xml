<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2020-09-29T04:11+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Secure parallel computation on national scale volumes of data Secure parallel computation on national scale volumes of data</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>August 12-14, 2020</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sahar</forename><surname>Mazloom</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">George Mason University</orgName>
								<orgName type="institution" key="instit2">George Mason University</orgName>
								<orgName type="institution" key="instit3">George Mason University</orgName>
								<orgName type="institution" key="instit4">George Mason University</orgName>
								<orgName type="institution" key="instit5">Unbound Tech</orgName>
								<orgName type="institution" key="instit6">George Mason University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phi</forename><forename type="middle">Hung</forename><surname>Le</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">George Mason University</orgName>
								<orgName type="institution" key="instit2">George Mason University</orgName>
								<orgName type="institution" key="instit3">George Mason University</orgName>
								<orgName type="institution" key="instit4">George Mason University</orgName>
								<orgName type="institution" key="instit5">Unbound Tech</orgName>
								<orgName type="institution" key="instit6">George Mason University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Ranellucci</surname></persName>
							<email>samuel.ranellucci@unboundtech.com</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">George Mason University</orgName>
								<orgName type="institution" key="instit2">George Mason University</orgName>
								<orgName type="institution" key="instit3">George Mason University</orgName>
								<orgName type="institution" key="instit4">George Mason University</orgName>
								<orgName type="institution" key="instit5">Unbound Tech</orgName>
								<orgName type="institution" key="instit6">George Mason University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Unbound</forename><surname>Tech</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">George Mason University</orgName>
								<orgName type="institution" key="instit2">George Mason University</orgName>
								<orgName type="institution" key="instit3">George Mason University</orgName>
								<orgName type="institution" key="instit4">George Mason University</orgName>
								<orgName type="institution" key="instit5">Unbound Tech</orgName>
								<orgName type="institution" key="instit6">George Mason University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">;</forename><forename type="middle">S Dov</forename><surname>Gordon</surname></persName>
							<email>gordon@gmu.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">George Mason University</orgName>
								<orgName type="institution" key="instit2">George Mason University</orgName>
								<orgName type="institution" key="instit3">George Mason University</orgName>
								<orgName type="institution" key="instit4">George Mason University</orgName>
								<orgName type="institution" key="instit5">Unbound Tech</orgName>
								<orgName type="institution" key="instit6">George Mason University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sahar</forename><surname>Mazloom</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">George Mason University</orgName>
								<orgName type="institution" key="instit2">George Mason University</orgName>
								<orgName type="institution" key="instit3">George Mason University</orgName>
								<orgName type="institution" key="instit4">George Mason University</orgName>
								<orgName type="institution" key="instit5">Unbound Tech</orgName>
								<orgName type="institution" key="instit6">George Mason University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phi</forename><forename type="middle">Hung</forename><surname>Le</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">George Mason University</orgName>
								<orgName type="institution" key="instit2">George Mason University</orgName>
								<orgName type="institution" key="instit3">George Mason University</orgName>
								<orgName type="institution" key="instit4">George Mason University</orgName>
								<orgName type="institution" key="instit5">Unbound Tech</orgName>
								<orgName type="institution" key="instit6">George Mason University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Ranellucci</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">George Mason University</orgName>
								<orgName type="institution" key="instit2">George Mason University</orgName>
								<orgName type="institution" key="instit3">George Mason University</orgName>
								<orgName type="institution" key="instit4">George Mason University</orgName>
								<orgName type="institution" key="instit5">Unbound Tech</orgName>
								<orgName type="institution" key="instit6">George Mason University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">Dov</forename><surname>Gordon</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">George Mason University</orgName>
								<orgName type="institution" key="instit2">George Mason University</orgName>
								<orgName type="institution" key="instit3">George Mason University</orgName>
								<orgName type="institution" key="instit4">George Mason University</orgName>
								<orgName type="institution" key="instit5">Unbound Tech</orgName>
								<orgName type="institution" key="instit6">George Mason University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Secure parallel computation on national scale volumes of data Secure parallel computation on national scale volumes of data</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 29th USENIX Security Symposium</title>
						<meeting>the 29th USENIX Security Symposium						</meeting>
						<imprint>
							<date type="published">August 12-14, 2020</date>
						</imprint>
					</monogr>
					<note>This paper is included in the Open access to the Proceedings of the 29th USENIX Security Symposium is sponsored by USENIX.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We revisit the problem of performing secure computation of graph-parallel algorithms, focusing on the applications of securely outsourcing matrix factorization, and histograms. Leveraging recent results in low-communication secure multi-party computation, and a security relaxation that allows the computation servers to learn some differentially private leakage about user inputs, we construct a new protocol that reduces overall runtime by 320X, reduces the number of AES calls by 750X, and reduces the total communication by 200X. Our system can securely compute histograms over 300 million items in about 4 minutes, and it can perform sparse matrix factorization, which is commonly used in recommendation systems, on 20 million records in about 6 minutes. 1 Furthermore , in contrast to prior work, our system is secure against a malicious adversary that corrupts one of the computing servers.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Instances of data breach and exfiltration continue to occur in great number. Secure computation offers an appealing avenue for defense. This cryptographic tool allows user data to be secret-shared across multiple computational servers, ensuring that the breach of any single server provides no information to an adversary, while still enabling the servers to perform arbitrary computation on the data. As compared with standard encryption, which provides security only while the data remains at rest, secure computation allows the data to remain secure throughout its life-cycle, from the moment it is uploaded by the user, through its incorporation into some statistic or learned model.</p><p>The theory of secure computation has been studied since the 1980's, and a rich literature has given rise to a line of practical work that has focused on reducing concrete costs to a near minimum. Of course, there are no free lunches, and computing on secret-shared data will always require increased communication and computation when compared with the cost of computing on plaintext data. However, several recent research directions have helped narrow the gap between secure data processing and plaintext computations.</p><p>Low communication MPC. Several results in secure computation have recently minimized the communication requirements by restricting the number of computing servers to three <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b16">17]</ref> or four <ref type="bibr" target="#b9">[10]</ref>, and assuming an honest majority of the servers. When representing the computation as an arithmetic circuit over a ring (as we will do here), the cheapest of these results, by Gordon et al. <ref type="bibr" target="#b9">[10]</ref>, requires sending only 1.5 ring elements per party, per circuit gate. In contrast, the best two-party protocol requires 290 bytes per party, per Boolean gate <ref type="bibr" target="#b21">[22]</ref>, and the best honest-majority protocol (supporting arbitrary numbers of parties) requires 12 field elements per party, per gate <ref type="bibr" target="#b3">[4]</ref>.</p><p>Parallelizing secure computation. Nayak et al. <ref type="bibr" target="#b17">[18]</ref> propose a framework for securely computing graph parallel algorithms. In such algorithms, the data is assumed to reside in a graph structure, and the result of the computation is reached through an iterative process in which a) the data is gathered from all edges to their neighboring nodes, b) a simple computation is applied on the data at each node, and c) the processed data is scattered back to the neighboring edges before the processes are repeated. Such frameworks have become very popular for plaintext computations on large amounts of data, because the Apply phase can be easily distributed among many processors, making parallelization straight-forward <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b13">14]</ref>. In this work we implement gradient descent, yielding a secure protocol for sparse matrix factorization (commonly used in recommendation systems), as well as histograms. Graph parallel frameworks are also used for PageRank, Markov random field parameter learning, parallelized Gibbs samplers, name entity resolution, and many other computations.</p><p>Allowing differentially private leakage. Very recently, researchers have explored the idea of relaxing security to al-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>USENIX Association</head><p>29th USENIX Security Symposium 2487 low leakage in secure computation, coupled with a bound demonstrating that the leakage preserves differential privacy <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b19">20]</ref>. Mazloom and Gordon <ref type="bibr" target="#b15">[16]</ref> demonstrated a protocol for computing graph parallel algorithms with differentially private leakage, shaving a log E factor off of the fully secure protocol of Nayak et al., where E is the number of edges in the graph.</p><p>Securely outsourcing computation. These advances have introduced an opportunity for several applications of secure computation in which user data from thousands of parties are secret shared among a few servers (usually three) to perform a secure computation on their behalf. Multiple variants of this application have now been deployed. In some cases, users have already entrusted their data, in the clear, to a single entity, which then wishes to safeguard against data breach; secret sharing the data among several servers, each with a unique software stack, helps diversify the risk of exposure. In other cases, users were unwilling, or were even forbidden by law, to entrust their data to any single entity, and the use of secure computation was essential to gaining their participation in the computation. In many of these cases, the servers executing the secure computation are owned and operated by a single entity that is trusted for the time being, but may be corrupted by an outside party. In other cases, some data were entrusted to one entity, while other data, from another set of users, were entrusted to a second entity, and these two distrusting parties wish to join in a shared computation.</p><p>The common denominator in all of these variants is that the computation servers are distinct from the data owners. In this context, the relaxation allowing these servers to learn some small, statistical information about the data may be quite reasonable, as long as the impact to any individual data contributor can be bounded. For example, when computing a histogram of the populations in each U.S. zip code, the servers see only a noisy count for each zip code, gaining little information about the place of residence of any individual data contributor. In the context of securely performing matrix factorization for use in a recommendation system, we allow the servers to learn a noisy count of the number of items that each contributing user has reviewed. Even when combined with arbitrary external data, this limits the servers from gaining any certainty about the existence of a link between any given user and any given item in the system.</p><p>Our reliance on a fourth server in the computation introduces a tradeoff between security and efficiency, when compared with the more common reliance on three servers. <ref type="bibr" target="#b1">2</ref> It is almost certainly easier for an adversary to corrupt two out of four servers than it is to corrupt two out of three. However, as our results demonstrate, the use of a fourth server enables far faster computation, which, for large-scale applications, might <ref type="bibr" target="#b1">2</ref> From a purely logistical standpoint, we do not envision that this requirement will add much complexity. The additional server(s) can simply be run in one or more public clouds. In some cases, as already mentioned, all servers are anyway run by a single entity, so adding a fourth server may be trivial. make the use of secure computation far more feasible than it was previously.</p><p>Results. In this work, we revisit secure computation of graph parallel algorithms, simultaneously leveraging all three of the advances just described: we assume four computation servers (with an honest majority, and one malicious corruption), allow differentially private leakage during computation, and, exploiting the parallelism that this affords, we construct an MPC protocol that can perform at national scales. Concretely, we compute histograms on 300 million inputs in 4.17 minutes, and we perform sparse matrix factorization, which is used in recommendation systems, on 20 million inputs in under 6 minutes. These problems have broad, real-world applications, and, at this scale, we could imagine supporting the Census Bureau, or a large company such as Amazon. For comparison, the largest experiments in GraphSC <ref type="bibr" target="#b17">[18]</ref> and OblivGraph <ref type="bibr" target="#b15">[16]</ref> had 1M inputs, and required 13 hours and 2 hours of runtime, respectively, while using 4 times the number of processors that we employ, and tolerating only semi-honest corruptions. End-to-end, our construction is 320X faster than OblivGraph, the faster of these 2 systems.</p><p>Technical contributions. Merging the four-party protocol of Gordon et al. <ref type="bibr" target="#b9">[10]</ref> with the construction of Mazloom and Gordon <ref type="bibr" target="#b15">[16]</ref> raises several challenges and opportunities:</p><p>Fixed point arithmetic. There are few results in the MPC literature that support fixed point computation with malicious security. The most efficient that we know of is the work by Mohassel and Rindal, which uses replicated sharing in the three party, honest majority setting <ref type="bibr" target="#b16">[17]</ref>, modifying the protocol of Furakawa et al. <ref type="bibr" target="#b6">[7]</ref>. Their construction requires each party then sends 8 ring elements for each multiplication without truncation. The parties execute two subtraction circuits in pre-processing phase for each truncation. The pre-processing costs each party at least 21 · (2k − d) bits for each truncation where k is the size of the ring, and d the length of the fraction bits. With a bit of care, we show that we can extend the fourparty protocol of <ref type="bibr">Gordon et al. [10]</ref> to handle fixed point arithmetic, without any additional overhead, requiring each party to send just 1.5 ring elements for each multiplication. This provides about a 20X improvement in communication over Mohassel and Rindal. The protocol of Gordon et al. proceeds through a dual execution of masked circuit evaluation: for circuit wire i carrying value w i , one pair of parties holds w i + λ i , while the other holds w i + λ i , where λ i , λ i are random mask values known to the opposite pair. To ensure that nobody has cheated in the execution, the two pairs of parties compute and compare w i + λ i + λ i . This already supports computation over an arbitrary ring, with malicious security. However, if w i is a fractional value, the two random masks may result in different rounded values, causing the comparisons to fail. We show how to handle rounding errors securely, allowing us to leverage the efficiency of this protocol for fixed point computation.</p><p>Four party, linear-time, oblivious shuffle. The experimental results of Mazloom and Gordon have complexity O(V α + E) log(V α+E), where α = α(ε, δ) is a function of the desired privacy parameters, E is the number of edges in the graph, and V is the number of nodes. The authors also show how to improve the asymptotic complexity to O(V α + E), removing the log factor by replacing a circuit for performing an oblivious shuffle of the data with a linear-time oblivious shuffle. They don't leverage this improvement in their experimental results, because it seems to require encrypting and decrypting the data inside a secure computation. (Additionally, for malicious security, it would require expensive zero-knowledge proofs.)</p><p>Operating in the 4-party setting allows us to construct a highly efficient, linear-time protocol for oblivious shuffle. One of the challenges we face in constructing this shuffle protocol is that we have to authenticate the values before shuffling, and verify correctness of the values after shuffling, and because we are committed to computing over elements from Z 2 k , we need to authenticate ring values. Recently, Cramer et al. <ref type="bibr" target="#b4">[5]</ref> proposed a mechanism for supporting arithmetic circuits over finite rings by constructing authentication in an "extension ring": to compute in Z 2 k , they sample α ← Z 2 s , and use a secret-sharing of αx ∈ Z 2 k+s for authentication. We adopt their construction in our shuffle protocol to ensure the integrity of the data during shuffling.</p><p>One of the benefits of using 4 parties is that we can separate the operations between two groups of parties, such that one group, for example Alice and Bob, is responsible for accessing the data during Gather and Scatter, while the other group, Charlotte and David, performs the shuffling. In contrast, in the 2-party setting, if one party knows the shuffling permutation, then the other party must access each data element in a manner that hides the data index. This seemingly requires using a short decryption key inside the secure computation, rather than a more efficient, 2-party secret sharing scheme. On the other hand, if neither party knows the shuffling permutation, we need to use a permutation network incurring the additional log overhead. When comparing our four-party, maliciously secure, oblivious shuffling protocol with the semi-honest construction of Mazloom and Gordon, they require 540X more AES calls and 140X communication than we do. Computation over a ring. Both the work of Nayak et al. <ref type="bibr" target="#b17">[18]</ref> and Mazloom and Gordon <ref type="bibr" target="#b15">[16]</ref> use Boolean circuits throughout the computation. Boolean circuits are a sensible choice when using sorting and shuffling circuits, which require bit comparisons. Additionally, as just discussed, Boolean circuits provide immediate support for fixed point computation, removing one further barrier. However, for the Apply phase, where, for example, we compute vector gradients, computation in a ring (or field) is far more efficient. With the introduction of our four-party shuffle, which is not circuit-based, and after modifying Gordon et al. <ref type="bibr" target="#b9">[10]</ref> to support fixed-point computation, there is no longer any reason to support computation on Boolean values. We construct a method for securely converting the shared, and authenticated values used in our shuffle protocol into the "masked" ring values required for our four-party computation of the Apply phase. For the problem of Matrix Factorization on dataset of 1 million ratings, the Apply phase of Mazloom and Gordon <ref type="bibr" target="#b15">[16]</ref> requires 550X more AES calls and 370X more bandwidth than ours.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Preliminaries</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Graph-parallel computation</head><p>The Graph-parallel abstraction as it is used in several frameworks such as MapReduce <ref type="bibr" target="#b5">[6]</ref>, GraphLab <ref type="bibr" target="#b12">[13]</ref> and PowerGraph <ref type="bibr" target="#b8">[9]</ref>, consists of a sparse graph that encodes computation as vertex-programs that run in parallel, and interact along edges in the graph. These frameworks all follow the same computational model, called the GAS model, which includes three conceptual phases: Gather, Apply, and Scatter. The framework is quite general, and captures computations such as gradient descent, which is used in matrix factorization for recommendation systems, as well as histograms or counting operation, and many other computations. In Matrix Factorization, as an example, an edge (u, v, data) indicates that user u reviewed item v, and the data stored on the edge contains the value of the user's review. The computation proceeds in iterations, and in each iteration, every node gathers (copy) data from their incoming edges, applies some computation to the data, and then scatters (copy) the result to their outgoing edges. Viewing each vertex as a CPU or by assigning multiple vertices to each CPU, the apply phase which computes the main functionality, is easily parallelized. <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b18">19]</ref> constructed frameworks for securely computing graph-parallel algorithms. They did this by designing a nicely parallelizable circuit for the gather and scatter phases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">MPC with differentially private leakage</head><p>The security definition for secure computation is built around the notion of protocol simulation in an ideal world execution <ref type="bibr" target="#b7">[8]</ref>. In the ideal world, a trusted functionality takes the inputs, performs the agreed upon computation, and returns the result. We say the protocol is secure if a simulator can simulate the adversary's protocol view in this ideal world, drawing from a distribution that is indistinguishable from the adversary's view in the real world execution. The simulator can interact with the adversary, but is otherwise given nothing but the output computed by the ideal functionality. <ref type="bibr" target="#b2">3</ref> In prior work, Mazloom and Gordon <ref type="bibr" target="#b15">[16]</ref> proposed a relaxation to this definition in which the simulator is additionally given the output of some leakage function, L, applied to all inputs, but L is proven to preserve differential privacy of the input. They define several varying security models. Here we focus on one variant, which supports more efficient protocol design. We assume that thousands of clients have secret shared their inputs with 4 computation servers, and we use E to denote the full set of inputs. We denote the set of secret shares received by server i as E i . We denote the input of party j as e j . Note that the servers learn the input size of each client. Formally, the security definition is as follows.</p><p>Definition 1 <ref type="bibr" target="#b15">[16]</ref> Let F be some functionality, and let π be an interactive protocol for computing F , while making calls to an ideal functionality G. π is said to securely compute F in the G-hybrid model with L leakage, known input sizes, and (κ, ε, δ)-security if L is (ε, δ)-differentially private, and, for every PPT, malicious, non-uniform adversary A corrupting a party in the G-hybrid model, there exists a PPT, non-uniform adversary S corrupting the same party in the ideal model, such that, on any valid input shares,</p><formula xml:id="formula_0">E 1 , E 2 , E 3 , E 4 HYBRID G π,A(z) (E 1 , E 2 , E 3 , E 4 , κ) z∈{0,1} * ,κ∈N c ≡ IDEAL F ,S (z,L(V ),∀ j:|e j |) (E 1 , E 2 , E 3 , E 4 , κ) z∈{0,1} * ,κ∈N<label>(1)</label></formula><p>Mazloom and Gordon construct a protocol for securely performing graph-parallel computations with differentially private leakage. In their protocol, the data is secret shared throughout each iteration: when the Apply phase is executed at each graph node, it is computed securely on secret shared data, with both input and output in the form of secret shares. The leakage is purely in the form of access patterns to memory: as data moves from edge to neighboring node and back again, during the Gather and Scatter phases, the protocol allows some information to leak about the structure of the graph. To minimize and bound this leakage, two additional actions are taken: 1) The edges are obliviously shuffled in between when the data is gathered at the left vertex, and when it is gathered at the right vertex. This breaks the connections between the left and right neighboring nodes, and reduces the graph structure leakage to a simple degree count of each node. 2) "Dummy" edges are created at the beginning of the protocol, and shuffled in with the real edges. These dummy edges ensure that the degree counts are noisy. When the dummy edges are sampled from an appropriate distribution, the leakage can be shown to preserve differential privacy. Note that when the input size of each party is known, the degree count of certain nodes may not need to be hidden, allowing for better performance. For example, if the data elements owned by user u are weighted edges of the form (u, v, data), it is essential that the degree of node v remain private, as its degree leaks the edge structure of the graph, but the degree of node u is implied by the input size of user u. The implications of this are discussed more fully in their work. Neighboring graphs: We represent multi-sets over a set V by a |V | dimensional vector of natural numbers: D ∈ N |V | . We refer to the ith element of this vector by D(i). We define a metric on these multi-sets in the natural way:</p><formula xml:id="formula_1">|D 1 − D 2 | = ∑ |V | i=1 |D 1 (i) − D 2 (i)|.</formula><p>Applying this to graphs, for each v ∈ V , we let in−deg(v) denote the in-degree of node v, and we define the indegree profile of a graph G as the multi-set D in (G) = {in−deg(v 1 ), . . . , in−deg(v n )}. Then, we have the following definition.</p><p>Definition 2 We say two graphs G and G have distance at most d if they have in-degree profiles of distance at most d:</p><formula xml:id="formula_2">| D in (G) − D in (G ) |≤ d.</formula><p>We say that G and G are neighboring if they have distance 1.</p><formula xml:id="formula_3">Definition 3 A randomized algorithm L : G → R L is (ε, δ)- edge private if for all neighboring graphs, G 1 , G 2 ∈ G, we have: Pr[L(G 1 ) ∈ T ] ≤ e ε Pr[L(G 2 ) ∈ T ] + δ</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">4-party computation protocol</head><p>We use the secure computation protocol by Gordon et al. for four parties, tolerating one malicious corruption <ref type="bibr" target="#b9">[10]</ref>. We provide an overview of the construction here. The four parties are split into two groups, and each group will perform an evaluation of the circuit to be computed. The invariant throughout each evaluation is that both evaluating parties hold x + λ x and y + λ y , where x and y are inputs to a circuit gate, and λ x , λ y are random mask values from the ring. After communicating, both parties hold z + λ z , where z is the result of evaluating the gate on x and y, and λ z is another uniformly chosen mask.</p><p>To maintain this invariant, the evaluating parties need secret shares of λ x , λ y , λ x λ y and λ z . Securely generating these shares in the face of malicious behavior is typically quite expensive, but, relying on the assumption that only one party is corrupt, it becomes quite simple. Each pair of parties generates the shares for the other pair, and, to ensure that the shares are correctly formed, the pair sends duplicates to each recipient: if any party does not receive identical copies of their shares, they simply abort the protocol. During the evaluation of the circuit, it is possible for a cheating party to perform an incorrect multiplication, violating the invariant. To prevent this, the two pairs securely compare their evaluations against one another. For wire value z, one pair should hold z + λ z , and the other should hold z + λ z . Since the first pair knows λ z and the second pair knows λ z , each pair can compute z + λ z + λ z . They compare these values with the other pair, verifying equality. Some subtleties arise in reducing the communication in this comparison; we allow the interested reader to read the original result.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Notation</head><p>Additive Shares: We denote the 2-out-of-2 additive shares of a value x between two parties P 1 and P 2 to be <ref type="bibr">[x]</ref> </p><formula xml:id="formula_4">1 and [x] 2 ,</formula><p>and between two parties P 3 and P 4 to be <ref type="bibr">[x]</ref>  <ref type="bibr">[x]</ref> i to denote the share of x held by the i th party. Additive secret shares are used in all steps of the graph computation model except for the Apply phase. In Apply phase, data is converted from additive secret shares to masked values and back.</p><formula xml:id="formula_5">3 and [x] 4 (x = [x] 1 + [x] 2 = [x] 3 + [x] 4 ). When it is clear, we use [x] instead of</formula><p>Function inputs Our protocol includes many function calls in which P 1 and P 2 either provide additive shares of some input, or they each provide duplicates of the same input. The same is true for P 3 and P 4 . We therefore denote inputs to functionalities and protocols as a pair: the first element denotes the input of P 1 and P 2 , and the second denotes that of P 3 and P 4 . When P 1 and P 2 each provide an additive share of some value E, we simply denote the input by <ref type="bibr">[E]</ref>. For example, the input to F MAC is denoted by (( <ref type="bibr">[X]</ref>, α), <ref type="bibr">[X]</ref>): P 1 and P 2 submit additive shares of X, and each separately provide a copy of α. P 3 and P 4 provide a different additive sharing of X. Masked Values: For a value x ∈ Z 2 k , its masked value is defined as m x ≡ x +λ x , where λ x ∈ Z 2 k+s is sampled uniformly at random. In our four party computation model, for a value x, P 1 and P 2 hold the same masked value x + λ x and P 3 and P 4 hold the same x + λ x . λ x is provided by P 3 and P 4 while P 1 and P 2 hold shares of λ x . Similarly, λ</p><p>x is provided by P 1 and P 2 while P 3 and P 4 hold shares of λ x .</p><p>Doubly Masked Values: Four players can locally compute the same doubly masked value for x from their masked values, defined as</p><formula xml:id="formula_6">d x ≡ x + λ x + λ x = m x + λ x = m x + λ x .</formula><p>Share or Masked Value of a Vector: When X is a vector of data, i.e,</p><formula xml:id="formula_7">X = {x 1 , ..., x n }, we define [X] ≡ {[x 1 ], ..., [x n ]}, λ X ≡ {λ x 1 , ..., λ x n }, m X ≡ {m x 1 , ..., m x n } and d X ≡ {d x 1 , ..., d x n }.</formula><p>Fixed Point Representation: All inputs, intermediate values, and outputs are k-bit fixed-point numbers, in which the least d significant bits are used for the fractional part. We represent a fixed-point number x by using a ring element in Z 2 k+s , where s denotes our statistical security parameter.</p><p>MAC Representation: We adapt the technique used in SPDZ2k <ref type="bibr" target="#b4">[5]</ref> for authenticating ring elements. For a value x ∈ Z 2 k and for a MAC key α ∈ Z 2 s , the MAC on value x is defined as</p><formula xml:id="formula_8">MAC α (x) ≡ αx ∈ Z 2 k+s . In our framework, MAC α (x)</formula><p>is always kept in the form of additive secret shares. <ref type="bibr" target="#b3">4</ref> We note that in our framework, all the values, the additive shares, and the masked values are represented as elements in the ring Z 2 k+s . However, the range of the data is in Z 2 k , and the MAC key is in Z 2 s .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Building blocks</head><p>In this section, we explain the details of each small component and building block in graph operations, present their real vs. ideal world functionalities, and provide the security proofs for each of them, under a single malicious corruption. We partition the 4 parties into 2 groups, with the first consisting of P 1 and P 2 , and the second P 3 and P 4 . For ease of explanation, we name the parties in the first group, Alice and Bob, and parties in the second group, Charlotte and David.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">MAC Computation and Verification</head><p>One of the main challenges we face in constructing a malicious secure version of the graph operations is that we have to authenticate the values before each operation begins, and then verify correctness of the results after the operation is done. This is simple in a Field, but we choose to compute in a ring to help support fixed point operations. We adapt the MAC computation and Verification technique proposed in SPDZ2k <ref type="bibr" target="#b4">[5]</ref>. In this part, we describe the ideal functionality and the real world protocol to generate MAC values for additive secret shares over a ring.</p><formula xml:id="formula_9">FUNCTIONALITY F MAC Inputs: P 1 , P 2 : [X] = {[x 1 ], . . . , [x n ]}, MAC key α. P 3 , P 4 : [X]</formula><p>. Functionality: <ref type="bibr" target="#b3">4</ref> . If the check does not pass, send abort to all parties.</p><formula xml:id="formula_10">• Verify that X = [X] 1 + [X] 2 = [X] 3 + [X]</formula><p>• If P 1 , P 2 submit different values of α, send abort to all parties.</p><p>• Compute Y = αX.</p><p>Outputs: P 1 , P 2 receive nothing.</p><formula xml:id="formula_11">P 3 , P 4 receive [Y ].</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 1: MAC computation ideal functionality</head><p>Theorem 1 The MAC computation protocol Π MAC ( <ref type="figure">Figure   2</ref>) securely realizes the ideal functionality F MAC <ref type="figure">(Figure 1)</ref> with abort, under a single malicious corruption.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Share-Mask Conversion</head><p>We construct a method for securely converting the shared, authenticated values which was used in the Shuffle and Gather phases, into the "masked" ring values required for our fourparty computation of the Apply phase.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Theorem 2</head><p>The share-mask conversion protocol <ref type="figure" target="#fig_1">(Figure 4</ref>) securely realizes the ideal functionality F sharemask (F <ref type="bibr">[x]</ref>→m x ) ( <ref type="figure" target="#fig_0">Figure 3</ref>) with abort, under a single malicious corruption.</p><formula xml:id="formula_12">Π sharemask (Π [x]→m x )</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>USENIX Association</head><p>29th USENIX Security Symposium 2491</p><formula xml:id="formula_13">PROTOCOL Π MAC Inputs: P 1 , P 2 : [X], MAC key α. P 3 , P 4 : [X]</formula><p>. F is a PRF. Protocol:</p><p>1. P 1 , P 2 sample a random PRF key k, by making a call to F coin .</p><formula xml:id="formula_14">2. P 1 sends [Y (1) ] = {α[X i ] + F k (i)|i = 1, ..., n} to P 3 . 3. P 2 sends [Y (1) ] = {α[X i ] − F k (i)|i = 1, ..., n} to P 4 .</formula><p>4. Four parties make a call to F mult (α, <ref type="bibr">[X]</ref> 3,4 ).</p><formula xml:id="formula_15">P 3 , P 4 receive [α] and [Y ] ← [αX]. P 1 , P 2 receive nothing. 5. P 3 , P 4 compute [Z] = [Y −Y (1) ]</formula><p>and verify Z = 0 by making a call to F checkZero ( <ref type="bibr">[Z]</ref>). If the functionality returns false, they send abort to P 1 and P 2 and terminate.</p><p>Outputs: P 1 , P 2 output nothing.</p><formula xml:id="formula_16">P 3 , P 4 output [Y ].</formula><p>Figure 2: MAC computation protocol</p><formula xml:id="formula_17">FUNCTIONALITY F sharemask (F [x]→m x )</formula><p>Inputs:</p><formula xml:id="formula_18">P 1 , P 2 : [β], [X], [Y ](Y ≡ βX). P 3 , P 4 : β. Functionality:</formula><p>• Reconstruct β, X, and Y from P 1 and P 2 . Verify that P 3 and P 4 have sent shares of the same β.</p><p>• Verify that Y = βX. If the check fails, send abort to all parties.</p><p>• </p><formula xml:id="formula_19">Sample shares [λ X ] 1 , [λ X ] 2 , [λ X ] 1 , [λ X ] 2 uniformly at random, then reconstruct λ X and λ X . • Compute m X = X + λ X and m X = X + λ X . Outputs: P 1 receive (m X , λ X , [λ X ] 1 ), P 2 (m X , λ X , [λ X ] 2 ) P 3 receive (m X , λ X , [λ X ] 3 ), P 4 (m X , λ X , [λ X ] 4 ).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Mask-Share Conversion</head><p>At the end of the Apply phase, the result of the 4-party computation is masked values that need to be converted back to additive shares, before updating the edges. This conversion step is very simple. Each party locally converts their masked values to additive shares, without any interaction: given</p><formula xml:id="formula_20">x + λ x and [λ x ], simply output [x] = x + λ x − [λ x ].</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Four-Party Evaluation With Truncation</head><p>This section presents the small sub-components that are utilized in the Apply operation.  </p><formula xml:id="formula_21">] = [X] + [λ X ], [m X ] = [X] + [λ X ], [Y ] ← [Y ] + [β]λ X (where λ X = [λ X ] 1 + [λ X ] 2</formula><formula xml:id="formula_22">b = false, they call abort. Else, if b = true, they open m X ← open([m X ]). 9. All parties compute d X = m X + λ X = m X + λ X , P 1 and P 3 compare h 1 = H(d X )</formula><p>with each other, while P 2 and P 4 compare h 2 = H(d X ) with each other. If any group sees a mismatch, they call abort. Masked value: In our protocol, we use masked values for the computation. Instead of holding shares <ref type="bibr">[x]</ref>, one group has</p><formula xml:id="formula_23">Outputs: P 1 , P 2 output m X , [λ X ], λ X . P 3 , P 4 output m X , [λ X ], λ X .</formula><formula xml:id="formula_24">(m x = x + λ x , λ x , [λ x ])</formula><p>and the other has (m</p><formula xml:id="formula_25">x = x + λ x , λ x , [λ x ])</formula><p>. Addition: Addition is performed locally by adding the masked values together.</p><p>For P 1 and Locally P 1 and P 2 compute</p><formula xml:id="formula_26">P 2 : (m x , λ x , [λ x ]) + (m y , λ y , [λ y ]) = (m x + m y , λ x + λ y , [λ x ] + [λ y ]). For P 3 and P 4 : (m x , λ x , [λ x ]) + (m y , λ y , [λ y ]) = (m x + m y , λ x + λ y , [λ x ] + [λ y ]).</formula><formula xml:id="formula_27">P 1 : [m z ] 1 = m x m y − [λ x ]m y − [λ y ]m x + [λ z + λ x λ y ]. P 2 : [m z ] 2 = −[λ x ]m y − [λ y ]m x + [λ z + λ x λ y ]</formula><p>. and exchange the shares to reconstruct m z = xy + λ z . They</p><formula xml:id="formula_28">output (m z , λ z , [λ z ]). Similarly, P 3 and P 4 output (m z , λ z , [λ z ]).</formula><p>Multiplication With Truncation: In our setting, x and y are fixed-point numbers with d bits for the fraction. The result of the multiplication is a number that has its least 2d significant bits in the fractional portion. A truncation is needed to throw away the d least significant bits: the output of the multiplication is the masked value of the truncation of xy in stead of that of xy. We provide a method to handle the truncation for our four-party mask evaluation. First, we have a simple observation: if z, λ z , λ z are integers, the following holds:</p><formula xml:id="formula_29">z+λ z +λ z 2 d = z+λ z 2 d + λ z 2 d + ε 1 = z 2 d + λ z 2 d + λ z 2 d + ε 1 + ε 2 , where ε i ∈ {0, 1}. For z ∈ Z 2 k , trun(z) = z 2 d , if 0 ≤ z ≤ 2 t 2 k − 2 k −z 2 d , if 2 k − 2 t ≤ z &lt; 2 k Assume that −2 t ≤ xy &lt; 2 t</formula><p>is the domain where xy lies in. We have two different cases.</p><p>First, we consider the case of a non-negative xy, which is represented by a ring element z = xy in the range [0; 2 t ]. The above equation works without any modifications when (z + λ z ) and (z + λ z ) are both less than 2 k . This happens with probability of at least 1 − 2 t−k+1 (we note that 2 t 2 k ).</p><p>Second, we consider the case of a negative xy. A negative xy is represented by a ring element z = 2 k − |xy| in the range</p><formula xml:id="formula_30">[2 k −2 t ; 2 k −1].</formula><p>With probability of at least 1−2 t−k+1 , both λ z and λ z will be chosen such that (z+λ z ) ≥ 2 k and (z+λ z ) ≥ 2 k , causing modular reduction in our computation. Specifically, for group 1, P 1 and P 2 hold z + λ z − 2 k = z + λ z mod 2 k , λ z and can compute the following in the integer domain:</p><formula xml:id="formula_31">(z+λ z mod 2 k )+λ z 2 d = (z+λ z −2 k )+λ z 2 d = (z−2 k )+λ z +λ z 2 d . = − 2 k −z 2 d + λ z 2 d + λ z 2 d + ε, where ε ∈ {0, 2} Let m z = (2 k − 2 k −z 2 d + ε) + λ z 2 d = (z+λ z mod 2 k )+λ z 2 d - λ z 2 d mod 2 k and m z = (2 k − 2 k −z 2 d + ε) + λ z 2 d = (z+λ z mod 2 k )+λ z 2 d -λ z 2 d mod 2 k .</formula><p>They are the masked value of the truncation of xy for group 1 and 2 respectively. P 1 and P 2 can compute m z and λ z 2 d themselves without any interaction as they know xy + λ z and λ z . P 3 and P 4 can provide P 1 and P 2 with shares</p><formula xml:id="formula_32">[ λ z 2 d ].</formula><p>At the end, P 1 and P 2 obtain the output of the truncated mask evaluation:</p><formula xml:id="formula_33">(m z , λ z 2 d , [ λ z 2 d ]). Similarly, P 3 and P 4 obtain (m z , λ z 2 d , [ λ z 2 d ]).</formula><p>The error of the truncated multiplication is at most 1 2 d−1 . Importantly, the error does not impact proper cross-checking of the two parallel evaluations.</p><p>Vectorization for dot products A naive way to perform a dot product between two vectors u = {u 1 , ..., u n }, v = {v 1 , ..., v n } is to perform n multiplications then add the shares up. We use the vectorization technique to bring this down to the cost of one multiplication. The details are shown in <ref type="figure" target="#fig_3">Figure 6</ref>. Communication cost Each multiplication with truncation requires the four parties to communicate only 6 rings in total when done in batch. For each gate, F triple costs 2 rings (one ring sent from P 3 to P 2 , and the other from P 1 to P 4 ) and the opening of m c and m c each costs 2 rings. F coin is free when common random seeds are used, and two hashes are needed to be sent for the whole batch. We note that the cost is the same for dot product gate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>FUNCTIONALITY F eval</head><p>Inputs: For each input wire w:</p><formula xml:id="formula_34">P 1 , P 2 : m w = x w + λ w , [λ w ], λ w ; P 3 , P 4 : m w = x w + λ w , [λ w ], λ w . Functionality:</formula><p>• Reconstruct λ received from P 1 , P 2 , and verify if it is equal to λ received from P 3 , P 4 . Reconstruct λ received from P 3 , P 4 , and verify if it is equal to λ received from P 1 , P 2 . If any of these verification fails, send abort to all parties.</p><p>• Compute</p><formula xml:id="formula_35">-(m (1) w , λ<label>(1)</label></formula><formula xml:id="formula_36">w , [λ (1) w ]) ← f unc (m w , λ w , [λ w ]) -(m<label>(1)</label></formula><formula xml:id="formula_37">w , λ<label>(1)</label></formula><formula xml:id="formula_38">w , [λ (1) w ]) ← f unc (m w , λ w , [λ w ])</formula><p>Outputs: </p><formula xml:id="formula_39">P 1 , P 2 receive (m (1) w , λ<label>(1)</label></formula><formula xml:id="formula_40">w , [λ (1) w ]). P 3 , P 4 receive (m (1) w , λ (1) w , [λ (1) w ]).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Differentially Private Graph Parallel Computation in Maliciously Secure Four-Party Settings</head><p>Our construction follows the graph-parallel computation model in which the computation is done using three main operations; Gather, Apply and Scatter. We partition the players into two groups, and in each group, there are two players. For ease of explanation, we name the parties in the first group Alice and Bob (P 1 , P 2 ), and parties in the second group, Charlotte and David (P 3 , P 4 ). These parties collaboratively compute a functionality, for example Matrix Factorization. During the computation, each group is responsible for performing an operation that its results then will be verified by the other group. For example, one group securely shuffles the data, and the other group verifies that the data is not maliciously tampered, then the latter group performs the operations that access the data (e.g., gather), and then the former group verifies the correctness of that operation. As described previously, each data access operation, Gather or Scatter, is always followed by a Shuffle operation, in order to hide the graph edge </p><formula xml:id="formula_41">m w = x w + λ w , λ w , [λ w ]</formula><p>. Evaluation: For each gate (a, b, c, T ) following topological order: Evaluation Group 1 (P 1 and P 2 )</p><formula xml:id="formula_42">1. if T = + : m c ← m a + m b ; [λ c ] ← [λ a ] + [λ b ]; λ c ← λ a + λ b 2. if T = · (Dot Product/Multiplication Gate) (a) ( ∑ n i=1 λ a i λ b i + λ c , λ c /2 d ) ← F Triple (a, b, c); (b) [m c ] ← ∑ n i=1 (m a i · m b i − m a i · [λ b i ] − m b i · [λ a i ]) + ∑ n i=1 λ a i · λ b i + λ c (c) m c ← open([m c ]); m c ← (m c + λ c )/2 d − λ c /2 d ; λ c ← λ c /2 d ; [λ c ] ← λ c /2 d</formula><p>Evaluation Group 2 (P 3 and P 4 )</p><formula xml:id="formula_43">1. if T = + : m c ← m a + m b ; [λ c ] ← [λ a ] + [λ b ]; λ c ← λ a + λ b 2. if T = · (Dot Product/Multiplication Gate) (a) ( ∑ n i=1 λ a i λ b i + λ c , λ c /2 d ) ← F Triple (a, b, c); (b) [m c ] ← ∑ n i=1 (m a i · m b i − m a i · [λ b i ] − m b i · [λ a i ]) + ∑ n i=1 λ a i · λ b i + λ c (c) m c ← open([m c ]); m c ← (m c + λ c )/2 d − λ c /2 d ; λ c ← λ c /2 d ; [λ c ] ← λ c /2 d</formula><p>Cross Check</p><p>1. All parties make a call to F coin to sample the same random nonce r, compute the double masked value for each wire</p><formula xml:id="formula_44">d w = m w + λ w = m w + λ w . They each computes h i ← hash(d 1 ||.</formula><p>..||d n ||r). 2. P 1 sends h 1 to P 2 and P 4 . P 3 sends h 3 to P 2 and P 4 . 3. P 2 verifies that h 1 = h 3 . If true, he sends 0 to F or a functionality, else he sends 1. P 4 does the same thing when verifying h 1 = h 3 .</p><p>4. Repeat the previous instructions with the variable exchanged as follows, P 2 sends h 2 to P 1 and P 3 , and P 4 sends h 4 to P 1 and P 3 .</p><p>5. P 1 and P 3 separately verify they received same values from P 2 and P 4 , and provide input to the F or functionality, accordingly. 6. All the parties will receive the result from F or in order to determine to continue or to abort.</p><p>Output: All parties output masked values of the output wires. P 1 , P 2 output (m </p><formula xml:id="formula_45">(1) V , λ<label>(1)</label></formula><formula xml:id="formula_46">V , [λ (1) V ]). P 3 , P 4 output (m (1) V , λ<label>(1)</label></formula><formula xml:id="formula_47">V , [λ (1) V ]).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Construction Overview</head><p>Data Structure: In our framework, the data is represented in a graph structure G = (V, E), in which vertices contain user and item profiles, and edges represent the relation between connected vertices. Each edge, represented as E, has five main elements, (E.l id , E.r id , E.l data , E.r data , E.isReal), where isReal indicates if an edge is "real" or "dummy". Each vertex, V, contains two main elements, (V id , V data ). The V data storage is large enough to hold aggregated edge data from multiple adjacent edges during the gather operation.</p><p>Dummy Generation: Before the main protocol begins, a number of dummy edges will be generated according to an appropriate distribution, and concatenated to the list of real edges, in order to provide (ε, δ)-Differential Privacy. Therefore, the input to the framework is a concatenated list of real and dummy edges, and list of vertices. The circuit for generating these dummies, together with the noise distribution, is taken directly from the work of Mazloom and Gordon, so we do not describe it again here. The cost of this execution is very small relative to the rest of the protocol, and it is only performed once at the beginning of the any computation, regardless of how many iterations the computation has (both the histogram and the matrix factorization computations require only one dummy generation operation). These dummy edges are marked with a (secret shared) flag isReal, indicating that dummies should not influence the computation during the Apply phase. However, they still have node identifiers, so they contribute to the number of memory accesses to these nodes during the Gather and Scatter phases. The protocol we use Step 0. Input preparation: We assume the input data is additively secret-shared between parties in each group, so that parties in each group, together can reconstruct the data. For example, Alice and Bob receive 2-out-of-2 secret shares of E, such that [E] A + [E] B = E mod 2 k+s , as shown in <ref type="figure" target="#fig_4">Figure 7</ref>.</p><p>Step Step 2. Oblivious Gather: The next operation after Shuffle is the Gather operation, which requires access to the node identifiers, and will be handled by Alice and Bob. In turn, Charlotte and David should be able to verify the correctness of the Gather operation. Therefore, before the Gather operation, Charlotte and David agree on a random value β, and all parties make a sequence of calls to the F MAC functionality, generating a new MAC tag for each data element of each edge. That is, they create three tags per edge: one tag for each of the two vertex ids, and one tag for the edge data. The Gather operation is performed on only one side of each edge at a time; in one iteration of the protocol, data is gathered at all of the left vertices, and in the next iteration, it is gathered at all of the right vertices. Gather for the left vertices is described in <ref type="figure" target="#fig_0">Figure 13</ref>: for each edge, Alice and Bob first reconstruct the id of the left vertex E.l id , locate the corresponding vertex, and then append the data of the other end of the edge, i.e. the data of the right vertex, [E.r data ] with its MAC tags, to the left vertex data storage. They do the same for all the incoming edges to that vertex. Note that in the next iteration of the algorithm they follow the same procedure for the right vertex, if applicable. When Alice and Bob access the left side of each edge, they learn the number of times each left vertex is accessed, which leaks the degree of each vertex in the graph. However, due to the dummy edges that we shuffled-in with the real ones, what they learn is the noisy degree of each vertex, which preserve deferential privacy. At the end of this phase, Charlotte and David verify that Gather was executed correctly by calling F checkZero , verifying that the data was unmodified.</p><p>They abort if the verification fails. We note that, in addition to modifying data, a malicious adversary might try to move data to the wrong vertex. From a security standpoint, this is equivalent to the case that the adversary moves data to the correct vertex during Gather, but modifies the shares of the authenticated identifier. To simplify the analysis, we assume that the adversary moves data to the correct vertex.</p><p>Step 3. Oblivious Apply: This operation consists of three sub-operations. First, additive shares of data are converted to masked values, then the main functionality (e.g. gradient descent) is applied on the masked values (at each vertex), and finally the masked values are converted back to additive secret-shares, which then will be used in the following phases of the framework.</p><p>Step 3.1. Secure Share-Mask Conversion: All the parties participate in the Apply phase, providing their shares as input to the Arithmetic Circuit that computes the intended functionality. However, in order to prepare the private data for the Apply operation, the secret-shared values need to be transformed into "masked" values. In order to convert shares to masked values, each group agrees on a vector of random mask values, denoted as λ for Alice-Bob and λ for Charlotte-David.</p><p>Then they call the F sharemask functionality and collaboratively transform the share values <ref type="bibr">[V ]</ref> to masked values V + λ and V + λ .</p><p>Step 3.2. Computing the function of interest on input data: As part of the Apply phase, the parties compute the function of interest on the input data: for example, they perform addition for Histograms, or gradient descent for Matrix Factorization. The parties execute the four-party protocol described in <ref type="figure" target="#fig_3">Figure 6</ref> to evaluate the relevant circuit.</p><p>Step 3.3. Secure Mask-Share Conversion: At the end of the Apply phase, data is in the masked format and needed to be converted to secret-shared values. As described previously, each party can locally convert their masked values to additive secret-shares, without interacting with other parties.</p><p>Step 4. Oblivious Scatter: The result of each computation resides inside the corresponding vertex. We need to update the data on the edges with the freshly computed data. In this step, all players copy the updated data from the vertex to the incoming (or outgoing) edges. The players refer to the list of opened ID's obtained during Gather to decide how to update each edge. Recall, edges are held as additive secret shares; the update of the edge data can be done locally. Finally, they re-randomize all the shares. This explanation and accompanying diagrams only show the graph operations applied on the left vertices of each edge. To complete one round of the graph computation, we need to repeat the steps 1-4 on the right vertices as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Oblivious Graph Operations</head><p>The hybrid world protocol is presented in <ref type="figure" target="#fig_8">Figure 9</ref>. There we assume access to ideal functionalities for Shuffle, Gather, Apply and Scatter. In this section, we explain how we instantiate each of these ideal functionalities, and provide the security proofs for each protocol under a single malicious corruption. Charlotte, David hold secret shares of E, such that</p><formula xml:id="formula_48">[E] C + [E] D = E mod 2 k+s . ([E] A , [E] B , [E] C , [E] D ∈ Z 2 k+s</formula><p>, and E ∈ Z 2 k ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Functionality:</head><p>1. Waits for input from all parties.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Verifies that</head><formula xml:id="formula_49">[E] A + [E] B = [E] C + [E] D . If not, sends</formula><p>abort to all parties.</p><p>3. Reconstructs E, then computes E (1) = f unc(E).</p><p>4. Secret shares E (1) to P 1 , P 2 ; and E (1) to P 3 , P 4 .</p><p>5. Computes the leakage L(G), sends it to all parties.</p><p>Output: Secret shares of the updated edge values (e.g. user and item profiles). The parties also obtain the leakage L(G). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Four-Party Oblivious Shuffle</head><p>The Shuffle operation is used to hide the edge structure of the graph: during the Gather and Scatter operations, the vertex on each side of an edge is accessed, and shuffling the edges between these two phases hides the connection between Π sgas : Four-Party Secure Graph Parallel Computation Protocol</p><p>Input: User input is a directed graph, G(E,V ), secret shared between the parties: Alice, Bob hold secret shares of E, s.t. for each edge,</p><formula xml:id="formula_50">[E] A + [E] B = E mod 2 k+s .</formula><p>Charlotte, David hold secret shares of E, s.t. for each edge, <ref type="bibr">[E]</ref> </p><formula xml:id="formula_51">C + [E] D = E mod 2 k+s . ([E] A , [E] B , [E] C , [E] D ∈ Z 2 k+s , and E ∈ Z 2 k ).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Protocol:</head><p>Note: The following steps are conducted on the left vertex of each edge (for example in computing Histogram). In order to perform one single iteration of Matrix Factorization, these steps should be done twice, once on the left vertices, then on the right vertices.</p><p>1. Oblivious Shuffle Four players make a call to </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Oblivious Gather The parties call F gather ([E (1) ])</head><p>to aggregate edge data into vertices. Alice, Bob receive:  </p><formula xml:id="formula_52">[V ] = [{V 1 1 ..V 1 i }, ..., {V n 1 ..V n j }], [W ] = [{W 1 1 ..W 1 i }, ..., {W n 1 ..W n j }],</formula><formula xml:id="formula_53">Inputs:P 1 , P 2 : [E] (s.t. [E] 1 + [E] 2 = E). P 3 , P 4 : [E] (s.t. [E] 3 + [E] 4 = E)</formula><p>. Functionality: <ref type="bibr" target="#b3">4</ref> . If the check fails, send abort to all parties.</p><formula xml:id="formula_54">• Verify that [E] 1 + [E] 2 = [E] 3 + [E]</formula><p>• Sample a random permutation π. Figure 10: Oblivious Shuffle Ideal Functionality the security of our Oblivious Shuffle, we provide a simulation for P 1 and P 3 . The simulations for other parties are identical. First, a simulation for P 1 :</p><p>• S receives P 1 's input <ref type="bibr">[E]</ref> 1 from the distinguisher and places it in the input tape of P 1 .</p><p>• α: S samples a random α and hands it to P 1 to simulate the output from F coin . S then observes the message that P 1 sends to F MAC : if P 1 does not send the intended messages ( α, [E] 1 ), S submits abort to F shuffle , and outputs the partial transcript. Else, S submits P 1 's input <ref type="bibr">[E]</ref> 1 to the ideal functionality F shuffle and receives [E (1) ].</p><p>• [ E (1) ], [ M (1) ]: S samples random ring elements as shares</p><formula xml:id="formula_55">[ M (1) ], hands [ E (1) ] (where [ E (1) ] ≡ [E 1 ])</formula><p>and [ M (1) ] to P 1 to simulate the messages [E (1) ], [M (1) ] P 1 receives from F MAC . S computes [Z] himself to mirror P 1 's action.</p><p>• b: S observes the messages that P 1 sends to F checkZero . If P 1 modifies his shares <ref type="bibr">[Z]</ref>, S hands b = false to P 1 as the output of F CheckZero , outputs the partial view, and aborts.</p><p>Else, S hands b = true to P 1 and outputs whatever P 1 outputs.</p><p>Claim 1 For the simulator S corrupting party P 1 as described above, and interacting with the functionality F shuffle ,</p><formula xml:id="formula_56">HYBRID π shuffle ,A(z) (E, κ) z∈{0,1} * ,κ∈N c ≡ IDEAL F shuffle ,S(z) (E, κ) z∈{0,1} * ,κ∈N</formula><p>Case 0: If the adversary behaves honestly, the joint distributions in the hybrid and ideal executions are:  In conclusion, the joint distributions between the two worlds are identical. Now, a simulation for P 3 :</p><formula xml:id="formula_57">HYBRID π shuffle ,A(z) (E, κ) z∈{0,1} * ,κ∈N = {α, [E (1) ], [M (1) ], b = true, o 1 , o 2 , o 3 , o 4 } IDEAL F shuffle ,S(z) (E, κ) z∈{0,1} * ,κ∈N = { α, [ E (1) ], [ M (1) ], b = true, o 1 , o 2 , o 3 , o 4 }</formula><p>• [ M]: S receives [E] 3 and places it in the input tape of P 3 . S observes the message that P 3 sends to F MAC : if P 3 modifies [E] 3 before sending it to the functionality, S aborts and outputs the partial view. Else, S samples random ring elements as shares <ref type="bibr">[ M]</ref> 3 and hands them to P 3 to simulate the output P 3 receives from F MAC in the hybrid world.</p><p>• π: S queries the ideal functionality with P 3 's input, <ref type="bibr">[E]</ref> 3 ,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>USENIX Association 29th USENIX Security Symposium 2497</head><p>and obtains the output [E (1) ] 3 . S computes π such that [E (1) ] 3 ← π( <ref type="bibr">[E]</ref> 3 ), then agrees on the permutation π with P 3 in Step 3 (playing the part of P 4 ). S computes [m (1) ] ← [ π( m)] to mirror P 3 's action.</p><p>• b: S observes the messages that P 3 sends to P 1 in Step 3.</p><formula xml:id="formula_58">If P 3 sends [E (1) ] 3 = [E (1) ] 3 +D or [m (1) ] = [m (1) ] 3 +D</formula><p>where D = 0 mod 2 k , D = 0 mod 2 k+s , S aborts and outputs the partial view. Else, S outputs whatever P 3 outputs.</p><p>Claim 2 For the simulator S corrupting party P 3 as described above, and interacting with the functionality F shuffle ,</p><formula xml:id="formula_59">HYBRID π shuffle ,A(z) (E, κ) z∈{0,1} * ,κ∈N c ≡ IDEAL F shuffle ,S(z) (E, κ) z∈{0,1} * ,κ∈N</formula><p>Case 0: If P 3 follows the protocol honestly, the joint distributions in the hybrid and ideal execution is:</p><formula xml:id="formula_60">HYBRID π shuffle ,A(z) (E, κ) z∈{0,1} * ,κ∈N = {[M], π, b, o 1 , o 2 , o 3 , o 4 } IDEAL F shuffle ,S(z) (E, κ) z∈{0,1} * ,κ∈N = {[ M], π, b, o 1 , o 2 , o 3 , o 4 }</formula><p>The messages <ref type="bibr">[M]</ref>, <ref type="bibr">[ M]</ref> and π, π are all distributed uniformly at random, and independently from the remainder of the view, including the joint distribution over the output shares. The output distribution is identical in both worlds as well. Thus, the joint distributions between both worlds are identical.</p><p>Case 1: If P 3 deviates from the protocol in Step 2 by sending the wrong shares of <ref type="bibr">[E]</ref>, abort happens in both worlds, and the joint distributions in both worlds are both {⊥} and identical.</p><p>Case 2: S observes what P 3 sends to P 1 in Step 3. If he does not send the intended messages:</p><formula xml:id="formula_61">P 3 sends [E (1) ] = [E (1) + D] or [M (1) ] = [M (1) + D ] where D = 0 mod 2 k , D = 0 mod 2 k+s , S abort in the ideal execution. The joint distribu- tion in the ideal world is {[ M], π, b = false, ⊥}.</formula><p>In the hybrid world, there is a small chance that P 1 and P 2 do not abort. This happens if P 3 chooses the additive terms D and D such that αD + D = 0 mod 2 k+s . The probability that this happens is at most 2 −s as shown in Section 3.1. So, with probability 1 − 2 −s , the joint distribution in the hybrid world is { <ref type="bibr">[M]</ref>, <ref type="bibr">[π]</ref>, b = false, ⊥}. Thus, the joint distributions in both worlds are statistically close.</p><p>In conclusion, the joint distributions in both worlds are statistically close.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Four-Party Oblivious Gather</head><p>Gather operation aggregates the data from neighboring edges to each vertex. The data will be stored at the vertices for further computation handled by Apply operation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F gather</head><p>Inputs:P 1 ,</p><formula xml:id="formula_62">P 2 : [E] (s.t. [E] 1 + [E] 2 = E). P 3 , P 4 : [E] (s.t. [E] 3 + [E] 4 = E). Functionality:</formula><p>• Sample a random MAC key β.</p><p>• Wait for shares <ref type="bibr">[E]</ref> from all parties. Verify that <ref type="bibr">[E]</ref> </p><formula xml:id="formula_63">1 + [E] 2 = [E] 3 +[E] 4 .</formula><p>If the verification fails, send abort to all parties. Else, reconstruct E.</p><p>• For all vertices v ∈ V , set v ← / 0. • For each edge e ∈ E do:</p><formula xml:id="formula_64">For v ∈ V s.t. v.id = l id : v.Append(e.r data )</formula><p>• Compute W ← βV . <ref type="bibr">[β]</ref>. P 3 , P 4 receive β.</p><formula xml:id="formula_65">Outputs: P 1 , P 2 receive [{V 1 1 ..V 1 i }, ..., {V n 1 ..V n j }] , [{W 1 1 ..W 1 i }, ..., {W n 1 ..W n j }],</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 12: Oblivious Gather Ideal Functionality</head><p>Theorem 5 The Oblivious Gather protocol ( <ref type="figure" target="#fig_0">Figure 13)</ref> securely realizes the ideal functionality F gather <ref type="figure">(Figure 12)</ref> with abort, under a single malicious corruption.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3">Four-Party Oblivious Apply</head><p>Apply computes the main functionality of the framework on the input data. In the Gather operation, the data is aggregated into vertices, therefore Apply runs the computation on the vertex data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Theorem 6</head><p>The oblivious Apply protocol Π apply <ref type="figure" target="#fig_2">(Figure 15)</ref> securely realizes the ideal functionality F apply <ref type="figure" target="#fig_1">(Figure 14)</ref> with abort, under a single malicious corruption.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.4">Four-Party Oblivious Scatter</head><p>During the Scatter operation, the updated data in the vertices are pushed back to their corresponding edges in the graph, replacing the old values stored in the edges. This step is done locally by each party, P 1 and P 2 , with no interaction between them. Therefore, this step is secure. After updating the edges, the shares are re-randomized to break the correlation between the edges (edges with the same left (or right) id are updated with the same shares during scattering phase. If any of the parties cheats and modifies the data before scattering to the edges, it will be detected in the following phase, which is the Shuffle operation of the next round.  Inputs:</p><formula xml:id="formula_66">P 1 , P 2 : [{V 1 1 ..V 1 i }, ..., {V n 1 ..V n j }], [{W 1 1 ..W 1 i }, ..., {W n 1 ..W n j }], [β].</formula><p>P 3 , P 4 : β. Functionality:</p><p>• Verify that β[V ] = <ref type="bibr">[W ]</ref>. If the verification fails, send abort to all parties. Else, reconstruct V.</p><p>•</p><formula xml:id="formula_67">For v ∈ [{V 1 1 ..V 1 i }, ..., {V n 1 ..V n j }]:</formula><p>Compute v (1) ← f unc(v). Note: f unc is the computation applied on the data, e.g. computing Gradient Decent for Matrix Factorization or Addition in Histogram algorithm.</p><p>Output: All parties receive:[{V </p><formula xml:id="formula_68">(1) 1 1 ..V (1) 1 i }, ..., {V (1) n 1 ..V (1) n j }].</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Four-Party Secure GAS computation</head><p>In this section, we formally define our overall framework in a hybrid-world model. But first, we define the leakage function L(G) to be the noisy degree of each vertex in the graph, as was done by Mazloom and Gordon <ref type="bibr" target="#b14">[15]</ref> (Definition 7). That is, in the ideal world, after receiving secret shares of the graph description, the functionality creates an array containing the to masked values.</p><p>•</p><formula xml:id="formula_69">P 1 , P 2 use input [{V 1 1 ..V 1 i }, ..., {V n 1 ..V n j }] , [{W 1 1 ..W 1 i }, ..., {W n 1 ..W n j }], [β] ). P 3 , P 4 use input β.</formula><p>• For each vertex, P 1 ,</p><formula xml:id="formula_70">P 2 receive (m V , λ V , [λ V ]). P 3 , P 4 receive (m V , λ V , [λ V ]).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Apply Functionality</head><formula xml:id="formula_71">For v ∈ [{V 1 1 ..V 1 i }, ..., {V n 1 ..V n j }]:</formula><p>Four parties execute F eval ( <ref type="figure" target="#fig_2">Figure 5</ref>), to obtain the masked values of the updated vertex data. 4. Secure Mask-Share Conversion Each party locally converts their masked values to additive shares.</p><p>• P 1 and</p><formula xml:id="formula_72">P 2 computes [V ] ← (V + λ V ) − [λ V ], • P 3 and P 4 computes [V ] ← (V + λ V ) − [λ V ].</formula><p>Output: All parties output:[{V</p><formula xml:id="formula_73">(1) 1 1 ..V (1) 1 i }, ..., {V (1) n 1 ..V (1) n j }].</formula><p>Figure 15: Protocol for securely computing Apply.</p><p>vertex degrees. It then generates an equal length array of integer noise values, each independently sampled from some appropriate distribution. <ref type="bibr" target="#b4">5</ref> The functionality perturbs the vertex degrees by adding the two arrays, and returns the result to the simulator. Mazloom and Gordon describe a particular distribution that is easy to sample inside a secure computation, and prove that it provides differential privacy. We use the same one in our experiments.</p><formula xml:id="formula_74">Theorem 7 ( [16]) The randomized algorithm L is (ε, δ)- approximate differentially private.</formula><p>Theorem 8 The protocol Π sgas <ref type="figure" target="#fig_8">(Figure 9</ref>) securely computes the ideal functionality F sgas <ref type="figure" target="#fig_6">(Figure 8</ref>) with L leakage in the (F shuffle , F gather , F apply , F scatter )-hybrid model with abort, under a single malicious corruption.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Implementation and Evaluation</head><p>We implemented our four-party secure computation framework in C++. The source code is available at https://github.com/sama730/National-Scale-Secure-ParallelComputation. We measure the performance of our framework on a set of benchmark algorithms in order to evaluate our design. These benchmarks consist of the histogram and matrix factorization problems, which are commonly used for evaluating highly-parallelizable frameworks. In all scenarios, we assume that the data is secret-shared across four non-colluding cloud providers, as motivated in Section 1. We compare our results with the closest large-scale secure parallel graph computation schemes, such as GraphSC <ref type="bibr" target="#b17">[18]</ref> and OblivGraph <ref type="bibr" target="#b15">[16]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Implementation</head><p>In our four-party framework, the histogram and matrix factorization problems can be represented as directed bipartite graphs.</p><p>Histogram: In the histogram computation, which for example can be used to count the number of people in each zip code, left vertices represent data elements (people), right vertices are the counters for each type of data element (the zip code), and existence of an edge indicates that data element on the left has the data type of the right node (e.g. the user on the left belong to the zip code on the right).</p><p>Matrix Factorization: In matrix factorization, left vertices represent users, right vertices are items (e.g. movies in movie recommendation systems or a product in targeted advertising systems), an edge indicates that a user ranked that item, and the weight of the edge represents the rating value. Vertex and Edge representation: In all scenarios, our statistical security parameter s = 40. We choose k = 40 to represent k-bit fixed-point numbers, in which the least d significant bits are used for the fractional part. For histogram d = 0 and for matrix factorization d = 20. This requires data and MACs to be secret shared in the Z 2 80 ring. In our matrix factorization experiments, we factorize the ratings matrix into two matrices, represented by feature vectors that each has dimension 10. We choose these parameters as to be compatible with the GraphSC and OblivGraph representations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Evaluation</head><p>We run the Histogram experiments on graphs with sizes ranging from 1 million to more than 300 million edges, which can simulate the counting operation in census data gathering <ref type="bibr" target="#b0">[1]</ref>. For example, if each user contributed a salary value and a zip-code, using our framework we can compute the average salary in each zip-code, while ensuring that the access patterns preserve user privacy. We run matrix factorization with gradient descent on the real-world MovieLens datasets <ref type="bibr" target="#b10">[11]</ref> that contains user ratings on movies. We report the result for one complete iteration of the protocol, performing GAS operations one time on both the left and right nodes. The results are the average of five executions of the experiments.</p><p>Experiment settings: We run all the experiments on AWS (Amazon Web Services) using four r4.8xlarge instances, each has 32 processors and 244 GiB RAM, with 10 Gbps network connectivity. For the LAN experiments, all instances were in the same data center (Northern Virginia). For the WAN experiments, they were spread across Northern Virginia (P 1 and P 4 ) and Oregon data centers (P 2 and P 3 ). The pairs (P 1 , P 4 ) and (P 2 , P 3 ) each communicate O <ref type="formula" target="#formula_0">(1)</ref>  . In all the experiments, the privacy parameters are set as ε = 0.3, δ = 2 −40 . Run time and Communication Cost: <ref type="figure" target="#fig_3">Figure 16a</ref> demonstrates that the run time required to compute the Histogram protocol on a graph with 300 million edges is less than 4.17 mins, using multiprocessor machines in the LAN setting. Table 1 shows the results in more detail. <ref type="figure" target="#fig_3">Figure 16b</ref> shows the amount of data in MB, transferred between the parties during the Histogram protocol. Communication cost shows linear decrease with increasing the number of processors. Both graphs are in log-log scale.   Similarly, <ref type="figure" target="#fig_4">Figure 17a</ref> shows that computing Matrix Factorization on large scale graph data sets takes less than 6 minutes, using our four-party framework, in our AWS LAN setting. The running time is expected to decrease linearly as we increase the number of processors, however due to some small overhead incurred by parallelization, the run time improvement is slightly sub-linear. <ref type="table" target="#tab_12">Table 2</ref> shows the results in details. <ref type="figure" target="#fig_4">Figure 17b</ref> shows the communication cost during Matrix Factorization on large data sets. Both graphs are in log-log scale.   We measure the run time for each of the graph oblivious operations in our framework, to understand the effect of each step in the performance of the framework as a whole. <ref type="figure" target="#fig_6">Figure  18a</ref> and 18b demonstrates the run time break-down of each oblivious operation in Histogram and Matrix Factorization problem, on the input graph with only 1 million edges. The oblivious Shuffle operation has the highest cost in calculating the Histogram, while Apply phase is taking the most time in Matrix Factorization, due to the calculation of gradient descent values, which are more expensive than counting. Comparison with previous work: We compare our results with OblivGraph which is the closest large-scale secure parallel graph computation. OblivGraph used garbled circuits for all the phases of the graph computation, while we use arithmetic circuits. In both approaches, the amount of time needed to send and receive data, and the time spent computing AES, are the dominant costs. We compare the two protocols by the communication cost and the number of AES calls in each of them. In <ref type="table" target="#tab_14">Table 3</ref> and 4, we demonstrated both the gain in our four party oblivious shuffle against the two party shuffle <ref type="bibr" target="#b20">[21]</ref>      <ref type="table" target="#tab_17">Table 5</ref>, compares our running time with those of GraphSC <ref type="bibr" target="#b17">[18]</ref> and OblivGraph <ref type="bibr" target="#b15">[16]</ref>, while computing matrix factorization on the real-world, MovieLens dataset, with 6040 users, 3883 movies, 1M ratings, and 128 processors. Effect of differential privacy parameters on the run time:</p><formula xml:id="formula_75">(k + s)|E| Share Conversion - (192|E| + 120|V |)(k + s) Oblivious Apply 186032κ|E| + 2960κ|V | (212|E| + 120|V |)(k + s) Oblivious Scatter 0 0 Total 4752κ|E| log |E| + 181312κ|E| (996|E| + 240|V |)(k + s) +2960κ|V | + 4752</formula><p>We study the effect of differential privacy parameters on the performance of our framework using multiprocessor machines in the LAN setting, <ref type="figure" target="#fig_8">Figure 19</ref>. We also provide the number of dummy edges required for different value of ε and δ in     <ref type="figure" target="#fig_18">Figure 20</ref> shows a dramatic slowdown in the run time when we deployed the computation servers across data centers, rather than having them in the same geographic region. Nevertheless, even in the WAN setting, we still greatly out-perform the LAN implementations of GraphSC and OblivGraph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this work, we combine the best results of secure multi-party computation with low-communication cost, and a security relaxation that allows the computation servers to learn some differentially private leakage about user inputs, and construct a new framework which can compute the histogram problem on 300 million users in almost 4 mins and the Matrix Factorization problem on 20 million records in about 6 mins. It reduces the overall runtime of the state of the art solution by 320X, and its communication cost by 200X. Furthermore, in contrast to prior work, our system is secure against a malicious adversary that corrupts one of the computing servers. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">0 1 3 4 5 Number of Processors</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Assumed Protocols</head><p>We assume that we have access to the following oracles: F coin <ref type="figure" target="#fig_20">(Figure 21</ref>), F rerand <ref type="figure">(Figure 22</ref>  Input Two parties P 1 , P 2 hold shares of <ref type="bibr">[X]</ref>. Functionality</p><p>• The ideal functionality waits for shares <ref type="bibr">[X]</ref> from the parties, reconstruct X.</p><p>• The ideal functionality samples random values ∆, sends [X (1) ] 1 = ∆ to P 1 and [X (1) ] 2 = X − ∆ to P 2 .</p><p>Output The parties receive [X (1) ]</p><p>Figure 22: Rerandomize additive shares FUNCTIONALITY F checkZero Input Two parties (P 1 , P 2 or P 3 , P 4 ) hold shares of <ref type="bibr">[Z]</ref>. Functionality</p><p>• The ideal functionality waits for shares <ref type="bibr">[Z]</ref> from the parties, reconstruct Z.</p><p>Output If z i = 0 mod 2 k+s ∀i ∈ {1, ..., n}, output True. Else, send False to all parties. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F Triple</head><p>Inputs: All parties have input (A, B, c), where A, B are input wires, and c is output wire. A = {a 1 , ..., a n }, B = {b 1 , ..., b n }, c = ∑ n i=1 a i b i . P 1 and P 2 both provide λ A , λ B . P 3 and P 4 both provide λ A , λ B . Functionality:</p><p>• If either pair sends mismatched messages, send abort to all parties.</p><p>• Sample λ c uniformly at random.</p><p>•  Inputs: All parties have input (A, B, c), where A, B are input wires, and c is output wire. A = {a 1 , ..., a n }, B = {b 1 , ..., b n }, c = ∑ n i=1 a i b i . P 3 and P 4 both provide λ A , λ B . Protocol:</p><p>• P 1 , P 3 , and P 4 query F coin to sample shares <ref type="bibr">[</ref>   Functionality:</p><p>• Verify that P 1 and P 2 send the same α. If not, send abort to all parties.</p><p>• If the corrupted party is P 3 or P 4 : wait for the attack terms U = {u 1 , ..., u n } from that party, compute Z = α(X +U) mod 2 k+s .</p><p>• Send shares <ref type="bibr">[α]</ref> and <ref type="bibr">[Z]</ref> to P 3 and P 4 .</p><p>Output: P 3 and P 4 receive <ref type="bibr">[α]</ref> and <ref type="bibr">[Z]</ref>. P 1 and P 2 receive nothing. Inputs: P 1 and P 2 have inputs α. P 3 and P 4 have inputs <ref type="bibr">[X]</ref>. F is a PRF. Protocol:</p><p>1. P 1 and P 2 make two calls to F coin to sample two random numbers λ α , r. They both send r to P 3 and λ α − r to P 4 . Then they compute (α − λ α ). They both send (α − λ α ) to P 3 and P 4 . P 3 and P 4 verify that they receive the same values, otherwise, they abort.</p><p>2. P 1 and P 2 agree on a random key k 1 , k 2 . They both send k 1 to P 3 , then k 2 to P 4 . P 3 and P 4 verify that they receive the same values, otherwise, they abort.  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Ideal Functionality to convert additive secret-shares to masked values</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Real-world protocol to convert additive shares to masked values</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Ideal Functionality to handle Masked Evaluation With Truncation</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Protocol to handle Masked Evaluation With Truncation</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Input preparation phase: input data is secret-shared between both groups of parties</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>F</head><label></label><figDesc>sgas : Four-Party Secure Graph Parallel Computation Functionality Input: User input is a directed graph, G(E,V ), secret shared between the parties: Alice, Bob hold secret shares of E, such that, for each edge, [E] A + [E] B = E mod 2 k+s .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: F sgas : Four-party ideal functionality for securely applying the graph parallel model of computation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>F</head><label></label><figDesc>shuffle ([E]) to shuffle their shares. They receive shares of shuffled edges, [E (1) ] ← [π(E)].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Π sgas : Four-party protocol in the hybrid-world for securely applying the graph parallel model of computation. the neighboring vertices. Additionally, the Shuffle operation mixes the dummy edges in with the real ones, which hides the exact degree of each vertex. Theorem 4 The Oblivious Shuffle protocol Π shuffle (Figure 11 securely realizes the ideal functionality F shuffle (Figure 10) with abort, under a single malicious corruption. Proof Theorem 4. The Oblivious Shuffle protocol: To prove</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>F</head><label></label><figDesc>shuffle</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 11 :</head><label>11</label><figDesc>Figure 11: Oblivious Shuffle Real-World Protocol</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 13 :</head><label>13</label><figDesc>Figure 13: Oblivious Gather Real-World Protocol</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>F</head><label></label><figDesc>apply</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 14 :</head><label>14</label><figDesc>Figure 14: Oblivious Apply ideal functionality</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 16 :</head><label>16</label><figDesc>Figure 16: Run time(s) and Communication cost(MB) of Histogram on graph sizes 1M, 10M, 20M and 300M edges</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Figure 17 :</head><label>17</label><figDesc>Figure 17: Run time(s) and Communication cost(MB) of Matrix Factorization on graph sizes 1M, 10M and 20M edges</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Figure 18 :</head><label>18</label><figDesc>Figure 18: Run time for each operation in Histogram and Matrix Factorization on graph size 1M edges (LAN)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Figure 19 :</head><label>19</label><figDesc>Figure 19: Effect of differential privacy parameters, ε and δ on run time in Matrix Factorization with graph size 1M edges</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>Figure 20 :</head><label>20</label><figDesc>Figure 20: Run time of Matrix Factorization on graphs size 1M, showing the effect of network delay in LAN vs WAN.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head></head><label></label><figDesc>), F checkZero (Figure 23), F Triple (Figure 25). FUNCTIONALITY F coin -Generating Random Value The ideal functionality F coin chooses a random r ∈ Z 2 k+s then gives r to all the parties.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head>Figure 21 :</head><label>21</label><figDesc>Figure 21: Sample a random ring element</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head>Figure 23 :</head><label>23</label><figDesc>Figure 23: Ideal Functionality to verify if [Z] is a share of 0.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_22"><head>Figure 24 :</head><label>24</label><figDesc>Figure 24: Triple Generation</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_23"><head>Figure 25 :</head><label>25</label><figDesc>Figure 25: Triple Generation</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_24"><head>F</head><label></label><figDesc>Mult Ideal Functionality to perform multiplication up to an additive attack Inputs: P 1 and P 2 have inputs α. P 3 and P 4 have inputs [X] (X = {x 1 , ..., x n }).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_25"><head>Figure 26 :</head><label>26</label><figDesc>Figure 26: Multiplication up to an Attack</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_26"><head>Figure 27 :</head><label>27</label><figDesc>Figure 27: Multiplication up to an Attack</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head></head><label></label><figDesc>1. Oblivious Shuffle: In this step, Charlotte and David shuffle the edges. Shuffling edges between the gathering of data at the left nodes and the gathering of data at the right nodes ensures that the graph edge structure remains hidden. Alice and Bob are responsible to verify that the shuffle op- eration has been done correctly.</figDesc><table>To facilitate that, before the 
shuffle begins, they need to compute a MAC tag for each 
edge. To compute the MACs, first Alice and Bob agree on 

a random value α, then all parties call a functionality, F MAC , 

to securely compute shares of MAC tags, [M]([M] ≡ [αE]). 
To perform the shuffle, Charlotte and David agree on a ran-
dom permutation π, then each locally shuffles its shares of the 
edges E along with its shares of the corresponding MAC tags, 
according to permutation π. At the the end of this step, Alice 
and Bob receive the shuffled edges from the other group, and 

call the verification function, F CheckZero . If the verification 

fails, it means one of the parties in the shuffling group, either 
Charlotte or David, has cheated and modified the edge data, 
and the protocol aborts; otherwise they continue to the next 
phase. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Details of running time (sec) for computing His-
togram problem on different input sizes 

Processors / Edges 
1M 
10M 
20M 
300M 

1 
13.8 
85.0 
207.7 
2149.4 
2 
7.5 
46.5 
98.1 
1136.5 
4 
4.3 
28.0 
57.8 
643.2 
8 
2.7 
16.2 
34.4 
382.5 
16 
1.8 
11.2 
23.3 
279.2 
32 
1.5 
10.1 
21.7 
250.4 </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Details of running time (sec) for computing Matrix 
Factorization problem on different input sizes 

Processors / Edges 
1M 
10M 
20M 

1 
258.3 
1639.7 
3401.8 
2 
132.9 
834.7 
1913.7 
4 
80.4 
455.6 
1055.9 
8 
44.6 
292.2 
613.1 
16 
28.2 
190.6 
423.7 
32 
25.1 
163.4 
357.2 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Estimated number of AES operations per party for a 
single iteration of matrix factorization: |E| is total number of 
edges (real and dummies), |V| number of vertices. 

OblivGraph 
This work 
Oblivious Shuffle 
7128(|E| log |E| − |E| + 1) 
132|E| 
Oblivious Gather 
0 
72|E| 
Share Conversion 
-
72|E| + 30|V | 
Oblivious Apply 
279048|E| + 4440|V | 
252|E| + 4|V | 
Oblivious Scatter 
0 
20|E| 
Total 
7128|E| log |E| + 271920|E|+ 548|E| + 34|V | 
4440|V | + 7128 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Estimated total communication cost for all par-
ties(bits), for a single iteration of matrix factorization: κ is the 
number of bits per ciphertext, s = 40, |E| is total number of 
edges (real and dummies), |V| number of vertices. The length 
of the fixed point numbers used is k = 40 bits 

OblivGraph 
This work 
Oblivious Shuffle 
4752κ(|E| log |E| − |E| + 1) 
432(k + s)|E| 
Oblivious Gather 
32κ|E| 
160</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16" validated="false"><head>Table 6 .</head><label>6</label><figDesc>Note that the stated number of dummy edges are for each right node in the graph. For example, in a movie recommendation system based on our framework, we require 118 dummy edges</figDesc><table>GraphSC [18] OblivGraph [16] This work 

Time 
13hrs 
2hrs 
25s 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Run time comparison on this work vs. OblivGraph 
vs. GraphSC. Single iteration of Matrix Factorization on real-
world dataset, MovieLens with 6K users ranked 4K movies 
with 1M ratings 

per movie, to achieve (0.3, 2 −40 )-Differential Privacy. 

1 
2 
4 
8 
16 
32 
Number of Processors 

0 

50 

100 

150 

200 

250 

Execution Time (seconds) 

=0.3, =2 40 
=0.3, =2 16 
=1, =2 40 
=1, =2 16 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_18" validated="false"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table>Number of dummy elements required for each type 
depending on different privacy parameters 

ε=0.05 ε=0.3 ε=1 ε=5 
δ = 2 −40 
707 
118 
35 
7 
δ = 2 −16 
374 
62 
19 
4 

LAN vs. WAN runtime </table></figure>

			<note place="foot" n="3"> This brushes over some of the important technical details, but we refer the reader to a formal treatment of security in Goldreich&apos;s book [8].</note>

			<note place="foot" n="4"> Technically, calling this a MAC is an abuse of terminology, since it is not a secure authentication code if αx is ever revealed. However, when computing on secret shared data, it is common to use shares of αx to prevent any incorrect manipulation of the data.</note>

			<note place="foot" n="5"> In addition to proving that the noise distribution provides privacy, we also require that all the noise values are positive, except with probability δ.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This material is based upon work supported by the Defense Advanced Research Projects Agency (DARPA) and Space and Naval Warfare Systems Center, Pacific (SSC Pacific) under Contract No. N66001-15-C-4070. It is also supported by NSF award #1564088.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">The 2020 united states census</title>
		<ptr target="https://2020census.gov" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Optimized honest-majority MPC for malicious adversaries -breaking the 1 billiongate per second barrier</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Toshinori</forename><surname>Araki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Assi</forename><surname>Barak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Furukawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tamar</forename><surname>Lichter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yehuda</forename><surname>Lindell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ariel</forename><surname>Nof</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazuma</forename><surname>Ohara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adi</forename><surname>Watzman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Or</forename><surname>Weinstein</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="843" to="862" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Foundations of differentially oblivious algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T-H. Hubert</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai-Min</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bruce</forename><forename type="middle">M</forename><surname>Maggs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elaine</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Symposium on Discrete Algorithms, SODA &apos;19</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2448" to="2467" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Fast largescale honest-majority MPC for malicious adversaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koji</forename><surname>Chida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Genkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koki</forename><surname>Hamada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dai</forename><surname>Ikarashi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryo</forename><surname>Kikuchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yehuda</forename><surname>Lindell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ariel</forename><surname>Nof</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="34" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">SPD Z 2 k : Efficient MPC mod 2 k for dishonest majority</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronald</forename><surname>Cramer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Damgård</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Escudero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Scholl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaoping</forename><surname>Xing</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="769" to="798" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Mapreduce: Simplified data processing on large clusters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjay</forename><surname>Ghemawat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th Conference on Symposium on Opearting Systems Design &amp; Implementation</title>
		<meeting>the 6th Conference on Symposium on Opearting Systems Design &amp; Implementation<address><addrLine>Berkeley, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="10" to="10" />
		</imprint>
	</monogr>
<note type="report_type">USENIX Association</note>
	<note>OSDI&apos;04</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Ariel Nof, and Or Weinstein. High-throughput secure three-party computation for malicious adversaries and an honest majority</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Furukawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yehuda</forename><surname>Lindell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="225" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Oded Goldreich. Foundations of Cryptography</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<date type="published" when="2009" />
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
	<note>Basic Applications</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Powergraph: Distributed graph-parallel computation on natural graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><forename type="middle">E</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yucheng</forename><surname>Low</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haijie</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danny</forename><surname>Bickson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><surname>Guestrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Presented as part of the 10th USENIX Symposium on Operating Systems Design and Implementation (OSDI 12)</title>
		<meeting><address><addrLine>Hollywood, CA</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="17" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Secure computation with low communication from crosschecking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dov</forename><surname>Gordon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Ranellucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="59" to="85" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The movielens datasets: History and context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxwell</forename><surname>Harper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><forename type="middle">A</forename><surname>Konstan</surname></persName>
		</author>
		<idno>19:1-19:19</idno>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Interact. Intell. Syst</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2015-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Composing differential privacy and secure computation: A case study on scaling private record linkage</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashwin</forename><surname>Machanavajjhala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheryl</forename><forename type="middle">J</forename><surname>Flynn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Divesh</forename><surname>Srivastava</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1389" to="1406" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Graphlab: A new framework for parallel machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yucheng</forename><surname>Low</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><forename type="middle">E</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aapo</forename><surname>Kyrola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danny</forename><surname>Bickson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><surname>Guestrin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><forename type="middle">M</forename><surname>Hellerstein</surname></persName>
		</author>
		<idno>abs/1408.2041</idno>
		<imprint>
			<date type="published" when="2014" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Pregel: A system for large-scale graph processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grzegorz</forename><surname>Malewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><forename type="middle">H</forename><surname>Austern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Aart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">C</forename><surname>Bik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilan</forename><surname>Dehnert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naty</forename><surname>Horn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grzegorz</forename><surname>Leiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Czajkowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 ACM SIGMOD International Conference on Management of Data, SIG-MOD &apos;10</title>
		<meeting>the 2010 ACM SIGMOD International Conference on Management of Data, SIG-MOD &apos;10<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="135" to="146" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Differentially private access patterns in secure computation. Cryptology ePrint Archive</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sahar</forename><surname>Mazloom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S. Dov</forename><surname>Gordon</surname></persName>
		</author>
		<ptr target="http://eprint.iacr.org/2017/1016" />
		<imprint>
			<date type="published" when="1016" />
		</imprint>
	</monogr>
<note type="report_type">Report</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Secure computation with differentially private access patterns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sahar</forename><surname>Mazloom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S. Dov</forename><surname>Gordon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="490" to="507" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">ABY 3 : A mixed protocol framework for machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Payman</forename><surname>Mohassel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Rindal</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="35" to="52" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">GraphSC: Parallel secure computation made easy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kartik</forename><surname>Nayak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><forename type="middle">Shaun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stratis</forename><surname>Ioannidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Udi</forename><surname>Weinsberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nina</forename><surname>Taft</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elaine</forename><surname>Shi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="377" to="394" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Privacypreserving matrix factorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Valeria</forename><surname>Nikolaenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stratis</forename><surname>Ioannidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Udi</forename><surname>Weinsberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Joye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nina</forename><surname>Taft</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Boneh</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="801" to="812" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Differentially private oblivious RAM</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Wagh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Cuff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prateek</forename><surname>Mittal</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>PoPETs</publisher>
			<biblScope unit="volume">2018</biblScope>
			<biblScope unit="page" from="64" to="84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A permutation network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abraham</forename><surname>Waksman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the ACM (JACM)</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="159" to="163" />
			<date type="published" when="1968" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Authenticated garbling and efficient maliciously secure two-party computation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Ranellucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Katz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="21" to="37" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
