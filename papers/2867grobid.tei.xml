<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2020-09-29T02:54+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Operating Systems Should Manage Accelerators</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sankaralingam</forename><surname>Panneerselvam</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Sciences Department</orgName>
								<orgName type="institution">University of Wisconsin</orgName>
								<address>
									<settlement>Madison</settlement>
									<region>WI</region>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">M</forename><surname>Swift</surname></persName>
							<email>swift@cs.wisc.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Sciences Department</orgName>
								<orgName type="institution">University of Wisconsin</orgName>
								<address>
									<settlement>Madison</settlement>
									<region>WI</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Operating Systems Should Manage Accelerators</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>The inexorable demand for computing power has lead to increasing interest in accelerator-based designs. An accelerator is specialized hardware unit that can perform a set of tasks with much higher performance or power efficiency than a general-purpose CPU. They may be embedded in the pipeline as a functional unit, as in SIMD instructions, or attached to the system as a separate device, as in a cryptographic co-processor. Current operating systems provide little support for accelerators: whether integrated into a processor or attached as a device, they are treated as CPU or a device and given no additional consideration. However, future processors may have designs that require more management by the operating system. For example , heterogeneous processors may only provision some cores with accelerators, and IBM&apos;s wire-speed processor allows user-mode code to launch computations on a shared accelerator without kernel involvement. In such systems, the OS can improve performance by allocating accelerator resources and scheduling access to the accelerator as it does for memory and CPU time. In this paper, we discuss the challenges presented by adopting accelerators as an execution resource managed by the operating system. We also present the initial design of our system, which provides flexible control over where and when code executes and can apply power and performance policies. It presents a simple software interface that can leverage new hardware interfaces as well as sharing of specialized units in a heterogeneous system.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>For many years, processor performance improved as predicted by Moore's law <ref type="bibr" target="#b16">[17]</ref>. The recent decline in Dennard's scaling <ref type="bibr" target="#b5">[6]</ref> motivated the creation of many-core processors to reduce power consumption. However, the continued rise in transistor density has provided processors with more transistors than they can use simultaneously.</p><p>This situation motivates the use of accelerators to further improve performance. Accelerators are fixed-or programmable-function hardware that improves power or performance significantly for a small set of codes. While common for widely used functions, such as floating-point computation and video decoding, accelerators are receiving more interest because they promise an efficient use for the transistors becoming available on future processors.</p><p>Accelerators can take on many forms. At the finest granularity, specialized instructions, such as SIMD or CRC32 support in Intel x86, provide accelerated computation over small data items at low latency. In contrast, coarse-grained accelerators may be accessed through a kernel-mode device driver, as in cryptography accelerators in Sun/Oracle Niagara processors and H.264 video encoders for mobile devices <ref type="bibr" target="#b21">[22]</ref>. Recent years have seen a flurry of accelerator architectures, from GPUs for offloading data-parallel computations <ref type="bibr" target="#b14">[15]</ref> to specialized units like c-cores <ref type="bibr" target="#b20">[21]</ref> and DySER <ref type="bibr" target="#b9">[10]</ref> to shared accelerators in IBM's wire-speed processor <ref type="bibr" target="#b8">[9]</ref>.</p><p>Currently, accelerators are ignored by the operating system: the OS is unaware that a computation can execute either on a general purpose core or an accelerator, and provides no assistance in finding the "best" place for a computation. For example, a program that can either use a shared accelerator or execute on a CPU may choose to execute on the CPU for lower latency rather than wait for more efficient execution on the accelerator. In addition, processors that provide direct access to accelerators from user mode, such as wire-speed, may suffer from contention without OS involvement.</p><p>We propose that operating systems should abstract and manage accelerators, rather than leaving it up to compilers, runtimes, and drivers. First, many proposed accelerator systems are inherently asymmetric in that not every core is provisioned with identical accelerators. In a general-purpose system, the OS must manage contention for limited accelerator resources. Second, it may be useful to choose at runtime between execution on an accelerator and on a CPU. Supporting this capability requires the OS make accelerator usage information available. Finally, OS abstractions designed for accelerators can also be applied to heterogeneous systems by treating a CPU as an accelerator and scheduling or allocating its use. This provides a unified framework for all forms of hardware acceleration.</p><p>In the remainder of this paper, we first discuss motivat-ing hardware features and analyze the different classes of accelerators and the system challenges posed by accelerators. We then discuss the design of our proposed system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Motivation</head><p>Our work is motivated by the increasing interest in accelerators from the hardware community and the lack of support for accelerators in the systems community.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Rise of Accelerators</head><p>The choice of providing accelerators in the package is attractive for two reasons (i) they are power efficient (ii) with the increasing transistor count, all of them cannot powered on simultaneously <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b4">5]</ref>. Accelerators provide dramatically better efficiency than processors. Compared to custom-designed ASICs, a CPU may be 500 times less energy efficient due to costs such as instruction fetch and programmable data paths <ref type="bibr" target="#b11">[12]</ref>. Thus, specialized units within processors can be used to execute specific functions efficiently.</p><p>In addition, Moore's law continues to provide additional transistors, even though processors lack the power to use them all concurrently. As a result, general-purpose multicore architectures and even GPUs cannot continue to scale performance because of the limited power available to processors <ref type="bibr" target="#b7">[8]</ref>. Thus, there may be ample transistors available to provide accelerators even for uncommon workloads.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Accelerator Types</head><p>There are currently several types of accelerators that require different software interfaces. <ref type="table">Table 1</ref> gives the characteristics of three types of accelerators. Acceleration devices. Shared accelerators are commonly implemented as devices and accessed through memory-mapped or port I/O instructions from a kernel device driver. For example, the Oracle/Sun Niagara cryptography accelerator requires a kernel device driver for access, as do GPUs for accelerating data-parallel computations. Such accelerators promise the greatest power, as they are freed from the design constraints of executing in the processor pipeline. However, access through the kernel and I/O instructions increases the latency of access and limits these accelerators to coarse-grained computations.</p><p>Furthermore, as acceleration devices execute outside the processor, they may not have access to virtual addressing. Thus, invoking the accelerator may require pinning data in memory and translating virtual addresses in advance of launching the accelerated computation.</p><p>Co-processors. Several accelerator designs augment the processor pipeline with acceleration logic to offload program logic. A simple example is vector SIMD instructions, which provide data-parallel execution for greater performance and efficiency. More recently, ccores executes specific application logic with greater efficiency <ref type="bibr" target="#b20">[21]</ref>, and DySER provides a specialized data path <ref type="bibr" target="#b9">[10]</ref>.</p><p>These accelerators provide low-latency access directly from registers or virtual memory. However, co-processor designs may still contend for power if not all coprocessors or cores can be active simultaneously. In addition, heterogeneous system with a variety of accelerators attached to different cores may also experience contention. Finally, programmable accelerators, such as DySER, require a configuration step that may limit its ability to accelerate short code fragments.</p><p>Independent cores. Finally, asymmetric or heterogeneous processors can also be considered accelerator-based systems. Rather than specializing hardware to a specific computation, such a system provides a variety of generalpurpose cores with different performance and power characteristics. For example, NVidia's Kal-El processor provides a low-power companion core <ref type="bibr" target="#b17">[18]</ref>. On such a system, a program may execute faster or with lower power if it switches to a specific core for phases of its execution. Similar to other designs, these systems can experience contention if many processes desire a limited set of cores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Lack of OS Support</head><p>We examine how the following activities are handled in todays operating systems: (i) task invocation, (ii) virtualization, and (iii) scheduling.</p><p>Task Invocation. We refer to the function block or code region that executes on an accelerator, like encrypting a chunk of data as a task. Currently, each accelerator type presents a different interface to the programmer. For example, functional units are accessed via new instructions, while devices require a system call into the kernel. Thus, it is difficult to write programs that can use a variety of accelerators.</p><p>Furthermore, it may be desirable to decide at runtime whether to execute a computation on an accelerator or a CPU. If there is contention for an accelerator, it reduce latency to execute code on a general-purpose CPU rather than to wait for the accelerator. In addition, a process may desire to use both the accelerator and idle CPUs simultaneously to further speed execution.</p><p>Operating systems do not currently provide runtime support to allow programs to decide whether to use acceleration. Instead, a program may be written or compiled with calls to specific accelerators, as in a GPU. Virtualization. Several processors provide user-mode access to accelerator devices <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b3">4]</ref>. These systems provide new instructions that enqueue requests to a shared accelerator. This reduces the communication latency to a great extent since the path through driver/system is completely avoided. However, direct access from user mode raises several issues with virtualization. First, a shared accelerator must be able to translate virtual addresses from multiple processes, and the OS must provide those translations. Second, a process may be preempted after launching an accelerated computation, and may not be able to receive the output. Thus, the OS must be aware when the computation completes so it can reclaim the process's resources.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Properties</head><p>Scheduling. Accelerator-based systems raise several new scheduling problems. First, operating systems work best with uniform resources, such as identical cores or identical memory performance. When systems are heterogeneous, as in NUMA designs, the OS must predict future execution patterns in order to optimize performance, and works less well. Accelerator-based systems are fundamentally heterogeneous, as they require mapping a mix of workloads to a mix of accelerators. Scheduler work on ACMP systems has approached this problem where they dynamically decide on the type of core to execute on <ref type="bibr" target="#b12">[13]</ref>. But, generalizing this issue to all types of accelerators is difficult because predicting performance on a variety of accelerators may be more difficult.</p><p>Second, an accelerator-based systems requires policies to provide fairness and performance isolation for accelerator access in addition to CPU and memory. The OS must decide which processes deserve access to the accelerator and for how long. User-mode access to shared accelerators complicates such scheduling decisions, because the OS cannot interpose on every request. Third, the OS must provide usage information to inform application of what accelerators are available and for how long. This allows applications to make informed decisions about whether to use an accelerator or rely on direct execution on the CPU instead for low-latency operation.</p><p>In addition, device scheduling and sharing is implemented by device drivers. In a contended system where multiple processes desire acceleration, this prevents the OS from imposing a scheduling policy on accelerator access. Recent work on abstractions for GPUs have addressed this problem <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b18">19]</ref> with mechanisms that apply to other device, that works well for acceleration devices accessed through drivers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Design</head><p>We propose a simple accelerator programming model with operating system support. The model treats the use of an accelerator as a function call that can be dynamically dispatched to an accelerator or executed in-line on the CPU. Based on this model, we discuss kernel and runtime support mechanisms for flexible use of accelerators. <ref type="figure" target="#fig_0">Figure 1</ref> shows the different components in our system and how they interact.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Programming Model</head><p>The goal of our model is to allow accelerators to be integrated into common programming paradigms with little effort yet provide flexibility on how accelerators are accessed and when they are used. Thus, we treat accelerator invocation as a non-blocking procedure call, similar to a parallel function invocation in Cilk <ref type="bibr" target="#b1">[2]</ref>. The calling function may block, if the accelerated function can execute on the local core, or may return immediately. The calling function can then wait for the computation to complete, similar to handling work units in an event driven model or futures in asynchronous systems <ref type="bibr" target="#b15">[16]</ref>. The task to be accelerated is scheduled on an appropriate available accelerator unit and the main thread can continue with its execution or wait for the results.</p><p>This model provides great flexibility in how accelerators are invoked, as the mechanism is hidden behind a function call. Furthermore, an accelerated procedure may have multiple implementations depending on the accelerators available, which can be selected dynamically. Furthermore, the abstraction is simple enough that it fits many uses of accelerators, such as cryptography libraries invoking a kernel-mode driver. Finally, it can leverage existing parallel runtimes, to provide synchronization and scheduling.</p><p>The PTask dataflow model assumes coarse-grained tasks that must be executed completely by accelerators <ref type="bibr" target="#b18">[19]</ref>. In contrast, our model identifies the right execution resource to choose based on the system condition and also the task properties. Thus, both these models can co-exist to provide better benefits to the system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Accelerator Stub</head><p>The procedure call a program makes to invoke an accelerated function does not directly execute the function. To provide a dynamic choice of how to execute the task, our system interposes accelerator stubs on every invocation. The responsibility of the stub is to (i) select the best implementation of the task, either with an accelerator or natively, (ii) pass data to the implementation, and (iii) implement synchronization mechanisms if necessary to block the caller until the result is available. An accelerator stub is functionally similar to an RPC stub <ref type="bibr" target="#b0">[1]</ref>, which similarly dispatches a function to execute elsewhere. Stubs abstract the presence of different execution resources present in the system and instead expose a single procedural interface to applications. Furthermore, the stub enables the system to make online decisions of which implementation to choose based on power and performance considerations. For example, a simple policy would be to allow a web server with high priority to make complete use of a cryptography accelerator, but allow its use by other tasks when idle.</p><p>The mechanism for selecting the implementation of a task is called binding, and may occur early, when the program loads, or late, when the task is invoked (or later). For example, a program may link its stubs against implementations that invoke an accelerator when the program loads, and all subsequent invocations of those tasks will use the accelerator. If, however, binding is deferred until call time, then the program can choose on every call whether to use an accelerator or execute natively. This decision can even be based on the parameters to the function. Binding can be deferred further if tasks enqueued, because the choice of implementation can be made when executing a task rather than submitting it. The stub can also send tasks directly to the accelerator if it supports direct user-mode access from applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Accelerator Agent</head><p>Every accelerator has an agent that manages the accelerator. In the case of an acceleration device, it may be a driver that communicates with the device. For a co-processor, it may be a thread scheduled on the core with the accelerator. The role of the agent is to (i) provide mechanisms to bind programs to the accelerator and create communication channels, (ii) expose accelerator usage to the OS, to guide policy decisions, and (iii) implement scheduling decisions for the accelerator based on OS policy.  Before using an accelerator, a program must establish a communication channel to the accelerator. For example, many drivers establish a ring buffer of requests in a shared memory region to communicate with a device. A program establishes a connection with the agent in advance of using an accelerator, and the agent performs access-control checks and notifies the OS that the program is interested in using the accelerator. To ensure security and that one process does not interrupt another process's communication channel, an agent creates a separate channel for each requesting process.</p><p>Once bound, the stubs for an accelerator task can use the communication channel to invoke the accelerator. For a device accelerator, it may make a system call to the agent. For a co-processor or independent core, it may send data to the agent thread running on the accelerator's core or it may ask the agent to migrate the thread to the accelerator core for execution.</p><p>The agent provides policies to schedule the accelerator between processes. For a device with a kernel-mode driver, it may decide which queued requests to send to the device, while for a co-processor it may decide which tasks to execute on the desired core. If an accelerator supports direct communication from user-mode, then the agent may need additional hardware support to schedule its use. One possibility is to virtualize communication channels: when the accelerator is in use by one process, the channels of all other processes are disconnected from the accelerator. Alternatively, the agent can act as a proxy for the accelerator. In this scenario, the agent receives requests via shared memory and decides when to pass them to the accelerator. As communication can be overlapped with the accelerator's work, this does not increase latency. In this case, the agent can also decide to assign the accelerator to a single application if there are no competing requests from other applications.</p><p>Agents aid in virtualization by providing the mechanisms to map virtual memory for accelerator devices and to monitor communication channels. Thus, if a process is preempted while using an accelerator, the agent can take responsibility for eventually delivering the result.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Accelerator Monitor</head><p>The accelerator monitor is a centralized kernel service responsible for monitoring and scheduling access to multiple accelerators. Thus, it provides the global policy that decides which process should have access to an accelerator and when. It notifies agents of which processes should receive access, and it is up to the agent to put the policy into practice.</p><p>The monitor is responsible for system-wide energy and performance goals. It tracks accelerator usage by interrogating agents about their recent use. This provides information about the utilization of accelerators, and can be exposed to applications to help them choose whether to use an accelerator. Thus, the monitor acts as an online modeling tool that can return dynamic information such as queuing delay for the accelerators. This helps the system to decide on a better execution resource on which to schedule the task at that point of time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Related Work</head><p>Past work on OS support for accelerators has targeted a narrow set of accelerators. PTasks <ref type="bibr" target="#b18">[19]</ref> and Pegasus <ref type="bibr" target="#b10">[11]</ref> treat the GPU as first class resource and provide scheduling policies to ensure fair sharing among applications. However, these systems assume that GPUs must be used for the desired computation, and do not provide support for dynamically choosing between GPU or CPU implementations of a computation.</p><p>Frameworks like Merge <ref type="bibr" target="#b13">[14]</ref> and Harmony <ref type="bibr" target="#b6">[7]</ref> provide runtime support to incorporate different task implementations on different accelerators. However, they make decision based on the application parameters, such as task granularity. Thus, they do not consider other users of acceleration hardware that might be present in multiprogrammed systems.</p><p>Recently, there have been growing interests in designing hardware interfaces to target the segment between fine-grained and coarse-grained acceleration like wirespeed processor <ref type="bibr" target="#b8">[9]</ref>. This architecture is a good fit for our design, as it provides shared accelerators with user-mode access, and thus requires additional support from the OS to manage contention from multiple clients.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>Accelerators provide opportunities to achieve power efficiency without hurting performance. While different solutions exist for different type of accelerators, a common interface to leverage multiple accelerators is not available. Moreover, current systems cannot ensure performance isolation for accelerators. We propose a simple procedural interface to accelerators that can dynamically select an implementation at runtime. An accelerator agent abstracts the accelerator to the operating system, allowing it to participate in scheduling and resource allocation decisions. Finally, the accelerator monitor enforces global properties such as fairness, performance isolation, and power efficiency. With these mechanisms, the difference between regular cores and accelerators will be blurred, and new accelerators can be gracefully integrated into existing code.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: System Design</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We thank the anonymous reviewers for their feedback and also like to thank Mohit Saxena and Vijay Chidambaram for their comments on the earlier drafts of the paper. This work was supported by NSF Award CNS-0834473. Swift has a financial interest in Microsoft Corp.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Implementing remote procedure calls</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">D</forename><surname>Birrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">J</forename><surname>Nelson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Comput. Syst</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="39" to="59" />
			<date type="published" when="1984-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Cilk: an efficient multithreaded runtime system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">D</forename><surname>Blumofe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">F</forename><surname>Joerg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">C</forename><surname>Kuszmaul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">E</forename><surname>Leiserson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">H</forename><surname>Randall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 12th ACM SIGPLAN Symp. on Principles and Practice of Parallel Programming (PPOPP)</title>
		<meeting>of the 12th ACM SIGPLAN Symp. on Principles and Practice of Parallel Programming (PPOPP)</meeting>
		<imprint>
			<date type="published" when="1995-08" />
			<biblScope unit="page" from="207" to="216" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">The future of microprocessors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Borkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Chien</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011-05" />
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="page" from="67" to="77" />
		</imprint>
		<respStmt>
			<orgName>CACM</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<ptr target="http://www.cavium.com/OCTEON-IICN68XX.html" />
		<title level="m">Cavium Networks. OCTEON II CN68XX Multi-Core MIPS64 Processors</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">10x10: A General-purpose Architectural Approach to Heterogeneity and Energy Efficiency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Chien</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Snavely</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gahagan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Computational Science (ICCS)</title>
		<meeting>the International Conference on Computational Science (ICCS)</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Design of ion-implanted MOS-FET&apos;s with very small physical dimensions. SolidState Circuits</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Dennard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Gaensslen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Rideout</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Bassous</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Leblanc</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Journal</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="256" to="268" />
			<date type="published" when="1974-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Harmony: an execution model and runtime for heterogeneous many core systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">F</forename><surname>Diamos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yalamanchili</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th International Symposium on High performance distributed computing</title>
		<meeting>the 17th International Symposium on High performance distributed computing</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="197" to="200" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Dark Silicon and the End of Multicore Scaling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Esmaeilzadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Blem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Amant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sankaralingam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Burger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISCA</title>
		<imprint>
			<date type="published" when="2011-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Introduction to the wire-speed processor and architecture</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Franke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xenidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Basso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">M</forename><surname>Bass</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Woodward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Johnson</surname></persName>
		</author>
		<idno>3:1 -3:11</idno>
	</analytic>
	<monogr>
		<title level="j">IBM Journal of Research and Development</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2010-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Dynamically Specialized Datapaths for Energy Efcient Computing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Govindaraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-H</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sankaralingam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">High Performance Computer Architecture (HPCA)</title>
		<imprint>
			<date type="published" when="2011-02" />
			<biblScope unit="page" from="503" to="514" />
		</imprint>
	</monogr>
	<note>IEEE 17th International Symposium on</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Pegasus: coordinated scheduling for virtualized accelerator-based systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Schwan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Tolia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Talwar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ranganathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2011 USENIX conference on USENIX annual technical conference</title>
		<meeting>the 2011 USENIX conference on USENIX annual technical conference</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="3" to="3" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Understanding sources of inefficiency in general-purpose chips</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hameed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Qadeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wachs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Azizi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Solomatnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">C</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kozyrakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Horowitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISCA</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="37" to="47" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Efficient Operating System Scheduling for Performance-Asymmetric Multi-Core Architectures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Baumberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Koufaty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hahn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of SC2007</title>
		<meeting>of SC2007</meeting>
		<imprint>
			<date type="published" when="2007-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Merge: A Programming Model for Heterogeneous Multi-core Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Linderman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">H</forename><surname>Meng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th international conference on Architectural support for programming languages and operating systems</title>
		<meeting>the 13th international conference on Architectural support for programming languages and operating systems</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="287" to="296" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Nvidia Tesla: A Unified Graphics and Computing Architecture</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Lindholm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Nickolls</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Oberman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Montrym</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Micro</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="39" to="55" />
			<date type="published" when="2008-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Easier Asynchronous Programming with the New Visual Studio Async CTP. MSDN Magazine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Lippert</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Cramming More Components Onto Integrated Circuits</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Moore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="82" to="85" />
			<date type="published" when="1998-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
				<ptr target="http://www.nvidia" />
		<title level="m">NVIDIA Corporation. Variable SMP -A MultiCore CPU Architecture for Low Power and High Performance</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">PTask: Operating System Abstractions To Manage GPUs as Compute Devices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Rossbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Currey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Silberstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Witchel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Third ACM Symposium on Operating Systems Principles</title>
		<meeting>the Twenty-Third ACM Symposium on Operating Systems Principles</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="233" to="248" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Introduction to OpenOnloadBuilding Application Transparency and Protocol Conformance into Application Acceleration Middleware</title>
		<ptr target="http://www.solarflare.com/Content/UserFiles/Documents/SolarflareOpenOnloadIntroPaper.pdf" />
		<imprint/>
	</monogr>
	<note>Solarflare Communications</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Conservation Cores: Reducing the Energy of Mature Computations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Venkatesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sampson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Goulding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Bryksin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lugo-Martinez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Swanson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">B</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the fifteenth edition of ASPLOS on Architectural support for programming languages and operating systems</title>
		<meeting>the fifteenth edition of ASPLOS on Architectural support for programming languages and operating systems</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="205" to="218" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Implementation of H.264 on Mobile Device</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">L</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ngan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1109" to="1116" />
			<date type="published" when="2007-08" />
		</imprint>
	</monogr>
	<note>Consumer Electronics</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
