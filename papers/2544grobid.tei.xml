<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2020-09-29T02:46+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Improving Meek With Adversarial Techniques</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><forename type="middle">R</forename><surname>Sheffey</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Middle Tennessee State University</orgName>
								<orgName type="institution" key="instit2">Middle Tennessee State University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ferrol</forename><surname>Aderholdt</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Middle Tennessee State University</orgName>
								<orgName type="institution" key="instit2">Middle Tennessee State University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Improving Meek With Adversarial Techniques</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>As the internet becomes increasingly crucial to distributing information , internet censorship has become more pervasive and advanced. Tor aims to circumvent censorship, but adversaries are capable of identifying and blocking access to Tor. Meek, a traffic obfuscation method, protects Tor users from censorship by hiding traffic to the Tor network inside an HTTPS connection to a permitted host. However, machine learning attacks using side-channel information against Meek pose a significant threat to its ability to obfuscate traffic. In this work, we develop a method to efficiently gather reproducible packet captures from both normal HTTPS and Meek traffic. We then aggregate statistical signatures from these packet captures. Finally, we train a generative adversarial network (GAN) to minimally modify statistical signatures in a way that hinders classification. Our GAN successfully decreases the efficacy of trained classifiers, increasing their mean false positive rate (FPR) from 0.183 to 0.834 and decreasing their mean area under the precision-recall curve (PR-AUC) from 0.990 to 0.414.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Tor <ref type="bibr" target="#b5">[6]</ref> is often used to hide a user's internet traffic in order to gain privacy or circumvent censorship <ref type="bibr" target="#b6">[7]</ref>. However, the IP addresses of Tor relays are public, and authorities such as China have used this information to prevent access to Tor <ref type="bibr" target="#b7">[8]</ref>  <ref type="bibr" target="#b29">[29]</ref>. In response, researchers and activists developed traffic obfuscation methods that use techniques such as encryption and protocol mimicry to make it more difficult for censors to prevent access to Tor <ref type="bibr" target="#b6">[7]</ref>. Many of these traffic obfuscation methods are made available with Tor Browser as "pluggable transports" <ref type="bibr" target="#b24">[24]</ref>.</p><p>One such pluggable transport is Meek, which offers strong protection against metadata-based Deep Packet Inspection (DPI) attacks using domain fronting <ref type="bibr" target="#b9">[10]</ref>. Domain fronting obfuscates traffic by hiding traffic intended for a forbidden host inside the encrypted payload of an HTTPS connection to a permitted host <ref type="bibr" target="#b9">[10]</ref>. This is achieved by manipulating the Host header of the underlying encrypted HTTP payload in order to take advantage of cloud hosting services that forward HTTP traffic based on this header. Domain fronting exploits censors' unwillingness to cause collateral damage, as blocking domain fronting would require also blocking the typically more reputable, permitted host. From the point of view of an adversary using DPI and metadata-based filtering, there is no difference between Meek and normal HTTPS traffic. All unencrypted fields in Meek traffic that could indicate its true destination such as DNS requests, IP addresses, and the Server Name Indication (SNI) inside HTTPS connection headers do not reveal its true destination.</p><p>However, recent work has shown that Meek is vulnerable to machine learning attacks that use side-channel information such as packet size and timing distributions to differentiate Meek traffic from normal HTTPS traffic <ref type="bibr" target="#b20">[20]</ref>, <ref type="bibr" target="#b28">[28]</ref>, <ref type="bibr" target="#b30">[30]</ref>. <ref type="bibr">Wang et al. [28]</ref> were able to differentiate Meek traffic from normal HTTPS traffic with a FPR as low as 0.0002 using a CART decision tree, while Yao et al. <ref type="bibr" target="#b30">[30]</ref> achieved an accuracy of 99.98% on the same task using a hidden Markov model. Nasr et al. <ref type="bibr" target="#b20">[20]</ref> were able to deanonymize Meek traffic with a FPR of 0.0005 using a neural network. Machine learning attacks against Meek pose a dangerous threat to its effectiveness, and strengthening Meek against these attacks remains an open problem.</p><p>Traffic obfuscation is fundamentally a conflict between an adversary attempting to detect unwanted traffic and a user attempting to modify their traffic in a way that circumvents this <ref type="bibr" target="#b6">[7]</ref>. Generative Adversarial Networks (GANs) operate under a similar paradigm. GANs are typically composed of two components: a generator and a discriminator <ref type="bibr" target="#b11">[12]</ref>. The goal of the generator is to generate realistic looking data, while the goal of the discriminator is to determine whether this synthetic data is real or fake. By training the generator and discriminator in unison, each can learn from the other until an equilibrium is reached.</p><p>In this work, we evaluate the efficacy of GANs in identifying and correcting identifiable patterns in Meek traffic.</p><p>We achieve this by first developing a method capable of generating large amounts of normal HTTPS and Meek packet captures, with a focus on efficiency and reproducibility. We then extract statistical signatures modeling the identifiable side-channel features of this traffic. Finally, we train a modified version of StarGAN <ref type="bibr" target="#b3">[4]</ref>, and evaluate its ability to reduce the FPR and PR-AUC of multiple trained classifiers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Data Collection</head><p>The objective of our data collection method is to capture traffic generated by navigating to the same websites over both normal HTTPS and Meek, and to do so efficiently and reproducibly. Previous work analyzing Meek traffic uses sequential scripts <ref type="bibr" target="#b26">[26]</ref>, <ref type="bibr" target="#b28">[28]</ref> or does not appear to specify their Meek data collection process <ref type="bibr" target="#b20">[20]</ref>, <ref type="bibr" target="#b30">[30]</ref>. We use Docker <ref type="bibr" target="#b13">[13]</ref> to allow our data collection process to be performed in parallel, and in a reproducible environment.</p><p>Docker is a platform based on reproducible environments known as containers <ref type="bibr" target="#b13">[13]</ref>. Our data collection method is composed of two types of containers: a work queue and workers. The work queue manages and distributes a queue of data collection work. Each work item in the queue contains a URL and a proxy type. Workers navigate to URLs using the given proxy type, and produce packet captures for each piece of work.</p><p>Because Meek tunnels traffic through a single HTTPS connection <ref type="bibr" target="#b9">[10]</ref>, gathering individual Meek connections requires restarting the Meek process. This limitation presents a major bottleneck to our data collection process. In order to circumvent this, we use Docker Compose <ref type="bibr" target="#b14">[14]</ref> to allow for any number of data collection workers to operate in parallel.</p><p>During data collection, each worker repeats the process shown in <ref type="figure" target="#fig_0">Figure 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Datasets</head><p>We collect datasets from a residential desktop (H), a university office desktop (U), and an Amazon Web Service (AWS) server (A). Datasets H and U were collected using Docker installed on NixOS hosts, while dataset A was generated using an AWS m5.2xlarge instance provisioned by docker-machine. Each dataset contains 20000 samples, created by navigating to the top 10000 websites of the Alexa top 1M dataset <ref type="bibr" target="#b0">[1]</ref> using both regular HTTPS and Meek using the meek-azure bridge from Tor Browser. Datasets H and U were collected in Middle Tennessee, while dataset A was generated from the AWS us-east-1 region (North Virginia) <ref type="bibr" target="#b25">[25]</ref>.</p><p>Our datasets contain HTTPS traffic, generated with and without Meek. However, HTTPS traffic does not encompass the scope of all Meek traffic. We only collect traffic from connections to the homepages of popular websites, but Tor Browser users may navigate to other pages, use hidden services, or communicate using other protocols. Our data collec-1. Request URL and proxy from the work queue. If there is no more work, exit.</p><p>2. Start tcpdump to capture all packets.</p><p>3. Start Tor/Meek if applicable.</p><p>4. If using Meek, wait for 10 seconds to ensure Tor has been properly initialized, and to provide some measure of reducing network load.</p><p>5. Start Firefox using Selenium.</p><p>6. Navigate to the URL.</p><p>7. Wait for either an element with a common tag (&lt;script&gt;) to load, or 60 seconds to pass. This is done to speed up the data collection process and avoid getting stuck.</p><p>8. Thoroughly shut down Firefox, Tor/Meek, and tcpdump, in that order.</p><p>9. Send a report to the work queue containing information about the work done, and the filename of the generated PCAP file. tion framework may be extended to include hidden services, but is not suited to non-web traffic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Feature Extraction</head><p>In this work, we analyze the following side-channel traffic features: histograms of TCP payload sizes and per-direction packet inter-arrival times. We ignore basic packet metadata such as IP addresses or TLS parameters. While Meek traffic may have distinct values for these features compared to the wide variety of HTTPS clients on the internet, we assume that these basic fields could be trivially modified. The sidechannel features we analyze are acknowledged in the original implementation of Meek <ref type="bibr" target="#b9">[10]</ref> and used by <ref type="bibr">Wang et al. [28]</ref>, Nasr et al. <ref type="bibr" target="#b20">[20]</ref>, and Yao et al. <ref type="bibr" target="#b30">[30]</ref> to identify Meek. These features are identifiable weaknesses in Meek, but their statistical distribution may be modified through traffic shaping techniques; for example, Verma et al. <ref type="bibr" target="#b27">[27]</ref> propose inserting extra data (chaff) into packets or delaying packet transmission in order to match a distribution generated by an adversarial neural network. HTTPOS <ref type="bibr" target="#b17">[17]</ref> applies a similar technique to HTTP traffic. We use Bro, a DPI engine, to aggregate packets from each PCAP into a set of HTTPS connections <ref type="bibr" target="#b21">[21]</ref>. We then associate each packet with an HTTPS connection using its source IP, destination IP, source port, destination port, and timestamp. All packets unrelated to HTTPS connections are ignored. As much more information is found in smaller payload lengths and inter-arrival times than larger ones, we aggregate these features into logarithmic bins. For TCP payload lengths, we use bins of size 10 from 0 to 100 bytes, size 100 from 100 to 1000 bytes, size 1000 from 1000 to 10000 bytes, and a single bin for packets larger than 10000 bytes. For packet inter-arrival times, we use bins of size 1 from 0 to 10 ms, size 10 from 10 to 100 ms, size 100 from 100 to 1000 ms, and a single bin for inter-arrival times above 1000ms. These bin sizes are similar to those used by <ref type="bibr">Wang</ref>   show the average frequencies of TCP payload sizes, inter-arrival times from client, and inter-arrival times to client, respectively over dataset H, defined in Section 2.1. One difference between normal HTTPS and Meek traffic can be seen in <ref type="figure">Figure 2</ref> where Meek traffic has a much larger proportion of packets with payload size between 60 and , where Meek traffic exhibited a much larger number of payloads around 1400 bytes and a lack of payloads around 50 bytes. This may be due to a difference in data sources <ref type="bibr" target="#b9">[10]</ref>, or modifications to Meek <ref type="bibr" target="#b8">[9]</ref>. Fifield et al.</p><p>[10] compared Google traffic from Lawrence Berkeley National Laboratory to traffic generated by navigating to the Alexa top 500 over Meek. Since Meek's creation, it has introduced many changes such as HTTP/2 support <ref type="bibr" target="#b8">[9]</ref>, which can result in different traffic characteristics <ref type="bibr" target="#b18">[18]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Adversarial Transformation</head><p>While typical GANs contain a generator, which generates adversarial data from noise, our model uses a transformer, which transforms a traffic signature from one class to another. This model is similar to an adversarial transformation network <ref type="bibr" target="#b1">[2]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Architecture</head><p>In our model, we replace StarGAN's complex, multi-layered convolutional layers with a simple fully-connected hidden layer. While convolutional neural networks are useful for image classification tasks <ref type="bibr" target="#b16">[16]</ref>, our traffic signatures are very simple and can be classified using a very small number of parameters. The discriminator accepts a signature, contains a single fully-connected hidden layer of size 16, and outputs a label Y (the probability that the signature represents a Meek flow), and a source S (the probability that a signature was modified using a transformer). The transformer accepts a signature (X) and a target class, contains a single fully-connected hidden layer of size 128, and outputs a modified signature (X ′ ). The transformer contains a larger hidden layer in order to avoid losing information during reconstruction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Training</head><p>We train our model using a modified version of the StarGAN training process. For each training iteration, we train the discriminator using the following steps:  <ref type="bibr" target="#b15">[15]</ref>.</p><p>Every 5 iterations, we train the transformer using the following steps:</p><p>1. Calculate loss for the discriminator's label and source prediction over the transformed signatures.</p><formula xml:id="formula_0">Y ′ predicted , S ′ predicted = D(X ′ ) T Loss cls = BCE(Y random ,Y ′ predicted ) T Loss src = −mean(S ′ predicted )</formula><p>3. Transform the transformed signature back to its original class using the transformer, and measure the mean absolute difference between the original and reconstructed signature. The signatures generated by our transformer represent a new distribution of packet sizes and timings that, if matched, would make Meek traffic appear similar to regular HTTPS traffic. However, introducing delays or extra data into a traffic stream in order to match this distribution introduces overhead <ref type="bibr" target="#b27">[27]</ref>. In order to minimize this, we introduce an additional objective into our transformer's loss function called perturbation loss, defined above in step 2 of the training process. This measures the mean absolute difference between the original signature and the transformed signature. By introducing perturbation loss, we train the transformer to make minimal modifications to the traffic signature while simultaneously fooling the discriminator. By minimizing changes made by the transformer, we reduce the amount of work a traffic shaping method would have to do to modify the Meek traffic stream in order to fool classifiers.</p><p>In order to reduce overfitting, a situation in which neural networks generalize poorly due to relying on noise present in the training set, we introduce early stopping measures <ref type="bibr" target="#b2">[3]</ref>. Our training process iterates repeatedly over the training set until both the discriminator loss DLoss and transformer loss T Loss have not decreased by 0.0001 over 2000 batches. This is to ensure that D and T cease training when they have reached an equilibrium.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Evaluation</head><p>To avoid biasing our experiments by evaluating models using data that they have been trained on, we split each dataset into three parts:</p><p>• 30% GAN training set (G train )</p><p>• 20% Classifier training set (C train )</p><p>• 50% Classifier testing set (C test )</p><p>Our training and evaluation process is composed of 8 steps:</p><p>1. Train the Discriminator (D) and Transformer (T ) using G train , as described in Section 4.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Train a neural network classifier and decision tree with C train</head><p>3. Split the classifier training set in half</p><formula xml:id="formula_1">C train1 ,C train2 = split(C train )</formula><p>4. Transform one half of the classifier training set into the opposite class using the transformer, while retaining the original (unmodified labels). This is to simulate an adversary who is aware of the traffic modification scheme, and aims to classify modified traffic as its original class.</p><formula xml:id="formula_2">X train2 ,Y train2 = C train2 X ′ train2 = T (X train2 , 1 −Y train2 ) C ′ train2 = X ′ train2 .Y train2 C ′ train = C train1 񮽙 C ′ train2</formula><p>5. Train a neural network classifier over C ′ train 6. Evaluate the PR-AUC and FPR of all classifiers over C test</p><formula xml:id="formula_3">7. Transform C test using T C ′ test = T (C test )</formula><p>8. Evaluate the PR-AUC and FPR of all classifiers over C ′</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>test</head><p>The neural network classifiers are simple dense neural networks that accept a signature, contain a hidden layer identical to the discriminator, and output the probability that the signature represents Meek traffic. The decision tree is the default decision tree provided by scikit-learn <ref type="bibr" target="#b22">[22]</ref>, which is identical to the best-performing classifier type in Wang et al <ref type="bibr" target="#b28">[28]</ref>.</p><p>To avoid overfitting when training C, we separate C train into a smaller C train with 90% of its original size, and C val containing 10% of C train . Each epoch, we evaluate the loss of N using C val to calculate the validation loss. If the validation loss has not decreased by 0.001 in 5 epochs (full iterations over C train ), we stop training the classifier.</p><p>We evaluate classifiers using PR-AUC and FPR. PR-AUC is a particularly useful metric when dealing with a domain in which the number of negative samples vastly outweighs the number of positive samples <ref type="bibr" target="#b4">[5]</ref>. This suits traffic obfuscation well, as most internet users do not use Meek. Additionally, PR-AUC takes prediction confidence into account, and graphs precision vs recall based on a classifier's ability to confidently provide predictions <ref type="bibr" target="#b4">[5]</ref>. FPR is commonly used when evaluating obfuscation methods, as falsely blocking a connection can cause degraded network performance <ref type="bibr" target="#b28">[28]</ref>. Additionally, existing work <ref type="bibr" target="#b28">[28]</ref> uses PR-AUC and FPR to measure obfuscator classification performance, allowing our work to be more readily comparable.</p><p>Finally, to increase confidence in our results, we use a method similar to K-fold validation. We shuffle each dataset, then repeat the training and evaluation process using all 6 orderings of G train , C train , and C test . Our final results are the average of each evaluation metric over all orderings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head><p>The effects of our transformer on classifier PR-AUC and FPR are shown in <ref type="table" target="#tab_2">Tables 1 and 2</ref> respectively. "Naive NN" is the neural network classifier trained only on unmodified signatures, while "Informed NN" is the neural network classifier trained on both unmodified and modified signatures. Our transformer successfully hinders all tested classifiers on all datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data</head><p>Classifier  <ref type="figure" target="#fig_1">Figures 2, 3</ref>, and 4, the differences between modified Meek and Normal traffic are much less pronounced. One notable traffic signature modification can be seen in <ref type="figure" target="#fig_5">Figure 6</ref>, where the difference in payload lengths between 60 bytes and 70 bytes has been reduced. Modified Meek inter-arrival times, shown in <ref type="figure" target="#fig_6">Figures 7 and 8</ref> are much closer to those of normal traffic, and the frequency of inter-arrival times above 1000 ms has been reduced.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Discussion</head><p>The baseline classification results in <ref type="figure" target="#fig_0">Figures 1 and 2</ref> show that Meek is easily identifiable using machine learning attacks. In every case, our classifiers achieved a near perfect PR-AUC and FPR on unmodified data. <ref type="bibr">Wang</ref>    <ref type="table" target="#tab_2">0  10  20  30  40  50  60  70  80  90  100  200  300  400  500  600  700  800  900  1000  2000  3000  4000  5000  6000  7000  8000  9000</ref>  [20] also achieve impressive classification results. However, this strength can also be a weakness. Machine learning models are prone to overfitting <ref type="bibr" target="#b2">[3]</ref>, making them sensitive to perturbation. For example, over all datasets, the naive neural network achieves a PR-AUC of 1.00 on unmodified data while the informed neural network achieves a PR-AUC of 0.971. However, when classifying modified data, the neural network trained with unmodified data achieves a PR-AUC of 0.309, while the neural network trained using both unmodified and modified data achieves a PR-AUC of 0.440. However, the informed neural network tends to perform poorly in terms of false positive rate compared to the naive neural network. This may be due to catastrophic interference <ref type="bibr" target="#b10">[11]</ref> caused by conflicting information between the unmodified and modified training set. However, because we ignore hostnames, we lose some iden- For example, the meek-azure bridge uses ajax.aspnetcdn.com as the fronting host <ref type="bibr" target="#b23">[23]</ref>. This host typically serves "popular third party JavaScript libraries such as jQuery" <ref type="bibr" target="#b19">[19]</ref>. Traffic that mimics average HTTPS traffic to all domains may appear unusual to an adversary compared to typical traffic through this host. In this work, we assume that an increase in false positive rate is sufficient to make classification of Meek traffic less feasible, but future work may target hosts on CDN used for domain fronting during data collection. Additionally, our dataset lacks geographical diversity. All traffic was generated from the Eastern US, and models generated from this data may not be useful to Meek users in other countries. While the Alexa top 1M dataset <ref type="bibr" target="#b0">[1]</ref> contains websites from around the world, the data collection workers are set to use an English locale, which may result in latency differences compared to requesting the webpages in other languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions</head><p>In this work, we develop a data collection framework capable of efficiently producing reproducible packet captures of Meek and normal HTTPS traffic. We evaluate multiple classification methods over this captured traffic and train classifiers capable of identifying Meek. We then show that our adversarial modification scheme is capable of modifying traffic signatures in a way that reduces average classifier PR-AUC from 0.990 to 0.414 and increases average classifier FPR from 0.183 to 0.834.</p><p>While we focus on Meek and normal HTTPS traffic in this work, our adversarial modification scheme and data collection framework can potentially be applied to any Tor pluggable transport in order to identify and correct for weaknesses. In the future, adversarial models could be applied to shape traffic in real-time in order to improve any obfuscation method that relies on protocol mimicry or tunneling.</p><p>As adversaries performing censorship become more advanced, researchers developing obfuscation methods must become aware of their capabilities. Performing classification and transformation simultaneously using adversarial machine learning can allow researchers to model theoretical capabilities of both the censor and the obfuscator.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Overview of worker program.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Figure 2: Average TCP payload length frequency</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Average inter-arrival time frequency (to client)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Training process for our GAN, adapted from the original figure in [4].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>X rec = T (X ′ ,Y ) T Loss rec = mean(|X − X rec |) 4. Calculate the final loss function for the transformer T Loss = T Loss cls +T Loss src +10T Loss pert +10T loss rec 5. Perform gradient descent over the transformer's weights to minimize T Loss using the Adam optimizer [15].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Average TCP payload length frequency over dataset H</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 8 :</head><label>8</label><figDesc>Figure 7: Average inter-arrival time frequency (from client) over dataset H</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>1 . Retrieve a batch of 16 signatures X and labels Y fromBCE is binary cross-entropy. Y predicted , S predicted = D(X) DLoss cls = BCE(Y,Y predicted ) Dloss src = −mean(S predicted ) 3. Generate 16 random labels Y random 4. Use T to transform X given Y random X ′ = T (X,Y random )S ′ predicted = D(X ′ ) Dloss ′ src = mean(S ′ predicted ) 6. Calculate gradient penalty loss DLoss gp , as defined in [4]. 7. Calculate the final loss function for the discriminator Dloss = DLoss src + Dloss cls + DLoss ′ src + 10DLoss gp 8. Perform gradient descent over the discriminator's weights to minimize DLoss using the Adam opti- mizer</head><label>1</label><figDesc>5. Calculate loss for the discriminator's source prediction over the transformed signatures. Class is ignored here, because the class of traffic does not matter if it is deter- mined to be fake.</figDesc><table>the training set. A label is 0 if the flow is a regular flow, 
and 1 if the flow is Meek. 

2. Predict the flow's label and source, and calculate loss for 
the predictions. </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>and transformed Meek signatures from dataset H (T (H meek )), with a transformer T that has been trained on the entirety of dataset H. Compared to</head><label></label><figDesc></figDesc><table>Baseline 
Modified 
PR-AUC 
PR-AUC 

H 
Naive NN 
0.999 
0.309 
Informed NN 
0.915 
0.583 
Decision Tree 
0.998 
0.476 

U 
Naive NN 
1.000 
0.309 
Informed NN 
0.999 
0.428 
Decision Tree 
1.000 
0.503 

A 
Naive NN 
1.000 
0.309 
Informed NN 
0.999 
0.309 
Decision Tree 
0.999 
0.503 

Avg 
Naive NN 
1.000 
0.309 
Informed NN 
0.971 
0.440 
Decision Tree 
0.999 
0.494 

Table 1: Effect of transformer on PR-AUC 

Figures 6, 7, and 8 compare normal signatures from 
dataset H </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 2 : Effect of transformer on FPR</head><label>2</label><figDesc></figDesc><table></table></figure>

			<note place="foot" n="2">. Calculate the perturbation loss. This measures the mean absolute distance between unmodified and transformed traffic. T Loss pert = mean(|X − X ′ |)</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Availability</head><p>All code used to produce the results in this work including the traffic generation framework, feature extractor, and machine learning code is open source, and can be accessed at https://github.com/starfys/packet_captor_sakura</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Keyword research, competitive analysis, website ranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexa</forename><surname>Internet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Inc</surname></persName>
		</author>
		<ptr target="https://www.alexa.com.Ac-cessed" />
		<imprint>
			<biblScope unit="page" from="2019" to="2024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Adversarial transformation networks: Learning to generate adversarial examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shumeet</forename><surname>Baluja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Fischer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.09387</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Overfitting in neural nets: Backpropagation, conjugate gradient, and early stopping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rich</forename><surname>Caruana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Lawrence</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C Lee</forename><surname>Giles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="402" to="408" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Stargan: Unified generative adversarial networks for multi-domain image-to-image translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunjey</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minje</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Munyoung</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jung-Woo</forename><surname>Ha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sunghun</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaegul</forename><surname>Choo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2018-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The relationship between precision-recall and roc curves</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesse</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Goadrich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd international conference on Machine learning</title>
		<meeting>the 23rd international conference on Machine learning</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="233" to="240" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Tor: The second-generation onion router</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roger</forename><surname>Dingledine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nick</forename><surname>Mathewson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Syverson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th Conference on USENIX Security Symposium</title>
		<meeting>the 13th Conference on USENIX Security Symposium<address><addrLine>Berkeley, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2004" />
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="21" to="21" />
		</imprint>
	</monogr>
	<note>SSYM&apos;04</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Network traffic obfuscation and automated internet censorship</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Dixon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ristenpart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Shrimpton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Security Privacy</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="43" to="53" />
			<date type="published" when="2016-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Analyzing china&apos;s blocking of unpublished tor bridges</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arun</forename><surname>Dunna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillipa</forename><surname>Ciarán O&amp;apos;brien</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">8th {USENIX} Workshop on Free and Open Communications on the Internet ({FOCI} 18)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">pluggable-transports/meek -https transport</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Fifield</surname></persName>
		</author>
		<ptr target="https://gitweb.torproject.org/pluggable-transports/meek.git/commit/?id=cea86c937dc278ba6b2100c238b1d5206bbae2f0" />
		<imprint>
			<biblScope unit="page" from="2019" to="2024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Blocking-resistant communication through domain fronting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Fifield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rod</forename><surname>Hynes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Wegmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vern</forename><surname>Paxson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings on Privacy Enhancing Technologies</title>
		<meeting>on Privacy Enhancing Technologies</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">2015</biblScope>
			<biblScope unit="page" from="46" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Catastrophic forgetting in connectionist networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>French</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends in cognitive sciences</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="128" to="135" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sherjil</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<editor>Z. Ghahramani, M. Welling, C. Cortes, N. D</editor>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Q</forename><surname>Lawrence</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weinberger</surname></persName>
		</author>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2014" />
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="2672" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title/>
		<ptr target="https://www.docker.com/resources/what-container.Ac-cessed" />
	</analytic>
	<monogr>
		<title level="j">Docker Inc. Docker | what is a container</title>
		<imprint>
			<biblScope unit="page" from="2019" to="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Docker compose | docker documentation</title>
		<ptr target="https://docs.docker.com/compose/.Ac-cessed" />
		<imprint>
			<publisher>Docker Inc</publisher>
			<biblScope unit="page" from="2019" to="2026" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Httpos: Sealing information leaks with browser-side obfuscation of encrypted flows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiapu</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">W</forename><surname>Edmond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenke</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">C</forename><surname>Rocky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Perdisci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NDSS</title>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2011" />
			<biblScope unit="volume">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Learning from http/2 encrypted traffic: a machine learning-based analysis tool</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Coelho</forename><surname>Diogo Belarmino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Marques</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Microsoft ajax content delivery network | microsoft docs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Microsoft</surname></persName>
		</author>
		<ptr target="https://docs.microsoft.com/en-us/aspnet/ajax/cdn/overview.Accessed" />
		<imprint>
			<biblScope unit="page" from="2019" to="2026" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Deepcorr: Strong flow correlation attacks on tor using deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milad</forename><surname>Nasr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alireza</forename><surname>Bahramali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amir</forename><surname>Houmansadr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security</title>
		<meeting>the 2018 ACM SIGSAC Conference on Computer and Communications Security</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1962" to="1976" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Bro: a System for Detecting Network Intruders in Real-Time</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vern</forename><surname>Paxson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Networks</title>
		<imprint>
			<biblScope unit="page" from="2435" to="2463" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Scikit-learn: Machine learning in Python</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Dubourg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Vanderplas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Passos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cournapeau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brucher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Perrot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Duchesnay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
				<ptr target="https://trac.torproject.org/projects/tor/wiki/doc/meek.Accessed" />
		<title level="m">Tor Project. doc/meek -tor bug tracker &amp; wiki</title>
		<imprint>
			<biblScope unit="page" from="2019" to="2026" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Tor project: Pluggable transports</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tor</forename><surname>Project</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Aws regions and endpointsamazon web services</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Web</forename><surname>Amazon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Services</surname></persName>
		</author>
		<ptr target="https://docs.aws.amazon.com/general/latest/gr/rande.html.Accessed" />
		<imprint>
			<biblScope unit="page" from="2019" to="2026" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Traffic flow analysis of tor pluggable transports</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Khalid</forename><surname>Shahbar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A Nur Zincir-Heywood</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">11th International Conference on Network and Service Management (CNSM)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="178" to="181" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Network traffic obfuscation: An adversarial machine learning approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ciftcioglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sheatsley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Scott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MILCOM 2018 -2018 IEEE Military Communications Conference (MILCOM)</title>
		<imprint>
			<date type="published" when="2018-10" />
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Seeing through network-protocol obfuscation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><forename type="middle">P</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Akella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Ristenpart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Shrimpton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22Nd ACM SIGSAC Conference on Computer and Communications Security, CCS &apos;15</title>
		<meeting>the 22Nd ACM SIGSAC Conference on Computer and Communications Security, CCS &apos;15<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="57" to="69" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">How china is blocking tor</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Winter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Lindskog</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1204.0447</idno>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Meek-based tor traffic identification with hidden markov model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongjiang</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingguo</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuang</forename><surname>Zou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE 20th International Conference on High Performance Computing and Communications; IEEE 16th International Conference on Smart City; IEEE 4th International Conference on Data Science and Systems (HPCC/SmartCity/DSS)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="335" to="340" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
