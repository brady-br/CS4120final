<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2020-09-29T02:49+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">The Tail at Scale: How to Predict It?</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh</forename><surname>Nguyen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">The University of Texas at Arlington</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongwei</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">The University of Texas at Arlington</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Duan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">The University of Texas at Arlington</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Che</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">The University of Texas at Arlington</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Lei</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">The University of Texas at Arlington</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong</forename><surname>Jiang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">The University of Texas at Arlington</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">The Tail at Scale: How to Predict It?</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Scale-out applications have emerged as the dominant In-ternet services today. A request in a scale-out work-load generally involves task partitioning and merging with barrier synchronization, making it difficult to predict the request tail latency to meet stringent tail Service Level Objectives (SLOs). In this paper, we find that the request tail latency can be faithfully predicted, in the high load region, by a prediction model using only the mean and variance of the task response time as input. The prediction errors for the 99th percentile request latency are found to be consistently within 10% at the load of 90% for both model and measurement-based testing cases. Consequently, the work in this paper establishes an important link between the request tail SLOs and the low order task statistics in a high load region, where the resource provisioning is desired. Finally, we discuss how the prediction model may facilitate highly scalable, tail-constrained resource provisioning for scale-out workloads.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Scale-out, online-data-intensive (OLDI) workloads, such as web searching and social networking, provide userfacing services that involve a large number of servers for parallel processing, while requiring sub-second request responsiveness under high incoming request rates. The system running these workloads usually operates under stringent SLOs, such as imposing a tight tail constraint on high percentile request response time, e.g., 99th or 99.9th-percentile, to satisfy as many user requests as possible <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b16">17]</ref>.</p><p>However, imposing tight tail SLO for OLDI workloads makes resource provisioning in datacenter a challenging task. Due to the lack of good understanding of request tail behaviors, the current practice is to overprovision datacenter resources to meet SLO, at the cost of low resource utilization, e.g., less than 50% CPU and memory utilizations <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b21">22]</ref>. Although resource provisioning proposals with tail SLOs in mind exist, they generally do not incorporate tail SLOs explicitly as design constraints and rely on empirical data to verify whether the design meets tail SLOs or not. For example, the resource provisioning problem is formulated as the minimization of the variance of data flow path latency, as a way to indirectly curtail the tail latency <ref type="bibr" target="#b11">[12]</ref>; the target tail latency SLOs are tracked using online dynamic feedback-loop-control-based schedulers <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b24">25]</ref>; and employing job priority and a rate limiting technique based on the network calculus theory <ref type="bibr" target="#b26">[27]</ref>. The root cause of the status quo is due to the lack of a link between systemlevel request tail SLOs and the subsystem-level task performance requirements. The key difficulty lies in the fact that a scale-out workload may involve task partitioning and merging as well as task queuing. Each request in the request flow with average request rate λ involves tasks to be queued at and processed by up to several thousands of task subsystems in parallel and then all the task results are merged and returned, as depicted in <ref type="figure" target="#fig_1">Fig. 1a</ref>. Here a task subsystem may involve multiple replicated servers for task-level fault tolerance and load balancing, e.g., <ref type="figure" target="#fig_1">Fig. 1b</ref>, where λ r = λ /3 in the case of load balancing. Notable examples are Web search engines <ref type="bibr" target="#b3">[4]</ref> and social networking <ref type="bibr" target="#b19">[20]</ref>. In this case, the request response time is determined by the slowest task <ref type="bibr" target="#b6">[7]</ref>. As the system scales out, the probability that the request response time may hit the tail task latency quickly increases <ref type="bibr" target="#b6">[7]</ref>. To date, no general results are available that can predict the tail request response time at scale. This lack of understanding of request tail behaviors is further exacerbated by the various task scheduling and tail-cutting techniques being used in task processing. In particular, as an effective tail-cutting technique, replicated servers in each subsystem are being used to allow redundant task issues to more than one replicated server to be processed, with the earliest result returned  and rest removed <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b23">24]</ref>. Although some analytic results are available on redundant task issues <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b25">26]</ref>, they either address only a single replicated server subsystem with exponential task service time distribution only <ref type="bibr" target="#b9">[10]</ref> or parallel request load balancing without task partitioning <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b25">26]</ref>. The task partitioning-and-merging part of a scale-out workload generally lies in the critical path for request processing and constitutes a major part of request processing time and hardware cost, e.g., more than two-third of the total processing time and 90% hardware cost for a Web search engine <ref type="bibr" target="#b12">[13]</ref>. Hence, it is of paramount importance to establish a link between the system-level request tail SLOs and the subsystemlevel task performance requirements to facilitate explicitly tail-constrained resource provisioning at scale. This paper aims at tackling the above challenge. It makes the following two major contributions. First, by treating each subsystem as a black box, we find that the tail behavior of a task mapped to a subsystem can be captured by a generalized exponential distribution function in the high load region, which uses the mean and variance of the task response time as input. This black-box solution allows the request distribution function and thus any given request tail SLOs to be explicitly expressed as a function of the means and variances of the individual task response times as the system scales out. Hence, in the case of homogeneous subsystems for parallel task processing, the request tail SLO is only dependent on the mean and variance of the task response time for one task mapped to any given subsystem. Second, we discuss how the proposed request tail prediction mechanism may be used to facilitate highly scalable, explicitly tail-constrained resource provisioning using homogeneous virtual machines (VMs) in a cloud environment.</p><p>The remainder of the paper is organized as follows. Section 2 presents the prediction model, simulation results, and analyses. Section 3 discusses how the proposed model may facilitate tail-constraint resource provisioning. Finally, Section 4 concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Tail Latency Prediction Model</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Basic Ideas</head><p>A system serving scale-out, OLDI workloads commonly involves a large number of task subsystems for parallel processing. The diversity in the actual implementation of subsystems makes it extremely difficult to predict the task performance, let alone the request performance, in general. However, since the ultimate goal of this research is to be able to design request scheduling algorithms that can meet stringent tail SLOs by proof of design, while achieving high resource utilization, we are interested in the peak-load resource provisioning in a high load region, e.g., 90% or higher. In this region, it is possible to predict the task performance for a task mapped to a wide range of subsystems using a simple prediction model, as we now explain. There is a large body of research results in the context of queuing performance in high load regions (e.g., see <ref type="bibr" target="#b22">[23]</ref> and the references therein). In particular, a classic result, known as the central limit theorem for heavy traffic queuing systems <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b14">15]</ref>, states that for a G/G/m (here m is the number of servers) queue under heavy traffic load, the waiting time distribution could be approximated by an exponential distribution. Clearly, this theorem applies to the response time distribution as well, since the response time distribution converges to the waiting time distribution as the traffic load increases. The intuition behind this approximation is that in the high load region, the long queuing effect helps effectively smooth out service time fluctuations (i.e., the law of large numbers), which causes the waiting time or response time to converge to a distribution closely surrounding its mean value, i.e., the short-tailed exponential distribution, regardless of the actual arrival process and service time distribution. Inspired by this result, in this paper, we treat any task subsystem, e.g., the one in <ref type="figure" target="#fig_1">Fig. 1b</ref>, as a black box, given in <ref type="figure" target="#fig_2">Fig. 2</ref>. We further postulate that for a task mapped to a black box subsystem and in the high load region, the task response time distribution F(x) for any arrival process can be approximated as a generalized exponential distribution function <ref type="bibr" target="#b10">[11]</ref>, as follows,</p><formula xml:id="formula_0">E[X], V[X] λ λ</formula><formula xml:id="formula_1">F ge (x) = (1 − e −µx ) α x &gt; 0, 0 otherwise,<label>(1)</label></formula><p>where µ and α are the scale and shape parameter, respectively. The mean and variance of the task response time are given by <ref type="bibr" target="#b10">[11]</ref> E</p><formula xml:id="formula_2">[X] = 1 µ [ψ(α + 1) − ψ(1)],<label>(2)</label></formula><formula xml:id="formula_3">V [X] = 1 µ 2 [ψ ′ (1) − ψ ′ (α + 1)],<label>(3)</label></formula><p>where ψ(.) and its derivatives are the digamma and polygamma functions. From Eqs. <ref type="formula" target="#formula_2">(2)</ref> and <ref type="formula" target="#formula_3">(3)</ref>, it is clear that the distribution in Eq. <ref type="formula" target="#formula_1">(1)</ref> is completely determined by the mean and variance of the task response time. The rationale behind the use of this distribution, instead of the exponential distribution, is that it can capture both heavy-tailed and shorttailed task behaviors depending on the parameter settings and meanwhile, it degenerates to the exponential distribution at α = 1 and E[X] = 1/µ. As we shall see in the following subsection, this distribution significantly outperforms the exponential distribution in terms of tail latency predictive power for all the cases studied.</p><p>The implication of the above black box approximation is significant. It allows not only the task performance of a task mapped to a diverse range of subsystems to be captured by a unified distribution function, but also the request response time distribution and hence the tail SLO for the entire task-partitioning-merging system to be derived. To see why this is the case, one notes that with all the task subsystems in <ref type="figure" target="#fig_1">Fig. 1a</ref> being viewed as black boxes, one effectively transforms the task-partitioning-merging problem into a split-andmerge model <ref type="bibr" target="#b15">[16]</ref> whose distribution function can be expressed as follows, assuming the task response times for tasks mapped to different subsystems are independent random variables,</p><formula xml:id="formula_4">F (N) (x) = ∏ N i=1 (1 − e −µ i x ) α i x &gt; 0, 0 otherwise,<label>(4)</label></formula><p>Now assume that the parallel subsystems are homogeneous, the distribution function can be further simplified as,</p><formula xml:id="formula_5">F (N) (x) = (1 − e −µx ) Nα x &gt; 0, 0 otherwise,<label>(5)</label></formula><p>With Eq. (5), it can be easily shown that the p-th percentile request response time x p can be written as,</p><formula xml:id="formula_6">x p = − 1 µ log 1 − p 100 1 Nα<label>(6)</label></formula><p>Since x p is a function of µ and α, which in turn, are functions of E[X] and V [X] of the task response time (according to Eqs. <ref type="formula" target="#formula_2">(2)</ref> and <ref type="formula" target="#formula_3">(3)</ref>), a link between any given tail SLO in terms of x p and p, and E[X] and V [X] is established. The implication of this result is significant. On one hand, with any given tail SLO, the resulting E <ref type="bibr">[X]</ref> and V [X] can serve as the task response time budgets for highly scalable, distributed task-level resource provisioning. On the other hand, with given measured task response time statistics in terms of E[X] and V [X], whether the system meets the target tail SLO or not can be accurately predicted. In the following two subsections, we test the performance of this prediction model at the subsystem and system levels, separately.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Subsystem Tail Latency Prediction</head><p>In this section, we test the accuracy of the proposed prediction model against a wide range of subsystems including pure model-based subsystems, hybrid measurement-and-model-based subsystems, as well as a pure measurement-based subsystem.</p><p>For pure model-based and hybrid subsystems, we consider a typical subsystem setup given in <ref type="figure" target="#fig_1">Fig. 1b</ref>. It includes a dispatcher and three replicated servers. A task arriving at the subsystem is distributed to server replicas by a dispatcher based on a predetermined policy. Each server replica is modeled as an M/G/1 queuing system. Namely, for all the cases studied, the task arrival process is modeled as a Poisson process, which is considered a good model for scale-out workloads <ref type="bibr" target="#b18">[19]</ref>. Both modelbased and measurement-based service time distribution functions are considered, including the following, -Empirical distribution measured from a Google search test leaf node provided in <ref type="bibr" target="#b17">[18]</ref>, which has a mean service time of 4.22ms, a coefficient of variance (CV) of 1.12, and the largest tail value of 276.6ms;</p><p>-A heavy-tailed truncated Pareto distribution <ref type="bibr" target="#b1">[2]</ref> with the same mean service time, i.e., 4.22ms, and a CV of 1.2, resulting in the corresponding parameters: the shape α = 2.0119, the lower bound L = 2.14ms, and the upper bound H = 276.6ms, which is set at the same maximum value of the empirical distribution above.</p><p>-Weibull distribution <ref type="bibr" target="#b5">[6]</ref> also with the same mean service time and a CV of 1.5, resulting in the corresponding parameters: the shape parameter α = 0.6848 &lt; 1, i.e., a heavy-tailed distribution <ref type="bibr" target="#b5">[6]</ref>, and the scale parameter β = 3.2630.</p><p>We consider two task dispatching policies. The first policy is a popular one, known as the Round-Robin (RR) policy. In this policy, the dispatcher will send tasks to different server replicas in an RR fashion. The second policy is still RR, but it also allows redundant-task issue, a well-known tail-cutting technique <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b23">24]</ref>. This policy allows one or more replications of a task to be sent to different server replicas in the subsystem. The replications may be sent in predetermined intervals to avoid overloading the server replicas. In our experiments, at most one task replication can be issued, provided that the original one does not finish within 10ms, which is around the 95th-percentile of the empirical distribution above. For model-based and hybrid subsystems, the simulated tail task response time is compared against the tail response time predicted by the proposed prediction model, i.e., Eq. (1), which uses the simulated mean and variance of the task response time as input.</p><p>For the pure measurement-based subsystem, we implemented a Solr search engine <ref type="bibr" target="#b0">[1]</ref> subsystem using a cluster of three Amazon EC2 m3.medium instances, each responsible for the same sample shard of the Wikipedia index. The dispatching policy is, again, RR. In this experiment, multiple client threads issue tasks to the servers in a stop-and-wait fashion, i.e., a client sends a task and then waits for the response before sending the next one. The random combination of the task flows from all the clients mimics a random arrival process. We focus on the cases when the number of clients is large enough to put a heavy load on the servers. Without knowing the inner-working of the VMs, we simply treat them as black boxes and the testing is solely based on the measured task response time statistics.</p><p>For the experiments on both pure model-based and hybrid subsystems, <ref type="figure" target="#fig_3">Fig. 3</ref> presents the prediction errors for both the exponential and generalized exponential distributions at the load of 90%. First, we note that the generalized exponential distribution significantly outperforms the exponential distribution for all the cases studied. Second, the prediction errors for the generalized exponential distribution are consistently within 10% across the entire 95-99.9th percentile response time range, even for the RR case without tail cutting. These results confirm our postulation that the generalized exponential distribution function could accurately predict the task tail performance in the high load region. Now we further test the performance of the generalized exponential distribution for the aforementioned measurement-based subsystem. The relative errors of the predicted task tail latencies against the measured ones are given in <ref type="table" target="#tab_0">Table 1</ref>. In this experiment, as the number of clients increases, the aggregate task throughput increases and then levels off as the number of clients reaches 40, indicating that the subsystem is under heavy load condition. As one can see, the prediction errors reduce to less than 10% for all cases as the number of clients reaches 40, consistent with the performance data for the modelbased and hybrid cases. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">System Tail Latency Prediction</head><p>In this section, we evaluate the accuracy of our generalized exponential distribution model as the system scales out. We consider the task-partitioning-merging system in <ref type="figure" target="#fig_1">Fig. 1a</ref> with N = 10, 100, 500, and 1000 nodes for all the previously studied model-based and hybrid subsystems. <ref type="figure">Fig. 4</ref> presents the prediction errors at different load levels for the 99th percentile request response times. Again, for all the cases studied, the errors are within 10% at the load of 90%. Even at the load of 80%, the prediction errors are with 10% and 20% for the cases with and without tail cutting, respectively. As a work in progress, the testing of the proposed prediction model for a complete Solr-based search engine on Amazon EC2 is underway. The above testing results at both subsystem and system levels give us the confidence to expect that the results from this testing case will also be fairly accurate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Facilitating Resource Provisioning</head><p>In this section, we discuss how the above prediction model may be used to facilitate highly scalable, explicitly tail-constrained resource provisioning. For ease of discussion, we use the following example scenario as a guide throughout the discussion. Assume that a content service provider wants to outsource its OLDI scale-out services to a cloud service provider. With a given size of parallel searchable database D (e.g., an entire index as in a Web search engine) and monetary budget C, the content service provider wants to know whether or not the service to be deployed may sustain R requests per second, while meeting the tail SLO, i.e., the p-th-percentile request response time of L ms.</p><p>An ad hoc approach is to immediately deploy the service to a certain scale and at runtime, scale out/up or down the system dynamically in a pay-as-you-go manner to meet the performance targets or monetary budget. Without an initial estimation, however, such approaches run the risk of either over budgeting or failing to meet SLO and/or targeted request throughput performance. Moreover, using the pay-as-you-go service for dynamic resource provisioning is generally much more    <ref type="figure">Figure 4</ref>: The prediction errors for the system composed of both model-based and hybrid subsystems with the Round-Robin (upper three plots) and redundant-task-issue (lower three plots) policies.</p><formula xml:id="formula_7">                                                     d e f d g h i j d k t  l m n o o p  l m n o  q r s q t s u p v  l m n o o p v  l m n o  q r s q t s u p</formula><formula xml:id="formula_8">~ x  y  y                       Empirical, 3-replica, Round-Robin } y      } y y      x y y      } y y y                                   ¡  ¢  £ ¤ ¥ ¦ § ¨ © ¤ ¤ ª ª « ª ¬ ­ ® ¯ ° ± ² ³ ´ µ Truncated Pareto, 3-replica, Round-Robin   ¶ · ¸ ¹ º    ¶ · ¸ ¹ º    ¶ · ¸ ¹ º     ¶ · ¸ ¹ º » ¼ ½ » ¾ ½ » ¿ ½ » À ½ » Á ½ ½ Á ½ À ½ ¿ ½ ¾ ½ ¼ ½ ¼ ½ Â ¼ Ã ½ Ä ½ Å AE Ç È É Ê Ë AE AE Ì Ì Í Ì Î Ï Ð Ñ Ò Ó Ô Õ Ö × Weibull, 3-replica, Round-Robin Á ½ Ø Ù Ú Û Ü Á ½ ½ Ø Ù Ú Û Ü ¼ ½ ½ Ø Ù Ú Û Ü Á ½ ½ ½ Ø Ù Ú Û Ü Ý Þ ß Ý à ß Ý á ß Ý â ß Ý ã ß ß ã ß â ß á ß à ß Þ ß Þ ß ä Þ å ß ae ß ç è é ê ë ì í è è î î ï î ð ñ ò ó ô õ ö ÷ ø ù Empirical, 3-replica, Redundant ã ß ú û ü ý þ ã ß ß ú û ü ý þ Þ ß ß ú û ü ý þ ã ß ß ß ú û ü ý þ ÿ ¢ £ ÿ ¤ £ ÿ ¥ £ ÿ ¦ £ ÿ § £ £ § £ ¦ £ ¥ £ ¤ £ ¢ £ ¢ £ ¨ ¢ © £ £ ¡ ! " # $ % &amp; ' Truncated Pareto, 3-replica, Redundant § £ ( ) 0 1 2 § £ £ ( ) 0 1 2 ¢ £ £ ( ) 0 1 2 § £ £ £ ( )<label>0 1</label></formula><p>expensive than static resource reservation for resource planning <ref type="bibr" target="#b2">[3]</ref>. Given the sheer size of the system to be deployed, it is of paramount importance to develop an offline, highly scalable resource provisioning approach that can provide a quick initial assessment of whether the performance targets and monetary budget can be met or not. The idea of our approach is sketched by the following tail-constrained resource provisioning procedure, in the context of the above example scenario: -For a desired type of VMs with, e.g., given CPU speed, memory size, and pricing model, build a replicated server cluster subsystem in the cloud using m (two to three) VMs by replicating a portion of the total database, i.e., D/N, to all the VM replicas, where N, an integer value, may be selected in such a way that D/N can fit comfortably in the memory in each VM;</p><p>-Measure the mean and variance of task response time in the cluster running a task scheduling policy, at desired task rate λ = R;</p><p>-Find the parameters of the generalized exponential distribution in Eq. (1) by plugging in the measured mean and variance task latency into Eqs. (2) and (3), respectively;</p><p>-Estimate the p-th-percentile request response time x p based on Eq. (6); -Finally, x p is compared against L and the total cost for running N VM clusters with m each is compared against the associated budget C, to see if both the tail SLO and monetary budget are met. If both are met, a feasible tail-constrained resource provisioning is found. Otherwise, the performance targets and/or budget are revised and then rerun the procedure. Note that if x p is found well below L, one may consider reducing N and/or m and see if it is still below L. This iterative testing can help minimize the cost.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusions</head><p>This paper proposed a simple prediction model to predict the tail SLOs for scale-out applications involving taskpartitioning-merging. The required inputs to the prediction model are only the mean and variance of task response time for a task mapped to a subsystem. The experimental results showed that the prediction model yields accurate prediction with errors consistently within 10% at the server loads of 90% or higher, providing a much needed prediction tool to facilitate tail-constrained resource provisioning for scale-out applications.</p><p>This is a work in progress. A full-fledged testing of the proposed prediction model in Amazon EC2 cloud is currently underway.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Acknowledgments</head><p>We would like to thank anonymous reviewers for their helpful comments and suggestions on improving the presentation of the paper.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>(b) A subsystem with one dispatcher and three replicated servers.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The task partitioning and merging model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: A subsystem as a black box.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: The prediction errors for both model-based and hybrid subsystems with the Round-Robin (RR) and redundant-task-issue policies.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="true"><head>Table 1 : The prediction errors for the measurement-based subsystem.</head><label>1</label><figDesc></figDesc><table>Percentiles 
#clients 
95th 
99th 99.9th 
20 
-11.305 7.911 24.216 
30 
-3.233 5.295 13.429 
40 
-1.718 5.452 2.974 
50 
0.703 
2.015 -1.381 

</table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Solr</surname></persName>
		</author>
		<ptr target="http://lucene.apache.org/solr/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Parameter Estimation for the Truncated Pareto Distribution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aban</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">B</forename><surname>Meerschaert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Panorska</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="page" from="270" to="277" />
			<date type="published" when="2006-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The Datacenter as a Computer: An Introduction to the Design of Warehouse-Scale Machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barroso</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Clidaras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>And H ¨ Olzle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Synthesis Lectures on Computer Architecture</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="154" />
			<date type="published" when="2013-07" />
		</imprint>
	</monogr>
	<note>Second edition</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Web Search for a Planet: The Google Cluster Architecture</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barroso</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>And H ¨ Olzle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Micro</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="22" to="28" />
			<date type="published" when="2003-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The Case for Energyproportional Computing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barroso</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Olzle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="33" to="37" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Queueing Networks and Markov Chains: Modeling and Performance Evaluation with Computer Science Applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bolch</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Greiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>De Meer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trivedi</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">S</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>WileyInterscience</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dean</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barroso</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Tail at Scale. Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page" from="74" to="80" />
			<date type="published" when="2013-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Quasar: resourceefficient and QoS-aware cluster management</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Delimitrou</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kozyrakis</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGARCH Computer Architecture News</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="127" to="144" />
			<date type="published" when="2014-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Jockey : Guaranteed Job Latency in Data Parallel Clusters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ferguson</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">D</forename><surname>Bodik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Boutin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fonseca</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">7th ACM European Conference on Computer Systems</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="99" to="112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Reducing Latency via Redundant Requests: Exact Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gardner</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zbarsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Doroudi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Harchol-Balter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hyyti¨ahyyti¨ Hyyti¨a</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scheller-Wolf</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGMETRICS/international conference on Measurement and modeling of computer systems -SIGMETRICS &apos;15</title>
		<meeting>the ACM SIGMETRICS/international conference on Measurement and modeling of computer systems -SIGMETRICS &apos;15</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Generalized exponential distributions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gupta</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">D</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kundu</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Australian &amp; New Zealand Journal of Statistics</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="173" to="188" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Speeding Up Distributed RequestResponse Workflows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jalaparti</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Bodik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kandula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Menache</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Ry-Balkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGCOMM 2013 Conference on SIGCOMM</title>
		<meeting>the ACM SIGCOMM 2013 Conference on SIGCOMM<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="219" to="230" />
		</imprint>
	</monogr>
	<note>SIGCOMM &apos;13, ACM</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Predictive Parallelization: Taming Tail Latencies in Web Search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeon</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-W</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Elnikety</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rixner</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th international ACM SIGIR conference on Research and development in information retrieval -SIGIR &apos;14</title>
		<meeting>the 35th international ACM SIGIR conference on Research and development in information retrieval -SIGIR &apos;14</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="253" to="262" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The single server queue in heavy traffic</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kingman</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F C</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Atiyah</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">F</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the Cambridge Philosophical Society</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page" from="902" to="904" />
			<date type="published" when="1961" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Heavy Traffic Theory for Queues with</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K ¨ Ollerstr¨omollerstr¨</forename><surname>Ollerstr¨om</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Several Servers. I. Journal of Applied Probability</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="544" to="552" />
			<date type="published" when="1974" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Response Time Approximations in Fork-Join Queues</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lebrecht</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Knottenbelt</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">23rd Annual UK Performance Engineering Workshop</title>
		<imprint>
			<publisher>UKPEW</publisher>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Towards energy proportionality for largescale latency-critical workloads</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">O</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Govindaraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Barroso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kozyrakis</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename></persName>
		</author>
		<idno>ISCA &apos;14</idno>
	</analytic>
	<monogr>
		<title level="m">Proceeding of the 41st Annual International Symposium on Computer Architecuture (Piscataway</title>
		<meeting>eeding of the 41st Annual International Symposium on Computer Architecuture (Piscataway<address><addrLine>NJ, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Press</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="301" to="312" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">BigHouse: A simulation infrastructure for data center systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meisner</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Junjie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenisch</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">F</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Performance Analysis of Systems and Software (ISPASS)</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="35" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Power Management of Online DataIntensive Services</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meisner</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sadler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">M</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andre</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">B</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-D</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenisch</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">F</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th annual International Symposium on Computer Architecture</title>
		<meeting>the 38th annual International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="319" to="330" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Scaling Memcache at Facebook</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nishtala</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fugal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Grimm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">C</forename><surname>Mcelroy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Paleczny</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Peek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Saab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Stafford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Venkatara-Mani</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th USENIX conference on Networked Systems Design and Implementation -NSDI&apos;13</title>
		<meeting>the 10th USENIX conference on Networked Systems Design and Implementation -NSDI&apos;13</meeting>
		<imprint>
			<date type="published" when="2013-04" />
			<biblScope unit="page" from="385" to="398" />
		</imprint>
	</monogr>
	<note>USENIX Association</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Evaluating the Effectiveness of Replication for Tail-Tolerance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiu</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Perez</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">15th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015-05" />
			<biblScope unit="page" from="443" to="452" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Heterogeneity and dynamicity of clouds at scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reiss</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Tumanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ganger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">R</forename><surname>Katz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">H</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kozuch</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third ACM Symposium on Cloud Computing -SoCC &apos;12</title>
		<meeting>the Third ACM Symposium on Cloud Computing -SoCC &apos;12</meeting>
		<imprint>
			<date type="published" when="2012-10" />
			<biblScope unit="page" from="1" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Mathematical Modeling in Heavy Traffic Queuing Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sani</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daman</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Journal of Operations Research</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="340" to="350" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Low Latency via Redundancy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vulimiri</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sherry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Berkeley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><forename type="middle">C</forename><surname>Godfrey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">B</forename><surname>Ratnasamy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shenker</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CoNEXT&apos;13</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="283" to="294" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Cake: Enabling High-level SLOs on Shared Storage Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Venkataraman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Alspaugh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Katz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stoica</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third ACM Symposium on Cloud Computing -SoCC&apos;12</title>
		<meeting>the Third ACM Symposium on Cloud Computing -SoCC&apos;12</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Efficient Task Replication for Fast Response Times in Parallel Computation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wornell</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1404.1328</idno>
		<imprint>
			<date type="published" when="2014-04" />
			<biblScope unit="page" from="1" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">PriorityMeister: Tail Latency QoS for Shared Networked Storage</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhu</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tumanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kozuch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Harchol-Balter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ganger</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">R</forename></persName>
		</author>
		<imprint>
			<biblScope unit="page" from="1" to="14" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
