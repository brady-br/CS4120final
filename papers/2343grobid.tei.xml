<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2020-09-29T02:35+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">This paper is included in the Proceedings of the 12th USENIX Conference on File and Storage Technologies (FAST &apos;14). Open access to the Proceedings of the 12th USENIX Conference on File and Storage Technologies (FAST &apos;14) is sponsored by Balancing Fairness and Efficiency in Tiered Storage Systems with Bottleneck-Aware Allocation Balancing Fairness and Efficiency in Tiered Storage Systems with Bottleneck-Aware Allocation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>February 17-20, 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Rice University</orgName>
								<orgName type="institution" key="instit2">Rice University</orgName>
								<orgName type="institution" key="instit3">Rice University</orgName>
								<address>
									<settlement>Santa Clara</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Varman</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Rice University</orgName>
								<orgName type="institution" key="instit2">Rice University</orgName>
								<orgName type="institution" key="instit3">Rice University</orgName>
								<address>
									<settlement>Santa Clara</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Rice University</orgName>
								<orgName type="institution" key="instit2">Rice University</orgName>
								<orgName type="institution" key="instit3">Rice University</orgName>
								<address>
									<settlement>Santa Clara</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Varman</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Rice University</orgName>
								<orgName type="institution" key="instit2">Rice University</orgName>
								<orgName type="institution" key="instit3">Rice University</orgName>
								<address>
									<settlement>Santa Clara</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">This paper is included in the Proceedings of the 12th USENIX Conference on File and Storage Technologies (FAST &apos;14). Open access to the Proceedings of the 12th USENIX Conference on File and Storage Technologies (FAST &apos;14) is sponsored by Balancing Fairness and Efficiency in Tiered Storage Systems with Bottleneck-Aware Allocation Balancing Fairness and Efficiency in Tiered Storage Systems with Bottleneck-Aware Allocation</title>
					</analytic>
					<monogr>
						<title level="m">USENIX Association 12th USENIX Conference on File and Storage Technologies</title>
						<imprint>
							<biblScope unit="page">229</biblScope>
							<date type="published">February 17-20, 2014</date>
						</imprint>
					</monogr>
					<note>https://www.usenix.org/conference/fast14/technical-sessions/presentation/wang</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Multi-tiered storage made up of heterogeneous devices are raising new challenges in allocating throughput fairly among concurrent clients. The fundamental problem is finding an appropriate balance between fairness to the clients and maximizing system utilization. In this paper we cast the problem within the broader framework of fair allocation for multiple resources. We present a new allocation model BAA based on the notion of per-device bottleneck sets. Clients bottlenecked on the same device receive throughputs in proportion to their fair shares, while allocation ratios between clients in different bottleneck sets are chosen to maximize system utilization. We show formally that BAA satisfies fairness properties of Envy Freedom and Sharing Incentive. We evaluated the performance of our method using both simulation and implementation on a Linux platform. The experimental results show that our method can provide both high efficiency and fairness.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The growing popularity of virtualized data centers hosted on shared physical resources has raised the importance of resource allocation issues in such environments. In addition, the widespread adoption of multi-tiered storage systems <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3]</ref>, made up of solid-state drives (SSDs) and traditional hard disks (HDs), has made the already challenging problem of providing QoS and fair resource allocation considerably more difficult.</p><p>Multi-tiered storage has several advantages over traditional flat storage in the data center: improved performance for data access and potential operating cost reductions. However, this architecture also raises many challenges for providing performance isolation and QoS guarantees. The large speed gap between SSDs and HDs means that it is not viable to simply treat the storage system as a black box with a certain aggregate IOPS capacity. The system throughput is intrinsically linked to the relative frequencies with which applications access the different types of devices. In addition, the throughput depends on how the device capacities are actually divvied up among the applications. System efficiency is a major concern for data center operators since consolidation ratios are intimately connected to their competitive advantage. The operator also needs to ensure fairness, so that the increased system utilization is not obtained at the cost of treating some users unfairly.</p><p>This brings to focus a fundamental tension between fairness and resource utilization in a system with heterogeneous resources. Maintaining high overall system utilization may require favoring some clients disproportionately while starving some others, thereby compromising fairness. Conversely, allocations based on a rigid notion of fairness can result in reduced system utilization as some clients are unnecessarily throttled to maintain parity in client allocations.</p><p>The most-widely used concept of fairness is proportional sharing (PS), which provides allocations to clients in proportion to client-specific weights reflecting their priority or importance. Adaptations of the classic algorithms for network bandwidth multiplexing <ref type="bibr" target="#b48">[49,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b39">40]</ref> have been proposed for providing proportional fairness for storage systems <ref type="bibr" target="#b47">[48,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b20">21]</ref>. Extended proportionalshare schedulers which provide reservations and limit guarantees in addition to proportional allocation have also been proposed for storage systems <ref type="bibr" target="#b45">[46,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b22">23]</ref>. However, the vast majority of resource allocation schemes have been designed to multiplex a single resource, and have no natural extension to divide up multiple resources.</p><p>The question of fair division of multiple resources in computer systems was raised in a fundamental paper by Ghodsi et al <ref type="bibr" target="#b16">[17]</ref>, who advocated a model called Dominant Resource Fairness (DRF) to guide the allocation (see <ref type="bibr">Section 2)</ref>. A number of related allocation approaches <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b37">38]</ref> have since been proposed; these will be discussed in Section 6. These models deal mainly with defining the meaning of fairness in a multi-resource context. For example, DRF and its extensions consider fairness in terms of a client's dominant resource: the resource most heavily used (as a fraction of its capacity) by a client. The DRF policy is to equalize the shares of each client's dominant resource. In <ref type="bibr" target="#b11">[12]</ref>, fairness is defined in terms of proportional sharing of the empirically-measured global system bottleneck. A theoretical framework called Bottleneck-based fairness <ref type="bibr" target="#b10">[11]</ref> proves constructively the existence of an allocation giving each client its entitlement on some global system-wide bottleneck resource. While these models and algorithms make significant advances to the problem of defining multi-resource fairness, they do not deal with the dual problem of their effect on system utilization. In general these solutions tend to over constrain the system with fairness requirements, resulting in allocations with low system utilization.</p><p>In this paper we propose a model called Bottleneck Aware Allocation (BAA) based on the notion of local bottleneck sets. We present a new allocation policy to maximize system utilization while providing fairness in the allocations of the competing clients. The allocations of BAA enjoy all of the fairness properties of DRF <ref type="bibr" target="#b16">[17]</ref>, like Sharing Incentive, Envy Freedom <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b5">6]</ref>, and Pareto Optimality. However, within this space of "fair" solutions that includes DRF, it searches for alternative solutions with higher system efficiency. We prove formally that BAA satisfies these fairness properties. We use BAA as part of a two-tier allocate and schedule mechanism: one module uses a standard weighted fairscheduler to dispatch requests to the storage system; the other module monitors the workload characteristics and dynamically recomputes the weights using BAA for use by the dispatcher, based on the mix of workloads and their access characteristics. We evaluate the performance of our method using simulation and a Linux platform. The results show that our method can provide both high efficiency and fairness for heterogeneous storage and dynamic workloads.</p><p>The rest of the paper is organized as follows. In Section 2 we discuss the difficulties of achieving both fairness and efficiency in a heterogeneous storage system. In Section 3 we describe our model and approach to balance needs of fairness and system efficiency. Formal proofs are presented in Section 4. We present some empirical results in Section 5. Related work is summarized in Section 6, and we conclude in Section 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Overview</head><p>The storage system is composed of SSDs and HD arrays, as shown in <ref type="figure" target="#fig_0">Figure 1</ref>. SSDs and HDs are independent A client makes a sequence of IO requests; the target of each request is either the SSD or the HD, and is known to the scheduler. An access to the SSD is referred to as a hit and access to the HD is a miss. The hit (miss) ratio of client i is the fraction of its IO requests to the SSD (HD), and is denoted by h i (respectively m i ). The hit ratio of different applications will generally be different. It may also change in different application phases, but is assumed to be relatively stable within an application phase.</p><p>The requests of different clients are held in clientspecific queues from where they are dispatched to the storage array by an IO scheduler. The storage array keeps a fixed number of outstanding requests in its internal queues to maximize its internal concurrency. The IO scheduler is aware of the target device (SSD or HD) of a request. Its central component is a module to dynamically assign weights to clients based on the measured miss ratios. These weights are used by the dispatcher to choose the order of requests to send to the array; the number of serviced requests of a client is in proportion to its weight. The weights are computed in accordance with the fairness policies of BAA so as to maximize system utilization based on recently measured miss ratios.</p><p>We illustrate the difficulties in achieving these goals in the next section, followed by a description of our approach in Section 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Motivating Examples</head><p>In traditional proportional fairness a single resource is divided among multiple clients in the ratio of their assigned weights. For instance, if a single disk of 100 IOPS capacity is shared among two backlogged clients of equal weight, then each client will receive 50 IOPS. A work-conserving scheduler like Weighted Fair Queuing <ref type="bibr" target="#b8">[9]</ref> will provide fine-grained, weight-proportional bandwidth allocation to the backlogged clients; the system will be 100% utilized as long as there are requests in the system. When the IOs are from heterogeneous devices like HDs and SSDs, the situation is considerably more complicated. The device load is determined by both the allocation ratios (the relative fraction of the bandwidth assigned to clients), as well as their hit ratios. If the clients with high SSD loads have small allocation ratio, there may be insufficient requests to keep the SSD busy. Conversely, maintaining high utilization of both the HD and the SSD may require adjusting the allocations in a way that starves some clients, resulting in unfairness in the allocation.</p><p>Example I Suppose the HD and SSD have capacities of 100 IOPS and 500 IOPS respectively. The system is shared by backlogged clients 1 and 2 with equal weights and hit ratios of h 1 = 0.5 and h 2 = 0.9 respectively. Under proportional-share allocation, both clients should get an equal number of IOPS. The unique allocation in this case is for each client to get 166.6 IOPS. Client 1 will get 83.3 IOPS from each device, while client 2 will get 16.6 IOPS from the HD and 150 IOPS from the SSD. The HD has 100% utilization but the SSD is only 47% utilized <ref type="figure" target="#fig_2">(Figure 2(a)</ref>). In order to increase the system utilization, the relative allocation of the clients needs to be changed <ref type="figure" target="#fig_2">(Figure 2(b)</ref>). In fact, both devices can be fully utilized if the scheduler allocates 100 IOPS to client 1 (50 IOPS from the HD and 50 from the SSD), and 500 IOPS to client 2 (50 from the HD and 450 from the SSD). This is again the unique allocation that maximizes the system utilization for the given set of hit ratios. Note that increasing the utilization to 100% requires a 1 : 5 allocation ratio, and reduces client 1's throughput from 167 to 100 IOPS while increasing client 2's throughput from 167 to 500 IOPS.</p><p>The example above illustrates a general principle. For a given set of workload hit ratios, it is not possible to precisely dictate both the relative allocations (fairness) and the system utilization (efficiency). How then should we define the allocations to both provide fairness and achieve good system utilization?</p><p>Consider next how the DRF policy will allocate the bandwidth. The dominant resource for client 1 is the HD; for client 2 it is the SSD. Suppose DRF allocates n IOPS to client 1 and m IOPS to client 2. Equalizing the dominant shares means that 0.5n/100 = 0.9m/500 or n : m = 9 : 25. This results in an SSD utilization of approximately 77% <ref type="figure" target="#fig_2">(Figure 2(c)</ref>). The point to be noted is that none of these earlier approaches considers the issue of resource efficiency when deciding on an allocation. The policies deal with the question of how to set client allocation ratios to achieve some measure of fairness, but do not address how the choice affects system utilization.</p><p>Example II In the example above suppose we add a third backlogged client, also with hit ratio 0.5. In this case, proportional sharing in a 1 : 1 : 1 ratio would result in al-  locations of 90.9 IOPS each; the client with hit ratio 0.9 would be severely throttled by the allocation ratio, and the SSD utilization will be only 34.5%. If the weights were changed to 1 : 1 : 10 instead, then the HD-bound clients (hit ratio 0.5) would receive 50 IOPS each, and the SSD-bound client (hit ratio 0.9) would receive 500 IOPS. The utilization of both devices is 100%. The DRF policy will result in an allocation ratio of 9 : 9 : 25, allocations of 78, 78 and 217 IOPS respectively, and SSD utilization of 55% (further reduced from the 77% of example 1). This shows that the system utilization is highly dependent on the competing workloads, and stresses how relative allocations (fairness) and system utilization (efficiency) are intertwined.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Fairness and Efficiency in Multi-tiered Storage</head><p>As discussed in the previous section, the ratio of allocation and the system utilization cannot be independently controlled. In <ref type="bibr" target="#b16">[17]</ref>, DRF allocations are shown to possess desirable fairness properties, namely:</p><p>• Sharing Incentive: Each client gets at least the throughput it would get from statically partitioning each resource equally among the clients <ref type="bibr" target="#b0">1</ref> . This throughput will be referred to as the fair share of the client. In this paper we will use fair share defined by equal partition of the resources 2 .</p><p>• Envy-Freedom: A client cannot increase its throughput by swapping its allocation with any other client. That is, clients prefer their own allocation over the allocation of any other client.</p><p>• Pareto Efficiency: A client's throughput cannot be increased without decreasing another's throughput.</p><p>We propose a bottleneck-aware allocation policy (BAA), to provide both fairness and high efficiency in multi-tiered storage systems. BAA will preserve the desirable fairness features listed above. However, we add a fundamentally new requirement, namely maximizing the system utilization.</p><p>The clients are partitioned into bottleneck sets depending on the device on which they have a higher load. This is a local property of a client and does not depend on the system bottleneck as in <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12]</ref>.</p><p>In our model, clients in the same bottleneck set will receive allocations that are in the ratio of their fair share. However, there is no predefined ratio between the allocations of clients in different bottleneck sets. Instead, the</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Allocation Model</head><p>We begin by precisely defining several terms used in the model. The capacity of a device is defined as its throughput (IOPS) when continually busy. As is usually the case, this definition abstracts the fine-grained variations in access times of different types of requests (read or write, sequential or random etc), and uses a representative (e.g. random 4KB reads) or average IOPS number to characterize the device. Denote the capacity (in IOPS) of the disk as C d and that of the SSD as C s .</p><p>Consider a client i that is receiving a total throughput of T IOPS. This implies it is receiving T × h i IOPS from the SSD. The fraction of the capacity of the SSD that it uses is (T × h i )/C s . Similarly, the fraction of the capacity of the HD that it uses is (T × m i )/C d . </p><formula xml:id="formula_0">bal = C s /(C s + C d ).</formula><p>A workload with hit ratio equal to h bal will have equal load on both devices. If the hit ratio of a client is less than or equal to h bal it is said to be bottlenecked on the HD; if the hit ratio is higher than h bal it is bottlenecked on the SSD. 3. Partition the clients into two sets D and S based on their hit ratios. D = {i : h i ≤ h bal } and S = {i : h i &gt; h bal } are the sets of clients that are bottlenecked on the HD and SSD respectively. 4. Define the fair share of a client to be the throughput (IOPS) it gets if each of the resources are partitioned equally among all the clients. Denote the fair share of client i by f i . 5. Let A i denote the allocation of (total IOPS done by) client i under some resource partitioning. The total throughput of the system is ∑ i A i .</p><p>Example III Consider a system with C d = 200 IOPS, C s = 1000 IOPS and four clients p, q, r, s with hit ratios h p = 0.75, h q = 0.5, h r = 0.90, h s = 0.95. In this case, h bal = 1000/1200 = 0.83. Hence, p and q are bottlenecked on the HD, while r and s are bottlenecked on the SSD: D = {p, q} and S = {r, s}.</p><p>Suppose the resources are divided equally among the clients, so that each client sees a virtual disk of 50 IOPS and a virtual SSD of 250 IOPS. What are the throughputs of the clients with this static resource partitioning?</p><p>Since p and q are HD-bottlenecked, they would use their entire HD allocation of 50 IOPS, and an additional amount on the SSD depending on the hit ratios. Since p's hit ratio is 3/4, it would get 150 IOPS on the SSD for a total of 200 IOPS, while q (h q = 0.5) would get 50 SSD IOPS for a total of 100 IOPS. Thus the fair shares of p and q are 200 and 100 IOPS respectively. In a similar manner, r and s would completely use their SSD allocation of 250 IOPS and an additional amount on the disk. The fair shares of r and s in this example are 277.8 and 263.2 IOPS respectively.</p><p>Our fairness policy is specified by the rules below. The rules <ref type="formula" target="#formula_11">(1)</ref> and <ref type="formula" target="#formula_12">(2)</ref> state that the allocations between any two clients that are bottlenecked on the same device are in proportion to their fair share. Condition (3) states that clients backlogged on different devices should be envy free. The condition asserts that if client A receives a higher throughput on some device than client B it must get an equal or lesser throughput on the other. We will show in Section 4 that with just rules (1) and (2), the envy-free property is satisfied between any pair of clients that belong both in D or both in S. However, envy-freedom between clients in different sets is explicitly enforced by the third constraint.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fairness Policy</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Fairness between clients in D:</head><p>∀i</p><formula xml:id="formula_1">, j ∈ D, A i A j = f i f j . Define ρ d = A i f i</formula><p>to be the ratio of the allocation of client i to its fair share, i ∈ D.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Fairness between clients in S:</head><p>∀i, j ∈ S, A i A j</p><formula xml:id="formula_2">= f i f j . Define ρ s = A j f j</formula><p>to be the ratio of the allocation of client j to its fair share, j ∈ S.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Fairness between a client in D and a client in S:</head><p>∀i ∈ D, j ∈ S: </p><formula xml:id="formula_3">h</formula><formula xml:id="formula_4">i h r /h p = 1.2 ≥ A p /A r ≥ m r /m p = 0.4 ii h s /h p = 1.27 ≥ A p /A s ≥ m s /m p = 0.2 iii h r /h q = 1.8 ≥ A q /A r ≥ m r /m q = 0.2 iv h s /h q = 1.9 ≥ A q /A s ≥ m s /m q = 0.1</formula><p>These linear constraints will be included in a linear programming optimization model in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Optimization Model Formulation</head><p>The aim of the resource allocator is to find a suitable allocation A i for each of the clients. The allocator will maximize the system utilization while satisfying the fairness constraints described in Section 3.1, together with constraints based on the capacity of the HD and the SSD. A direct linear programming (LP) formulation will result in an optimization problem with n unknowns representing the allocations of the n clients, and O(n 2 ) constraints specifying the rules of the fairness policy.</p><p>The search space can be drastically reduced using the auxiliary variables ρ d and ρ s (called amplification factors) defined in Section 3.1. Rules 1 and 2 require that</p><formula xml:id="formula_5">A i = ρ d f i and A j = ρ s f j , for clients i ∈ D and j ∈ S.</formula><p>We now formulate the objective function and constraints in terms of the auxiliary quantities ρ d and ρ s . The total allocation is:</p><formula xml:id="formula_6">∑ ∀k A k = ( ∑ i∈D A i + ∑ j∈S A j ) = (ρ d ∑ i∈D f i + ρ s ∑ j∈S f j ).</formula><p>The total number of IOPS made to the HD is:</p><formula xml:id="formula_7">ρ d ∑ i∈D f i m i + ρ s ∑ j∈S f j m j .</formula><p>The total number of IOPS made to the SSD is:</p><formula xml:id="formula_8">ρ d ∑ i∈D f i h i + ρ s ∑ j∈S f j h j .</formula><p>Fairness rule 3 states that:</p><formula xml:id="formula_9">∀i ∈ D, j ∈ S, h j h i ≥ ρ d f i ρ s f j ≥ m j m i h j f j h i f i ≥ ρ d ρ s ≥ m j f j m i f i . β ≥ ρ d ρ s ≥ α.</formula><p>where</p><formula xml:id="formula_10">α = max i, j 񮽙 m j f j m i f i 񮽙 β = min i, j 񮽙 h j f j h i f i 񮽙</formula><p>The final problem formulation is shown below. It is expressed as a 2-variable linear program with unknowns ρ d and ρ s , and four linear constraints between them. Equations 2 and 3 ensure that the total throughputs from the HD and the SSD respectively do not exceed their capacities. Equation 4 ensures that any pair of clients, which are bottlenecked on the HD and SSD respectively, are envy free. As mentioned earlier, we will show that clients which are bottlenecked on the same device will automatically be envy free.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Optimization for Allocation</head><p>Maximize</p><formula xml:id="formula_11">ρ d ∑ i∈D f i + ρ s ∑ j∈S f j<label>(1)</label></formula><p>subject to: </p><formula xml:id="formula_12">ρ d ∑ i∈D f i m i + ρ s ∑ j∈S f j m j ≤ C d<label>(2)</label></formula><formula xml:id="formula_13">ρ d ∑ i∈D f i h i + ρ s ∑ j∈S f j h j ≤ C s<label>(3)</label></formula><formula xml:id="formula_14">β ≥ ρ d ρ s ≥ α<label>(4</label></formula><formula xml:id="formula_15">Maximize : 300ρ d + 541ρ s<label>(5)</label></formula><p>subject to:</p><formula xml:id="formula_16">100ρ d + 41ρ s ≤ 200 (6) 200ρ d + 500ρ s ≤ 1000 (7) 1.67 ≥ ρ d ρ s ≥ 0.55<label>(8)</label></formula><p>Solving the linear program gives ρ d = 1.41, ρ s = 1.44, which result in allocations A p = 282.5, A q = 141.3, A r = 398.6, A s = 377.6, and HD and SSD utilizations of 100% and 100%.</p><p>We end the section by stating precisely the properties of BAA with respect to fairness and utilization. The properties are proved in Section 4.</p><p>• P1: Clients in the same bottleneck set receive allocations proportional to their fair shares.</p><p>• P2: Any pair of clients bottlenecked on the same device will not envy each other. Combined with fairness policy (3) which enforces envy freedom between clients bottlenecked on different devices, we can assert that the allocations are envy free.</p><p>• P3: Every client will receive at least its fair share. In other words, no client receives less throughput than it would if the resources had been hardpartitioned equally among them. Usually, clients will receive more than their fair share by using capacity on the other device that would be otherwise unused.</p><p>• P4: The allocation maximizes the system throughput subject to these fairness criteria.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Scheduling Framework</head><p>The LP described in Section 3.2 calculates the throughput that each client is allocated based on the mix of hit ratios and the system capacities. The ratios of these allocations make up the weights to a proportional-share scheduler like WFQ <ref type="bibr" target="#b8">[9]</ref>, which dispatches requests from the client queues. When a new client enters or leaves the system, the allocations (i.e. the weights to the proportional scheduler) need to be updated. Similarly, if a change in a workload's characteristics results in a significant change in its hit ratio, the allocations should be recomputed to prevent the system utilization from falling too low. Hence, periodically (or triggered by an alarm based on device utilizations) the allocation algorithm is invoked to compute the new set of weights for the proportional scheduler. We also include a module to monitor the hit ratios of the clients over a moving window of requests. The hit ratio statistics are used by the allocation algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1: Bottleneck-Aware Scheduling</head><p>Step 1. For each client maintain statistics of its hit ratio over a configurable request-window W.</p><p>Step 2. Periodically invoke the BAA optimizer of Section 3.2 to compute the allocation of each client that maximizes utilization subject to fairness constraints.</p><p>Step 3. Use the allocations computed in Step 2 as relative weights to a proportional-share scheduler that dispatches requests to the array in the ratio of their weights.</p><p>The allocation algorithm is relatively fast since it requires solving only a small 2-variable LP problem, so it can be run quite frequently. Nonetheless, it would be desirable to have a single-level scheme in which the be desirable to have a single-level scheme in which the scheduler continually adapts to the workload characteristics rather than at discrete steps. In future work we will investigate the possibility of such a single-level scheme.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Formal Results</head><p>In this section we formally establish the fairness claims of BAA. The two main properties are summarized in Lemma 3 and Lemma 7, which state that the allocations made by BAA are envy free (EF) and satisfy the sharing incentive (SI) property.  <ref type="table" target="#tab_1">Table 1</ref>: List of Symbols Lemma 1 finds expressions for fair shares. The fair share of a client is its throughput if it is given a virtual HD of capacity C d /n and a virtual SSD of capacity C s /n. A client in D will use all the capacity of the virtual HD, and hence have a fair share of C d /(n × m i ). A client in S uses all the capacity of the virtual SSD, and its fair share is C s /(n × h i ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Lemma 1. Let n be the number of clients. Then f i</head><formula xml:id="formula_17">= min{C d /(n × m i ),C s /(n × h i )}. If i ∈ D, then f i = C d /(n × m i ); else if i ∈ S, then f i = C s /(n × h i ).</formula><p>Proof. The fair share is the total throughput when a client uses one of its virtual resources completely. For</p><formula xml:id="formula_18">i ∈ D, h i ≤ h bal = C s /(C s + C d ) and m i ≥ 1 − h bal = C d /(C s + C d ). In this case, C d /(n × m i ) ≤ (C s + C d )/n and C s /(n × h i ) ≥ (C s + C d )/n.</formula><p>Hence, the first term is the smaller one, whence the result follows. A similar argument holds for i ∈ S.</p><p>Lemma 2 states a basic property of BAA allocations: all clients in a bottleneck set receive equal throughputs on the device on which they are bottlenecked. This is simply a consequence of fairness policy which requires that clients in the same bottleneck set receive throughput in the ratio of their fair shares.</p><p>Lemma 2. All clients in a bottleneck set receive equal throughputs on the bottleneck device. Specifically, all clients in D receive ρ d C d /n IOPS from the HD; and all clients in S receive ρ s C s /n IOPS from the SSD.</p><p>Proof. Let i ∈ D. From fairness policy (1) and lemma 1,</p><formula xml:id="formula_19">A i = ρ d f i = ρ d (C d /(n × m i )).</formula><p>The number of IOPS from the HD is therefore A i m i = ρ d C d /n. Similarly, for i ∈ S, A i = ρ s f i = ρ s (C s /(n × h i )), and the number of IOPS from the SSD is A i h i = ρ s C s /n.</p><p>To prove EF between two clients, we need to show that no client receives more throughput on both the resources (HD and SSD). If the two clients are in the same bottleneck set then this follows from Lemma 2, which states that both clients will get equal throughputs on their bottleneck device. When the clients are in different bottleneck sets then the condition is explicitly enforced by fairness policy (3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Lemma 3. For any pair of client i, j the allocations made by BAA are envy free.</head><p>Proof. From lemma 2, if i, j ∈ D both clients have the same number of IOPS on the HD; hence neither can improve its throughput by getting the others allocation. Similarly, if i, j ∈ S they do not envy each other, since nether can increases its throughput by receiving the others allocation.</p><p>Finally, we consider the case when i ∈ D and j ∈ S. From fairness policy (3), ∀i ∈ D, j ∈ S:</p><formula xml:id="formula_20">h j h i ≥ A i A j ≥ m j m i .</formula><p>Hence, the allocations on the SSD for clients i and j satisfy A i h i ≤ A j h j , and the allocations on HD for clients i and j satisfy A i m i ≥ A j m j . So any two flows in different bottleneck sets will not envy each other. Hence neither i nor j can get more than the other on both devices.</p><p>The following Lemma shows the Sharing Incentive property holds in the "simple" case. The more difficult case is shown in Lemma 6. Informally, if the HD is a system bottleneck (i.e., it is 100% utilized) then Lemma 4 shows that the clients in D will receive at least 1/n of the HD bandwidth. The clients in S may get less than that amount on the HD (and usually will get less). Similarly, if the SSD is a system bottleneck, then the clients in S will receive at least 1/n of the SSD bandwidth. In the remainder of this section we assume that the clients 1, 2, ·· ·n, are ordered in non-decreasing order of their hit ratios, and that r of them are in D and the rest in S. Hence, D = {1, ·· · , r} and S = {r + 1, ·· · , n}.</p><p>Lemma 4. Suppose the HD (SSD) has a utilization of 100%. Then every i ∈ D (respectively i ∈ S) receives a throughput of at least f i .</p><p>Proof. Let j denote an arbitrary client in S. From fairness policy (3), A i m i ≥ A j m j . That is, the throughput on the HD of a client in D is greater than or equal to the throughput on the HD of any client in S. Now, from lemma 2 the IOPS from the HD of all i ∈ D are equal. Since, by hypothesis, the disk is 100% utilized, the total IOPS from the HD is C d . Hence, for every i ∈ D, the IOPS on the disk must be at least C d /n. A symmetrical proof holds for clients in S.</p><p>In order to show the Sharing Incentive property for clients whose bottleneck device is not the system bottleneck (i.e. is less than 100% utilized), we prove the following Lemma. Informally, it states that utilization of the SSD improves if the clients in S can be given a bigger allocation. The result, while intuitive, is not self evident. An increase in the SSD allocation to a client in S increases its HD usage as well. Since the HD is 100% utilized, this reduces HD allocations of clients in D, which in turn reduces their allocation on the SSD. We need to check that the net effect is positive in terms of SSD utilization.</p><p>Lemma 5. Consider two allocations that satisfy fairness policy (1) - <ref type="formula" target="#formula_13">(3)</ref>, and for which the HD has utilization of 100% and the SSD has utilization less than100%. Let ρ s andˆρandˆ andˆρ s be the proportionally constants of clients in S for the two allocations, and let U andˆUandˆ andˆU be the respective system throughputs. IfˆρIfˆ Ifˆρ s &gt; ρ s thenˆUthenˆ thenˆU &gt; U. A symmetrical result holds if the SSD is 100% utilized and the HD is less than 100% utilized.</p><p>Proof. We show the case for HD 100% utilized. From Lemma 2, all clients in S have the same throughput ρ s C s /n on the SSD. Define δ s to be the difference between the SSD throughputs of a client in S in the two allocations. Sincê ρ s &gt; ρ s , δ s &gt; 0. Similarly, define δ d to be difference between the HD throughput of a client in D in the two allocations.</p><p>An increase of δ s in the throughput of client i ∈ S on the SSD implies an increase on the HD of δ s × (m i /h i ). Since the HD is 100% utilized in both allocations, the aggregate allocations of clients in D must decrease by the total amount ∑ i∈S δ s × (m i /h i ). By Lemma 2, since all clients in D have the same allocation on the HD, δ d = ∑ i∈S δ s × (m i /h i )/|D|. As a result, the decrease in the al-</p><formula xml:id="formula_21">location of client j ∈ D on the SSD isˆδisˆ isˆδ s = δ d × (h j /m j ).</formula><p>The total change in the allocation on the SSD in the two allocations, ∆ is therefore: ∆ = ∑ i∈S δ s − ∑ j∈Dˆδ j∈Dˆ j∈Dˆδ s . Substituting:</p><formula xml:id="formula_22">∆ = ∑ i∈S δ s − ∑ j∈D δ d × (h j /m j ) (9) ∆ = |S| × δ s − ∑ j∈D ( ∑ i∈S δ s × (m i /h i )/|D|) × (h j /m j ) (10) Now for all i ∈ S, (m i /h i ) ≤ (m r+1 /h r+1 ) and for all j ∈ D, (h j /m j ) ≤ (h r /m r ).</formula><p>Substituting in Equation 10:</p><formula xml:id="formula_23">∆ ≥ |S| × δ s − |S|δ s × (m r+1 /h r+1 ) × (h r /m r ) (11) ∆ ≥ |S| × δ s (1 − m r+1 m r × h r h r+1 )<label>(12)</label></formula><p>Now, m r+1 &lt; m r and h r &lt; h r+1 since r and r + 1 are in D and S respectively. Hence, ∆ &gt; 0.</p><p>Finally, we show the Sharing Incentive property for clients whose bottleneck device is not the system bottleneck. The idea is to make the allocation to the clients in S as large as we can, before the EF requirements prevent further increase.</p><p>Lemma 6. Suppose the HD (SSD) has utilization of 100% and the SSD (HD) has utilization less than 100%. Then every i ∈ S (respectively i ∈ D) receives a throughput of at least f i .</p><p>Proof. We will show it for clients in S. A symmetrical proof holds in the other case.</p><p>Since BAA maximizes utilization subject to fairness policy (1) -(3), it follows from Lemma 5 that ρ s must be as large as possible. If i ∈ S, the IOPS it receives on the HD are ρ s C s /n × (m i /h i ) which from the EF requirements of Lemma 3 must be no more than ρ d C d /n, the IOPS on the HD for any client in</p><formula xml:id="formula_24">D. Hence, ρ s C s /n × (m i /h i ) ≤ ρ d C d /n or ρ s ≤ ρ d (C d /C s ) × (h i /m i ), for all i ∈ S. Since h i /m i is smallest for i = r + 1, the maximum feasible value of ρ s is ρ s = ρ d (C d /C s ) × (h r+1 /m r+1 ). Now, h r+1 &gt; h bal , so h r+1 /m r+1 &gt; h bal /(1 − h bal ) = C s /C d . Hence ρ s &gt; ρ d .</formula><p>Since the HD is 100% utilized we know from Lemma 4 that ρ d ≥ 1, and so ρ s &gt; 1.</p><p>From Lemmas 4 to 6 we can conclude:</p><p>Lemma 7. Allocations made by BAA satisfy the Sharing Incentive property.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Performance Evaluation</head><p>We evaluate our work using both simulation and Linux system implementation. For simulation, a synthetic set of workloads was created. Each request is randomly assigned to the SSD or HD based on its hit ratio. The request service time is an exponentially distributed random variable with mean equal to the reciprocal of the device IOPS capacity.</p><p>In the Linux system, we implemented a prototype by interposing the BAA scheduler in the IO path. Raw IO is performed to eliminate the influence of OS buffer caching. The storage server includes a 1TB SCSI Western Digital hard disk (7200 RPM 64MB Cache SATA 6.0Gb/s) and 120GB SAMSUNG 840 Pro Series SSD. Various block-level workloads from UMass Trace Repository <ref type="bibr" target="#b0">[1]</ref> and Microsoft Exchange server <ref type="bibr" target="#b30">[31]</ref> are used for the evaluation. These traces are for a homogeneous server and do not distinguish between devices. Since we needed to emulate different proportions of HD and SSD requests we randomly partitioned the blocks between the two devices to meet the assumed hit ratio of the workload. The device utilizations are measured using Linux tool "iostat".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Simulation Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1">System Efficiency</head><p>This experiment compares the system efficiency for three different schedulers: Fair Queuing (FQ), DRF, and BAA. The capacities of the HD and SSD are 100 IOPS and 5000 IOPS respectively. The first experiment employs two clients with hit ratios 0.5 and 0.99. FQ allocates equal amounts of throughput to the two clients. The DRF implementation uses the dominant resource shares policy of <ref type="bibr" target="#b16">[17]</ref> to determine allocation weights, and BAA is the approach proposed in this paper. All workloads are assumed to be continuously backlogged.</p><p>The throughputs of the two clients with different schedulers are shown in <ref type="figure">Figure 3(a)</ref>. The figure also shows the fair share allocation, i.e. the throughput the workload would get by partitioning the SSD and HD capacities equally between the two workloads. As can be seen, the throughput of client 2 under FQ is the lowest of the three schedulers. In fact, sharing is a disincentive for client 2 under FQ scheduling, since it would have been better off with a static partitioning of both devices. The problem is that the fair scheduler severely throttles the SSD-bound workload to force the 1 : 1 fairness ratio. DRF performs much better than FQ. Both clients get a little more than their fair shares. BAA does extremely well in this setup and client 2 is able to almost double the throughput it would have received with a static partition. We also show the system utilization for the three schedulers in <ref type="figure">Figure 3(b)</ref>. BAA is able to fully utilize both devices, while DRF reaches system utilization of only around 65%.</p><p>Next we add another client with hit ratio of 0.8 to the workload mix. The throughputs of the clients are shown in <ref type="figure" target="#fig_6">Figure 4(a)</ref>. Now the throughput of the DRF scheduler is also degraded, because it does not adjust the relative allocations to account for load imbalance. The BAA scheduler gets higher throughput (but less than 100%) because it adjusts the weights to balance the system load. The envy-free requirements put an upper-bound on the SSD-bound client's throughput, preventing the utilization from going any higher, but still maintaining fairness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2">Adaptivity to Hit Ratio Changes</head><p>In this experiment, we show how the two-level scheduling framework restores system utilization following a change in an application's hit ratio. The capacities of the HD and SSD are 200 IOPS and 3000 IOPS respectively. In this simulation, allocations are recomputed every 100s and the hit ratio is monitored in a moving window of 60s. There are two clients with initial hit ratios of 0.45 and 0.95. At time 510s, the hit ratio of client 1 falls to 0.2. <ref type="figure">Figure 5</ref> shows a time plot of the throughputs of the clients. The throughputs of both clients falls significantly at time 510 as shown in <ref type="figure">Figure 5</ref>. The scheduler needs to be cognizant of changes in the application characteristics and recalibrate the allocations to increase the efficiency. At time 600s (the rescheduling interval boundary) the allocations are recomputed using the hit ratios that reflect the current application behavior, and the system throughput rises again.</p><p>In practice the frequency of calibration and the rate at which the workload hit ratios change can affect system performance and stability. As is the case in most adaptive situations, the techniques work best when significant changes in workload characteristics do not occur at a very fine time scale. We leave the detailed evaluation of robustness to future work. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Linux Experiments</head><p>We now evaluate BAA in a Linux system, and compare its behavior with allocations computed using the DRF policy <ref type="bibr" target="#b16">[17]</ref> and the Linux CFQ <ref type="bibr" target="#b38">[39]</ref> scheduler. The first set of experiments deals with evaluating the throughputs (or system utilization) of the three scheduling approaches. The second set compares the fairness properties.   Clients in the same bottleneck set. Two workloads from Web Search <ref type="bibr" target="#b0">[1]</ref> are used in this experiment. The requests include reads and writes and the request sizes range from 8KB to 32KB. We first evaluate the performance when all the clients fall into the same bottleneck set; that is, all the clients are bottlenecked on the same device. We use hit ratios of 0.3 and 0.5 for the two workloads which makes them both HD bound. As shown in <ref type="table" target="#tab_3">Table 2</ref> all three schedulers get similar allocation. In this situation there is just one local bottleneck set in BAA, which (naturally) coincides with the system bottleneck device for CFQ as well as being the dominant resource for DRF. The device utilizations are the same for all schedulers, as can be expected. Clients in different bottleneck sets. In this experiment, we evaluate the performance when the clients fall into different bottleneck sets; that is, some of the clients are bottlenecked on the HD and some on the SSD. Two clients, one running a Financial workload <ref type="bibr" target="#b0">[1]</ref> (client 1) and the second running an Exchange workload <ref type="bibr" target="#b30">[31]</ref> (client 2) with hit ratios of 0.3 and 0.95 respectively, are used in the experiment. The request sizes range from 512 bytes to 8MB, and are a mix of read and write requests. The total experiment time is 10 minutes. <ref type="figure">Figure 6</ref> shows the throughput of each client achieved by the three schedulers. As shown in the figure, BAA has better total system throughput than the others. CFQ performs better than DRF but not as good as BAA. <ref type="figure">Figure 7</ref> shows the measured utilizations for HD and SSD using the three schedulers. <ref type="figure">Figure 7</ref>(a) shows that BAA achieves high system utilization for both HD and SSD; DRF and CFQ have low SSD utilizations compared with BAA, as shown in <ref type="figure">Figure 7</ref>(b) and (c). HD utilizations are good for both DRF and CFQ (almost 100%), because the system has more disk-bound clients that saturate the disk.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2">Allocation Properties Evaluation</head><p>In this experiment, we evaluate the fairness properties of allocations (P1 to P4). Four Financial workloads <ref type="bibr" target="#b0">[1]</ref> with hit ratios of 0.2, 0.4, 0.98 and 1.0 are used as the input. The workloads have a mix of read and write requests and request sizes range from 512 bytes to 8MB.   <ref type="table">Table 3</ref>: Allocations for Financial workloads using BAA <ref type="table">Table 3</ref> shows the allocations of BAA-based scheduling. The second column shows the Fair Share for each workload. The third column shows the IOPS achieved by each client, and the portions from the HD and SSD are shown in the next two columns.</p><p>The average capacity of the HD for the workload is around 140-160 IOPS and the SSD is 2000-2200 IOPS. We use the upper-bound of the capacity to compute the fair shares shown in the second column. In this setup, Financial 1 and Financial 2 are bottlenecked on the HD and belong to D, while Financial 3 and Financial 4 are bottlenecked on the SSD and belong to S.</p><p>First we verify that clients in the same bottleneck set receive allocations in proportion to their fair share (P1). As shown in the Table 3, Financial 1 and 2 get throughputs of 76 and 101, which are in the same ratio as their fair share (50 : 67). Similarly, Financial 3 and 4 get throughputs 1068 and 1047, which are in the ratio of their fair share of (561 : 550).</p><p>HD-bottlenecked workloads Financial 1 and Financial 2 receive more HD allocation (60.8 IOPS) than both workloads Financial 3 (21.4 IOPS) and 4 (0 IOPS). Similarly, SSD-bottlenecked workloads Financial 3 and Financial 4 receive more SSD allocation (1047 and 1047 IOPS) than both workload 1 (15.2 IOPS) and 2 (40.4 IOPS).</p><p>It can be verified from columns 2 and 3 that every client receives at least its fair share. Finally, the system shows that both HD and SSD are almost fully utilized, indicating the allocation maximizes the system throughput subject to these fairness criteria. Similar experiments were also conducted with other workloads, including those from Web Search and Exchange Servers. The results show that properties P1 to P4 are always guaranteed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related Work</head><p>There has been substantial work dealing with proportional share schedulers for networks and CPU <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b43">44]</ref>. These schemes have since been extended to handle the constraints and requirements of storage and IO scheduling <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b32">33]</ref>. Extensions of WFQ to provide reservations for constant capacity servers were presented in <ref type="bibr" target="#b40">[41]</ref>. Reservation and limit controls for storage servers were studied in <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b23">24]</ref>. All these models provide strict proportional allocation for a single resource based on static shares possibly subject to reservation and limit constraints.</p><p>As discussed earlier, Ghodsi et al <ref type="bibr" target="#b16">[17]</ref> proposed the DRF policy, which provides fair allocation of multiple resources on the basis of dominant shares. Ghodsi et al. <ref type="bibr" target="#b15">[16]</ref> extended DRF to packet networks and compared it to the global bottleneck allocation scheme of <ref type="bibr" target="#b11">[12]</ref>. Dolev et al <ref type="bibr" target="#b10">[11]</ref> proposed an alternative to DRF based on fairly dividing a global system bottleneck resource. Gutman and Nisan <ref type="bibr" target="#b24">[25]</ref> considered generalizations of DRF in a more general utility model, and also gave a polynomial time algorithm for the construction in Dolev et al <ref type="bibr" target="#b10">[11]</ref>. <ref type="bibr">Parkes et al. [36]</ref> extended DRF in several ways, and in particular studied the case of indivisible tasks. Envy-freedom has been studied in the areas of economics <ref type="bibr" target="#b25">[26]</ref> and in game theory <ref type="bibr" target="#b9">[10]</ref>.</p><p>Techniques for isolating random and sequential IOs using time-quanta based IO allocation were presented in <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b7">8]</ref>. IO scheduling for SSDs is examined in <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b34">35]</ref>. Placement and scheduling tradeoffs for hybrid storage were a studied in <ref type="bibr" target="#b46">[47]</ref>. For a multitiered storage system, Reward scheduling <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b14">15]</ref> proposed making allocations in the ratio of the throughputs a client would receive when executed in isolation. Interestingly, both Reward and DRF perform identical allocations for the storage model of this paper <ref type="bibr" target="#b13">[14]</ref> (concurrent operation of the SSD and the HD), although they start from very different fairness criteria. Hence, Reward also inherits the fairness properties proved for DRF <ref type="bibr" target="#b16">[17]</ref>. For a sequential IO model where only 1 IO is served at a time, Reward will equalize the IO time allocated to each client. Note that neither DRF nor Reward explicitly address the problem of system utilization.</p><p>In the system area, Mesos <ref type="bibr" target="#b4">[5]</ref> proposes a two-level approach to allocate resources to frameworks like Hadoop and MPI that may share an underlying cluster of servers. Mesos (and related solutions) rely on OS-level abstractions like resource containers <ref type="bibr" target="#b3">[4]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions and Future Work</head><p>Multi-tiered storage made up of heterogeneous devices are raising new challenges in providing fair throughput allocation among clients sharing the system. The fundamental problem is finding an appropriate balance between fairness to the clients and increasing system utilization. In this paper we cast the problem within the broader framework of fair allocation for multiple resources, which has been drawing considerable amount of recent research attention. We find that existing methods almost exclusively emphasize the fairness aspect to the possible detriment of system utilization.</p><p>We presented a new allocation model BAA based on the notion of per-device bottleneck sets. The model provides clients that are bottlenecked on the same device with allocations that are proportional to their fair shares, while allowing allocation ratios between clients in different bottleneck sets to be set by the allocator to maximize utilization. We show formally that BAA satisfies the properties of Envy Freedom and Sharing Incentive that are well accepted fairness requirements in microeconomics and game theory. Within these fairness constraints BAA finds the best system utilization. We formulated the optimization as a compact 2-variable LP problem. We evaluated the performance of our method using both simulation and implementation on a Linux platform. The experimental results show that our method can provide both high efficiency and fairness.</p><p>One avenue of further research is to better understand the theoretical properties of the Linux CFQ scheduler. It performs remarkably well in a wide variety of situations; we feel it is important to better understand its fairness and efficiency tradeoffs within a suitable theoretical framework. We are also investigating single-level scheduling algorithms to implement the BAA policy, and plan to conduct empirical evaluations at larger scale beyond our modest experimental setup.</p><p>Our approach also applies, with suitable definitions and interpretation of quantities, to broader multiresource allocation settings as in <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b35">36]</ref>, including CPU, memory, and network allocations. It can also be generalized to handle client weights; in this case clients in the same bottleneck set receive allocations in proportion to their weighted fair shares. We are also investigating settings in which the SSD is used as a cache; this will involve active data migration between the devices, making the resource allocation problem considerably more complex.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Tiered storage model</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Allocations using DRF. Allocations are in the ratio 9 : 25. Utilization of the SSD is 77%.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Allocations in multi-tiered storage. HD capacity: 100 IOPS and SSD Capacity: 500 IOPS. The hit ratios of the clients are 0.5 and 0.9 respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Definitions 1 .</head><label>1</label><figDesc>The load of a client i on the SSD is h i /C s and on the HD is m i /C d . It represents the average fraction of the device capacity that is utilized per IO of a client. 2. Define the system load-balancing point as h</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>)</head><label></label><figDesc>Example V We show the steps of the optimization for the scenario of Example III. D = {p, q}, S = {r, s}, and the fair shares f p = 200, f q = 100, f r = 277.8 and f s = 263.2. ∑ i∈D f i = 200 + 100 = 300, ∑ j∈S f j = 277.8 + 263.2 = 541, ∑ i∈D f i m i = 50 + 50 = 100, ∑ j∈S f j m j = 27.78 + 13.2 = 41, ∑ i∈D f i h i = 150 + 50 = 200, and ∑ j∈S f j h j = 250 + 250 = 500. Also it can be verified that α = 0.55 and β = 1.67. Hence, we get the follow- ing optimization problem:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>Figure 5: Scheduling with dynamic weights when hit ratio changes</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 4 :</head><label>4</label><figDesc>Figure 3: Throughputs and utilizations for 2 flows</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 6 :Figure 7 :</head><label>67</label><figDesc>Figure 6: Throughputs using three schedulers. BAA achieves higher system throughput (1396 IOPS) than both DRFbased Allocation (810 IOPS) and Linux CFQ (1011 IOPS).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 1 summarizes the mean- ings of different symbols., m i Hit (Miss) ratio for client i h bal Load Balance Hit Ratio: C s /(C s +C d ) n Total number of clients</head><label>1</label><figDesc></figDesc><table>Symbol 
Meaning 

C s ,C d 
Capacity in IOPS of SSD (HD) 
S, D 
Set of clients bottlenecked on the SSD (HD) 
ρ s , ρ d 
Proportionality constants of fairness policy 
f i 
Fair Share for client i 
h i </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 2 : Throughputs: all clients in one bottleneck set</head><label>2</label><figDesc></figDesc><table></table></figure>

			<note place="foot" n="1"> [36] extends the definition to weighted clients and weighted partition sizes. 2 We can apply the framework of [36] to BAA to handle the case of unequal weights as well. system is free to set them in a way that maximizes utilization as long as Envy Freedom, Sharing Incentive and Pareto Optimality properties are preserved by the resulting allocation. 3 Bottleneck-Aware Allocation In this section, we will discuss our resource allocation model called Bottleneck-Aware Allocation (BAA) and the corresponding scheduling algorithm.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank the reviewers of the paper for their insightful comments which helped shape the revision. We are grateful to our shepherd Arif Merchant whose advice and guidance helped improve the paper immensely. The support of NSF under Grant CNS 0917157 is greatly appreciated.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Storage performance council (umass trace repository</title>
		<ptr target="http://traces.cs.umass.edu/index.php/Storage" />
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">EMC: Fully automate storage tiering</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<ptr target="http://www.tintri.com" />
		<title level="m">Tintri: VM aware storage</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Resource containers: a new facility for resource management in server systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Banga</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Druschel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mogul</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">OSDI &apos;99</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Mesos: a platform for fine-grained resource sharing in the data center</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">T</forename><surname>Al</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NSDI&apos;11</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">On the efficiency-fairness trade-off</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bertsimas</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Farias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">F</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trichakis</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Manage. Sci</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page" from="2234" to="2250" />
			<date type="published" when="2012-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The price of fairness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bertsimas</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Farias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">F</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trichakis</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">F</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Operations Research</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="17" to="31" />
			<date type="published" when="2011-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Disk scheduling with Quality of Service guarantees</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bruno</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Brustoloni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gabber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ozden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silberschatz</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Multimedia Computing and Systems</title>
		<meeting>the IEEE International Conference on Multimedia Computing and Systems</meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="1999" />
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Analysis and simulation of a fair queuing algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Demers</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Keshav</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shenker</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Internetworking Research and Experience</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3" to="26" />
			<date type="published" when="1990-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Envy freedom and prior-free mechanism design</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devanur</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">R</forename><surname>Hartline</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename></persName>
		</author>
		<idno>CoRR abs/1212.3741</idno>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">No justified complaints: On fair sharing of multiple resources</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dolev</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Feitelson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Halpern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Y</forename><surname>Kupfer-Man</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linial</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd Innovations in Theoretical Computer Science Conference</title>
		<meeting>the 3rd Innovations in Theoretical Computer Science Conference<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="68" to="75" />
		</imprint>
	</monogr>
	<note>ITCS &apos;12, ACM</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Improved parallelism and scheduling in multicore software routers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Egi</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Iannaccone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Manesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ratnasamy</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Supercomputing</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="page" from="294" to="322" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Reward scheduling for QoS scheduling in cloud applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elnably</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Varman</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">12th IEEE/ACM International Conference on Cluster, Cloud, and Grid Computing (CCGRID&apos;12</title>
		<imprint>
			<date type="published" when="2012-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Application specific QoS scheduling in storage servers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elnably</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Varman</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">24th ACM Symposium on Parallel Algorithms and Architectures (SPAA&apos;12</title>
		<imprint>
			<date type="published" when="2012-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Efficient QoS for multi-tiered storage systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elnably</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Gulati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Varman</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">4th USENIX Workshop on Hot Topics in Storage and File Systems</title>
		<imprint>
			<date type="published" when="2012-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Multi-resource fair queueing for packet processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ghodsi</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sekar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Zaharia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stoica</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGCOMM 2012 Conference on Applications, Technologies, Architectures, and Protocols for Computer Communication</title>
		<meeting>the ACM SIGCOMM 2012 Conference on Applications, Technologies, Architectures, and Protocols for Computer Communication<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
	<note>SIGCOMM &apos;12, ACM</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Dominant resource fairness: fair allocation of multiple resource types</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ghodsi</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zaharia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hindman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Konwinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shenker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stoica</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th USENIX conference on Networked systems design and implementation</title>
		<meeting>the 8th USENIX conference on Networked systems design and implementation<address><addrLine>Berkeley, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="24" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Start-time fair queueing: a scheduling algorithm for integrated services packet switching networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Goyal</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">M</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Trans. Netw</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="690" to="704" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">PARDA: Proportional Allocation of Resources in Distributed Storage Access</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gulati</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ahmad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Waldspurger</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">FAST &apos;09)Proceedings of the Seventh Usenix Conference on File and Storage Technologies</title>
		<imprint>
			<date type="published" when="2009-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Automated io load balancing across storage devices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gulati</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ahmad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kumar</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Basil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Usenix FAST</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="169" to="182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">An arrival curve based approach for QoS in shared storage systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gulati</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Merchant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Varman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pclock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGMETRICS</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Handling Throughput Variability for Hypervisor IO Scheduling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gulati</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Merchant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Varman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mclock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">USENIX OSDI</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Demand based hierarchical qos using storage resource pools</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gulati</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shanmuganathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Var-Man</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 USENIX conference on Annual Technical Conference</title>
		<meeting>the 2012 USENIX conference on Annual Technical Conference<address><addrLine>Berkeley, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1" to="1" />
		</imprint>
	</monogr>
	<note>USENIX ATC&apos;12, USENIX Association</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Demand based hierarchical qos using storage resource pools</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gulati</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shanmuganathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Var-Man</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 USENIX Conference on Annual Technical Conference</title>
		<meeting>the 2012 USENIX Conference on Annual Technical Conference<address><addrLine>Berkeley, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1" to="1" />
		</imprint>
	</monogr>
	<note>USENIX ATC&apos;12, USENIX Association</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Fair allocation without trade. CoRR abs/1204</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gutman</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nisan</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page">4286</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Envy-freeness and implementation in large economies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jackson</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">O</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kremer</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Review of Economic Design</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="185" to="198" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Interposed proportional sharing for a storage service utility</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jin</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Chase</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaur</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGMETRICS &apos;04</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joe-Wong</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chiang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
		<title level="m">IN-FOCOM</title>
		<editor>A. G. Greenberg and K. Sohraby</editor>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1206" to="1214" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Triage: Performance differentiation for storage systems using adaptive control</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karlsson</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Karamanolis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhu</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trans. Storage</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="457" to="480" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">No agent left behind: Dynamic fair division of multiple resources</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kash</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Procaccia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">D</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shah</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 International Conference on Autonomous Agents and Multi-agent Systems</title>
		<meeting>the 2013 International Conference on Autonomous Agents and Multi-agent Systems<address><addrLine>Richland, SC</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="351" to="358" />
		</imprint>
	</monogr>
	<note>AAMAS &apos;13, International Foundation for Autonomous Agents and Multiagent Systems</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Characterization of storage workload traces from production windows servers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kavalanekar</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Worthington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharda</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Symposium on</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="119" to="128" />
		</imprint>
	</monogr>
	<note>Workload Characterization</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lumb</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Merchant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alvarez</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Façade</surname></persName>
		</author>
		<title level="m">Virtual storage devices with performance guarantees. File and Storage technologies (FAST&apos;03</title>
		<imprint>
			<date type="published" when="2003-03" />
			<biblScope unit="page" from="131" to="144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Towards higher disk head utilization: extracting free bandwidth from busy disk drives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lumb</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename><surname>Schindler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ganger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">R</forename><surname>Nagle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">F</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Riedel</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Usenix OSDI</title>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Fios: A fair, efficient flash i/o scheduler</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Park</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">FAST</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Flashfq: A fair queueing i/o scheduler for flash-based ssds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Park</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Usenix ATC</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Beyond dominant resource fairness: Extensions, limitations, and indivisibilities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Parkes</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">C</forename><surname>Procaccia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">D</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shah</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th ACM Conference on Electronic Commerce</title>
		<meeting>the 13th ACM Conference on Electronic Commerce<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="808" to="825" />
		</imprint>
	</monogr>
	<note>EC &apos;12, ACM</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Efficient guaranteed disk request scheduling with Fahrrad</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Povzner</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kaldewey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brandt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Golding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maltzahn</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGOPS Oper. Syst. Rev</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="13" to="25" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Cake cutting: Not just child&apos;s play</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Procaccia</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">D</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page" from="78" to="87" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Choosing an I/O Scheduler for Red Hat Enterprise Linux 4 and the 2.6 Kernel</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shakshober</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Red Hat magazine</title>
		<imprint>
			<date type="published" when="2005-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Efficient fair queueing using deficit round robin</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shreedhar</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Varghese</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of SIGCOMM &apos;95</title>
		<meeting>of SIGCOMM &apos;95</meeting>
		<imprint>
			<date type="published" when="1995-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">On the duality between resource reservation and proportional-share resource allocation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stoica</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abdel-Wahab</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffay</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SPIE</title>
		<imprint>
			<date type="published" when="1997-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">High Throughput Disk Scheduling with Fair Bandwidth Distribution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Valente</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Checconi</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computers</title>
		<imprint>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1172" to="1186" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Argon: performance insulation for shared storage servers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wachs</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abd-El-Malek</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Thereska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ganger</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">R</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">USENIX FAST</title>
		<meeting><address><addrLine>Berkeley, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Lottery scheduling: flexible proportional-share resource management</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Waldspurger</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">A</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weihl</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">E</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Usenix OSDI</title>
		<imprint>
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Proportional-share scheduling for distributed storage systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>And Merchant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Usenix FAST</title>
		<imprint>
			<date type="published" when="2007-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Storage performance as a managed resource</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wong</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Golding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>And Becker-Szendy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Zygaria</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th IEEE Real-Time and Embedded Technology and Applications Symposium</title>
		<meeting>the 12th IEEE Real-Time and Embedded Technology and Applications Symposium<address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="125" to="134" />
		</imprint>
	</monogr>
	<note>RTAS &apos;06</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Exploiting concurrency to improve latency and throughput in a hybrid storage system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">U</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>And Reddy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MAS-COTS</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="14" to="23" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Storage performance virtualization via throughput and latency control</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sivasubramaniam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Riska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Riedel</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MASCOTS</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="135" to="142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">VirtualClock: A new traffic control algorithm for packet-switched networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Comput. Syst</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="101" to="124" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
