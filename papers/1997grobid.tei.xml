<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2020-09-29T02:21+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">STMS: Improving MPTCP Throughput Under Heterogeneous Networks STMS: Improving MPTCP Throughput Under Heterogeneous Networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>July 11-13. 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Shi</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Cui</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuming</forename><surname>Hu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minglong</forename><surname>Dai</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fanzhao</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Zheng</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Shi</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Cui</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuming</forename><surname>Hu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minglong</forename><surname>Dai</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fanzhao</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Zheng</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<addrLine>Xin Wang</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">Stony Brook University</orgName>
								<orgName type="institution" key="instit2">Tsinghua University</orgName>
								<orgName type="institution" key="instit3">Huawei Technologies</orgName>
								<orgName type="institution" key="instit4">Tsinghua University</orgName>
								<orgName type="institution" key="instit5">Tsinghua University</orgName>
								<orgName type="institution" key="instit6">Stony Brook University</orgName>
								<orgName type="institution" key="instit7">Tsinghua University</orgName>
								<orgName type="institution" key="instit8">Tsinghua University</orgName>
								<orgName type="institution" key="instit9">Huawei Technologies</orgName>
								<orgName type="institution" key="instit10">Huawei Technologies</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">STMS: Improving MPTCP Throughput Under Heterogeneous Networks STMS: Improving MPTCP Throughput Under Heterogeneous Networks</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 USENIX Annual Technical Conference (USENIX ATC &apos;18)</title>
						<meeting>the 2018 USENIX Annual Technical Conference (USENIX ATC &apos;18) <address><addrLine>Boston, MA, USA</addrLine></address>
						</meeting>
						<imprint>
							<date type="published">July 11-13. 2018</date>
						</imprint>
					</monogr>
					<note>Open access to the Proceedings of the 2018 USENIX Annual Technical Conference is sponsored by USENIX. This paper is included in the</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Using multiple interfaces on mobile devices to get high throughput is promising to improve the user experience. However, Multipath TCP (MPTCP), the de-facto standardized solution, suffers when different paths have heterogeneous quality. This problem is especially severe when the difference is the path latency. Our experimental results show that it causes the burst sending of packets from the fast path, which requires the in-network buffer to be big to achieve the full benefit of the bandwidth aggregation. In addition, it also requires bigger host buffer to fully utilize the fast path. To solve these problems, we propose and implement a new scheduler, which pre-allocates packets to send over the fast path for in-order arrival. Instead of relying on the estimation of network path condition, our scheduler dynamically adapts the MPTCP-level send window based on the packets acknowledged. Our evaluation shows that our scheduler can improve the throughput by 30% when the in-network buffer is limited, 15% when the host buffer is limited.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>There is a huge demand on network bandwidth with the rapid growth of network users and applications, as well as the emergence of bandwidth hungry applications such as multimedia streaming, cloud computing and virtual reality. To obtain high network throughput, a lot of recent interests have been drawn to exploit multi-path transmissions and aggregate the bandwidth through Multi-path TCP (MPTCP) <ref type="bibr" target="#b11">[12]</ref>. As an example application, many wireless devices have two network interfaces, one to the local-area WiFi network and another to the wide-area cellular network. As wireless bandwidth is limited, a data stream can go through both networks to increase the transmission rate. * Corresponding author MPTCP is expected to be backward-compatible with conventional TCP and work with existing network components such as middle-boxes <ref type="bibr" target="#b24">[26]</ref>. For the practical deployment of MPTCP, it is designed to be transparent to both applications and middle-boxes. From the perspective of applications, a single standard TCP is seen, whereas lower in the stack, MPTCP splits the data over multiple sub-flows. From the perspective of middle-boxes, each sub-flow is a normal TCP connection. MPTCP has already been implemented in Linux kernel <ref type="bibr" target="#b6">[7]</ref> and used in iOS <ref type="bibr" target="#b3">[4]</ref> and Giga Path in Korean Telecom <ref type="bibr" target="#b25">[27]</ref>. Agache et al. <ref type="bibr" target="#b1">[2]</ref> deploy MPTCP in the datacenter network to obtain better network utilization. Han et al. <ref type="bibr" target="#b13">[15]</ref> apply MPTCP to improve the user experience on video streaming.</p><p>The core element of MPTCP design is the scheduler <ref type="bibr" target="#b26">[28]</ref>, which determines when and how to distribute packets to each sub-flow. MPTCP's default scheduler (minRTT) <ref type="bibr" target="#b24">[26]</ref> sends packets through the available path with the smallest estimated Round-Trip Time (RTT). However, this scheduler does not take into account the path heterogeneity while there often exist different types and quality of paths in practical use and this is especially the case for wireless applications <ref type="bibr" target="#b15">[17,</ref><ref type="bibr" target="#b27">29]</ref>. The measurement of Alexa top-500 U.S. websites from Nikravesh et al. <ref type="bibr" target="#b22">[24]</ref> shows that the difference in RTT between WiFi and Cellular paths is common and big. When RTTs in separate paths differ, the default scheduler will cause an out-oforder arrival of packets at the receiver side. Thus the memory requirements of MPTCP are much higher than those of conventional TCP. To alleviate this problem, opportunistic retransmission and penalization mechanism is proposed <ref type="bibr" target="#b24">[26]</ref> and improved <ref type="bibr" target="#b23">[25]</ref> along with the progress of the default scheduler.</p><p>Despite these efforts, we find that the complete gain from bandwidth aggregation of MPTCP is still far from being achieved. In our experiments conducted in the controlled lab environment ( ยง 2), we observe that when the host buffer is limited, the aggregation throughput is far smaller than two single-path TCP combined under the same network and buffer settings. Sometimes it can only reach 40% the throughput of two single-path TCP together, which is even worse than a single-path TCP running over the best network interface.</p><p>Apart from the host buffer problem, we find that it also requires a big in-network buffer on the fast path to reach the full-bandwidth allowed by multiple paths. The in-network buffer requirement for the fast path is increased by 4X when using both paths compared with those for single-path TCP. Examining the problem carefully, we find that the default scheduler breaks down the ACK clocking <ref type="bibr" target="#b17">[19]</ref> on the fast path, which gives rise to the burst sending of packets during fast sub-flow's transmission. Thus more in-network buffers are necessitated to hold the burst packets, otherwise the packets that cannot be stored have to be dropped, resulting in the throughput degradation on the fast path. This problem is more serious in the wireless networks where WiFi path is usually the fast one and has less buffer than that of the Cellular path <ref type="bibr" target="#b18">[20]</ref>. Therefore when competing with single-path TCP, MPTCP is more likely to experience loss and the throughput will suffer. To the best of our knowledge, we are the first to identify the burst transmission pattern on the fast-path of MPTCP.</p><p>In this work, we propose a new scheduler to reduce both host buffer and in-network buffer requirements in MPTCP, called STMS (Slide Together Multipath Scheduler). To solve the above two problems fundamentally, we need to reduce the out-of-order arrival. Our scheduler preallocates packets for the fast path and sends packets with larger sequence number through slow path so that packets can arrive at the receiver in order. This task appears to be straightforward, but it faces several challenges. As a matter of fact, there exists a "visibility gap" between the sender and the receiver. Therefore, it is hard for the scheduler that runs at the sender to ensure that packets arrive in order at the receiver. A sender can choose to utilize the measurement of path condition to schedule the packets, but the network condition is fluctuated in nature. Consequently, it is hard to measure the delay and bandwidth accurately especially in wireless networks. Even under stable network conditions, we can only obtain RTT but not one-way delay (OWD) in a practical distributed network. To address these challenges, we design an adaptation scheme that exploits the intelligent transmission of feedback signal Data ACK existing in MPTCP to dynamically schedule packet transmissions.</p><p>We implemented STMS as a Linux kernel module ( ยง 4) and evaluated it extensively in both emulated and real Cellular/WiFi networks. The results show that, compared with state-of-the-art schedulers <ref type="bibr" target="#b21">[23,</ref><ref type="bibr" target="#b23">25]</ref>, STMS achieves significantly higher performance under a wide range of buffer/network conditions. We highlight some of results as follows:</p><p>โข Under stable network conditions, STMS can achieve higher throughput under any buffer conditions. When the host buffer is extremely limited, STMS can fall back to using the single-path TCP, while the default scheduler still uses slow path of MPTCP and its fast path suffers from significant throughput degradation. In this case, our scheduler can improve the throughput as much as 400%. When the host buffer is small, STMS can bring 15% improvement over the default scheduler. When in-network buffer is limited, STMS improves the throughput as much as 30% due to the reduction of the burst.</p><p>โข Under varying network conditions, STMS also performs well, and brings 8% to 40% throughput improvement. Our adaptive scheduling scheme is reactive to network condition changes.</p><p>โข In real world test, STMS can reduce the file downloading time by 20% even when the host buffer is big enough, proving that the limited in-network buffer does exist in real network and our scheme effectively alleviates the problem.</p><p>Overall, our results show that by strategically scheduling packet transmissions to reduce the out-of-order arrival, STMS can significantly improve the throughput of MPTCP under heterogeneous networks. The rest of the paper is organized as follows. Firstly, we analyze the reason that lead to the throughput degradation when using the default scheduler in ยง 2. Then in ยง 3, we present the design and analysis of STMS. Next we introduce our implementation of STMS in ยง 4. We further present our performance evaluations in a controlled-lab environment in ยง 5, and the results from the real-world test in ยง 6. Finally, related work is discussed in ยง 7 and we conclude the paper in ยง 8.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background and Motivation</head><p>In this section, we first identify and analyze the problem associated with the in-network buffer. Then we demonstrate that host buffer problem still remains unsolved and discuss why the existing solution is still inadequate. We support our analyses with experiments conducted in the controlled lab environment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Controlled experiment setup</head><p>In our experiment setup in <ref type="figure" target="#fig_1">fig. 2</ref>, we use two PCs running the version 0.92 kernel of MPTCP <ref type="bibr" target="#b6">[7]</ref> as the client and server respectively. The client has two interfaces, and the server has one interface. Under this topology, MPTCP will establish two sub-flows. We use the decoupled TCP  congestion control to obtain the best bandwidth aggregation effect <ref type="bibr" target="#b8">[9]</ref>. Ethernet is used to simulate WiFi and LTE to avoid the interference of the wireless network. Client and server are connected through a router running OpenWrt. We use tc <ref type="bibr" target="#b28">[30]</ref> in OpenWrt to regulate the bandwidth and latency of the two paths. The bandwidths of both paths are set to 30 Mbits and the loss rate is set to 0.01%. The in-network buffer is set to 50ms for Wifi path unless specified otherwise and 500ms for LTE path based on <ref type="bibr" target="#b18">[20]</ref>. Both receiving and sending buffers are set to the Linux default size (6MB) unless specified otherwise. Only the RTT of slow path varies. In each network setup, we run iPerf 3 <ref type="bibr" target="#b16">[18]</ref> 90s five times to measure the throughput.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Big in-network buffer requirement</head><p>Guido et al. <ref type="bibr" target="#b2">[3]</ref> points out that it becomes more and more difficult to design the router with the buffer size equal to the bandwidth-delay product as the link speed increases. The router buffer is limited especially in the bottleneck of path. However, we find that the aggregated throughput is subject to the in-network buffer on the fast path as shown in <ref type="figure">fig. 3</ref>. For conventional TCP, 8ms network buffer (30KB) is enough to reach the full bandwidth. However, for MPTCP under different RTT paths, the innetwork buffer requirement increases as much as 4X to fully unleash the power of the bandwidth aggregation. The bigger the difference of RTT between two paths, the bigger the in-network buffer of the fast path is needed. When there is a space in the congestion window, the default MPTCP scheduler sends a set of packets with the smallest sequence numbers on the path with the smallest estimated RTT. This approach will produce the out-oforder arrivals at the receiver, as is elaborated in the following example ( <ref type="figure" target="#fig_0">fig. 1)</ref>. At the time t = 0, we assume the fast path is unavailable while the slow path has space, <ref type="figure">Figure 3</ref>: MPTCP throughput degradation when innetwork buffer is limited then packets 1-10 will be sent on the slow path. Later on at t = ฮด , the fast path becomes available, packets 11-30 will be sent on the fast path. After the round-trip time of the fast path RT T f , packets 11-30 arrive at the receiver but packets 1-10 do not, and the send/receive window is blocked as shown in <ref type="figure" target="#fig_0">fig. 1b</ref>. TCP has the delayed ACK mechanism <ref type="bibr" target="#b5">[6]</ref> to avoid the overhead of sending ACK packets. It works as follows. Upon receiving a data packet, if it is in order, i.e., the right edge of the receiving window advances, the receiver can choose to delay the sending of ACK hoping to piggy-back the ACK with other packets to send in the reverse direction. Nevertheless, RFC 1122 <ref type="bibr" target="#b5">[6]</ref> suggests that each ACK acknowledge at most two packets regardless of whether the delayed ACK mechanism is used, i.e., upon receiving two successive packets, an ACK must be sent. Thus, during the congestion avoidance phase, upon receiving one ACK, the sender's send window can have the space for at most two packets so that it can send at most two packets at a time. This is also known as ACK clocking.</p><p>In MPTCP, the semantics of the TCP send window is generalized. Instead of maintaining a separate window for each sub-flow, a single buffer pool is shared by all sub-flows at the MPTCP-level to avoid deadlock <ref type="bibr" target="#b24">[26]</ref>. To remain compatible with TCP, MPTCP needs a separate ACK for MPTCP-level send window, called Data ACK. The delayed ACK mechanism of conventional TCP is adapted to Data ACK. When receiving data packets in-order on the MPTCP-level, Data ACK will still be generated every other packet. However, when receiving out-of-order packets on the MPTCP-level, it will not send a duplicate Data ACK immediately since out-of-order packets on the MPTCP-level is a normal behavior especially when paths are heterogeneous. The Data ACK won't be sent until the packets from the slow path reach the receiver, i.e., the hole is filled. This Data ACK will acknowledge many packets sent from the fast path at the same time, thus fast path can send many packets at once, leading to the burst sending. In a nutshell, the out-of-order arrival of packets breaks down the ACK clocking effect of fast sub-flow, causing the burst sending behavior. This is shown in <ref type="figure" target="#fig_0">fig. 1c</ref>. At t = RT T s , packets 1-10 arrive at the receiver and packets 1-30 are acknowledged to the sender. So both the send and receive window will progress with a large step, and packets 31-50 are sent from the fast path in a burst. Simply removing the delayed ACK mechanism can not solve the problem, since the MPTCP-level send window progress is still blocked by the late arriving packets from the slow path. We conduct a simple experiment to demonstrate the burst transmission pattern of the fast sub-flow.</p><p>First we analyze the progress of Data ACK of the fast path from the trace file. The result is shown in <ref type="figure">fig. 5</ref>. Only when packets from the slow path arrive, the Data ACK can make a progress with a large step ( <ref type="figure">fig. 5a</ref>). When RTT is the same, no sudden Data ACK progress happens. Then   <ref type="figure" target="#fig_4">6</ref>). When RTT is the same, the ACK clocking is maintained like the conventional TCP ( <ref type="figure" target="#fig_4">fig. 6b)</ref>. However, when RTT over two paths significantly differs, the ACK clocking of the fast path is broken down. Consequently, MPTCP-level send window is stalled until the packets from the slow path arrive. As a result, the free space of the send window of the fast sub-flow will accumulate as we see in <ref type="figure" target="#fig_4">fig. 6a</ref>.</p><p>The sudden progress of MPTCP-level window and the big send window space of fast path will lead to the burst packet transmissions on the fast path as we see in <ref type="figure">fig. 4b</ref>. Compared to the sending behavior of the fast path when RTT is similar ( <ref type="figure">fig. 4a)</ref>, the fast sub-flow clearly demonstrates an on-off transmission pattern that leads to the burst of the fast sub-flow. When the network buffer is not big enough, the loss will happen and the Congestion window (CWND) is capped to a small value as we see in <ref type="figure">fig. 7a</ref>. When there is a difference between RTT on the two paths, the CWND of the fast path is capped around 40, compared to 60 when RTT values of two paths are the same. Note that there is usually a large space in fast path's CWND when RTT is different, so the area below the CWND line is actually bigger than the total throughput.</p><p>We also verify the loss rate under different in-network  buffer configurations (table 1). Note that this loss is more detrimental to the throughput than the random packet loss since each time CWND grows to certain value, the packet burst will exceed the in-network buffer size and the loss will happen. As a result, the throughput of the fast path is significantly limited. As shown in table 1, to reach the same throughput as that of single-path TCP, the buffer for two-path MPTCP has to be increased by 4X from 30KB to 150KB. [26] derives that the default scheduler buffer requirement is:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Big host buffer requirement</head><formula xml:id="formula_0">Bu f (de f ault) = (B f + B s ) ร RT T s<label>(1)</label></formula><p>From eq. <ref type="formula" target="#formula_0">(1)</ref> we can see that the key to reducing the buffer requirement is to reduce the effective RTT of the connection i.e., to acknowledge packet as soon as possible so that the buffer can get freed. Raiciu et al. <ref type="bibr" target="#b24">[26]</ref> proposed the penalize and opportunistic retransmission mechanism (PR) to deal with the host buffer problem. When it detects the left edge of the send window blocks the sending of packets, it will retransmit the packet from the fast path. To avoid constant retransmissions, it will penalize the slow sub-flow by halving the CWND of slow sub-flow. This approach  <ref type="figure">fig. 4c</ref>, the packets marked get retransmitted and the new Data ACK goes back through the fast path so many packets can be sent. Due to its opportunistic nature, the PR scheme can not always reduce the RTT to the optimal value. Moreover, the retransmission wastes the bandwidth. <ref type="figure">fig. 4c</ref> also shows that the retransmission does not change the fast path's burst transmission pattern, as the Data ACK coming back through the fast path will still acknowledge many packets. Hence the in-network buffer requirement issue remains unsolved which is also shown in the in-network buffer requirement measurement. Enabling retransmission doesn't improve the throughput at all. Despite the PR approach, the throughput of MPTCP is still unsatisfactory as shown in <ref type="figure" target="#fig_7">fig. 8</ref>. When evaluating the receiving buffer, the sending buffer size is set to the default value of Linux which is 6 MB (Big enough under our network setting). As we can see in <ref type="figure" target="#fig_7">fig. 8a</ref>: the bigger the RTT difference of two paths, the more receiving buffer is needed to get full bandwidth aggregation effect of MPTCP. The same conclusion goes to the sending buffer as is shown in <ref type="figure" target="#fig_7">fig. 8b</ref>.</p><p>Actually, the burst sending pattern can be fixed by adding traditional pacing to the fast path. Linux has supported pacing in tc qdisc fq <ref type="bibr">[13]</ref> since the version 2.4. However the pacing rate argument needs to be manually tuned according to the bandwidth of the network path. New congestion control algorithm Bottleneck Band-width and Round-trip propagation time (BBR) <ref type="bibr" target="#b7">[8]</ref> incorporates the pacing and can set the pacing rate equal to the measured bottleneck bandwidth automatically. However the congestion control of MPTCP needs to be fair with the conventional TCP. Many active research efforts <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b19">21,</ref><ref type="bibr" target="#b29">31]</ref> have been put into developing the coupled congestion control algorithms of MPTCP, but there is no coupled BBR congestion control for MPTCP yet. To put it another way, this approach is not congestion control agnostic. Besides, the pacing can not solve the big host buffer requirement issue. Pacing works only on sub-RTT level and thus the packet sent from the slow path will still arrive later than packets sent from the fast path. We verify that by adding pacing manually and it turns out that the throughput is not improved at all.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Design</head><p>The root cause of the throughput degradation is the stall and sudden progress of MPTCP-level send window. To solve both host buffer and in-network buffer problems, we need to restore the ACK clocking for MPTCP. To achieve this, packets need to arrive in order at the receiver.</p><p>In this section, we first present our algorithm design, then derive the size required from the host-buffer for noblocked transmissions, and finally compare the transmission latency of different schemes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">STMS algorithm</head><p>We propose STMS to schedule the packets strategically so that they arrive in order. This solution is congestion control agnostic which allows for separate evolving of congestion control algorithm and scheduler algorithm.</p><p>Scheduler algorithm The core idea of our scheduler is to buffer packets for the fast sub-flow and assign packets with larger sequence numbers to the slow sub-flow so that they arrive in order. The running process of our algorithm is shown on <ref type="figure" target="#fig_9">fig. 9</ref> and algorithm 1. The scheduler runs when at least one of paths is available to send packets. The fast sub-flow always sends the packets with the smallest set of sequence numbers in the buffer. As illustrated in <ref type="figure" target="#fig_9">fig. 9a</ref>, the slow sub-flow sends packets with bigger sequence numbers. Rather than taking packets whose numbers are right after those transmitted on the fast path, it leaves a sequence gap for the fast path to send the corresponding packets in the future. By the time the packets from the slow path arrive, all packets from the fast path which have smaller sequence numbers should have already arrived <ref type="figure" target="#fig_9">(fig. 9b)</ref>. Since packets arrive in order, the normal ACK clocking is ensured, so there are no burst transmissions on the fast path and the send/receive window will not be blocked. Scheduler runs when one of sub-flow is available <ref type="bibr">2:</ref> if Fast sub-flow has space in send window then</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3:</head><p>Fast sub โ f low โunsentPackets <ref type="bibr">[0]</ref> 4:</p><p>elseSlow sub-flow has space in send window</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5:</head><p>Slow sub โ f low โunsentPackets <ref type="bibr">[Gap]</ref> 6: end if 7: end procedure</p><p>The key parameter of the scheduler algorithm is Gap, which is the number of packets pre-allocated for fast path to send. The efficiency of the scheduler algorithm depends on the accuracy of the gap value. Any deviation from the true value will cause out-of-order arrival of packets.</p><p>The naive way to get the gap value is to utilize the measurement of path conditions. If we can measure network conditions accurately, then we can derive the true gap value in the following way. It takes OW D f + Gap B f for all packets in the gap to arrive at the receiver through the fast path, where B f is the bandwidth of the fast path. This should be equal to OW D s so that the first packet from the slow path arrives at the same time as packets from the fast path. Then we have the true Gap value:</p><formula xml:id="formula_1">True Gap = B f ร (OW D s โ OW D f )<label>(2)</label></formula><p>However, the naive solution has two fundamental flaws. One is that the one-way delay of path can not be measured accurately. We can not assume the uplink delay and the downlink delay are the same on both paths. If we modify the protocol to carry the one-way delay information, it may cause other compatibility problem with middleboxes <ref type="bibr" target="#b14">[16]</ref>. The other one is that the bandwidth of the path can not be measured accurately, especially when the in-network buffer is limited. Because of the burst sending pattern of fast sub-flow, it can never reach the actual available bandwidth. So we design the feedback-based gap adjustment scheme to adjust the value of gap more accurately and quickly.</p><p>Key insight: Every out-of-order packet in the receiver will generate duplicate Data ACK or burst Data ACK.</p><p>What STMS actually does is moving stalled packets from the receiver to the sender (i.e., the packets inside gap). The out-of-order packets will be acknowledged at one time when packets from the slow path arrive to fill in the hole. The number of packets acknowledged by Data ACK reflects the degree of out-of-order arrival of packets. Accordingly we can use this as the feedback signal to adjust the gap value. Since Data ACK is presented in MPTCP, our scheme remains compatible with current MPTCP. In addition, this scheme does not require any modification at the receiver, which further eases the deployment process.</p><p>How to adjust The gap adjustment algorithm is shown in algorithm 2. Let delta gap and ad just interval be the gap adjustment step and interval. When the gap is smaller than the true gap value, the packets from the slow path arrive late and the send window of MPTCP-level will be stalled by packets sent from the slow path. Therefore the left edge of the send window is determined by unacknowledged packets from the slow path. Symmetrically, when the gap is bigger than the true gap value, the left edge of the send window will be determined by the packets sent from the fast path. Each time we receive a Data ACK, we first calculate how many packets this Data ACK acknowledged (data acked). If the data acked is bigger than 2, we will adapt the gap value.</p><p>We check the packet of the left edge of the send window. If the packet is the first one sent from the slow path, delta gap = data acked; otherwise, delta gap = โdata acked. We use the Exponentially Weighted Moving Average (EWMA) of delta gap over ad just interval to adjust the gap value. The ad just interval is a tunable parameter, which determines how fast the gap adjustment can react to the network change. Setting it too small will cause the gap overshoot and oscillation since the previous gap adjustment has not taken into effect yet. However, setting it too big leads to the slow convergence time. send una โ left edge of MPTCP-level send window <ref type="bibr">4:</ref> if send una was sent from slow path then</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5:</head><p>delta gap = data acked <ref type="bibr">6:</ref> elsesend una was sent from fast path </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Analysis of host buffer size requirement</head><p>At a first glance, buffering packets for the fast path may require a big buffer on the sender side. However, we can prove that when both paths are fully utilized, the send buffer requirement is actually less than that of the default scheduler without PR (eq. <ref type="formula" target="#formula_0">(1)</ref>). When using STMS the send buffer consists of three parts:</p><p>1. sent but unacknowledged packets from the fast path:</p><formula xml:id="formula_2">B f ร RT T f</formula><p>2. sent but unacknowledged packets from the slow path:</p><formula xml:id="formula_3">B s ร (OW D s + OW D f ) (</formula><p>Data packet is sent through the slow path, but ACK returns from the fast path).</p><p>3. buffered packets for the fast path i.e., True Gap (eq. <ref type="formula" target="#formula_1">(2)</ref>) By adding these three parts together, we get the buffer requirement of STMS:</p><formula xml:id="formula_4">Bu f (ST MS) = (B f + B s ) ร (OW D S + OW D f ) (3)</formula><p>This is smaller than Bu f (de f ault) (eq. <ref type="formula" target="#formula_0">(1)</ref>). It also reveals that STMS reduces the effective RTT of the MPTCP connection to OW D s + OW D f , which is the smallest RTT when both paths are utilized. Thus our STMS can reduce the send buffer requirement.</p><p>If we take into consideration the opportunistic retransmission, then in the ideal case, upon receiving the late arrival packet from the slow path, the Data ACK of the retransmitted packet will go back through the fast path. Therefore the effective RTT of the MP connection is reduced to OW D s + OW D f , which is the same as STMS and the buffer requirement is also the same.</p><p>When the host buffer is between [Bu f (ST MS), Bu f (de f ault)], both retransmission and STMS can improve the throughput. But STMS can always achieve the optimal throughput by ensuring RTT of MP connection to be the minimum.</p><p>If the host buffer is smaller than Bu f (ST MS), neither STMS nor default scheduler can get the full bandwidth aggregation. In this case, STMS will prefer to use the fast path. The slow path will be used only if it will not cause the blocking. The buffer requirement to take advantage of the use of the slow path is:</p><formula xml:id="formula_5">Bu f ( f allback) = RT T f ร B f + Gap = B f ร (OW D s + OW D f )<label>(4)</label></formula><p>When the host buffer is between [Bu f ( f allback), Bu f (ST MS)], STMS will use the fast path first, as the slow path will not block the fast path. However, for the default scheduler, the slow path will get the frequent use, which would trigger the retransmission of packets. This will further lead to the goodput degradation and the big end-to-end latency. What if the host buffer is even smaller than Bu f ( f allback)? Then STMS will fall back to the single TCP over the fast path. But the default scheduler will still send some packets from the slow path, which pushes the effective RTT of MPTCP connection to at least OW D s + OW D f . Thus the throughput will be even worse than the bandwidth B f allowed by the fast path alone. Actually, in this case, falling back to the single-path TCP is the optimal choice.</p><p>So our scheduler can get the optimal throughput across all range of host buffer sizes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Analysis of latency</head><p>It seems that STMS will cause the inflation of transmission latency because it holds packets in the gap longer than the default scheduler. However, it also reduces the time duration for the packets to be stalled in the receiver. Using both types of scheduler, the end-to-end latency of packets sent from the slow path is OW D s . The latency of the fast path is OW D f + Delay(Stalled). For each packet sent from the fast path, it is either stalled at the receiver buffer or held at the send buffer. Delay(Stalled) remains the same. Therefore STMS does not increase the average end-to-end latency of packets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Implementation</head><p>We implement STMS in the Linux kernel based on MPTCP version 0.92 from <ref type="bibr" target="#b6">[7]</ref>. The algorithm 1 is implemented as a scheduler module.</p><p>The MPTCP scheduler will run when two types of event happen. The first type of event happens when ACK returns from one of the sub-flows, which means there will be space in the sub-flow send window. The second type of event happens when application sends more data. The scheduler makes the decision every data segment. For each segment pushed in by the application, the scheduler will determine which sub-flow to send the packet. This framework of scheduler limits how we can implement our scheduler, since we can not access an arbitrary segment inside the send buffer. To remain compatible with this framework. We implement our scheduler as follows.</p><p>When the scheduler picks the next segment to send, we first check if the fast path is available, i.e., there is space in the send window. If the space is available, then send the packet over the fast path; otherwise, we check if the slow path is available. If it is available, we find the packet according to the gap value, i.e., jump across the gap packets to find the packets to send over the slow path. If the packet does not exist, that means either the packet is out of the right boundary of the send window or the application has not pushed enough data yet, in either of which case we skip this round of scheduling. Note that we need to mark the packets sent from the slow path so that we can skip the out-of-order packets when finding the next packet to send from the slow path. To avoid traversing the send buffer from the beginning each time, we save the pointer of the last send packet of the slow path as the beginning point for the next search.</p><p>We implement two variants of STMS: STMS-C ("Calculation") and STMS-A ("Adjustment"). They both preallocate packets for the fast sub-flow so that packets can arrive in-order at the receiver side ( ยง 3.1). They differ in how they obtain the gap value. Each time a packet is sent from the slow path, STMS-C extracts the bandwidth estimation of smoothed RTT from subflow TCP's algorithm and calculates the gap value (assume the uplink and downlink delay are symmetric). For STMS-A the Data ACK process function is modified to calculate delta gap according to algorithm 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Evaluation in a controlled lab environment</head><p>In this section, we test both STMS-C and STMS-A in a controlled lab setting, which allows us to evaluate the performance across a wide variety of network conditions. We compare our scheduler with the default scheduler with PR (denoted as Default thereafter) and ECF <ref type="bibr" target="#b21">[23]</ref>. ECF uses the send buffer length to estimate the flow complete time(FCT) of using each path. If using slow path will cause inflation of FCT, it will wait for fast sub-flow. However, for elephant flow, the send buffer is full for most of the time. Only when flow is about to finish, the send buffer length can be small enough to wait for fast subflow. Besides, when calculating the FCT, ECF does not take into account the one way delay thus it is not able to achieve accurate in-order arrival. STMS schedules the packets out-of-orderly to achieve the in-order arrival regardless of the send buffer status so STMS can outperform ECF. For apples-to-apples comparison, we port the ECF according to the analysis in ยง 3.1. The parameter of ECF is chosen as the same as <ref type="bibr" target="#b21">[23]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Microbenchmarks</head><p>We first focus on some micro-benchmarks to see whether our scheduler can accomplish the design goal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1">Reducing the out-of-order arrival at the receiver side</head><p>We first investigate whether our scheduler can achieve the in-order arrival at the receiver side. We use the outof-order (OOO) delay as the metric. The OOO delay of a packet is defined as the time difference between when a packet arrives at the receiver to when the packet can be submitted to the application (i.e., all packets with the smaller data sequence numbers have already arrived). <ref type="figure" target="#fig_0">fig. 10a</ref> shows the CDF of the OOO delay of each packet with different schedulers. STMS-C and STMS-A can both achieve smaller OOO delay than Default and ECF. The largest OOO delay is around 300ms. Default effectively pushes the OOO delay of most packets sent from fast path to OW D s . ECF sends tail packets out-oforderly so it can reduce OOO delay for those tail packets. However since we transmit many packets for a test, this delay reduction is negligible. STMS-A can effectively push the OOO delay close to zero.</p><p>We vary the latency of slow path and calculate average of OOO latency. The result of one experiment is shown in <ref type="figure" target="#fig_0">fig. 10b</ref>. When paths become more heterogeneous, both Default and ECF have larger OOO delay. However STMS-A can keep its average OOO delay at a very small value. When RTT of two paths are similar(20ms and 50ms), ECF, STMS-C and STMS-A get close performance.</p><p>We also test the OOO delay under different host buffer sizes. The result is shown in <ref type="figure" target="#fig_0">fig. 10</ref>. It demonstrates that both STMS-A and STMS-C can effectively reduce the OOO delay regardless of the host buffer size, and the gain is larger when the host buffer sizes are larger with more packets stalled at the receiver. For ECF, only when the send buffer is very small, it wait for fast sub-flow to reduce the OOO delay. We now study whether our scheduler can reduce the burst of the fast path thus the in-network buffer requirement accordingly. We print the CWND free space of the fast sub-flow when it receives ACK. Since all schedulers try to fill this free space, the peak value of CWND free space reflects the burst of fast path. The average CWND free space throughout the running time is used as a metric of burstness of fast subfow. The result is shown in <ref type="figure" target="#fig_0">fig. 11</ref>. The trend is the same as <ref type="figure" target="#fig_0">fig. 10b</ref>. Our scheduler can reduce the burstness of the fast path and makes it close to that of the single-path TCP.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2">Reducing the burst on the fast path</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.3">Gap adjustment is reactive to network change</head><p>To understand how STMS-A handles dynamic network conditions, we change the network conditions in the middle of MPTCP flow and record the gap value changes around the condition changing point. Recall that the true gap value is calculated using eq. (2). It is affected by the accuracy of the measurement of the fast path bandwidth and the one-way delay of both fast path and slow path. We choose to change the latency of the fast path and slow path to demonstrate how our Gap adjustment algorithm reacts to the network change. In <ref type="figure" target="#fig_0">fig. 12a</ref>, the latency of the fast path changes from 20ms to 5ms. Therefore there will be many ACK packets and the fast path can send a lot of packets out which leads to the wrong estimation of the bandwidth. Thus, we see the peak of the gap calculated value. However, our gap adjustment algorithm can converge to the new value smoothly. In <ref type="figure" target="#fig_0">fig. 12b</ref>, the latency of the slow path changes from 200ms to 100ms. Again STMS-A converges to the new value smoothly and fast. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Macrobenchmark: improving aggregated throughput</head><p>We then investigate how our scheduler improves the aggregated throughput under different buffer sizes setting.</p><p>Stable network condition We begin by investigating whether our scheduler improves the throughput when the network condition is stable. <ref type="figure" target="#fig_0">fig. 13</ref> shows the result. When the in-network buffer is limited, our scheduler can improve the throughput by about 30% compared to Default and ECF. When the host buffer is extremely limited, our scheduler falls back to single path TCP and outperforms Default as analyzed in ยง 3.2. When the host buffer is big enough(&gt;4MB), there is no blocking, so all four schedulers can get the full bandwidth aggregation effect.</p><p>The STMS-C and STMS-A produce analogous results under the same buffer settings, which indicates the gap adjustment algorithm can track the true gap value precisely.</p><p>We then vary the latency of slow path. Both STMS-C and STMS-A improve the aggregation throughput over Default and ECF. We pick the improvement of STMS-A over Default as an example. <ref type="figure" target="#fig_0">fig. 14</ref> shows the throughput of STMS-A normalized relative to that of Default. The improvement become more prominent as the paths become more heterogeneous and the buffer gets smaller.</p><p>Varying bandwidth Then we investigate the performance of our scheduler under network fluctuations. Here we change the bandwidth of both path randomly every 10 seconds. The bandwidth value is chosen from set {5, 10, 20, 30} Mbps. We generate 5 network configurations using different random seeds and run test five times for each network configurations. <ref type="figure" target="#fig_0">fig. 15a</ref> shows the average throughput of four schedulers for each configuration. Note the error bar indicates the variability of the same configuration. Our scheduler outperforms other schedulers in every configuration. STMS-A performs even better than the STMS-C. This indicates that STMS-A is more adaptive to network fluctuations than the STMS-C.</p><p>Varying latency We simulate the varying latency condition using tc netem module. Both paths' latency is changed every 10 seconds, and the stddev of latency is set to 40% of the mean latency. We generate five latency configurations and run the test five times <ref type="figure" target="#fig_0">(fig. 15b)</ref>. Similar to the bandwidth change scenario, STMS-A always performs best.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Evaluation in the wild</head><p>We next evaluate our scheduler in more realistic environments. The server is deployed in Aliyun <ref type="bibr" target="#b0">[1]</ref> and has only one interface. The client is located inside our campus and connects to the server through WiFi and LTE. The China Telecom LTE cellular network incurs higher delay than the WiFi network. The average bandwidth and latency characteristic of each path are shown in table 2. We use tc to add extra latency on LTE path.  Kuhn et al. <ref type="bibr" target="#b20">[22]</ref> propose DAPS to address the RTT difference of two paths. But it only considers the stable CWND and the scheduler running interval is very big thus can not react to the dynamic network changes.</p><p>Lim et al. <ref type="bibr" target="#b21">[23]</ref> propose ECF which outperforms both DAPS and BLEST. But it only considers the tail packets.</p><p>Guo et al. <ref type="bibr" target="#b12">[14]</ref> propose a new scheduler to balance two sub-flow completion time by sending packets inside a "chunk" in the opposite direction. Nonetheless, this approach will require a huge host buffer to store the whole chunk.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion</head><p>In this work, we identify a new root cause of MPTCP throughput degradation under heterogeneous path con- ditions. We propose STMS to effectively alleviate the problems due to the limitation in the host buffer size and in-network buffer size. Our experimental results show that STMS outperforms state-of-the-art schedulers in diverse network and buffer settings, especially when the path heterogeneity is large.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Out-of-order arrival and burst transmissions on the fast path due to the use of default scheduler. Green (lighter) packets are sent/received through the fast path, while blue (darker) ones are sent/received through the slow path.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Topology setup</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>(</head><label></label><figDesc>Figure 4: Burst sending pattern of fast path</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>(</head><label></label><figDesc>a) RT T f = 20ms, RT T s = 200ms (b) RT T f = 20ms, RT T s = 20ms</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Send window free space jitter when RTT differs</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>(</head><label></label><figDesc>Figure 7: CWND of fast sub-flow is capped when innetwork buffer is limited and RTTs are different.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>Another problem of MPTCP when RTTs are different is the big host buffer requirement. Let us denote the band- width of fast and slow sub-flow as B f and B s respectively. The one-way delay (OWD) values of both paths are de- noted as OW D f and OW D s respectively. The RTTs of both paths are denoted as RT T s and RT T f . Raciu et al.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: MPTCP throughput degradation when host buffer is limited</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Algorithm 1</head><label>1</label><figDesc>Slide Together Scheduler 1: procedure ST SCHEDULE(unsentPackets)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Demonstration of STMS, with green and blue for packets over fast and slow paths respectively. Let RT T s = 3RT T f and assume the uplink delay and downlink delay are symmetric, then we have gap = CW ND f according to eq. (2). Note that slow path always send packets with sequence numbers bigger than those of the fast path.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>7: delta gap = โdata acked 8: end if 9: end if 10: gap+ = EW MA(delta gap, ad just interval) 11: end procedure</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 10 :</head><label>10</label><figDesc>Figure 10: Out-of-order latency of different schedulers</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 11 :</head><label>11</label><figDesc>Figure 11: Burstness of all four schedulers under different path latencies</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 12 :</head><label>12</label><figDesc>Figure 12: Gap adjustment is reactive to network change</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 13 :</head><label>13</label><figDesc>Figure 13: Throughput of different schedulers</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Figure 16 :</head><label>16</label><figDesc>Figure 16: Average file download time in the wild (lower is better)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 : Loss rate of fast path under different in-network buffer setting in-network buffer/KB observed loss rate Fast path in MPTCP/Mbps Single TCP/</head><label>1</label><figDesc></figDesc><table>Mbps Utilization 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 : Path characteristics</head><label>2</label><figDesc></figDesc><table>Bandwidth(Mbps) Latency(ms) 
WiFi 
40 
50 
LTE 
30 
70 </table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Related work</head><p>There are many studies on the improvement of MPTCP scheduler. To solve the host buffer problem, Raiciu et al. <ref type="bibr" target="#b24">[26]</ref> propose the PR mechanism. Ferlin et al. <ref type="bibr" target="#b10">[11]</ref> propose the Blocking Estimation-based Scheduler (BLEST) which aims to prevent the blocking by reducing the usage of slow path even if it has available CWND space. Both schedulers try to restrict the use of the slow path to alleviate the need of big host buffer resulting in the under-utilization of slow path.</p><p>Acknowledgments. We thank the anonymous reviewers and our shepherd Theophilus Benson for their feedback on the paper. This work is supported by National Key R&amp;D Program of China under Grant 2017YFB1010002, National 863 project (no. 2015AA015701) and a joint research with Protocol Research Lab, Huawei Technologies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>USENIX Association</head></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alibaba</forename><surname>Cloud</surname></persName>
		</author>
		<ptr target="https://www.alibabacloud.com/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Increasing datacenter network utilisation with grin</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Agache</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Deaconescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raiciu</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NSDI</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="29" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Sizing router buffers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Appenzeller</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Keslassy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mckeown</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<publisher>ACM</publisher>
			<biblScope unit="volume">34</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<ptr target="http://www.tessares.net/highlights-from-advances-in-networking-part-1/" />
		<title level="m">APPLE Opens Multipath TCP In iOS11</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Balanced Linked Adaptation Congestion Control Algorithm for MPTCP</title>
		<ptr target="https://tools.ietf.org/html/draft-walid-mptcp-congestion-control-00" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Requirements for internet hosts-communication layers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Braden</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Paasch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Barre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">A</forename></persName>
		</author>
		<ptr target="http://www.multipath-tcp.org" />
		<title level="m">Multipath TCP in the Linux Kernel</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cardwell</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gunn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">S</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yeganeh</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">H</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacobson</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bbr: Congestion-based congestion control. Queue</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page">50</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">lte, or both?: Measuring multi-homed wireless internet performance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deng</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Netravali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sivaraman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>And Balakr-Ishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wifi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Internet Measurement Conference</title>
		<meeting>the 2014 Conference on Internet Measurement Conference</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="181" to="194" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
				<ptr target="http://www.cs.umass.edu/~ylim/mptcp_ecf" />
		<title level="m">ECF implementation in old MPTCP version</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Blocking estimation-based mptcp scheduler for heterogeneous networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ferlin</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Alay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">ยจ</forename><forename type="middle">O</forename><surname>Mehani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boreli</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Blest</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IFIP Networking Conference (IFIP Networking) and Workshops</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="431" to="439" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Tcp extensions for multipath operation with multiple addresses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ford</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Raiciu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Handley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bonaventure</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Tech. rep</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Accelerating multipath transport through balanced subflow completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guo</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">E</forename><surname>Nikravesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><forename type="middle">M</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sen</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd Annual International Conference on Mobile Computing and Networking</title>
		<meeting>the 23rd Annual International Conference on Mobile Computing and Networking</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="141" to="153" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Mp-dash: Adaptive video streaming over preference-aware multipath</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">I</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Gopalakrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bedminster</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th International on Conference on emerging Networking EXperiments and Technologies</title>
		<meeting>the 12th International on Conference on emerging Networking EXperiments and Technologies</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="129" to="143" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Is it still possible to extend tcp?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Honda</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nishida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Raiciu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Greenhalgh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Handley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tokuda</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2011 ACM SIGCOMM conference on Internet measurement conference</title>
		<meeting>the 2011 ACM SIGCOMM conference on Internet measurement conference</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="181" to="194" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A close examination of performance and power characteristics of 4g lte networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Gerber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><forename type="middle">M</forename><surname>Sen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Spatscheck</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th international conference on Mobile systems, applications, and services</title>
		<meeting>the 10th international conference on Mobile systems, applications, and services</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="225" to="238" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tcp</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Udp</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sctp</forename></persName>
		</author>
		<ptr target="https://iperf.fr/iperf-download.php" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Congestion avoidance and control</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacobson</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIG-COMM computer communication review</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1988" />
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="314" to="329" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Tackling bufferbloat in 3g/4g networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rhee</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 ACM conference on Internet measurement conference</title>
		<meeting>the 2012 ACM conference on Internet measurement conference</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="329" to="342" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Mptcp is not pareto-optimal: performance issues and a possible solution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Khalili</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Gast</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Popovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Upadhyay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">E</forename><surname>Boudec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-Y</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th international conference on Emerging networking experiments and technologies</title>
		<meeting>the 8th international conference on Emerging networking experiments and technologies</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Daps: Intelligent delay-aware packet scheduling for multipath transport</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuhn</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Lochin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Mifdaoui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sarwar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Mehani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boreli</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1222" to="1227" />
		</imprint>
	</monogr>
	<note>Communications (ICC)</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">An mptcp path scheduler to manage heterogeneous paths</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lim</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-S</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nahum</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">M</forename><surname>Towsley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gibbens</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Ecf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 ACM SIGMETRICS/International Conference on Measurement and Modeling of Computer Systems</title>
		<meeting>the 2017 ACM SIGMETRICS/International Conference on Measurement and Modeling of Computer Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="33" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">An in-depth understanding of multipath tcp on mobile devices: measurement and system design</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikravesh</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><forename type="middle">M</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sen</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd Annual International Conference on Mobile Computing and Networking</title>
		<meeting>the 22nd Annual International Conference on Mobile Computing and Networking</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="189" to="201" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">On the benefits of applying experimental design to improve multipath tcp</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paasch</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Khalili</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bonaventure</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ninth ACM conference on Emerging networking experiments and technologies</title>
		<meeting>the ninth ACM conference on Emerging networking experiments and technologies</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="393" to="398" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">How hard can it be? designing and implementing a deployable multipath tcp</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raiciu</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Paasch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Barre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Honda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Duchene</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Bonaventure</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Handley</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th USENIX conference on Networked Systems Design and Implementation</title>
		<meeting>the 9th USENIX conference on Networked Systems Design and Implementation</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="29" to="29" />
		</imprint>
	</monogr>
	<note>USENIX Association</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">In</forename><surname>Korean</surname></persName>
		</author>
		<ptr target="http://blog.multipath-tcp.org/blog/html/2015/07/24/korea.html" />
	</analytic>
	<monogr>
		<title level="j">Multipath TCP is pronounced GIGA Path</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Why is the Multipath TCP scheduler so important ?</title>
		<ptr target="http://blog.multipath-tcp.org/blog/html/2014/03/30/why_is_the_multipath_tcp_scheduler_so_important.html" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Cell vs. wifi: on the performance of metro area mobile connections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sommers</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barford</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 ACM conference on Internet measurement conference</title>
		<meeting>the 2012 ACM conference on Internet measurement conference</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="301" to="314" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
				<ptr target="http://lartc.org/lartc.html" />
		<title level="m">tc: Linux Advanced Routing and Traffic Control</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Design, implementation and evaluation of congestion control for multipath tcp</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wischik</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Raiciu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Greenhalgh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Handley</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NSDI</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="8" to="8" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
