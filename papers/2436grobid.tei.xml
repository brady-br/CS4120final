<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2020-09-29T02:41+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">This paper is included in the Proceedings of the 16th USENIX Conference on File and Storage Technologies. Open access to the Proceedings of the 16th USENIX Conference on File and Storage Technologies is sponsored by USENIX. MQSim: A Framework for Enabling Realistic Studies of Modern Multi-Queue SSD Devices MQSim: A Framework for Enabling Realistic Studies of Modern Multi-Queue SSD Devices</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arash</forename><surname>Tavakkol</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Saugata Ghose, Carnegie Mellon University; Onur Mutlu, ETH Zürich and Carnegie Mellon University</orgName>
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<addrLine>February 12-15</addrLine>
									<postCode>2018 •</postCode>
									<settlement>Oakland</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juan</forename><surname>Gómez-Luna</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Saugata Ghose, Carnegie Mellon University; Onur Mutlu, ETH Zürich and Carnegie Mellon University</orgName>
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<addrLine>February 12-15</addrLine>
									<postCode>2018 •</postCode>
									<settlement>Oakland</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Sadrosadati</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Saugata Ghose, Carnegie Mellon University; Onur Mutlu, ETH Zürich and Carnegie Mellon University</orgName>
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<addrLine>February 12-15</addrLine>
									<postCode>2018 •</postCode>
									<settlement>Oakland</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eth</forename><surname>Zürich</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Saugata Ghose, Carnegie Mellon University; Onur Mutlu, ETH Zürich and Carnegie Mellon University</orgName>
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<addrLine>February 12-15</addrLine>
									<postCode>2018 •</postCode>
									<settlement>Oakland</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arash</forename><surname>Tavakkol</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Saugata Ghose, Carnegie Mellon University; Onur Mutlu, ETH Zürich and Carnegie Mellon University</orgName>
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<addrLine>February 12-15</addrLine>
									<postCode>2018 •</postCode>
									<settlement>Oakland</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juan</forename><surname>Gómez-Luna</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Saugata Ghose, Carnegie Mellon University; Onur Mutlu, ETH Zürich and Carnegie Mellon University</orgName>
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<addrLine>February 12-15</addrLine>
									<postCode>2018 •</postCode>
									<settlement>Oakland</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Sadrosadati</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Saugata Ghose, Carnegie Mellon University; Onur Mutlu, ETH Zürich and Carnegie Mellon University</orgName>
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<addrLine>February 12-15</addrLine>
									<postCode>2018 •</postCode>
									<settlement>Oakland</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saugata</forename><surname>Ghose</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Saugata Ghose, Carnegie Mellon University; Onur Mutlu, ETH Zürich and Carnegie Mellon University</orgName>
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<addrLine>February 12-15</addrLine>
									<postCode>2018 •</postCode>
									<settlement>Oakland</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Onur</forename><surname>Mutlu</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Saugata Ghose, Carnegie Mellon University; Onur Mutlu, ETH Zürich and Carnegie Mellon University</orgName>
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<addrLine>February 12-15</addrLine>
									<postCode>2018 •</postCode>
									<settlement>Oakland</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eth</forename><surname>Zürich</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Saugata Ghose, Carnegie Mellon University; Onur Mutlu, ETH Zürich and Carnegie Mellon University</orgName>
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<addrLine>February 12-15</addrLine>
									<postCode>2018 •</postCode>
									<settlement>Oakland</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">This paper is included in the Proceedings of the 16th USENIX Conference on File and Storage Technologies. Open access to the Proceedings of the 16th USENIX Conference on File and Storage Technologies is sponsored by USENIX. MQSim: A Framework for Enabling Realistic Studies of Modern Multi-Queue SSD Devices MQSim: A Framework for Enabling Realistic Studies of Modern Multi-Queue SSD Devices</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Solid-state drives (SSDs) are used in a wide array of computer systems today, including in datacenters and enterprise servers. As the I/O demands of these systems continue to increase, manufacturers are evolving SSD ar-chitectures to keep up with this demand. For example, manufacturers have introduced new high-bandwidth interfaces to replace the conventional SATA host-interface protocol. These new interfaces, such as the NVMe protocol , are designed specifically to enable the high amounts of concurrent I/O bandwidth that SSDs are capable of delivering. While modern SSDs with sophisticated features such as the NVMe protocol are already on the market, existing SSD simulation tools have fallen behind, as they do not capture these new features. We find that state-of-the-art SSD simulators have three shortcomings that prevent them from accurately modeling the performance of real off-the-shelf SSDs. First, these simulators do not model critical features of new protocols (e.g., NVMe), such as their use of multiple application-level queues for requests and the elimination of OS intervention for I/O request processing. Second, these simulators often do not accurately capture the impact of advanced SSD maintenance algorithms (e.g., garbage collection), as they do not properly or quickly emulate steady-state conditions that can significantly change the behavior of these algorithms in real SSDs. Third, these simulators do not capture the full end-to-end latency of I/O requests, which can incorrectly skew the results reported for SSDs that make use of emerging non-volatile memory technologies. By not accurately modeling these three features, existing sim-ulators report results that deviate significantly from real SSD performance. In this work, we introduce a new simulator, called MQSim, that accurately models the performance of both modern SSDs and conventional SATA-based SSDs. MQSim faithfully models new high-bandwidth protocol implementations, steady-state SSD conditions, and the full end-to-end latency of requests in modern SSDs. We validate MQSim, showing that it reports performance results that are only 6%-18% apart from the measured actual performance of four real state-of-the-art SSDs. We show that by modeling critical features of modern SSDs, MQSim uncovers several real and important issues that were not captured by existing simulators, such as the performance impact of inter-flow interference. We have released MQSim as an open-source tool, and we hope that it can enable researchers to explore directions in new and different areas.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Solid-state drives (SSDs) are widely used in today's computer systems. Due to their high throughput, low response time, and decreasing cost, SSDs have replaced traditional magnetic hard disk drives (HDDs) in many datacenters and enterprise servers, as well as in consumer devices. As the I/O demand of both enterprise and consumer applications continues to grow, SSD architectures are rapidly evolving to deliver improved performance.</p><p>For example, a major innovation has been the introduction of new host interfaces to the SSD. In the past, many SSDs made use of the Serial Advanced Technology Attachment (SATA) protocol <ref type="bibr" target="#b66">[67]</ref>, which was originally designed for HDDs. Over time, SATA has proven to be inefficient for SSDs, as it cannot enable the fast I/O accesses and millions of I/O operations per second (IOPS) that contemporary SSDs are capable of delivering. New protocols such as NVMe <ref type="bibr" target="#b62">[63]</ref> overcome these barriers as they are designed specifically for the high throughput available in SSDs. NVMe enables high throughput and low latency for I/O requests through its use of the multi-queue SSD (MQ-SSD) concept. While SATA exposes only a single request port to the OS, MQ-SSD protocols provide multiple request queues to directly expose applications to the SSD device controller. This allows (1) an application to bypass OS intervention for I/O request processing, and (2) the SSD controller to schedule I/O requests based on how busy the SSD's resources are. As a result, the SSD can make higher-performance I/O request scheduling decisions.</p><p>As SSDs and their associated protocols evolve to keep pace with changing system demands, the research community needs simulation tools that reliably model these new features. Unfortunately, state-of-the-art SSD simulators do not model a number of key properties of modern SSDs that are already on the market. We evaluate several real modern SSDs, and find that state-of-the-art simulators do not capture three features that are critical to accurately model modern SSD behavior.</p><p>First, these simulators do not correctly model the multi-queue approach used in modern SSD protocols. Instead, they implement only the single-queue approach used in HDD-based protocols such as SATA. As a result, existing simulators do not capture (1) the high amount of request-level parallelism and (2) the lack of OS intervention in modern SSDs.</p><p>Second, many simulators do not adequately model steady-state behavior within a reasonable amount of simulation time. A number of fundamental SSD maintenance algorithms, such as garbage collection <ref type="bibr">[11- 13, 23]</ref>, are not executed when an SSD is new (i.e., no data has been written to the drive). As a result, manufacturers design these maintenance algorithms to work best when an SSD reaches the steady-state operating point (i.e., after all of the pages within the SSD have been written to at least once) <ref type="bibr" target="#b70">[71]</ref>. However, simulators that cannot capture steady-state behavior (within a reasonable simulation time) perform these maintenance algorithms on a new SSD. As such, many existing simulators do not adequately capture algorithm behavior under realistic conditions, and often report unrealistic SSD performance results (as we discuss in Section 3.2).</p><p>Third, these simulators do not capture the full end-toend latency of performing I/O requests. Existing simulators capture only the part of the request latency that takes place during intra-SSD operations. However, many emerging high-speed non-volatile memories greatly reduce the latency of intra-SSD operations, and, thus, the uncaptured parts of the latency now make up a significant portion of the overall request latency. For example, in Intel Optane SSDs, which make use of 3D XPoint memory <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b24">25]</ref>, the overhead of processing a request and transferring data over the system I/O bus (e.g., PCIe) is much higher than the memory access latency <ref type="bibr" target="#b15">[16]</ref>. By not capturing the full end-to-end latency, existing simulators do not report the true performance of SSDs with new and emerging memory technologies.</p><p>Based on our evaluation of real modern SSDs, we find that these three features are essential for a simulator to capture. Because existing simulators do not model these features adequately, their results deviate significantly from the performance of real SSDs. Our goal in this work is to develop a new SSD simulator that can faithfully model the features and performance of both modern multi-queue SSDs and conventional SATA-based SSDs.</p><p>To this end, we introduce MQSim, a new simulator that provides an accurate and flexible framework for evaluating SSDs. MQSim addresses the three shortcomings we found in existing simulators, by (1) providing detailed models of both conventional (e.g., SATA) and modern (e.g., NVMe) host interfaces; (2) accurately and quickly modeling steady-state SSD behavior; and (3) measuring the full end-to-end latency of a request, from the time an application enqueues a request to the time the request response arrives at the host. To allow MQSim to adapt easily to future SSD developments, we employ a modular design for the simulator. Our modular approach allows users to easily modify the implementation of a single component (e.g., I/O scheduler, address mapping) without the need to change other parts of the simulator. We provide two execution modes for MQSim: (1) standalone execution, and (2) integrated execution with the gem5 full-system simulator <ref type="bibr" target="#b7">[8]</ref>. We validate the performance reported by MQSim using several real SSDs. We find that the response time results reported by MQSim are very close to the response times of the real SSDs, with an average (maximum) error of only 11% (18%) for real storage workload traces.</p><p>By faithfully modeling the major features found in modern SSDs, MQSim can uncover several issues that existing simulators are unable to demonstrate. One such issue is the performance impact of inter-flow interference in modern MQ-SSDs. For two or more concurrent flows (i.e., streams of I/O requests from multiple applications), there are three major sources of interference: (1) the write cache, (2) the mapping table, and (3) the I/O scheduler. Using MQSim, we find that inter-flow interference leads to significant unfairness (i.e., the interference slows down each flow unequally) in modern SSDs. This is a major concern, as fairness is a first-class design goal in modern computing platforms <ref type="bibr">[4, 17, 19, 31, 37, 56- 60, 66, 73-76, 80, 84, 88]</ref>. Unfairness reduces the predictability of the I/O latency and throughput for each flow, and can allow a malicious flow to deny or delay I/O service to other, benign flows.</p><p>We have made MQSim available as an open source tool to the research community <ref type="bibr" target="#b0">[1]</ref>. We hope that MQSim enables researchers to explore directions in several new and different areas.</p><p>We make the following key contributions in this work: • We use real off-the-shelf SSDs to show that stateof-the-art SSD simulators do not adequately capture three important properties of modern SSDs: (1) the multi-queue model used by modern host-interface protocols such as NVMe, (2) steady-state SSD behavior, and (3) the end-to-end I/O request latency.</p><p>• We introduce MQSim, a simulator that accurately models both modern NVMe-based and conventional SATA-based SSDs. To our knowledge, MQSim is the first publicly-available SSD simulator to faithfully model the NVMe protocol. We validate the results reported by MQSim against several real state-of-the-art multi-queue SSDs.</p><p>• We demonstrate how MQSim can uncover important issues in modern SSDs that existing simulators cannot capture, such as the impact of inter-flow interference on fairness and system performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head><p>In this section, we provide a brief background on multiqueue SSD (MQ-SSD) devices. First, we discuss the internal organization of an MQ-SSD (Section 2.1). Next, we discuss host-interface protocols commonly used by SSDs (Section 2.2). Finally, we discuss how the SSD flash translation layer (FTL) handles requests and performs maintenance tasks (Section 2.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">SSD Internals</head><p>Modern MQ-SSDs are typically built using NAND flash memory chips. NAND flash memory <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12]</ref> supports read and write operations at the granularity of a flash page (typically 4 kB). Inside the NAND flash chips, multiple pages are grouped together into a flash block, which is the granularity at which erase operations take place. Flash writes can take place only to pages that are erased (i.e., free). To minimize the write latency, MQ-SSDs perform out-of-place updates (i.e., when a logical page is updated, its data is written to a different, free physical page, and the logical-to-physical mapping is updated). This avoids the need to erase the old physical page during a write operation. Instead, the old page is marked as invalid, and a garbage collection procedure <ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b11">[12]</ref><ref type="bibr" target="#b12">[13]</ref><ref type="bibr" target="#b22">23]</ref> reclaims invalid physical pages in the background. <ref type="figure">Figure 1</ref> shows the internal organization of an MQ-SSD. The components inside the MQ-SSD are divided into two groups: (1) the back end, which includes the memory devices; and (2) the front end, which includes the control and management units. The memory devices (e.g., NAND flash memory <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12]</ref>, phase-change  <ref type="table" target="#tab_2">Plane1  Multiplexed  Interface  Multiplexed  Interface  Bus   Interface Bus  Interface  Multiplexed  Interface  Bus   Interface   1</ref> 2 3 3 <ref type="figure">Figure 1</ref>: Organization of an MQ-SSD. As highlighted in the <ref type="figure" target="#fig_1">figure ( 1 , 2 , 3</ref> ), our MQSim simulator captures several aspects of MQ-SSDs not modeled by existing simulators.</p><p>memory <ref type="bibr" target="#b41">[42]</ref>, STT-MRAM <ref type="bibr" target="#b39">[40]</ref>, 3D XPoint <ref type="bibr" target="#b8">[9]</ref>) in the back end are organized in a highly-hierarchical manner to maximize I/O concurrency. The back end contains multiple independent bus channels, which connect the memory devices to the front end. Each channel connects to one or more memory chips. For a NAND flash memory based SSD, each NAND flash chip is typically divided into multiple dies, where each die can independently execute memory commands. All of the dies within a chip share a common communication interface. Each die is made up of one or more planes, which are arrays of flash cells. Each plane contains multiple blocks. Multiple planes within a single die can execute memory operations in parallel only if each plane is executing the same command on the same address offset within the plane.</p><p>In an MQ-SSD, the front end includes three major components <ref type="bibr" target="#b46">[47]</ref>. <ref type="formula">(1)</ref> The host-interface logic (HIL) implements the protocol used to communicate with the host (Section 2.2). (2) The flash translation layer (FTL) manages flash resources and processes I/O requests (Section 2.3). (3) The flash chip controllers (FCCs) send commands to and transfer data to/from the memory chips in the back end. The front end contains on-board DRAM, which is used by the three components to cache application data and store data structures for flash management.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Host-Interface Logic</head><p>The HIL plays a critical role in leveraging the internal parallelism of the NAND flash memory to provide higher I/O performance to the host. The SATA protocol <ref type="bibr" target="#b66">[67]</ref> is commonly used for conventional SSDs, due to widespread support for SATA on enterprise and client systems. SATA employs Native Command Queuing (NCQ), which allows the SSD to concurrently execute I/O requests. NCQ allows the SSD to schedule multiple I/O requests based on which back end resources are currently idle <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b49">50]</ref>.</p><p>The NVM Express (NVMe) protocol <ref type="bibr" target="#b62">[63]</ref> was designed to alleviate the bottlenecks of SATA <ref type="bibr" target="#b89">[90]</ref>, and to enable scalable, high-bandwidth, and low-latency communication over the PCIe bus. When an application issues an I/O request in NVMe, it bypasses the I/O stack in the OS and the block layer queue, and instead directly inserts the request into a submission queue (SQ in <ref type="figure">Fig- ure 1</ref>) dedicated to the application. The SSD then selects a request from the SQ, performs the request, and inserts the request's job completion information (e.g., ack, read data) into the request completion queue (CQ) for the corresponding application. NVMe has already been widely adopted in modern SSD products <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b63">64,</ref><ref type="bibr" target="#b78">79,</ref><ref type="bibr" target="#b84">85,</ref><ref type="bibr" target="#b85">86]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Flash Translation Layer</head><p>The FTL executes on a microprocessor within the SSD, performing I/O requests and flash management procedures <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12]</ref>. Handling an I/O request in the FTL requires four steps for an SSD using NVMe. First, when the HIL selects a request from the SQ, it inserts the request into a device-level queue. Second, the HIL breaks the request down into multiple flash transactions, where each transaction is at the granularity of a single page. Next, the FTL checks if the request is a write. If it is, and the MQ-SSD supports write caching, the write cache management unit stores the data for each transaction in the write cache space within DRAM, and asks the HIL to prepare a response. Otherwise, the FTL translates the logical page address (LPA) of the transaction into a physical page address (PPA), and enqueues the transaction into the corresponding chip-level queue. There are separate queues for reads (RDQ) and for writes (WRQ). The transaction scheduling unit (TSU) resolves resource contention among the pending transactions in the chip-level queue, and sends transactions that can be performed to its corresponding FCC <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b77">78]</ref>. Finally, when all transactions for a request finish, the FTL asks the HIL to prepare a response, which is then delivered to the host.</p><p>The address translation module of the FTL plays a key role in implementing out-of-place updates. When a transaction writes to an LPA, a page allocation scheme assigns the LPA to a free PPA. The LPA-to-PPA mapping is recorded in a mapping table, which is stored within the non-volatile memory and cached in DRAM (to reduce the latency of mapping lookups) <ref type="bibr" target="#b23">[24]</ref>. When a transaction reads from an LPA, the module searches for the LPA's mapping and retrieves the PPA.</p><p>The FTL is also responsible for memory wearout management (i.e., wear-leveling) and garbage collection (GC) <ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b11">[12]</ref><ref type="bibr" target="#b12">[13]</ref><ref type="bibr" target="#b22">23]</ref>. GC is triggered when the number of free pages drops below a threshold. The GC procedure reclaims invalidated pages, by selecting a candidate block with a high number of invalid pages, moving any valid pages in the block into a free block, and then erasing the candidate block. Any read and write transactions generated during GC are inserted into dedicated read (GC-RDQ) and write (GC-WRQ) queues. This allows the transaction scheduling unit to schedule GC-related requests during idle periods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Simulation Challenges for</head><p>Modern MQ-SSDs</p><p>In this section, we compare the capabilities of state-ofthe-art SSD simulators to the common features of the modern SSD devices. As shown in <ref type="figure">Figure 1</ref>, we identify three significant features of modern SSDs that are not supported by current simulation tools: 1 multi-queue support, 2 fast modeling of steady-state behavior, and <ref type="bibr" target="#b2">3</ref> proper modeling of the end-to-end request latency. While some of these features are also present in some conventional SSDs, their lack of support in existing simulators is more critical when we evaluate modern and emerging MQ-SSDs, resulting in large deviations between simulation results and measured performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Multi-Queue Support</head><p>A fundamental difference of a modern MQ-SSD from a conventional SSD is its use of multiple queues that directly expose the device controller to applications <ref type="bibr" target="#b89">[90]</ref>. For conventional SSDs, the OS I/O scheduler coordinates concurrent accesses to the storage devices and ensures fairness for co-running applications <ref type="bibr" target="#b65">[66,</ref><ref type="bibr" target="#b67">68]</ref>. MQSSDs eliminate the OS I/O scheduler, and are themselves responsible for fairly servicing I/O requests from concurrently-running applications and guaranteeing high responsiveness. Exposing application-level queues to the storage device enables the use of many optimized management techniques in the MQ-SSD controller, which can provide high performance and a high level of both fairness and responsiveness. This is mainly due to the fact that the device controller can make better scheduling decisions than the OS, as the device controller knows the current status of the SSD's internal resources. We investigate how the performance of a flow 1 changes when the flow is concurrently executed with other flows on real MQ-SSDs. We conduct a set of experiments where we control the intensity of synthetic workloads that run on four new off-the-shelf MQ-SSDs released between 2016 and 2017 (see <ref type="table" target="#tab_5">Table 4</ref> and Appendix A). In each experiment, there are two flows, is the response time of f i when it runs alone. Fairness (F) is calculated as <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b55">56,</ref><ref type="bibr" target="#b57">58]</ref>:</p><formula xml:id="formula_0">F = MIN i {S f i } MAX i {S f i } (1)</formula><p>According to the above definition: 0 &lt; F ≤ 1. Lower F values indicate higher differences between the minimum and maximum slowdowns of all concurrently-running flows, which we say is more unfair to the flow that is slowed down the most. Higher F values are desirable. <ref type="figure" target="#fig_1">Figure 2</ref> depicts the slowdown, normalized throughput (IOPS), and fairness results when we execute Flow-1 and Flow-2 concurrently on our four target MQ-SSDs (which we call SSD-A, SSD-B, SSD-C, and SSD-D). The x-axes in all of the plots in <ref type="figure" target="#fig_1">Figure 2</ref> represent the queue depth (i.e., the flow intensity) of Flow-2 in the experiments. For each SSD, we show three plots from left to right: (1) the slowdown and normalized throughput of Flow-1, (2) the slowdown and normalized throughput of Flow-2, and (3) fairness. We make four major observations from <ref type="figure" target="#fig_1">Figure 2</ref>. First, in SSD-A, SSD-B, and SSD-C, the throughput of Flow-2 substantially increases proportionately with the queue depth. Aside from the maximum bandwidth available from the SSD, there is no limit on the throughput of each I/O flow. Second, Flow-1 is slowed down significantly due to interference from Flow-2 when the I/O queue depth of Flow-2 is much greater than that of Flow-1. Third, for SSD-A, SSD-B, and SSD-C, the slowdown of Flow-2 becomes almost negligible (i.e., its value approaches 1) as the intensity of Flow-2 increases. Fourth, SSD-D limits the maximum throughput of each flow, and thus the negative impact of Flow-2 on the performance of Flow-1 is well controlled. Further experiments with a higher number of flows reveal that one flow cannot exploit more than a quarter of the full I/O bandwidth of SSD-D, indicating that SSD-D has some level of internal fairness control. In contrast, one flow can unfairly exploit the full I/O capabilities of the other three SSDs.</p><p>We conclude that (1) the relative intensity of each flow significantly impacts the throughput delivered to each flow; and (2) MQ-SSDs with fairness controls, such as SSD-D, perform differently from MQ-SSDs without fairness controls when the relative intensities of concurrently-running flows differ. Thus, to accurately model the performance of MQ-SSDs, an SSD simulator needs to model multiple queues and enable multiple concurrently-running flows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Steady-State Behavior</head><p>SSD performance evaluation standards explicitly clarify that the SSD performance should be reported in the steady state <ref type="bibr" target="#b70">[71]</ref>. <ref type="bibr" target="#b1">2</ref> As a consequence, pre-conditioning (i.e., quickly reaching steady state) is an essential requirement for SSD device performance evaluation, in order to ensure that the results are collected in the steady state. This policy is important for three reasons. First, the garbage collection (GC) activities are invoked only when the device has performed a certain number of writes, which causes the number of free pages in the SSD to drop below the GC threshold. GC activities interfere with user I/O activity and can significantly affect the sustained device performance. However, a fresh out-ofthe-box (FOB) device is unlikely to execute GC. Hence, performance results on an FOB device are unrealistic as they would not account for GC <ref type="bibr" target="#b70">[71]</ref>. Second, the steadystate benefits of the write cache may be lower than the short-term benefits, particularly for write-heavy workloads. More precisely, in the steady state, the write cache is filled with application data and warmed up, and it is highly likely that no free slot can be allocated to new write requests. This leads to cache evictions and increased flash write traffic in the back end <ref type="bibr" target="#b32">[33]</ref>. Third, the physical data placement of currently-running applications is highly dependent on the device usage history and the data placement of previous processes. For example, which physical pages are currently free in the SSD depends on how previous I/O requests wrote to and in-validated physical pages. As a result, channel-and chiplevel parallelism in SSDs is limited in the steady state.</p><p>Although a number of works do successfully precondition and simulate steady-state behavior, many previous studies have not explored the effect of steady-state behavior on their proposals. Instead, their simulations start with an FOB SSD, and never reach steady state (e.g., when each physical page of the SSD has been written to at least once). Most well-known storage traces are not large enough to fill the entire storage space of a modern SSD. <ref type="figure">Figure 3</ref> shows the total write volume of popular storage workloads <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b52">[53]</ref><ref type="bibr" target="#b53">[54]</ref><ref type="bibr" target="#b54">[55]</ref><ref type="bibr" target="#b60">61]</ref>. We observe that most of the workloads have a total write volume that is much smaller than the storage capacity of most SSDs, with an average write volume of 60 GB. Even for the few workloads that are large enough to fill the SSD, it is time consuming for many existing simulators to simulate each I/O request and reach steady state (see Section 5). Therefore, it is crucial to have a simulator that enables efficient and high-performance steady-state simulation of SSDs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Real End-to-End Latency</head><p>Request latency is a critical factor of MQ-SSD performance, since it affects how long an application stalls on an I/O request. The end-to-end latency of an I/O request, from the time it is inserted into the host submission queue to the time the response is sent back from the MQ-SSD device to the completion queue, includes seven different parts, as we show in <ref type="figure" target="#fig_2">Figure 4</ref>. Existing simulation tools model only some parts of the end-to-end latency, which are usually considered to be the dominant parts of the end-to-end latency <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b37">38]</ref>. <ref type="figure" target="#fig_2">Figure 4a</ref> illustrates the end-to-end latency diagram for a small 4 kB read request in a typical NAND flashbased MQ-SSD. It includes I/O job enqueuing in the submission queue (SQ) 1 , host-to-device I/O job transfer over the PCIe bus 2 , address translation and transaction scheduling in the FTL 3 , read command and address transfer to the flash chip 4 , flash chip read 5 , read data transfer over the Open NAND Flash Interface (ONFI) <ref type="bibr" target="#b64">[65]</ref> bus 6 , and device-to-host read data transfer over the PCIe bus <ref type="bibr" target="#b6">7</ref> . Steps 5 and 6 are assumed to be the most time-consuming parts in the end-to-end request processing. Considering typical latency values for an 8 kB page read operation, the I/O job insertion (&lt; 1 µs, as measured on our real SSDs), the FTL request processing on a multicore processor (1 µs) <ref type="bibr" target="#b46">[47]</ref>   quest processing may not always be negligible, and can even become comparable to the flash read access time. For example, prior work <ref type="bibr" target="#b25">[26]</ref> shows that if the FTL uses page-level address mapping, then a workload without locality incurs a large number of misses in the cached mapping table (CMT). In case of a miss in the CMT, the user read operation stalls until the mapping data is read from the SSD back end and transferred to the front end <ref type="bibr" target="#b23">[24]</ref>. This can lead to a substantial increase in the latency of Step 3 in <ref type="figure" target="#fig_2">Figure 4a</ref>, which can become even longer than the combined latency of Steps 5 and 6 . In an MQ-SSD, as a greater number of I/O flows execute concurrently, there is more contention for the CMT, leading to a larger number of CMT misses.</p><p>Second, as shown in <ref type="figure" target="#fig_2">Figure 4b</ref>, cutting-edge nonvolatile memory technologies, such as 3D XPoint <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b47">48]</ref>, dramatically reduce the access and data transfer times of the MQ-SSD back end, by as much as three orders of magnitude compared to that of NAND flash <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b42">43]</ref>. The total latency of the 3D XPoint read and transfer (&lt; 1 µs) contributes less than 10% to the end-to-end I/O request processing latency (&lt;10 µs) <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b15">16]</ref>. In this case, a conventional simulation tool would be inaccurate, as it does not model the major steps contributing to the end-to-end latency.</p><p>In summary, a detailed, realistic model of end-to-end latency is key for accurate simulation of modern SSD devices with (1) multiple I/O flows that can potentially lead to a significant increase in CMT <ref type="table">(cached mapping table)</ref> misses, and (2) very-fast NVM technologies such as 3D XPoint that greatly reduce raw memory read/write latencies. Existing simulation tools do not provide accurate performance results for such devices.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Modeling a Modern MQ-SSD with MQSim</head><p>To our knowledge, there is no SSD modeling tool that supports multi-queue I/O execution, fast and efficient modeling of the SSD's steady-state behavior, and a full end-to-end request latency estimation. In this work, we present MQSim, a new simulation framework that is developed from scratch to support all of these three important features that are required for accurate performance modeling and design space exploration of modern MQ-SSDs. Although mainly designed for MQ-SSD simulation, MQSim also supports simulation of the conventional SATA-based SSDs that implement native command queuing (NCQ). Our new simulator models all of the components shown in <ref type="figure">Figure 1</ref>, which exist in modern SSDs. <ref type="table" target="#tab_2">Table 1</ref> provides a quick comparison between MQSim and previous SSD simulators. MQSim is a discrete-event simulator written in C++ and is released under the permissive MIT License <ref type="bibr" target="#b0">[1]</ref>.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">SSD Back End Model</head><p>MQSim provides a simple yet detailed model of the flash memory chips. It considers three major latency components of the SSD back end: (1) address and command transfer to the memory chip; (2) flash memory read/ write execution for different technologies that store 1, 2, or 3 bits per cell <ref type="bibr" target="#b31">[32]</ref>; and (3) data transfer to/from memory chips. MQSim's flash model considers the constraints of die-and plane-level parallelism, and advanced command execution <ref type="bibr" target="#b64">[65]</ref>. One important new feature of MQSim is that it can be configured or easily modified to simulate new NVM chips (e.g., those that do not need erase-before-write). Due to decoupling of the NVM chip communication interface from the chip's internal implementation of the memory operations, one can modify the NVM chip of MQSim without the need to change the implementation of the other MQSim components.</p><p>Another new feature of MQSim is that it decouples the sizes of read and write operations. This feature helps to exploit large page sizes of modern flash memory chips in that can enable better write performance, while preventing the negative effects of large page sizes on read performance. For flash chip writes, the operation is always page-sized <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12]</ref>. MQSim's data cache controller can delay writes to eliminate write-back of partially-updated logical pages (where the update size is smaller than the physical page size). When a partially-updated logical page should be written back to the flash storage, the unchanged sub-pages (sectors) of the logical page are first read from the physical page that stores page data. Then, unchanged and updated pieces of the page are merged. In the last step, the entire page data is written to a new free physical page. For flash chip reads, the operation could be smaller than the physical page size. When a read operation finishes, only the data pieces that are requested in the I/O request are transferred from flash chips to the SSD controller, avoiding the data transfer overhead of large physical pages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">SSD Front End Model</head><p>The front end model of MQSim includes all of the basic components of a modern SSD controller and provides many new features that do not exist in previous SSD modeling tools.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Host-Interface Model</head><p>The host interface component of MQSim provides both NVMe multi-queue (MQ) and SATA native command queue models for a modern SSD. To our knowledge, MQSim is the first modeling tool that supports MQ I/O request processing. There is a request fetch unit within the host interface of MQSim that fetches and schedules application I/O requests from different input queues. The NVMe host interface provides users with a parameter, called QueueFetchSize, that can be used to tune the behavior of the request fetch unit, in order to accurately model the behavior of real MQ-SSDs. This parameter defines the maximum number of I/O requests from each SQ that can be concurrently serviced in the MQ-SSD. More precisely, at any given time, the number of I/O requests that are fetched from a host SQ to the device-level queue is always less than or equal to QueueFetchSize. This parameter has a large impact on the MQ-SSD multiflow request processing characteristics discussed in Section 3.1 (i.e., on maximum achievable throughput per I/O flow and probability of inter-flow interference). Appendix A.3 analyzes the effect of this parameter on performance.</p><p>MQSim also models different priority classes for hostside request queues, which are part of the NVMe standard specification <ref type="bibr" target="#b62">[63]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Data Cache Manager</head><p>MQSim has a data cache manager component that implements a DRAM-based cache with the least-recentlyused (LRU) replacement policy. The DRAM cache can be configured to cache (1) recently-written data (default mode), (2) recently-read data, or (3) both recentlywritten and recently-read data. A new feature of MQSim's cache manager, compared to previous SSD modeling tools, is that it implements a DRAM access model in which the contention among the concurrent accesses to DRAM chips and the latency of DRAM commands are considered. The DRAM cache models in MQSim can be extended to make use of detailed and fast DRAM simulators, such as Ramulator <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b38">39]</ref>, to perform detailed studies of the effect of DRAM cache performance on the overall MQ-SSD performance. We leave this to future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3">FTL Components</head><p>MQSim implements all the main FTL components, including (1) the address translation unit, (2) the garbage collection (GC) and wear-leveling (WL) unit, and (3) the transaction scheduling unit. MQSim provides different options for each of these components, including state-ofthe-art address translation strategies <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b77">78]</ref>, GC candidate block selection algorithms <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b80">81,</ref><ref type="bibr" target="#b90">91]</ref>, and transaction scheduling schemes <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b86">87]</ref>. MQSim also implements several state-of-the-art GC and flash management mechanisms, including preemptible GC I/O scheduling <ref type="bibr" target="#b43">[44]</ref>, intra-plane data movement from one physical page to another physical page using copyback read and write command pairs <ref type="bibr" target="#b26">[27]</ref>, and program/erase suspension <ref type="bibr" target="#b86">[87]</ref> to reduce the interference of GC operations with application I/O requests. One novel feature of MQSim is that all of its FTL components support multi-flow (i.e., multi-input queue) request processing. For example, the address mapping unit can partition the cached mapping table space among the concurrently running flows. This inherent support of multi-queueaware request processing facilitates the design space exploration of performance isolation and QoS schemes for MQ-SSDs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Modeling End-to-End Latency</head><p>In addition to the flash operation and internal data transfer latency (steps 3 , 4 , 5 , and 6 in <ref type="figure" target="#fig_2">Figure 4</ref>), there is a mix of variable and constant latencies that MQSim models to determine the end-to-end request latency. Variable Latencies. These are the variable request processing times in FTL that result from contention in the cached mapping table and the DRAM write cache. Depending on the request type (either read or write) and the request's logical address, the request processing time in FTL includes some of the following items: (1) the time required to read/write from/to the data cache, and (2) the time to fetch mapping data from flash storage in case of a miss in the cached address mapping table. Constant Latencies. These include the times required to transmit the I/O job information, the entire user data, and the I/O completion information over the PCIe bus, and the firmware (FTL) execution time on the controller's microprocessor. The PCIe transmission latencies are calculated based on a simple packet latency model provided by <ref type="bibr">Xilinx [41]</ref> that considers: (1) the PCIe communication bandwidth, (2) the payload and header sizes of the PCIe Transaction Layer Packets (TLP), (3) the size of the NVMe management data structures, and d) the size of the application data. The firmware execution time is estimated using both a CPU and cache latency model <ref type="bibr" target="#b0">[1]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Modeling Steady-State Behavior</head><p>The basic assumption of MQSim is that all simulations should be executed when the modeled device is in steady state. To model the steady-state behavior, MQSim, by default, automatically executes a preconditioning function before starting the actual simulation process. This function performs preconditioning in a short time (e.g., less than 8 min when running tpcc <ref type="bibr" target="#b52">[53]</ref> on an 800 GB MQ-SSD) without the need to execute additional I/O requests. During preconditioning, all available physical pages of the modeled SSD are transitioned to either a valid or invalid state, based on the steady-state valid/invalid page distribution model provided in <ref type="bibr" target="#b81">[82]</ref> (only very few flash blocks are assumed to remain free and are added to the free block pool). MQSim pre-processes the input trace to extract the LPA (logical page address) access characteristics of the application I/O requests in the trace, and then uses the extracted information as inputs to the valid/invalid page distribution model. In addition, input trace characteristics, such as the average write arrival rate and the distribution of write addresses, are used to warm up the write cache.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Execution Modes</head><p>MQSim provides two modes of operation: (i) standalone mode, where it is fed a real disk trace or a synthetic workload, and (ii) integrated mode, where it is fed disk requests from an execution-driven engine (e.g., gem5 <ref type="bibr" target="#b7">[8]</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Comparison with Previous Simulators</head><p>The increasing usage of SSDs in modern computing systems has boosted interest in SSD design space exploration. To this end, several simulators have been developed in recent years. <ref type="table" target="#tab_3">Table 2</ref> summarizes the features of MQSim and popular existing SSD modeling tools. The table also shows the average error rates for the performance of real storage workloads reported by each simulator, compared to the performance measured on four real MQ-SSDs (see Appendix A.1 for our methodology).</p><p>Existing tools either do not model some major components of modern SSDs or provide very simplistic component models that lead to unrealistic I/O request latency estimation. In contrast, MQSim provides detailed implementations for all of the major components of modern SSDs. MQSim is written in C++ and has 13K lines of code (LOC). Next, we discuss the main advantages of MQSim compared to the previous tools. Host-Interface Logic. As <ref type="table" target="#tab_3">Table 2</ref> shows, most of the existing simulators assume a very simplistic HIL model with no explicit management mechanism for the I/O request queue. This leads to an unrealistic SSD model regarding the requirements of both NVMe and SATA protocols. As we mention in Section 3, the concurrent execution of I/O flows presents many challenges for performance predictability and fairness in MQ-SSDs. No ex-  <ref type="bibr" target="#b12">13</ref> Built-in support for multi-queue-aware request processing in FTL <ref type="bibr" target="#b13">14</ref> Lines of source code isting simulator implements NVMe and multi-queue I/O request management, and, hence, accurately models the behavior of MQ-SSDs. Also, except for WiscSim, we find that no existing simulator implements an accurate model of the SATA protocol and NCQ request processing. This leads to unrealistic SATA device simulation, as NCQ-based I/O scheduling plays a key role in the performance of real SSD devices <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b25">26]</ref>. Steady-State Simulation. To our knowledge, accurate and fast steady-state behavior modeling is not provided by many existing SSD modeling tools. Among the tools listed in <ref type="table" target="#tab_3">Table 2</ref>, only SSDSim provides a function, called make aged, to change the status of a set of physical pages to valid before starting the actual execution of an input trace. This simple method cannot accurately replicate the steady-state behavior of an SSD for two reasons. First, after the execution of make aged, the physical blocks would include only valid pages or only free pages. This is far from the steady-state status of blocks in real devices, where each non-free block has a mix of valid and invalid pages <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b80">81,</ref><ref type="bibr" target="#b81">82]</ref>. Second, the steadystate status of the data cache is not modeled, i.e., the simulation starts with a completely empty write cache.</p><p>In general, it is possible to bring these simulators to steady state. However, there is no fast pre-conditioning support for them, and pre-conditioning must be performed by executing traces. Preconditioning an existing simulator requires users to generate traces with a large enough number of I/O requests, and can significantly slow down the simulator, especially when a highcapacity SSD is modeled. For example, our studies with SSDSim show that pre-conditioning may increase the simulation time up to 80x if an 800 GB SSD is modeled. <ref type="bibr" target="#b2">3</ref> Detailed End-to-End Latency Model. As described in Section 3.3, the end-to-end latency of an application I/O request includes different components. <ref type="table" target="#tab_3">Table 2</ref> shows that latency modeling in existing simulators is mainly focused on the latency of the flash chip operation and the SSD internal data transfer. As we explain in Section 3.3, this is an unrealistic model of the end-to-end I/O request processing latency, even for a conventional SSD.</p><p>To study the accuracy of the existing tools in modeling real devices, we create four models for the four real SSDs shown in <ref type="table" target="#tab_5">Table 4</ref> in each simulator, and execute three real traces, i.e., tpcc, tpce, and exchange. We exclude the simulators that do not support trace-based execution. The four rightmost columns of <ref type="table" target="#tab_3">Table 2</ref> show the average error rate of each simulator in modeling the performance (i.e., read and write latency) of these four real devices. The error rates of the four evaluated simulators are almost one order of magnitude higher than that of MQSim. We believe that these high error rates are due to four major reasons: (1) the lack of write cache or inaccurate modeling of the write cache access latency, (2) the lack of built-in support for steady-state modeling, (3) incomplete modeling of the request processing latency in FTL, and (4) the lack of modeling of the host-to-device communication latency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Research Directions Enabled by MQSim</head><p>MQSim is a flexible simulation tool that enables different studies on both modern and conventional SSD devices. In this section, we discuss two new research directions enabled by MQSim, which could not be explored easily using existing simulation tools. First, we use MQSim to perform a detailed analysis of inter-flow interference in a modern MQ-SSD (Section 6.1). We explain how sharing different internal resources in an MQ-SSD, such as the write cache, cached mapping table, and back end resources, can introduce fairness issues. Second, we explain how the full-system simulation mode of MQSim can enable detailed application-level studies (Section 6.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Design Space Exploration of Fairness and QoS Techniques for MQ-SSDs</head><p>As we describe in Section 1, fairness and QoS should be considered as first-class design criteria for modern datacenter SSDs. MQSim provides an accurate framework to study inter-flow interference, thus enables the ability to devise interference-aware MQ-SSD management algorithms for sharing of the internal MQ-SSD resources.</p><p>As we show in Section 3.1, concurrently running two I/O flows might lead to disproportionate slowdowns for each flow, greatly degrading fairness and proportional progress. This is particularly important in high-end SSD devices, which provide higher throughput per I/O flow, as we show in Appendix A.3. We find that this inter-flow interference is mainly the result of contention that takes place at three locations in an MQ-SSD: 1) the write cache in the front end, 2) the cached mapping table (CMT) in the front end, and 3) the storage resources in the back end. In this section, we use MQSim to explore the impact of these three points of contention on performance and fairness, which cannot be explored accurately using existing simulators.</p><p>6.1.1 Methodology MQ-SSD Configuration. <ref type="table" target="#tab_4">Table 3</ref> lists the specification of the MQ-SSD that we model in MQSim for our contention studies. Metrics. To measure performance, we use weighted speedup (WS) <ref type="bibr" target="#b69">[70]</ref> of the average response time (RT), which represents the overall efficiency and system-level throughput <ref type="bibr" target="#b20">[21]</ref> provided by an MQ-SSD during the concurrent execution of multiple flows:</p><formula xml:id="formula_1">WS = ∑ i RT alone i RT shared i<label>(2)</label></formula><p>where RT alone i and RT shared i are defined in Section 3.1. To demonstrate the effect of inter-flow interference on fairness, we report slowdown and fairness (F) metrics, as defined in Section 3.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.2">Contention at the Write Cache</head><p>One point of contention among concurrently-running flows in an MQ-SSD is the write cache. For flows with low to moderate write intensity (where the average depth of the I/O queue less than 16), or with high spatial locality, the write cache decreases the response time of write requests, by avoiding the need for the requests to wait for the write to complete to the underlying memory. For flows with high write intensity or with highlyrandom accesses, the write requests fill up the limited capacity of the write cache quickly, causing significant cache thrashing and limiting the decrease in write request response time. Such flows not only do not benefit from the write cache themselves, but also prevent other lower-write-intensity flows from benefiting from the write cache, leading to a large performance loss for the lower-write-intensity flows.</p><p>To understand how the contention at the write cache affects system performance and fairness, we perform a set of experiments where we run two flows, Flow-1 and Flow-2, both of which perform only random-access write requests. In both flows, the average request size is set to 8 kB. We set Flow-1 to have a moderate write intensity, by limiting the queue depth to 8 requests. We vary the queue depth of Flow-2 from 8 requests to 256 requests, to control the write intensity of the flow. In order to isolate the effect of write cache interference in our experiments, we (1) assign each flow to a dedicated subset of back end resources (i.e., Flow-1 uses Channels 1-4, and Flow-2 uses Channels 5-8), to avoid introducing any interference in the back end; and (2) use a perfect CMT, where all address translation requests are hits, to avoid interference due to limited CMT capacity. <ref type="figure">Figure 6a</ref> shows the slowdown of each flow when the two flows run concurrently, compared to when each flow runs alone. <ref type="figure">Figure 6b</ref> shows the fairness and performance of the system when the two flows run concurrently. We make four key observations from the figures. First, Flow-1 is slowed down significantly when Flow-2 has a high write intensity (i.e., its queue depth is greater than 16), indicating that at high write intensities, Flow-2 induces write cache trashing. Second, the slowdown of Flow-2 is negligible, because of the low write intensity of Flow-1. Third, fairness degrades greatly, as a result of the write cache contention, when Flow-2 has a high write intensity. Fourth, write cache contention causes an MQ-SSD to be inefficient at concurrently running multiple I/O flows, as the weighted speedup is reduced by over 50% when Flow-2 has a high write intensity compared to when it has a low write intensity. (b) Fairness (left) and system performance (right) <ref type="figure">Figure 6</ref>: Impact of write cache contention.</p><p>We conclude that write cache contention leads to unfairness and overall performance degradation for concurrently-running flows when one flow has a high write intensity. In these cases, the high-write-intensity flow (1) does not benefit from the write cache; and (2) prevents other, lower-write-intensity flows from taking advantage of the write cache, even though the other flows would otherwise benefit from the cache. This motivates the need for fair write cache management algorithms for MQ-SSDs that take inter-flow interference and flow write intensity into account.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.3">Contention at the Cached Mapping Table</head><p>As we discuss in Section 3.3, address translation can noticeably increase the end-to-end latency of an I/O request, especially for read requests. We find that for I/O flows with random access patterns, the cached mapping table (CMT) miss rate is high due to poor reuse of address translation mappings, which causes the I/O requests generated by the flow to stall for long periods of time during address translation. This is not true for I/O flows with sequential accesses, for which the CMT miss rate remains low due to spatial locality. However, when two I/O flows run concurrently, where one flow has a random access pattern and another flow has a sequential access pattern, the poor locality of the flow with the random access pattern may cause both flows to have high CMT miss rates.</p><p>To understand how contention at the CMT affects system performance and fairness, we perform a set of experiments where we concurrently run two flows that issue read requests with an average request size of 8 kB. In these experiments, Flow-1 has a fully-sequential access pattern, and Flow-2 has a random access pattern for a fraction of the total execution time, and has a sequential access pattern for the remaining time. We vary the randomness (i.e., the fraction of the execution time with a random access pattern) of Flow-2. To isolate the effects of CMT contention, we assign Flow-1 to Channels 1-4 in the back end, and assign Flow-2 to Channels 5-8. <ref type="figure" target="#fig_7">Figure 7a</ref> shows the slowdown and change in CMT hit rate of each flow when Flow-1 and Flow-2 run concur-rently, compared to when each flow runs alone. <ref type="figure" target="#fig_7">Figure 7b</ref> shows the fairness and overall performance of the system when the two flows run concurrently. We make two observations from the figures. First, as the randomness of Flow-2 increases, the CMT hit rate of Flow-1 decreases, while the CMT hit rate of Flow-2 remains constant. This indicates that the randomness of Flow-2 introduces contention at the CMT, which hurts the CMT hit ratio of Flow-1. Second, as the CMT hit rate of Flow-1 decreases, the flow experiences a greater slowdown, with a 2.1x slowdown when Flow-2's access pattern is completely random. Third, as the randomness of Flow-2 increases, both fairness and overall system performance decrease, as the interference introduced by Flow-2 hurts the performance of Flow-1 without providing any noticeable benefit to Flow-2. (a) Slowdown and CMT hit rate (normalized to the hit rate when Flow-2 randomness is 0%) for Flow-1 (left) and Flow-2 (right) We conclude that the CMT contention induced by an I/O flow with a random access pattern disproportionately slows down concurrently-running flows with sequential access patterns, which would otherwise benefit from the CMT, leading to high unfairness and system performance degradation. To avoid such unfairness and performance loss, an MQ-SSD should use CMT management algorithms that are aware of inter-flow interference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.4">Contention at the Back End Resources</head><p>A third point of contention is at the back end resources within an MQ-SSD (see Section 2.1). A high-intensity flow can use up most of the back end resources if the flow issues a large number of requests in a short period of time. This stalls the requests issued by a low-intensity concurrently-running flow, as the requests cannot be serviced before the back end resources finish servicing requests from the high-intensity flow.</p><p>To understand how contention at the back end resources affects system performance and fairness, we perform a set of experiments where we concurrently run two I/O flows that issue random reads with a request size of 8 kB. Flow-1 is a low-intensity I/O flow, as we limit its submission queue size (see Section 2.2) to 2 requests.</p><p>We vary the submission queue size of Flow-2 from 2 requests to 256 requests, to control the flow intensity. In order to isolate the effect of back end resource contention, we disable the write cache, and simulate a CMT where address translation requests always hit. <ref type="figure" target="#fig_8">Figure 8a</ref> shows the slowdown when Flow-1 and Flow-2 run concurrently, and the change in the average chip-level queue depth (i.e., the number of requests waiting to be serviced by the back end; see Section 2.3) for each flow during concurrent execution, compared to the depth when each flow runs alone. <ref type="figure" target="#fig_8">Figure 8b</ref> shows the fairness and overall performance of the system when the two flows run concurrently. We make four observations from the figures. First, the average chip-level queue depth of Flow-1 increases significantly when the intensity of Flow-2 increases. Second, Flow-1 is slows down significantly when we increase the host-side queue depth of Flow-2 beyond 16. For example, when Flow-2 is at the highest intensity that we test (with a host-side queue depth of 256 requests), Flow-1 slows down by 14.4x. Third, the effect of inter-flow interference on Flow-2 is negligible, as its slowdown is almost equal to 1 for hostside queue depths larger than 4. Fourth, the asymmetric slowdowns (i.e., the large slowdown for Flow-1 and the lack of slowdown for Flow-2) cause both fairness and the overall system performance to decrease. We conclude that a high-intensity flow can significantly increase the depth of the chip-level queues and thus lead to a large slow-down for concurrently-running low-intensity flows. The FTL transaction scheduling unit must be aware of the inter-flow interference at the MQ-SSD back end to make the per-flow performance more fair and thus keep the overall performance high.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Application-Level Studies</head><p>To study the effect of SSD device-level design choices on application-level performance metrics, such as instructions per cycle (IPC), an SSD simulator must be integrated and run together with a full-system simulator. We integrate MQSim with gem5 <ref type="bibr" target="#b7">[8]</ref> to provide a complete model of multi-queue I/O execution and a complete computer system. As <ref type="table" target="#tab_3">Table 2</ref> shows, among existing SSD simulators, only SimpleSSD <ref type="bibr" target="#b34">[35]</ref> is integrated with a full-system simulator, and SimpleSSD does not simulate multi-queue I/O execution. In this section, we show the effectiveness of our integrated simulator, by studying how changes to QueueFetchSize (see Section 4.2.1) affect the IPC of concurrently-executing applications due to storage-level interference.</p><p>We conduct a set of experiments, running instances of file server (fs) <ref type="bibr" target="#b76">[77]</ref>, mail server (ms) <ref type="bibr" target="#b76">[77]</ref>, web server (ws) <ref type="bibr" target="#b76">[77]</ref>, and IOzone large file access (io) <ref type="bibr" target="#b61">[62]</ref> applications using the integrated execution mode of MQSim. We first execute each application alone (i.e., without interference from other applications), and then concurrently execute the application with a second application to study the effect of inter-application interference. To isolate the effect of inter-flow interference, where each flow belongs to one application, we assign each application to a single processor core and a single memory channel. We test two different values of QueueFetchSize (16 entries and 1024 entries) to examine how QueueFetchSize affects inter-application interference. For these experiments, we measure application slowdown (S app ), which is calculated as S app i = IPC alone app i /IPC shared app i , and use application slowdown to determine fairness using Equation 1. <ref type="figure" target="#fig_9">Figure 9</ref> shows the slowdown of each application and the system fairness for six pairs of concurrentlyexecuting applications. On the x-axis, we list the applications used in each pair, along with the value of QueueFetchSize that we use. We make two observations from the figure. First, for application pairs where one of the applications is ms or ws, the impact of QueueFetchSize on fairness is negligible. Both ms and ws benefit mainly from caching a large part of their data set in main memory, and hence issue very few requests to the SSD. This keeps storage-level interference low, as ms and ws do not contend often for access to the SSD with the other applications that they are paired with. Second, fs and io have high storage access intensities, and hence interfere significantly when they are paired together. In this case, we observe that a large QueueFetchSize value leads to 60% fairness reduction. We conclude that full-system behavior can greatly impact the fairness and performance of I/O flows on an MQ-SSD, as it affects the storage-level intensity of each flow.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Related Work</head><p>To our knowledge, MQSim is the first simulator that (1) accurately simulates both modern and conventional SSDs, (2) faithfully models modern host-interface protocols such as NVMe, and (3) supports the accurate simulation of SSDs that use emerging ultra-fast memory technologies. We compare MQSim to existing stateof-the-art SSD simulation tools in Section 5, and show that MQSim provides greater capabilities and accurate results. In this section, we provide a brief summary of other related works.</p><p>A number of prior works consider the performance and implementation challenges of MQ-SSDs <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b88">89,</ref><ref type="bibr" target="#b89">90]</ref>. <ref type="bibr">Xu et al. [89]</ref> analyze the effect of MQ-SSDs on the performance of modern hyper-scale and database applications. Awad et al. <ref type="bibr" target="#b4">[5]</ref> evaluate the impact of different NVMe host-interface implementations on the system performance. Vučini´Vučini´c et al. <ref type="bibr" target="#b82">[83]</ref> show that the current NVMe protocol will be a performance bottleneck in future PCM-based storage devices. The authors modify the NVMe standard in order to improve its performance for future PCM-based SSDs.</p><p>Other works <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b71">72]</ref> focus on managing multiple flows in modern SSDs. <ref type="bibr">Song and Yang [72]</ref> partition the SSD back end resources among concurrently-running I/O flows to provide performance isolation and alleviate inter-flow interference. Jun and Shin <ref type="bibr" target="#b30">[31]</ref> propose a device-level scheduling technique for MQ-SSDs with built-in virtualization support.</p><p>None of these previous studies provide a simulation framework for MQ-SSDs or study the sources of interflow interference inside MQ-SSDs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion</head><p>We introduce MQSim, a new simulator that accurately captures the behavior of both modern multi-queue SSDs and conventional SATA-based SSDs. MQSim faithfully models a number of critical features absent in existing state-of-the-art simulators, including (1) modern multi-queue-based host-interface protocols (e.g., NVMe), (2) the steady-state behavior of SSDs, and (3) the end-to-end latency of I/O requests. MQSim can be run as a standalone tool, or integrated with a fullsystem simulator. We validate MQSim against real offthe-shelf SSDs, and demonstrate that it provides highlyaccurate results. By accurately modeling modern SSDs, MQSim can uncover important issues that cannot be modeled accurately using existing simulators, such as the impact of inter-flow interference. We have released MQSim as an open-source tool <ref type="bibr" target="#b0">[1]</ref>, and we hope that MQSim enables researchers to explore new ideas and directions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A MQSim Validation A.1 Evaluation Methodology</head><p>To validate the accuracy of MQSim, we compare its performance results to four state-of-the-art MQ-SSDs (SSD-A, SSD-B, SSD-C, and SSD-D) manufactured between 2016 and 2017. <ref type="table" target="#tab_5">Table 4</ref> lists key properties of the four MQ-SSDs. We precondition each device with full-load write traffic to write to 70% of the available logical space <ref type="bibr" target="#b70">[71]</ref>. The device preconditioning process includes two 4-hour phases. In the first phase, we perform sequential writes, while in the second phase, we perform random writes. We perform real-system experiments on a server that contains an Intel Xeon E3-1240 v6 3.70GHz processor and 32 GB of DDR4 main memory. The system uses Ubuntu 16.04.2 with version 2.6.27 of the Linux kernel, and the OS is stored in a 500 GB Western Digital HDD. We run the fio benchmark tool for performance evaluations, and all storage devices are connected to the PCIe bus as add-in cards. We validate our simulator with four different configurations that correspond to our four real MQ-SSDs. To this end, we extract the main structural parameters of each real SSD using a microbenchmarking program. This program analyzes and estimates the SSD's internal configuration (e.g., NAND flash page size, NAND flash read/write latency, number of channels in the SSD, address mapping strategy, write cache size) based on the methods described in prior SSD modeling studies <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b35">36]</ref>. We have open-sourced our microbenchmark <ref type="bibr" target="#b0">[1]</ref>. For garbage collection (GC) management, we enable all of the advanced GC mechanisms described in Section 4.2.3, except write suspension, in MQSim. According to the specifications of the flash chips used in two of the SSD devices, write suspension is not supported.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Performance Validation</head><p>We validate MQSim against real devices using both synthetic and real workloads. Our synthetic workloads issue random accesses, and consist of only read requests or only write requests, where we set the queue depth to 1 request. <ref type="figure" target="#fig_10">Figure 10</ref> compares the read and write request response time 4 measured on our four real MQ-SSDs with the latencies reported by MQSim for our synthetic workloads. The plots in <ref type="figure" target="#fig_10">Figure 10a</ref> and 10b show the read and the write latencies, respectively. The x-axes reflect different I/O request sizes, ranging from 4 kB to 1 MB. The blue curves show the error percentage of the simulation model. We observe that across all request sizes, the response times reported by MQSim match very closely <ref type="bibr" target="#b3">4</ref> Response time is defined as the time from when a host request is enqueued in the submission queue to when the SSD response is enqueued in the completion queue. with the measured response times of the real devices, especially for SSD-B and SSD-D. Averaged across all four MQ-SSDs and all I/O request sizes, the error rates for read and write requests are 2.9% and 4.9%, respectively. <ref type="figure" target="#fig_11">Figure 11</ref> shows the accuracy of the request response time reported by MQSim as a cumulative distribution function (CDF), for three real workloads <ref type="bibr" target="#b52">[53]</ref>: tpcc, tpce, and exchange. We observe that MQSim's reported response times are very accurate when compared to the response times measured on the real MQ-SSDs. The average error rates for SSD-A, SSD-B, SSD-C, and SSD-D are 8%, 6%, 18%, and 14%, respectively.</p><p>We conclude that MQSim accurately models the performance of real MQ-SSDs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 Multi-Queue Simulation</head><p>To validate the accuracy of the multi-queue I/O execution model in MQSim, we conduct a set of simulation experiments using two I/O flows, Flow-1 and Flow-2, where each flow generates only sequential read requests. We maintain a constant request intensity for Flow-1, by setting its I/O queue depth to 8 requests. We vary the intensity of Flow-2 across our experiments, by varying the I/O queue depth between 8 entries and 256 entries.  <ref type="figure" target="#fig_1">Figure 12</ref> shows the slowdown and normalized throughput (IOPS) of Flow-1 (left) and Flow-2 (center), and the fairness (see Section 3.1) of the system (right). We make two key observations from the figure. First, we find that MQSim successfully models the behavior of real MQ-SSDs that are optimized for higher per-flow throughput (e.g., SSD-A, SSD-B, SSD-C) when the value of QueueFetchSize is equal to 1024. <ref type="figure" target="#fig_1">Fig- ure 12a</ref> shows similar trends for slowdown, throughput, and fairness to the measurements we perform on real MQ-SSDs, which we show in <ref type="figure" target="#fig_1">Figure 2</ref>. When QueueFetchSize is set to 1024, a higher number of I/O requests from each flow are fetched into the devicelevel queue of the MQ-SSD. In both our MQSim results and the measured results on real MQ-SSDs, we observe that as the intensity of Flow-2 increases, its throughput increases significantly with little slowdown, while the throughput of Flow-1 decreases significantly, causing Flow-1 to slow down greatly. This occurs because when Flow-2 has a high intensity, it unfairly uses most of the back end resources in the MQ-SSD, causing requests from Flow-1 to wait for longer latencies before they can be serviced.</p><p>Second, MQSim accurately models the behavior of real MQ-SSD products that implement mechanisms to control inter-flow interference, such as SSD-D, when QueueFetchSize is set to 16. We see that the trends in <ref type="figure" target="#fig_1">Figure 12b</ref> are similar to those observed in our measured results from SSD-D in <ref type="figure" target="#fig_1">Figure 2</ref>. When QueueFetchSize is set to 16, only a limited number of I/O requests for each concurrently-running flow are serviced by the back end, preventing any one flow from unfairly using most of the resources within the MQ-SSD. As a result, even when Flow-2 has a high intensity, Flow-1 does not experience significant slowdown.</p><p>We conclude that by adjusting QueueFetchSize, MQSim successfully models different multi-queue I/O processing mechanisms in modern MQ-SSD devices.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4 Steady-State Behavior Modeling</head><p>As we discuss in Section 4.4, MQSim pre-conditions the flash storage space and warms up the SSD data cache based on the characteristics of the co-running workloads. To validate the steady-state model in MQSim, we conduct a set of experiments using MQSim under high write intensity, and compare the results to those from real MQ-SSD devices. <ref type="figure">Figure 13</ref> plots the read and write response times for (1) actual I/O execution on SSD-B (which is representative of the general behavior of the state-ofthe-art SSDs we examine); (2) MQSim-NoPrec, where MQSim is run without pre-conditioning, and (3) MQSimPrec, where MQSim is run with pre-conditioning. Actual SSD-B <ref type="figure">Figure 13</ref>: MQSim accurately models the steady-state read and write response times (RT) of SSD-B, using fast preconditioning.</p><p>We make two observations from the figure. First, MQSim with pre-conditioning successfully follows the response time results extracted from SSD-B. Second, MQSim without pre-conditioning reports lower response time results at the beginning of the experiment, since the simulated SSD is not yet in steady state. Once the whole storage space is written, the response time results become similar to the real device, as garbage collection and write cache evictions now take place in simulation at a rate similar to the rate measured on SSD-B. We conclude that MQSim's pre-conditioning quickly and accurately models the steady-state behavior of real MQ-SSDs.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Performance of Flow-1 (left) and Flow-2 (center), and fairness (right), when flows are concurrently executed with different intensities on four real MQ-SSDs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Timing diagram for a 4 kB read request in (a) NAND-flash and (b) 3D XPoint MQ-SSDs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 depicts</head><label>5</label><figDesc>a high-level view of MQSim's main components and their interaction. In this section, we briefly describe these components and explain their novel features with respect to the previous simulators.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>Figure 5: High-level view of MQSim components.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Impact of CMT contention.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>ΔFigure 8 :</head><label>8</label><figDesc>Figure 8: Impact of back end resource contention.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Application-level impact of QueueFetchSize.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 10 :</head><label>10</label><figDesc>Figure 10: Average response time (RT) for read (a) and write (b) requests, reported by MQSim, compared to RT measured on four real MQ-SSD devices, for synthetic workloads. The blue curves show the error rates of MQSim's reported latency.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 11 :</head><label>11</label><figDesc>Figure 11: Comparison of response time CDF when running real workloads on MQSim and on real MQ-SSDs. For each Flow-2 I/O queue depth, we test two different values (16 and 1024) of QueueFetchSize (see Section 4.2.1). Figure 12 shows the slowdown and normalized throughput (IOPS) of Flow-1 (left) and Flow-2 (center), and the fairness (see Section 3.1) of the system (right). We make two key observations from the figure.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 12 :</head><label>12</label><figDesc>Figure 12: MQSim successfully models the multi-queue I/O processing model in (a) SSD-A, SSD-B, and SSD-C, and (b) SSD-D (compare with Figure 2).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true"><head>Table 1 : A quick comparison between MQSim and existing SSD modeling tools.</head><label>1</label><figDesc></figDesc><table>Tool 
Multi-Queue Support 
Preconditioning 
End-to-end Latency 
Built-in Implementation 
of SSD Components 

MQSim 
Multi-queue scheduling 
and prioritization 

Fast and automatic 
(enabled by default) 

Detailed model of the 
end-to-end latency 

All major components that 
exist in modern SSDs 

Existing Tools 
Not supported 
Manual, optional, 
and long execution time 

Missing some constant-or 
variable-latency components 

Implementation is missing for 
some major components </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="true"><head>Table 2 : Comparison of MQSim with previous SSD modeling tools.</head><label>2</label><figDesc></figDesc><table>Simulator 

HIL Protocol Execution Mode End-to-End Latency Front-End Components 
Simulation Error (%) 
NVMe SATA 
Alone 1 
Full 2 
Emul 3 
Prec 4 

NVM R/W 5 
NVM Xfer 
FTL Proc 6 
Cache Acc. 7 
Host Xfer 8 
Map P 9 
Map H 10 
GC 

Write Cache 
TSU 11 
WRL 12 

MQ FTL 13 
LOC 14 
SSD-A 
SSD-B 
SSD-C 
SSD-D 
MQ NCQ 

MQSim 




13K 8 
6 18 
14 

SSDModel [3] 






1K 91 155 196 
136 

FlashSim [38] 





8K 99 259 310 
138 

SSDSim [27] 




5K 70 68 74 
85 

NANDFlashSim [32] 

7K 
-
-
-
-

VSSIM [92] 




6K 
-
-
-
-

WiscSim [26] 





7K 95 277 324 
135 

SimpleSSD [35] 




7K 
-
-
-
-

1 Standalone execution 
2 Integrated execution with full-system simulator 
3 SSD emulation for real system 
4 Fast and accurate preconditioning of the modeled SSD to enable accurate steady-state results 
5 Flash (NVM) read/write timing 
6 FTL request processing overhead 
7 Accurate modeling of write cache access latency 
8 Host-to-device and device-to-host data transfer delay 
9 Page-level address mapping 
10 Hybrid address mapping 
11 FTL transaction scheduling unit 
12 FTL wear-leveling unit 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="true"><head>Table 3 : Configuration of the simulated SSD.</head><label>3</label><figDesc></figDesc><table>SSD Organization 

Host interface: PCIe 3.0 (NVMe 1.2) 
User capacity: 480 GB 
Write cache: 256 MB, CMT: 4 MB 
8 channels, 4 chips per channel 
QueueFetchSize = 512 

Flash Communication 
ONFI 3.1 (NV-DDR2) 
Interface 
Width: 8 bit, Rate: 333 MT/s 

Flash 
Microarchitecture 

8 KiB page, 448 B metadata per page, 
256 pages per block, 2048 blocks per 
plane, 2 planes per die 

Flash Access 
Parameters 

Read latency: 75 µs, Program 
latency: 750 µs, Erase latency: 3.8 ms </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="true"><head>Table 4 : Key characteristics of real MQ-SSDs.</head><label>4</label><figDesc></figDesc><table>Code 
Production Year Capacity Flash Technology 

SSD-A 
2016 
800 GB 
MLC 
SSD-B 
2016 
256 GB 
MLC 
SSD-C 
2017 
1 TB 
TLC 
SSD-D 
2016 
512 GB 
TLC 

</table></figure>

			<note place="foot" n="2"> Based on the SNIA definition [71], a device is in the steady state if its performance variation is limited to a deterministic range.</note>

			<note place="foot" n="3"> The increase in simulation time depends on the access pattern, intensity, and mix of I/O requests (read vs. write) of the workload.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank our shepherd Haryadi Gunawi and the anonymous referees for their feedback on this work. We thank our industrial partners, especially Google, Huawei, Intel, and VMware, for their generous support.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mqsim Github Repository</surname></persName>
		</author>
		<ptr target="https://github.com/CMU-SAFARI/MQSim" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ramulator Github Repository</surname></persName>
		</author>
		<ptr target="https://github.com/CMU-SAFARI/ramulator" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Design Tradeoffs for SSD Performance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Agrawal</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Prabhakaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Wobber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Manasse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>And Pan-Igrahy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">USENIX ATC</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Staged memory scheduling: Achieving high performance and scalability in heterogeneous systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ausavarungnirun</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">K.-W</forename><surname>Subramanian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Loh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">H</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mutlu</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISCA</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Non-Volatile Memory Host Controller Interface Performance Analysis in High-Performance I/O Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Awad</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kettering</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Solihin</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bates</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mcnutt</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Umass Rrace Repository</surname></persName>
		</author>
		<ptr target="http://traces.cs.umass.edu/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">How NVMe and 3D XPoint Will Create a New Datacenter Architecture</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Billi</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">FMS</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The gem5 Simulator</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Binkert</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Beckmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Reinhardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">K</forename><surname>Saidi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Basu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hes-Tness</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hower</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Krishna</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Sar-Dashti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sewell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Shoaib</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Vaish</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wood</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGARCH Comput. Archit. News</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Has Intel Created a Universal Memory Technology?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bourzac</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Spectrum</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Performance of Greedy Garbage Collection in Flash-Based SolidState Drives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bux</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>And Iliadis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perform. Eval</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Error Characterization, Mitigation, and Recovery in Flash-Memory-Based SolidState Drives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cai</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ghose</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Haratsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">F</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mutlu</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE</title>
		<meeting>IEEE</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cai</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ghose</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Haratsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">F</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mutlu</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1711.11427</idno>
		<title level="m">Flash-Memory-Based Solid-State Drives: Analysis, Mitigation, and Recovery</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>cs:AR</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Real-Time Garbage Collection for Flash-Memory Storage Systems of Real-Time Embedded Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-P</forename><surname>Kuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-W</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">O</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-W</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TECS</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Internal Parallelism of Flash Memory-Based Solid-State Drives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lee</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TOS</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Essential Roles of Exploiting Internal Parallelism of Flash Memory Based Solid State Drives in High-Speed Data Processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HPCA</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">3D XPoint Technology Drives System Architecture</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Coulson</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SNIA Storage Industry Summit</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Application-Aware Prioritization Mechanisms for On-Chip Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Das</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mutlu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Moscibroda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Das</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<pubPlace>MICRO</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Analytic Modeling of SSD Write Performance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Desnoyers</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SYSTOR</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Fairness via Source Throttling: A Configurable and High-Performance Fairness Substrate for Multi-Core Memory Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ebrahimi</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Mutlu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patt</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">N</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ASPLOS</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Exploiting Intra-Request Slack to Improve SSD Performance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elyasi</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Arjomand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sivasubrama-Niam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kandemir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">T</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jung</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ASPLOS</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">System-Level Performance Metrics for Multiprogram Workloads</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eyerman</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eeckhout</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Micro</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Fairness and Throughput in Switch on Event Multithreading</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabor</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mendelson</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<pubPlace>In MICRO</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Algorithms and Data Structures for Flash Memories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gal</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Toledo</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CSUR</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">DFTL: A Flash Translation Layer Employing Demand-Based Selective Caching of Page-Level Address Mappings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gupta</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Urgaonkar</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ASPLOS</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Handy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xpoint</surname></persName>
		</author>
		<title level="m">Speed at What Cost? In FMS</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">The Unwritten Contract of Solid State Drives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">E</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kannan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Arpaci-Dusseau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arpaci-Dusseau</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">H</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Performance Impact and Interplay of SSD Parallelism Through Advanced Commands, Allocation Strategy and Data Granularity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">U</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICS</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Rectifying Pitfalls in the Performance Evaluation of Flash Solid-State Drives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iliadis</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perform. Eval</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
				<title level="m">INTEL CORPORATION. Intel SSD DC S3500 Series Datasheet</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
				<title level="m">INTEL CORPORATION. Intel 3D NAND SSD DC P4500 Series Datasheet</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Workload-Aware Budget Compensation Scheduling for NVMe Solid State Drives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shin</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NVMSA</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jung</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wilson Iii</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">H</forename><surname>Donofrio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Shalf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">And</forename><surname>Kan-Demir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">T</forename><surname>Nandflashsim</surname></persName>
		</author>
		<title level="m">High-Fidelity, Microarchitecture-Aware NAND Flash Memory Simulation. TOS</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Revisiting Widely Held SSD Expectations and Rethinking System-Level Implications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jung</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kandemir</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMETRICS</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Maximizing Resource Utilization in Many-Chip Solid State Disks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jung</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kandemir</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">T</forename><surname>Sprinkler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HPCA</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">SimpleSSD: Modeling Solid State Drives for Holistic System Simulation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jung</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Abulila</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kwon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shahidi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shalf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">S</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kandemir</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CAL</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">SSD Performance Modeling Using Bottleneck Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kim</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kim</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CAL</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Thread Cluster Memory Scheduling: Exploiting Differences in Memory Access Behavior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kim</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Papamichael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mutlu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harchol-Balter</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<pubPlace>MICRO</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">FlashSim: A Simulator for NAND Flash-Based Solid-State Drives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kim</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tauras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ur-Gaonkar</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIMUL</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Ramulator: A Fast and Extensible DRAM Simulator</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kim</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mutlu</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CAL</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Evaluating STT-RAM as an Energy-Efficient Main Memory Alternative</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K ¨ Ult¨ursayult¨ Ult¨ursay</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Kandemir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sivasubra-Maniam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mutlu</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISPASS</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Understanding Performance of PCI Express Systems. XILINX White Paper</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lawley</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Architecting Phase Change Memory as a Scalable DRAM Alternative</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lee</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">C</forename><surname>Ipek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Mutlu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Burger</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISCA</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Phase-Change Technology and the Future of Main Memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lee</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">C</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ipek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Mutlu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Burger</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<publisher>IEEE</publisher>
			<pubPlace>Micro</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Preemptible I/O Scheduling of Garbage Collection for Solid State Drives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lee</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shipman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">M</forename><surname>Oral</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kim</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TC</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Stochastic Modeling of Large-Scale Solid-State Storage Systems: Analysis, Design Tradeoffs and Optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">I</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">P</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lui</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMETRICS</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Performance Evaluation of InfiniBand with PCI Express</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liu</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mamidala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vishnu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>And Panda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">K</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CONNECT</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
				<title level="m">MARVELL. Marvell 88SS1093 Flash Memory Controller</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Breakthrough Nonvolatile Memory Technology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Inc</forename><surname>Micron Technology</surname></persName>
		</author>
		<ptr target="https://www.micron.com/products/advanced-solutions/3d-xpoint-technology" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">NAND Flash Memory -MT29E64G08CECBB Datasheet</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Inc</forename><surname>Micron Technology</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
				<title level="m">MICRON TECHNOLOGY, INC. M500 2.5-Inch SATA NAND Flash SSD Series Datasheet</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
				<title level="m">MICRON TECHNOLOGY, INC. NAND Flash Memory -MLC+ MT29F256G08CKCAB Datasheet</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
				<title level="m">MICRON TECHNOLOGY, INC. NAND Flash Memory -MT29E128G08CBCCB Datasheet</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Microsoft</forename><surname>Corporation</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Microsoft Enterprise</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Traces</surname></persName>
		</author>
		<ptr target="http://iotta.snia.org/traces/130" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Microsoft Production Server Traces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Microsoft</forename><surname>Corporation</surname></persName>
		</author>
		<ptr target="http://iotta.snia.org/traces/158" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">Microsoft Research Cambridge Traces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Microsoft</forename><surname>Corporation</surname></persName>
		</author>
		<ptr target="http://iotta.snia.org/traces/388" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Memory Performance Attacks: Denial of Memory Service in Multi-Core Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moscibroda</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mutlu</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">USENIX Security</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Memory Scaling: A Systems Architecture Perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mutlu</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IMW</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Stall-Time Fair Memory Access Scheduling for Chip Multiprocessors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mutlu</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moscibroda</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICRO</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">ParallelismAware Batch Scheduling: Enhancing Both Performance and Fairness of Shared DRAM Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mutlu</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moscibroda</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISCA</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Research Problems and Opportunities in Memory Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mutlu</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Subramanian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SUPERFRI</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Migrating Server Storage to SSDs: Analysis of Tradeoffs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Narayanan</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Thereska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Donnelly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Elnikety</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rowstron</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">EuroSys</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">IOzone Filesystem Benchmark</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Norcott</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">D</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Capps</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nvm</forename><surname>Express Workgroup</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NVM Express Specification, Revision</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
				<title level="m">OCZ. RD400/400A Series Datasheet</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Onfi</forename><surname>Workgroup</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Open NAND Flash Interface Specification</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>Revision 4.0</note>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Efficient Flash I/O Scheduler</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Park</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fios: A Fair</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">FAST</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sata-Io</forename></persName>
		</author>
		<ptr target="http://www.sata-io.org" />
	</analytic>
	<monogr>
		<title level="j">Serial ATA Revision</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">A Fair Queueing I/O Scheduler for Flash-Based SSDs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Park</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Flashfq</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">USENIX ATC</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">K</forename><surname>Hynix Inc</surname></persName>
		</author>
		<title level="m">F26 32Gb MLC NAND Flash Memory TSOP Legacy</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Symbiotic Jobscheduling for a Simultaneous Multithreaded Processor</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Snavely</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tullsen</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ASPLOS</title>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
		<title level="m" type="main">Solid State Storage (SSS) Performance Test Specification (PTS) Enterprise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Snia</forename><surname>Technical Position</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note>version 1.1</note>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Architecting Flash-Based Solid-State Drive for HighPerformance I/O Virtualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CAL</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<title level="m" type="main">The Blacklisting Memory Scheduler: Achieving High Performance and Fairness at Low Cost</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Subramanian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Seshadri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Rastogi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mutlu</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">BLISS: Balancing Performance, Fairness and Complexity in Memory Access Scheduling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Subramanian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Seshadri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Rastogi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mutlu</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPDS</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<monogr>
		<title level="m" type="main">The Application Slowdown Model: Quantifying and Controlling the Impact of Inter-Application Interference at Shared Caches and Main Memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Subramanian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Seshadri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mutlu</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<pubPlace>MICRO</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">MISE: Providing Performance Predictability and Improving Fairness in Shared Main Memory Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Subramanian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Seshadri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Jaiyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mutlu</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HPCA</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tarasov</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Zadok</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shepler</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Filebench</surname></persName>
		</author>
		<title level="m">A Flexible Framework for File System Benchmarking. USENIX; login</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Performance Evaluation of Dynamic Page Allocation Strategies in SSDs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tavakkol</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mehrvarzy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Arjomand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sarbazi-Azad</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TOMPECS</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<monogr>
				<title level="m">TOSHIBA CORPORATION. PX04PMB Series Datasheet</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">DASH: Deadline-Aware High-Performance Memory Scheduler for Heterogeneous Systems with Hardware Accelerators</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Usui</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Subramanian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">K.-W</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mutlu</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TACO</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">A Mean Field Model for a Class of Garbage Collection Algorithms in Flash-based Solid State Drives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Van Houdt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMETRICS</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">On the Necessity of Hot and Cold Data Identification to Reduce the Write Amplification in Flash-Based SSDs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Van Houdt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perform. Eval</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Shortest Latency Protocol for Reading Phase Change Memory Over PCI Express</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vučini´cvuˇvučinivučini´</forename><surname>Vučini´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Guyot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ma-Teescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Blagojevi´cblagojevi´ Blagojevi´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Franca-Neto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Le Moal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bunker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Swan-Son</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Bandi´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Express</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">FAST</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Lottery Scheduling: Flexible Proportional-Share Resource Management</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Waldspurger</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">A</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weihl</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">E</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">OSDI</title>
		<imprint>
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<monogr>
				<title level="m">WESTERN DIGITAL CORPORATION. HGST Ultrastar SN200 Series Datasheet</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Western</forename><surname>Digital Corporation</surname></persName>
		</author>
		<title level="m">SanDisk Skyhawk &amp; Skyhawk Ultra NVMe PCIe SSD Datasheet</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Reducing SSD Read Latency via NAND Flash Program and Erase Suspension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">U</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">E</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">FAST</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">A Model for Application Slowdown Estimation in On-Chip Networks and Its Use for Improving System Fairness and Performance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ghose</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mutlu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tzeng</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N.-F</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCD</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Performance Characterization of Hyper-Scale Applications on NVMe SSDs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><forename type="middle">U</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Siyamwala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Awasthi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Suri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Guz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Shayesteh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Balakrishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMETRICS</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Performance Analysis of NVMe SSDs and Their Implication on Real World Databases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><forename type="middle">U</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Siyamwala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Suri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Awasthi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Guz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Shayesteh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Balakrishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SYSTOR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Garbage Collection and Wear Leveling for Flash Memory: Past and Future</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-C</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-M</forename><surname>Tsao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-W</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-C</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-H</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuo</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-W</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SMARTCOMP</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">VSSIM: Virtual Machine Based SSD Simulator</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoo</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Won</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Choil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cha</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MSST</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
