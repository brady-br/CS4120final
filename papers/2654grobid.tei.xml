<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2020-09-29T02:49+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Pricing Games for Hybrid Object Stores in the Cloud: Provider vs. Tenant</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Cheng</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Virginia Tech</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Safdar Iqbal</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Virginia Tech</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aayush</forename><surname>Gupta</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">IBM Research -Almaden</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><forename type="middle">R</forename><surname>Butt</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Virginia Tech</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Pricing Games for Hybrid Object Stores in the Cloud: Provider vs. Tenant</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Cloud object stores are increasingly becoming the de facto storage choice for big data analytics platforms, mainly because they simplify the management of large blocks of data at scale. To ensure cost-effectiveness of the storage service, the object stores use hard disk drives (HDDs). However, the lower performance of HDDs affect tenants who have strict performance requirements for their big data applications. The use of faster storage devices such as solid state drives (SSDs) is thus desirable by the tenants, but incurs significant maintenance costs to the provider. We design a tiered object store for the cloud, which comprises both fast and slow storage devices. The resulting hybrid store exposes the tiering to tenants with a dynamic pricing model that is based on the tenants&apos; usage and the provider&apos;s desire to maximize profits. The tenants leverage knowledge of their work-loads and current pricing information to select a data placement strategy that would meet the application requirements at the lowest cost. Our approach allows both a service provider and its tenants to engage in a pricing game, which our results show yields a win-win situation.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction and Motivation</head><p>To make data analytics easy to deploy and elastically scale in the cloud while eliminating redundant data copying cost, cloud providers typically let their tenants run Big Data processing jobs on vast amount of data stored in object stores. For example, AWS <ref type="bibr" target="#b7">[8]</ref>, Google Cloud <ref type="bibr" target="#b3">[4]</ref> and OpenStack <ref type="bibr" target="#b9">[10]</ref> provide their own Hadoop to object store connectors that allow tenants to directly use object stores as a replacement of HDFS <ref type="bibr" target="#b25">[26]</ref>. Moreover, commercial Big Data platforms such as Amazon EMR <ref type="bibr" target="#b0">[1]</ref> and Azure HDInsight <ref type="bibr" target="#b4">[5]</ref> go a step further and directly employ object stores as the primary storage technology.</p><p>Cloud-based object stores use low-cost HDDs as the underlying storage medium. This is because the price gap between HDDs and SSDs continue to be significant <ref type="bibr" target="#b8">[9]</ref>, especially for datacenter-scale deployments. Object stores have traditionally been used as data dumps for large objects such as backup archives and largevolume pictures or videos; use cases where SSDs would incur a high acquisition as well as maintenance cost <ref type="bibr" target="#b23">[24]</ref>, e.g., premature device replacement. Nevertheless, recent research has shown that SSDs can deliver significant benefits for many types of Big Data analytics workloads <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b17">18]</ref>, which are thus driving the need for adopting SSDs. Newer technology on this front is promising, but does not adequately address the cost and performance trade-offs. For example, while the newer 3-bit MLC NAND technology promises to deliver higher SSD densities and potentially drive down the acquisition cost, it has taken a major toll on SSD endurance <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b27">28]</ref>, which raises the maintenance costs.</p><p>Tiered storage is used in many contexts to balance the HDD-SSD cost and benefits by distributing the workload on a hybrid medium consisting of multiple tiers <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b26">27]</ref>. Data analytics applications are particularly amenable to such tiered storage deployments because of the inherent heterogeneity in workload I/O patterns. The choice of tiers depends on tenants' workloads and the performance benefits achieved by using specific tiers. A growing class of data analytics workloads demonstrate different unique properties <ref type="bibr" target="#b12">[13]</ref>, which cannot be satisfied by extant heat-based tier allocation approaches <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b26">27]</ref>. To this end, we propose an innovative tiered object store that exposes tiering control to tenants by offering the tiers under dynamic pricing. Thus, the tenants can meet their price-performance objectives by partitioning their workloads to utilize different tiers based on their application characteristics.</p><p>In this paper, we argue that traditional HDD-based object stores are inefficient. (1) From the cloud tenants' perspective, an HDD-based object store cannot effectively meet their requirements (e.g., deadlines) due to the relatively slow I/O performance of HDDs. (2) From the cloud provider's perspective, an HDD-only object store does not provide any pricing leverage, which reduces profitability. A faster tier can provide a higher qualityof-service (QoS), which can be strategically priced to increase profits. Hence, a hybrid HDD-SSD approach is desirable for both cloud providers and tenants.</p><p>To verify our argument, we conducted a trace-driven simulation study by replaying two 250-job snippet traces from Facebook's Hadoop production traces <ref type="bibr" target="#b11">[12]</ref>. We set the HDD tier price as $0.0011/GB/day-average of the Google Cloud Storage price of $0.00087/GB/day and the Google Cloud's HDD persistent block storage price of $0.0013/GB/day-and the SSD tier price as $0.0044/GB/day, i.e., 4× the HDD price. Note that we have chosen to use per-day pricing for our study as the granularity of our proposed price adjustment is one day ( §3). trace 1 consumes 12 TB data and generates 4.7 TB output, while trace 2 consumes 18 TB data and generates 8.2 TB output. For the hybrid storage tiering case (HDD+SSD), the tenant places jobs in differ- ent tiers with a desired workload completion deadline of 105 hours. For this purpose, we use Algorithm 1 that essentially tries to optimize the tier allocation to meet the deadline while minimizing the cost ( §2.2). <ref type="figure" target="#fig_0">Figure 1</ref> shows the results, from which we make three observations. (1) Workloads with HDD-only config. cannot meet the tenant-defined deadline and the cloud provider earns the lowest profit. (2) With HDD+SSD tiering config., both workloads are able to meet the deadline, while the cloud provider sees significantly more profit (trace 2 has larger input and output datasets and hence yields more profit). This is because the tenant places part of the workloads on the SSD tier, which is more expensive than the HDD tier. (3) SSD only config. improves performance, but with marginally higher profit, compared to HDD+SSD. This is mainly due to HDD+SSD's tiering optimization. This experiment demonstrates that through object storage tiering both the cloud provider and tenants can effectively achieve their goals.</p><p>Cloud providers have a multitude of device options available for deploying object storage infrastructure, including HDDs with different RPMs, SATA and PCIe SSDs and the emerging SCM devices, etc. These options offer different performance-price trade-offs. For example, each device type offers different cost/GB and, in case of SSDs and SCMs, different endurance. In a tiered setup comprising such a variety of storage choices, estimating price points while keeping maintenance costs under control is a challenge. Moreover, while the cloud providers encourage tenants to use more SSDs to increase their profits, they want to keep SSDs' wear-out in check -if tenant workloads are skewed towards SSDs due to high performance requirements, providers run the risk of SSD wear-out earlier than expected, which ends up increasing management costs and decreasing overall profits.</p><p>To remedy the above issue, we introduce a dynamic pricing model that providers can leverage to mitigate additional costs and increase overall operating profits for providers. The dynamic pricing model has two objectives: (1) to balance the price-increasing and SSD wearout rate by exploiting the trade-off between high revenue versus high operational costs (e.g., replacing SSDs) for high profit; (2) to provide an effective incentivizing mechanism to tenants so that the tenants can meet their goals via object store tiering in a more cost-efficient fashion. Generally, storage tiering has been looked at from just one entity's perspective. In contrast, the novelty of this work lies in the leader/follower game theoretic model that we adopt, where the objectives of cloud provider and tenants are either disjoint or contradictory. We take the first step towards providing a cloud-providerdriven game-theoretic pricing model through object storage tiering. Yet another unique aspect of our storage tiering approach is handling of the lack of information available to the players (cloud, tenants). In extant tiering solutions adopted in private datacenters, data placement decisions are generally made by administrators who have detailed information about the systems involved. This is not true in public cloud space, where information about many aspects or details may be missing. Thus, not only the motivations different from the private deployments for providers and tenants in a public cloud, but they also have to make decisions based on partial information.</p><p>Specifically, we makes the following contributions in this paper. <ref type="formula">(1)</ref> We design a leader/follower gaming model with the goal to maximize cloud provider's profit. The provider makes the pricing decisions by estimating tenants' storage capacity demand distribution among different tiers; driven by the prices, tenants employ a simulated annealing based tiering solver to guide object storage tiering for maximizing their utility. (2) We demonstrate through trace-driven simulations that our novel object storage tiering pricing mechanism can deliver increased profit for the cloud provider and potentially achieve win-win for both the provider and tenants.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Model Design</head><p>We design a leader/follower cloud pricing framework with the objective of maximizing a cloud provider's profit. We model the object storage tiering for tenants and dynamic pricing for the provider, and capture the provider-tenant interactions. In our model, the game is played in two steps. First, the cloud provider (leader) makes the pricing decisions ( §2.1) based on predictions of tenants' demand on storage resources. Second, given prices of different storage resources, a tenant (follower) makes tiering decisions based on her own requirements ( §2.2), and the strategy is represented by the tenant's storage tiering specification, i.e., which jobs use what tier.</p><p>While the tenants can see the price changes by the provider, they are unaware of the actual reasons for the changes. Even if the tenants understood the reasons, multi-tenancy prevents modeling of the provider's behavior. Hence, in our formulation tenants can only predict the provider's price movements based on historical data. Similarly, the provider is not aware of explicit tenant requirements, and only garners information from the requested storage capacity and the writes operations (PUT Notation Description F set of all tiers in object store capacity (n,s) total capacity of tier s in time slot n f <ref type="bibr">(n,s)</ref> fraction of data placed on tier s in time slot n w <ref type="bibr">(n,s)</ref> writes in GB on tier s in time slot n provider p <ref type="bibr">(n,s)</ref> price of tier s in time slot n (decision var) a HDD class b SSD class α 1 , β 1 , α 2 , β 2 model parameters θ parameter used to constraint SSD's price J set of all analytics jobs in a workload sz i dataset size of job i tenant x i tier used by job i (decision var) c i capacity provisioned for job i (decision var) α 3 , β <ref type="bibr" target="#b2">3</ref> model parameters <ref type="table" target="#tab_0">Table 1</ref>: Notations used in the provider and tenant models.</p><p>requests are tracked for accounting purposes <ref type="bibr" target="#b5">[6]</ref>). Thus, the provider also only uses historical information about these aspects to predict tenant demand. Consequently, both the tenants and the provider models adopted in our game are purposefully "myopic" controls for predicting only the next time slot, and not beyond that in the future.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Provider Model</head><p>We model the provider cost as follows. Assuming that the fraction of the cost that comes from SSDs wear-out is t &lt; 1, 1 the cost can be modeled as: cost = 1 t · p ssd endurance · w, where p ssd is the market price of one SSD, endurance is the endurance lifespan of the particular SSD, and w is the amount of data written to the SSD in GB. <ref type="table" target="#tab_0">Table 1</ref> lists all the notations used in our provider and tenant models. The pricing decision making process can be modeled as a non-linear optimization problem that maximizes the profit defined by Equation 1.</p><formula xml:id="formula_0">max pro f it = ∑ i ∑ f (capacity f · f (i, f ) · p (i, f ) ) − cost i (1) s.t. f ′ (n+1,b) = α 1 · f (n,b) − β 1 · (p ′ (n+1,b) − p (n,b) )<label>(2)</label></formula><formula xml:id="formula_1">f ′ (n+1,a) = 1 − f ′ (n+1,b)<label>(3)</label></formula><formula xml:id="formula_2">f (n,b) = α 1 · f (n−1,b) − β 1 · (p (n,b) − p (n−1,b) )<label>(4)</label></formula><formula xml:id="formula_3">f (n,a) = 1 − f (n,b)<label>(5)</label></formula><formula xml:id="formula_4">w ′ (n+1,b) = α 2 · w (n,b) + β 2 · ( f ′ (n+1,b) − f (n,b) )<label>(6)</label></formula><formula xml:id="formula_5">w (n,b) = α 2 · w (n−1,b) + β 2 · ( f (n,b) − f (n−1,b) )<label>(7)</label></formula><p>∀i :</p><formula xml:id="formula_6">w (i,b) ≤ L i (8) ∀i, s : 0 ≤ capacity i · f (i,s) ≤ L s (9) ∀i : p min,b ≤ p (i,b) ≤ θ · p (i,a) , where θ &gt; 1 (10) ∀i, s : f (i,s) ≤ 1 where i ∈ {n, n + 1}, s ∈ F<label>(11)</label></formula><p>In a time slot n, we predict the SSD demand proportion for the next time slot n + 1 with Equation 2, which depends on the difference between the predicted SSD price for n + 1 and the calculated SSD price for n. The predicted HDD demand proportion is determined by Equation 3. Similarly, Equation 4 and 5 define the predicted <ref type="bibr" target="#b0">1</ref> We choose to use a fixed t for simplicity; in real world, there are numerous factors that come into play and t may not be a constant. SSD and HDD demand proportion for n, respectively, and Equation 11 enforces the proportion range.</p><p>Equation 6 predicts the amount of data that will be written to SSDs, which is determined by the difference of predicted SSD demand proportion in time slot n + 1 to that in time slot n. If the SSD demand is predicted to increase, it implies that the amount of data that will be absorbed by the SSD tier will also increase. Equation 8 defines the SSD tier data writing constraint, which ensures that the expected amount of data written to the SSD tier will not exceed the threshold that is calculated based on accumulated historical statistics. The factor indirectly controls the value adaptation of decision variables p (n,b) and p ′ (n+1,b) . The storage capacity limit in the cloud datacenter is defined by Equation 9. We assume HDD prices p (n,a) and p (n+1,a) are fixed, and SSD prices are constrained in a range given by Equation 10. <ref type="bibr" target="#b1">2</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Tenant Model</head><p>The data placement and storage provisioning at the tenant side is modeled as a non-linear optimization problem as well. The goal is to maximize tenant utility as defined by Equation 12.</p><formula xml:id="formula_7">max utility = 1 (T · $)<label>(12)</label></formula><formula xml:id="formula_8">s.t. ∀i ∈ J : c i ≥ sz i<label>(13)</label></formula><formula xml:id="formula_9">T = J ∑ i=1 񮽙 x i , c[s i ], ˆ R, ˆ L i 񮽙 + penalty(data migrated) ≤ deadline , where x i ∈ F<label>(14)</label></formula><formula xml:id="formula_10">$ = F ∑ s=1 c[s] · 񮽙 p (n,s) · T / 60 (15)</formula><p>where ∀s ∈ F,</p><formula xml:id="formula_11">∀i ∈ J, s.t. x i ≡ f : c[s] = ∑ c i , p ′ (n+1,b) = α 3 · p (n,b) + β 3 · p (n−1,b)<label>(16)</label></formula><p>The performance of the tenant's workload is modeled as the reciprocal of the estimated completion time in minutes ( 1 / T ) and the cost includes mainly the storage costs. The cost of each storage service is determined by the workload completion time (storage cost is charged on a hourly basis) and capacity provisioned for that service. The overall storage cost is obtained by aggregating the individual costs of each tier in the object store (Equation 15). Equation 13 defines the capacity constraint, which ensures that the storage capacity (c i ) provisioned for a job is sufficient to meet its requirements for all the workload phases (map, shuffle, reduce). Given a specific tiering solution, the estimated total completion time of the workload is defined by Equation 14, and constrained by a tenant-defined deadline. Equation 16 is the price predictor at the tenant side. The predicted price value can also be supplied as a hint by the cloud provider. The function penalty(.) serves as a penalty term that the ten- ant takes into account in terms of performance loss (e.g., longer completion time) while deciding tiers. We devise a simulated annealing based algorithm [13] (Algorithm 1) for computing tenants' data partitioning and job placement plans. The algorithm takes as input workload information ( ˆ L ), compute cluster configuration ( ˆ R), and information about performance of analytics applications on different storage services ( ˆ M ) as defined in <ref type="table" target="#tab_0">Table 1</ref>. ˆ P init serves as the initial tiering solution that is used to specify preferred regions in the search space. The results from a simple greedy algorithm based on the characteristics of analytics applications (e.g., the four described in §3) can be used to devise an initial placement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Preliminary Results</head><p>We have used trace-driven simulations to demonstrate how our cloud-tenant interaction models perform in practice. We use the production traces collected from a 3, 000-machine Hadoop deployment at Facebook <ref type="bibr" target="#b11">[12]</ref>. The original traces consist of 25, 428 Hadoop jobs; we chose to use a snippet of 1, 750 jobs to simulate a 7-day workload. The workload runs on a cloud object store with built-in tiering mechanism that tenants can control. We set the time slot for our models to one day.</p><p>We assign to our workload, in a round-robin fashion, four analytics applications that are typical components of real-world analytics <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b28">29]</ref>   making it reduce intensive. KMeans is an iterative CPUintensive clustering application that expends most of its time in the compute phases of map and reduce iterations. <ref type="figure" target="#fig_1">Figure 2</ref> shows price variation by the cloud provider's model based on the amount of data written by the tenant to the SSD tier on a per-day basis. The HDD price is fixed, while the SSD price is dynamically adjusted on a daily basis for dynamic pricing (the pricing is the same as for <ref type="figure" target="#fig_0">Figure 1)</ref>. Under static pricing, the provider sets a static price and tenants periodically run Algorithm 1, whereas under dynamic pricing, the provider and tenants interact. The per-day write limit L n is dynamically adjusted based on the amount of writes from the tenant side (though not discernible in the <ref type="figure">figure)</ref>. <ref type="figure" target="#fig_1">Figure 2(a)</ref> shows the price changes for a 7-day trace, with a different workload running on each day. We observe that as the amount of writes by the tenant on SSD tier increases above the write limit, the cloud provider begins to adjust the SSD price. The tenant's model will adjust the tiering strategy to either put more data in the HDD tier or pay more for the SSD tier in the case of a strict deadline requirement. Since, each day has a different workload and hence a different deadline. For example, from day 4, the tenant, with the goal of maximizing the tenant utility, allocates fewer jobs to the SSD tier. Once the SSD writes are reduced below the threshold, the provider lowers the SSD tier price to incentivize the tenant to use more of the SSD resource on the next day. The tenant responds to this change on day 7, where the workload deadline is stricter than the previous 2 days. <ref type="figure" target="#fig_1">Figure 2</ref>(b) shows the price changes for a 7-day period with the same single-day trace replayed every day. This trace shows stronger correlation between per-day  SSD writes from the tenant and the SSD price from the provider. This workload exhibits the same specifications every day (e.g. dataset size, a relaxed deadline, etc.), thus the daily writes on the SSD tier remain stable under static pricing. However, the dynamic pricing model can effectively respond to the spike in the amount of writes on the first day and adjust the SSD price accordingly. Given the increased SSD price, the tenant tries to reduce their monetary cost by migrating more jobs to the cheaper HDD tier, while still meeting the deadline. When the provider lowers the SSD price in response, the tenant increases their use of SSD, prompting the provider to increase the SSD price again. This interaction of the tenant and the provider results in an average of 2.7 TB/day SSD writes compared to an average of 7 TB/day under static pricing (with 0% deadline miss rate for both cases). The test demonstrates that our dynamic pricing model can adaptively adjust the SSD pricing based on the amount of data written to the SSD tier to maintain high profits while keeping the SSD wear-out under control by keeping write loads to SSD in check.</p><p>In our next test, we examine the impact of different SSD pricing models on provider profit and tenant utility, i.e., the cloud-tenant interaction. <ref type="figure" target="#fig_3">Figure 3</ref> shows the results. We choose three static prices for SSDs: low (the minimum SSD price that we use: $0.0035/GB/day), medium ($0.0082/GB/day), and high (the maximum SSD price, $0.0121/GB/day). We also compare static prices with our dynamic pricing model. As observed in <ref type="figure" target="#fig_3">Figure 3</ref>(a), dynamic pricing yields the highest provider profit as it increases the price based on SSD writes from the tenant. Both static low and medium high yield similar profits that are 32.6% lower than that gained under dynamic pricing. This is because static medium results in more jobs placed on the HDD tier, which lowers the tenant cost while causing longer workload completion time. static low is not able to generate enough profit due to the very low price, while under static high the tenant solely migrates all the jobs to the HDD tier, thus resulting in low profit.</p><p>Next, we examine the tenant utility in <ref type="figure" target="#fig_3">Figure 3</ref>(b).</p><p>With static low SSD price, the tenant utility is 17.1% higher than that achieved under dynamic pricing. However, this would result in significantly shortened SSD lifetime (by as much as 76.8%), hence hurting the cloud profit in the long term. With static high SSD price, the tenant utility is reduced by 17.1% compared to that of dynamic pricing, as the tenant shifts most jobs to the HDD tier. static medium SSD price yields slightly higher tenant utility as compared to static high but still 13.1% lower than that seen under dynamic pricing. This is because the tenant has to assign some jobs to the faster SSD tier in order to guarantee that the workload does not run for too long. Dynamic pricing, on the other hand, maintains the tenant utility at a reasonably high level (higher than both static medium and static high but slightly lower than static low), while guaranteeing that the SSD lifetime constraints are met. This demonstrates that our dynamic pricing model can effectively achieve a winwin for both the cloud provider and tenants.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Related Work</head><p>Storage Tiering Recent research <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b17">18]</ref> demonstrates that adding a SSD tier for serving reads is beneficial for HDFS-based HBase and Hadoop. Existing implementations of cloud object stores provide mechanisms for tiered storage. OpenStack Swift supports storage tiering through Storage Policies <ref type="bibr" target="#b6">[7]</ref>. Ceph, which exposes an object store API, has also added tiering support <ref type="bibr" target="#b1">[2]</ref>. Our work focuses on providing insights into the advantages of dynamically priced tiered object storage management involving both cloud providers and tenants. Cloud Pricing Researchers have also looked at cloud dynamic pricing <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b24">25]</ref>. CRAG <ref type="bibr" target="#b2">[3]</ref> focuses on solving the cloud resource allocation problems using game theoretical schemes, while Londono et al. <ref type="bibr" target="#b21">[22]</ref> propose a cloud resource allocation framework using colocation game strategy with static pricing. Ben-Yehuda et al. <ref type="bibr" target="#b10">[11]</ref> propose a game-theoretic market-driven bidding scheme for memory allocation in the cloud. We adopt a simplified game theoretic model where the cloud providers give incentives in the form of dynamic pricing and tenants adopt tiering in object stores for achieving their goals.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We show that by combining dynamic pricing with cloud object storage tiering, cloud providers can increase their profits while meeting the SSD wear-out requirements, and tenants can effectively achieve their goals with a reasonably high utility. We demonstrate this win-win situation via real-world trace-drive simulations. In our future work, we plan to explore different tiering algorithms and best dynamic pricing models in multi-tenant clouds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Discussion Points</head><p>While a lot of research has looked at the technical aspects of building clouds, their impact and their use by the tenants, we believe the current cloud pricing mechanism (especially for storage services) is vague and lacks transparency. In this work, we have attempted to reconcile the economic principles of demand and supply with the technical aspects of storage tiering through dynamic pricing to showcase the benefits for both the cloud provider as well as the tenants. We believe that our paper will lead to discussion on the following points of interest: (1) The need for revisiting pricing strategies in established hybrid storage deployments and practices. Since storage tiering is a wellstudied area, we believe that the paper will lead to hot discussion on how the paradigm shift is happening, and why the extant approaches and ideas need to be revisited. A particular point of interest in the context of tiering is that the objectives of different players are often times in conflict. (2) Issues such as how useful can our pricing "knob" be for the cloud provider to shape tenant behavior to suit the provider requirements, and at what granularity should the proposed price variations be implemented, are part of our future work and would make for a productive discussion. <ref type="formula" target="#formula_1">(3)</ref> The role of flash and other emerging technologies in cloud-based object stores.</p><p>An unexplored issue is tenant behavior modeling. Our preliminary results assume a smart tenant using models described in §2. However, in reality, tenants can have very different behaviors and utility functions. Furthermore, we have not looked at multi-tenancy in detail. For instance, a "naive" or "rogue" tenant that performs a lot of SSD writes without considering their utility can cause the cloud to increase the price of SSDs, thus affecting the utility of other well-behaved tenants. Another open aspect of our current work is investigating the game theoretic results of our model. These include the behavior of provider's profit and the tenant's utility when the system reaches equilibrium and the comparison of these objectives under Nash and Stackelberg equilibria.</p><p>Furthermore, prices of SSDs are falling. Even though the gap between HDD and SSD prices is still wide today, in the future with increase in NAND flash production, improvement in flash yields, lithographic improvements such as 3D stacking, etc., can reduce the price difference, resulting in SSDs becoming the de facto storage medium in cloud environments. From the tenant side, while researchers have shown the merit of using SSDs (e.g., in interactive HBase workloads <ref type="bibr" target="#b15">[16]</ref>), their use in batchoriented analytics workloads is just starting. Indeed, in another research work <ref type="bibr" target="#b12">[13]</ref>, we have shown through real experiments on Google Cloud that SSDs can provide great benefits especially when considering heterogeneity in cloud storage services, enforcing our belief that our future hybrid object store prototyping efforts will yield desirable win-win solutions.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Tenant workload runtime for trace 1 and trace 2, and provider's profits under different configurations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Dynamic pricing by the provider and the tenant's response for two 7-day workloads. The dotted horizontal line represents the daily write limit L i . The variation in L i is too small to be discernible at this scale.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Cloud profit and tenant utility averaged over 7 days. static low, static medium and static high mean a low, medium, and high static SSD price, respectively. Cloud profit and tenant utility are normalized wrt. static high.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Algorithm 1 : Tiering solver.</head><label>1</label><figDesc></figDesc><table>Input: Job information matrix: ˆ 
L , Analytics job model matrix: 
ˆ 
M , Runtime configuration: ˆ 
R, Initial solution: ˆ 
P init . 
Output: Tiering planˆPplanˆ planˆP best 

1 begin 

2 

ˆ 
P best ← {} 

3 

ˆ 
P curr ← ˆ 
P init 

4 

exit ← False 

5 

iter ← 1 

6 

temp curr ← temp init 

7 

U curr ← Utility( ˆ 
M , ˆ 
L , ˆ 
P init ) 

8 

while not exit do 

9 

temp curr ← Cooling(temp curr ) 

10 

for nextˆPnextˆ nextˆP neighbor in AllNeighbors( ˆ 
L , ˆ 
P curr ) do 

11 

if iter &gt; iter max then 

12 

exit ← True 

13 

break 

14 

U neighbor ← Utility( ˆ 
M , ˆ 
L , ˆ 
P neighbor ) 

15ˆP 

15ˆ 15ˆP best ← U pdateBest( ˆ 
P neighbor , ˆ 
P best ) 

16 

iter++ 

17 

if Accept(temp curr , U curr , U neighbor ) then 

18ˆP 

18ˆ 18ˆP curr ← ˆ 
P neighbor 

19 

U curr ← U neighbor 

20 

break 

21 

returnˆPreturnˆ returnˆP best 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head></head><label></label><figDesc>and exhibit diversified I/O and computation characteristics. Sort, Join and Grep are I/O-intensive applications. The execution time of Sort is dominated by the shuffle phase I/O. Grep spends most of its runtime in the map phase I/O, reading input and find- ing records that match given patterns. Join represents an analytic query that combines rows from multiple tables and performs the join operation during the reduce phase,</figDesc><table>0 
0.003 
0.006 
0.009 
0.012 
0.015 

1 
2 
3 
4 
5 
6 
7 
0 

2 

4 

6 

8 

Price ($/GB/day) 
Data size (TB) 

Day 

SSD price(dynamic) 
SSD writes(dynamic) 

SSD price(static) 
SSD writes(static) 

(a) A 7-day trace. 

0 
0.002 
0.004 
0.006 
0.008 
0.01 

1 
2 
3 
4 
5 
6 
7 
0 

2 

4 

6 

8 

Price ($/GB/day) 
Data size (TB) 

Day 

(b) A single-day trace repeated 7 times. 

</table></figure>

			<note place="foot" n="2"> We plan to include IOPS per client in our future pricing models.</note>
		</body>
		<back>

			<div type="acknowledgement">
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title/>
		<ptr target="http://goo.gl/GXzwaU" />
	</analytic>
	<monogr>
		<title level="j">Amazon Elastic MR</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ceph Storage Pools</surname></persName>
		</author>
		<ptr target="http://docs.ceph.com/docs/argonaut/config-cluster/pools/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Cloud Resource Allocation Games</title>
		<ptr target="https://www.ideals.illinois.edu/handle/2142/17427" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Google Cloud Storage Connector for Hadoop</title>
		<ptr target="http://goo.gl/ji4qqp" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hdinsight</forename><surname>Microsoft Azure</surname></persName>
		</author>
		<ptr target="http://goo.gl/wsQ9QG" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Openstack</forename><surname>Ceilometer</surname></persName>
		</author>
		<ptr target="https://wiki.openstack.org/wiki/Ceilometer" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Openstack</forename><surname>Swift Policies</surname></persName>
		</author>
		<ptr target="http://docs.openstack.org/developer/swift/overview_policies.html" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<ptr target="https://wiki.apache.org/hadoop/AmazonS3" />
		<title level="m">S3 as a replacement of HDFS</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
				<ptr target="//www.enterprisestorageforum.com/storage-hardware/ssd-vs.-hdd-pricing-seven-myths-that-need-correcting.html" />
		<title level="m">SSD vs. HDD Pricing: Seven Myths That Need Correcting</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Swift Connector To Hadoop</surname></persName>
		</author>
		<ptr target="http://docs.openstack.org/developer/sahara/userdoc/hadoop-swift.html" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Market-driven memory allocation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Agmon</forename><surname>Ben-Yehuda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Posener</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ben-Yehuda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>And Mu&amp;apos;alem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ginseng</surname></persName>
		</author>
		<idno>VEE &apos;14</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th ACM SIG-PLAN/SIGOPS International Conference on Virtual Execution Environments</title>
		<meeting>the 10th ACM SIG-PLAN/SIGOPS International Conference on Virtual Execution Environments<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="41" to="52" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Interactive analytical processing in big data systems: A cross-industry study of mapreduce workloads</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Alspaugh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katz</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. VLDB Endow</title>
		<meeting>VLDB Endow</meeting>
		<imprint>
			<date type="published" when="2012-08" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="1802" to="1813" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Cast: Tiering storage for data analytics in the cloud</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Iqbal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>And Butt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">R</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24rd International Symposium on High-performance Parallel and Distributed Computing</title>
		<meeting>the 24rd International Symposium on High-performance Parallel and Distributed Computing<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>HPDC &apos;15</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The bleak future of nand flash memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grupp</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">M</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Swanson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th USENIX Conference on File and Storage Technologies</title>
		<meeting>the 10th USENIX Conference on File and Storage Technologies<address><addrLine>Berkeley, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="2" to="2" />
		</imprint>
	</monogr>
	<note>FAST&apos;12, USENIX Association</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Cost effective storage using extent based dynamic tiering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guerra</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pucha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Glider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Belluomini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rangaswami</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th USENIX Conference on File and Stroage Technologies</title>
		<meeting>the 9th USENIX Conference on File and Stroage Technologies<address><addrLine>Berkeley, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="20" to="20" />
		</imprint>
	</monogr>
	<note>FAST&apos;11, USENIX Association</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Analysis of hdfs under hbase: A facebook messages case study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harter</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Borthakur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Aiyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Arpaci-Dusseau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arpaci-Dusseau</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">H</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th USENIX Conference on File and Storage Technologies</title>
		<meeting>the 12th USENIX Conference on File and Storage Technologies<address><addrLine>Santa Clara, CA; USENIX</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="199" to="212" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Evaluating phase change memory for enterprise storage systems: A study of caching and tiering approaches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kim</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Seshadri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Dickey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chiu</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th USENIX Conference on File and Storage Technologies</title>
		<meeting>the 12th USENIX Conference on File and Storage Technologies<address><addrLine>Santa Clara, CA; USENIX</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="33" to="45" />
		</imprint>
	</monogr>
	<note>FAST 14</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">hats: A heterogeneityaware tiered storage for hadoop</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Krish</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Anwar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>And Butt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Cluster, Cloud and Grid Computing (CCGrid)</title>
		<imprint>
			<date type="published" when="2014-05" />
			<biblScope unit="page" from="502" to="511" />
		</imprint>
	</monogr>
	<note>14th IEEE/ACM International Symposium on</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Profit-maximizing virtual machine trading in a federation of selfish clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">I</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lau</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">INFOCOM, 2013 Proceedings IEEE</title>
		<imprint>
			<date type="published" when="2013-04" />
			<biblScope unit="page" from="25" to="29" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">On the importance of evaluating storage systems&apos; $costs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">I</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Mukker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zadok</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th USENIX Conference on Hot Topics in Storage and File Systems</title>
		<meeting>the 6th USENIX Conference on Hot Topics in Storage and File Systems<address><addrLine>Berkeley, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="6" to="6" />
		</imprint>
	</monogr>
	<note>HotStorage&apos;14, USENIX Association</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Pricing data center demand response. SIGMETRICS Perform</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liu</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Low</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wierman</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Eval. Rev</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="111" to="123" />
			<date type="published" when="2014-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Colocation games: And their application to distributed resource management</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Londo˜nolondo˜</forename><surname>Londo˜no</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bestavros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Teng</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-H</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2009 Conference on Hot Topics in Cloud Computing</title>
		<meeting>the 2009 Conference on Hot Topics in Cloud Computing<address><addrLine>Berkeley, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
	<note>HotCloud&apos;09, USENIX Association</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Extending the lifetime of flash-based storage through reducing write amplification from file systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">U</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Presented as part of the 11th USENIX Conference on File and Storage Technologies (FAST 13)</title>
		<meeting><address><addrLine>San Jose, CA; USENIX</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="257" to="270" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Migrating server storage to ssds: Analysis of tradeoffs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Narayanan</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Thereska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Donnelly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Elnikety</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rowstron</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename></persName>
		</author>
		<idno>Eu- roSys &apos;09</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th ACM European Conference on Computer Systems</title>
		<meeting>the 4th ACM European Conference on Computer Systems<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="145" to="158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">An online auction framework for dynamic resource provisioning in cloud computing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shi</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lau</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">C</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 2014 ACM International Conference on Measurement and Modeling of Computer Systems</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="71" to="83" />
		</imprint>
	</monogr>
	<note>SIGMETRICS &apos;14, ACM</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">The hadoop distributed file system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shvachko</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Radia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chansler</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 IEEE 26th Symposium on Mass Storage Systems and Technologies (MSST)</title>
		<meeting>the 2010 IEEE 26th Symposium on Mass Storage Systems and Technologies (MSST)<address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
	<note>MSST &apos;10</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Balancing fairness and efficiency in tiered storage systems with bottleneck-aware allocation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Varman</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th USENIX Conference on File and Storage Technologies</title>
		<meeting>the 12th USENIX Conference on File and Storage Technologies<address><addrLine>Santa Clara, CA; USENIX</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="229" to="242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Delta-ftl: Improving ssd lifetime via exploiting content locality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">U</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">E</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th ACM European Conference on Computer Systems</title>
		<meeting>the 7th ACM European Conference on Computer Systems<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="253" to="266" />
		</imprint>
	</monogr>
	<note>EuroSys &apos;12, ACM</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Delay scheduling: A simple technique for achieving locality and fairness in cluster scheduling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zaharia</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Borthakur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sen Sarma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Elmele-Egy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Shenker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stoica</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th European Conference on Computer Systems</title>
		<meeting>the 5th European Conference on Computer Systems<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="265" to="278" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
