<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2020-09-29T04:24+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Working Set Model for Multithreaded Programs</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kishore</forename><forename type="middle">Kumar</forename><surname>Pusukuri</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Oracle Inc</orgName>
								<address>
									<settlement>Santa Clara</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Working Set Model for Multithreaded Programs</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Knowledge of the working set of pages associated with an application provides an opportunity for effective allocation of resources in multicore multiprocessor systems. Various techniques for approximating the working set size using either simulations or program traces have been proposed. However, these techniques are very expensive, and therefore not practical for dynamically optimizing resources. To alleviate this problem, in this work, we develop a statistical model based on machine learning techniques for approximating the working set size of mul-tithreaded programs running on multicore multiprocessor systems. The basic idea is to correlate the working set size of a program with its resource usage characteristics, such as resident set size and TLB miss rate. Through extensive experimentation with 20 multithreaded programs from SPEC OMP2012 and PARSEC on a SPARC T4-4 running Oracle Solaris 11 TM , we demonstrate that the model has 96% prediction accuracy and its overhead is negligible.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Multicore multiprocessor systems with large caches and many cores have become ubiquitous. Large caches used in shared memory multicore architectures can avoid high memory access time only if data is referenced within the address scope of the cache. Therefore, locality is a key issue in achieving high performance for multithreaded applications running on multicore systems <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b18">19]</ref>. Locality (temporal locality) is often expressed in terms of working sets <ref type="bibr" target="#b10">[11]</ref>. The working set of an application is a measure of its dynamic memory demand in an execution window <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b22">23]</ref>. The working set size (WSS) of an application is computed by multiplying the number of pages referenced over an interval with the size of the page. WSS has been used to model resource sharing among concurrent tasks of an application <ref type="bibr" target="#b9">[10]</ref> and for effective resource management in the Cloud <ref type="bibr" target="#b23">[24]</ref>. Therefore, knowing the WSS of an application provides an opportunity for effective allocation of resources and thus improved performance.</p><p>Various techniques for approximating WSS using either simulations or program traces have been proposed <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b22">23]</ref>. Although using these techniques we can determine the WSS of a particular program, the overhead of these techniques is very high and therefore not appropriate for dynamically optimizing resources. Moreover, most of the above existing techniques were evaluated using single-threaded programs on machines with very few cores. Oracle Solaris 11 provides the number of pages referenced by an application running on SPARC systems through the proc file system (/proc/pid/pagedata). However, it is very expensive to derive the WSS through the proc file system, as the overhead increases with the size of the working set. For example, the overhead of measuring the working set sizes of 20 multithreaded programs from PARSEC <ref type="bibr" target="#b2">[3]</ref> and SPEC OMP2012 <ref type="bibr" target="#b24">[25]</ref> on SPARC T4-4, ranges from 80 millisecs to 150,000 millisecs.</p><p>To address the above problems, in this paper, we develop a statistical model based on supervised learning for approximating the WSS of a multithreaded program running on a multicore multiprocessor system. To develop this model, first, we study the important resource usage characteristics of 20 emerging multithreaded programs from the PARSEC and SPEC OMP2012 benchmark suites on a SPARC T4-4 running Oracle Solaris 11. The basic idea is to correlate the WSS of an application with its important resource usage characteristics, such as resident set size (RSS) and TLB miss rate. We collect these characteristics using performance monitoring counters and simple utilities available in modern operating systems. Through extensive experimentation, we demonstrate that the model has 96% prediction accuracy. Moreover, the overhead of this model is negligible. Thus, we can use this model dynamically for effective allocation of resources in multicore multiprocessor systems. We also briefly present two potential applications of the above model to maximize the performance of multithreaded programs running on multicore multiprocessor systems. PARSEC: bodytrack (BT), fluidanimate (FA), ferret (FR), facesim (FS), streamcluster (SC), swaptions (SW); SPEC OMP2012: applu (AL), botsalgn (BA), bt331 (BB), botsspar (BS),bwaves (BW), fma3d (FM), ildbc (IL), imagick (IG), kdtree (KD), md (MD), mgrid (MG), nab (NM), smithwa (ST), swim (SM) <ref type="table" target="#tab_0">Table 1</ref>: The 20 multithreaded programs and their short names. These programs mainly stress CPU and main memory.</p><p>The key contributions of our work are as follows:</p><p>• We identify that resident set size, TLB miss rate, number of threads, and LLC miss rate are strongly correlate with the working set characteristics of multithreaded programs running on multicore multiprocessor systems.</p><p>• We demonstrate the usage of machine learning techniques in developing simple and robust models for characterizing working set sizes of emerging multithreaded applications.</p><p>The remainder of this paper is organized as follows. Section 2 presents the development of statistical models for approximating working set size in detail. We briefly describe our future work in Section 3. Finally, related work and conclusions are given in Sections 4 and 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Characterizing Working Set Size</head><p>The working set of pages associated with an application is the collection of its most recently used pages over a time interval <ref type="bibr" target="#b9">[10]</ref>. The working set size (WSS) is computed by multiplying the page-size with the number of pages referenced over a time interval. Characterizing the WSS is a challenging problem as it significantly varies from application to application. For example, a well-tuned scientific application can have a small working set of a few kilobytes, while a large database application can have a huge working set running into several gigabytes. Moreover, several factors affect the WSS of a multithreaded application running on multicore multiprocessor systems.</p><p>The basic idea for developing a model for approximating WSS is correlate it with important resource usage characteristics (i.e., factors) of the application. Therefore, identifying important factors is the key in developing an effective model to characterize the WSS of multithreaded applications. We use statistical models to capture important factors for approximating WSS. These models are constructed using supervised learning, where a set of input-output values is first observed and then a statistical model is trained to predict similar output values when similar input values are observed <ref type="bibr" target="#b14">[15]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Identifying Important Factors</head><p>To identify important resource usage characteristics that affect WSS, first we study 20 multithreaded programs from the PARSEC and SPEC OMP2012 with varying number of threads on a SPARC T4-4 running Oracle Solaris 11. These programs mainly stress CPU and main memory.  Time (seconds)</p><formula xml:id="formula_0">• • • • • • • • • • • • • • • • • • • • Main Memory (MB)</formula><p>•</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RSS WSS</head><p>(a) Facesim.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RSS WSS</head><p>(c) Imagick. <ref type="figure">Figure 1</ref>: Although RSS is correlated with WSS, it is not alone enough to accurately approximate WSS. The number of threads used to run the multithreaded program affects its WSS and RSS.</p><p>we ran them using native inputs (i.e., the largest inputs available). The SPEC OMP2012 programs were run on medium sized inputs. The range of the execution times of the programs is from 50 seconds to 4800 seconds. <ref type="table" target="#tab_1">Table 2</ref> provides the description of SPARC T4-4: it has four SPARC T4 processors, each of the processors (or sockets) has 64 virtual CPUs (vCPUs), and a total of 256 vCPUs. Since most of the above 20 programs exhibit poor performance because of high lock contention when running them with 256 threads on our SPARC T4-4, we assume that the above mentioned programs run with a maximum of 128 threads on SPARC T4-4. Therefore, we run the programs with 16, 32, 64, and 128 threads and collect their important resource usage characteristics for developing a statistical model to approximate WSS.</p><p>Resident Set Size &amp; Number of Threads. The resident set size (RSS) is a measure of how much physical memory is actually being used by the application <ref type="bibr" target="#b12">[13]</ref>. Therefore, RSS is correlated with the WSS. However, it is not sufficient to accurately approximate the WSS of multithreaded programs (see <ref type="figure">Figure 1</ref> (b)). <ref type="figure">Figure 1</ref> shows the RSS and the WSS of three multithreaded programs: facesim (FS), fluidanimate (FA) from PARSEC, and Imagick (IG) from SPEC OMP2012. We ran FS and FA with 64 threads and IG with varying number of threads <ref type="bibr">(16, 32, 64, and 128</ref>). The utility ps(1) is used to measure resident set size (RSS). As <ref type="figure">Figure 1</ref> shows, while the WSS of FS is steady, the WSS of FA varies. As we can see in Figures 1 (a), (b), and (c):</p><p>• RSS is not sufficient to accurately approximate WSS.</p><p>• Depending on the application WSS varies significantly. <ref type="figure">Figure 1</ref> (b) shows this.</p><p>• The number of threads used to run the multithreaded program significantly affects both WSS and RSS.</p><p>We can see this in <ref type="figure">Figure 1</ref> (c).</p><p>Therefore, both RSS and number of threads are important factors for approximating WSS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TLB Miss Rate &amp; Number of Threads.</head><p>Translation lookaside buffer (TLB) is used to improve the speed of virtual to physical address translation in modern computer systems. The number of entries in a TLB multiplied by the page size is defined as TLB reach. The TLB reach is critical to the performance of an application. If the TLB reach is not enough to cover the working set of a process, the process may spend a significant portion of its time satisfying TLB misses <ref type="bibr" target="#b9">[10]</ref>. Therefore, TLB miss rate is one of the important application characteristics for approximating WSS.</p><p>We also observe that multithreaded programs based on data parallelism experience smaller TLB miss rate when running them with more threads compared to running the same program with relatively small number of threads (or sequential version) on multicore multiprocessor systems. This is because, when we run the program with multiple threads, the thread scheduler migrates threads across all the cores (and sockets) of the system for balancing load. This allows threads to share the TLB cache of the whole system and also the working set is shared among all the threads. Therefore, the number of threads used to run a multithreaded program significantly affects TLB miss rate and thus it is one of the important factors for approximating WSS.</p><p>LLC Miss Rate &amp; Thread Migrations. The thread schedulers dynamically distribute threads across multiple processors to balance the load across the processors. However, the distribution of threads across processors of a multicore multiprocessor system impacts important application resource usage characteristics such as data locality, last-level cache misses (LLC misses) and thus performance of the multithreaded application. Typically, programs with large working set sizes exhibit high LLC miss rates.  Therefore, we consider RSS, TLB miss rate, number of threads used to run the application, and LLC miss rate as potential predictors (or important resource usage characteristics) of WSS. These predictors are used as inputs to the statistical models. <ref type="table" target="#tab_4">Table 3</ref> lists the predictors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Data Collection</head><p>We run the above 20 multithreaded programs <ref type="table" target="#tab_0">(Table 1)</ref> with varying number of threads <ref type="bibr">(16, 32, 64 , and 128</ref>) and collect input data (values of the predictors) for developing the models. From the runs of the 20 programs, we collect 80 data points, where each data point is a 7-tuple containing the 6 predictors (shown in <ref type="table" target="#tab_4">Table 3</ref>) and the observed value of WSS as the target parameter. Here each of the 20 programs contributes 4 data points. We use cputrack(1) utility <ref type="bibr" target="#b17">[18]</ref> (accessing performance event counters) for collecting TLB misses per instruction (tlbpi), LLC misses per instruction (mpi), TLB misses per second (tlbps), and LLC misses per second (mps). While ps(1) utility is used to measure resident set size (RSS), WSS data is derived by collecting the number of pages referenced information through the proc file system.</p><p>Collecting WSS Data. Oracle Solaris 11 on SPARC provides the information of referenced pages of a process through the proc file system. Therefore, in this work, WSS data is derived by collecting the number of pages referenced information through the /proc/pid/pagedata. The proc pagedata corresponding to a process is another representation of the process's address space and provides page-level reference and modification tracking <ref type="bibr" target="#b17">[18]</ref>. The proc pagedata file contains the information of total pages mapped and how many pages are referenced or modified. Therefore, accessing the proc pagedata file enables tracking of address space references and modifications on a per-page basis. However, depending on the number of pages mapped, this takes a huge amount of time --from 80 milliseconds to 150,000 milliseconds for the programs we used in this work. Thats why it is not appropriate to collect WSS data through the proc file system for dynamically optimizing resources. The range of WSS values of the 20 programs is from 4MB to 21,000 MB. We express WSS in terms of MB in this work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Finding Important Predictors</head><p>To balance the prediction accuracy and the cost of approximation, we use forward and backward input selection techniques with Akaike Information Criterion (AIC) <ref type="bibr" target="#b14">[15]</ref> for finding important predictors among the six initial predictors. The AIC is a measure of the relative goodness of fit of a statistical model. AIC deals with the trade-off between the complexity of the model and the goodness of fit of the model. The R stepAIC() <ref type="bibr" target="#b25">[26]</ref> function uses the AIC criterion for weighing the choices, which takes proper account of the number of parameters fit. Therefore, using R stepAIC() method, we identified the two most important predictors: rss and tlbpi. Although number of threads and LLC miss rate are other important factors for approximating WSS, TLB miss rate includes the affect of these on WSS. That's why RSS and TLB miss rates are enough to approximate WSS of multithreaded programs.</p><p>Moreover, we also tested the predictors for the multicollinearity problem to develop robust models. Multicollinearity is a statistical phenomenon in which two or more predictor variables in a multiple regression model are highly correlated. In this situation the coefficient estimates may change erratically in response to small changes in the model or the data. We use R Variance Inflation Factor (VIF) method to observe the correlation strength among the predictors <ref type="bibr" target="#b19">[20]</ref>. If VIF &gt; 5, then the variables are highly correlated <ref type="bibr" target="#b25">[26]</ref>. The VIF values of the predictors rss and tlbpi are around 1.04. Therefore, there is no multicollinearity problem. In other words, the model developed using these two predictors does not overfit the training data and has a better expected prediction accuracy on test data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Developing Models</head><p>Using the above two important predictors (rss and tlbpi) we developed three popular models based on supervised learning techniques. The models are: 1) Linear Regression (LR); 2) Regression Tree (RT); and 3) K Nearest Neighbour (KNN) <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b15">16]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.1">Linear Regression (LR)</head><p>Linear regression models are simple and often provide an adequate and interpretable description of how the inputs affect the output. Linear regression models the relationship between a scalar dependent variable y and one or more explanatory variables denoted X. Given a vector of inputs X T = (X1, X2, ..., X p), we predict the output Y via the model <ref type="bibr" target="#b14">[15]</ref> shown in Equation (1). The term β 0 is the intercept and β j represents the vector of coefficients. Equation <ref type="formula">(2)</ref> shows the linear regression model developed with the above data set. We use R lm() <ref type="bibr" target="#b25">[26]</ref> to develop the model.</p><formula xml:id="formula_1">Y = β 0 + P ∑ j=1 X j β j<label>(1)</label></formula><formula xml:id="formula_2">WSS = (−150) + (1.015 * rss) + (−23830 * tlbpi) (2)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.2">Regression Tree (RT)</head><p>Recursive binary partitioning is a popular tool for regression analysis. Conditional inference trees estimate a regression relationship by binary recursive partitioning in a conditional inference framework. Roughly, the algorithm works as follows: 1) Test the global null hypothesis of independence between any of the input variables and the response. Stop if this hypothesis cannot be rejected. Otherwise, select the input variable with the strongest association to the response. This association is measured by a p-value corresponding to a test for the partial null hypothesis of a single input variable and the response. 2) Implement a binary split in the selected input variable. 3) Recursively repeat steps 1) and 2) <ref type="bibr" target="#b15">[16]</ref>.</p><p>We use R ctree() <ref type="bibr" target="#b25">[26]</ref> to develop the model. The internal node of regression tree represents test on an attribute, each branch represents outcome of test and each leaf node represents the number of data points (n) fall into it and the response value (y). Regression trees are known to be robust to the effect of outliers. Moreover, they are simple to understand and interpret.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.3">K Nearest Neighbor (KNN)</head><p>Despite its simplicity, KNN has been successful in many classification problems and regression problems, including handwritten digits, satellite image scenes, etc. Nearest-neighbor methods use those observations in the training set T closest in input space to x to form Y. Specifically, the KNN fit for Y is defined in Equation (3). Here N k (x) is the neighborhood of x defined by the k closest points x i in the training sample. Closeness implies a metric, which in this work is Euclidean distance. In other words, we find the k observations with x i closest to x in input space, and average their responses <ref type="bibr" target="#b14">[15]</ref>. We use R knn.reg() <ref type="bibr" target="#b25">[26]</ref> to develop the model. In this work, we use two neighbors (k = 2) as it is giving the best prediction accuracy.</p><formula xml:id="formula_3">Y(x) = 1 k ∑ x i ∈N k (x) y i (3)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Model Selection</head><p>We use both WEKA <ref type="bibr" target="#b8">[9]</ref> and R <ref type="bibr" target="#b25">[26]</ref> for selecting the best among the above three models. For this, we evaluate the three models using a 10-fold cross-validation (CV) test <ref type="bibr" target="#b14">[15]</ref>. In a 10-fold CV test, we split the data (80 data points) into 10 equal-sized partitions. The function approximator is trained using all the data except for one partition and a prediction is made for that partition.  </p><formula xml:id="formula_4">RMSE = 1 N N ∑ i=1 |F i − A i | 2 (4) NRMSE = RMSE A max − A min * 100 (5)</formula><p>where A i is the actual value and F i is the forecast value.</p><p>normalized root mean squared error (NRMSE) <ref type="bibr">[27]</ref>. The prediction accuracy (%) is defined as (100 -NRMSE).</p><p>As we can see in <ref type="table" target="#tab_5">Table 4</ref>, although all the three models perform well, KNN model is found to have the highest prediction accuracy among the three models. NRMSE is defined in Equation. 5. <ref type="figure" target="#fig_2">Figure 2</ref> shows the visual summary of how the models perform in terms of normalized errors in the 10-fold CV test. As <ref type="figure" target="#fig_2">Figure 2</ref> shows the two regions (shaded and non-shaded) represent performance of different models in terms of normalized errors. For example, in <ref type="figure" target="#fig_2">Figure 2</ref> (a), while the x-coordinate of each dot represents the normalized error of the LR model for a test data point, the y-coordinate represents the normalized error of the KNN model for the same test data point. The region with more dots reflect lower prediction accuracy by the model. As we can see in Figures 2(a) and 2(b), the KNN model has high prediction accuracy and outperforms both the LR and RT models. Therefore, we chose the KNN model as the working set model. Algorithm 1 summarizes the methodology used in this work for developing the best model for approximating working set size of a multithreaded application running on a multicore multiprocessor system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Approximating WSS of SPEC jbb2005 &amp; memcached.</head><p>While the KNN model achieves 96% prediction accuracy on the above 20 parallel scientific applications, its prediction accuracies for the workloads memcached <ref type="bibr" target="#b16">[17]</ref> and SPEC jbb2005 <ref type="bibr" target="#b24">[25]</ref> are 93% and 88% respectively. Here the workload based on memcached is the Data Caching Benchmark from the CloudSuite <ref type="bibr" target="#b11">[12]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6">Overhead of Working Set Model</head><p>The overhead for approximating WSS of a multithreaded program with the working set model (i.e., the KNN model) is 24 microseconds. However, as we described before (Section 2 B), the overhead of measuring WSS through the proc file system is very high --from 80 millisecs to 150,000 millisecs. Therefore, the overhead of the KNN model is negligible.</p><p>Algorithm 1: The methodology for developing the best model for approximating WSS.</p><p>Input: Training data and test data.</p><p>Output: The best model for approximating WSS.</p><p>4 Use cross-validation tests (on both Training Data and Test Data) to select the best model among the models developed in step 3. Here, the best model is the model that produces the lowest normalized root mean squared error.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Future Work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Working Set Aware Scheduling</head><p>We observe that multithreaded programs with small WSS (e.g., fewer than 16MB on SPARC T4-4) achieve high performance with grouping threads, i.e., running the threads on a few processors compared to spreading threads uniformly across all the processors (i.e., running with the default Solaris scheduler). However, for the programs with large working sets, spreading yields higher performance than grouping on multicore multiprocessor systems. In our preliminary evaluation, choosing between spreading and grouping based on the WSS of the application significantly improves performance of several multithreaded programs. For example, bodytrack, a high lock contention program from the PARSEC benchmark suite achieves a 31% reduction in running time. Therefore, we would like to develop a thread scheduling technique based on the WSS model for effectively scheduling multithreaded programs on multicore multiprocessor systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Resource Management in the Cloud</head><p>Virtual machines (VMs) have become one of the primary computing environments in the cloud <ref type="bibr" target="#b23">[24]</ref>. One benefit of virtualization is the ability to save and restore the state of a running VM. However, depending on the application, restoring the saved memory image takes significant amount of time. Therefore, memory management is crucial for this restoring process. Since the overhead of the WSS model developed in this work is negligible, it can play a role in allocating memory resources effectively when restoring VMs in the Cloud. Moreover, we can optimize memory resources while deploying multithreaded applications in the cloud by approximating their working set sizes using the above WSS model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Related Work</head><p>Several researchers have explored working set characteristics for understanding the resource requirements of the programs <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b12">13]</ref>. Denning <ref type="bibr" target="#b9">[10]</ref> proposes a model for estimating working set sizes to capture the degree of locality in how a process accesses memory. The model affords a convenient way to determine which information is in use by a computation and which is not and therefore makes it easier to determine memory demands <ref type="bibr" target="#b9">[10]</ref>.</p><p>Darryl Gove <ref type="bibr" target="#b12">[13]</ref> analyzes the memory demands of the SPEC CPU2006 benchmark programs by measuring their working set sizes using simulator <ref type="bibr" target="#b7">[8]</ref>. <ref type="bibr">Darryl[22]</ref> evaluates the idea of WSS in relationship to TLB misses for the SPEC CPU2000 benchmark programs. In another context, Cantin and Hill <ref type="bibr" target="#b4">[5]</ref> look at the idea of WSS at the level of L1 caches and evaluate the decline in the number of cache misses as the cache size increases. Similarly, Hallnor and Reinhardt <ref type="bibr" target="#b13">[14]</ref> investigate the impact of data compression on the WSS of the SPEC CPU2000 benchmark programs. However, the above works only consider single-threaded programs.</p><p>The working set model used by the WSClock algorithm <ref type="bibr" target="#b5">[6]</ref> considers the number of pages referenced in a time interval as a working set and leverages this information for deciding which page to replace next. However, since this model does not consider page-sizes, it is not possible to compute the working set sizes of programs. Therefore, it is not appropriate for effective scheduling of threads across cores of multicore multisocket system. Bellosa and Steckermeier <ref type="bibr" target="#b0">[1]</ref> use hardware performance counters to detect sharing among threads and to colocate them onto the same processor. They stress the importance of using locality information in thread scheduling for performance scalability of NUMA multiprocessors. Bellosa proposes using TLB information to reduce cache misses across context switches and maximized cache reuse by identifying threads that share the same data regions. The idea is to schedule threads that share regions sequentially one after each other to maximize the chance of cache reuse.</p><p>Several other researchers use program traces and simulations for measuring (or approximating) WSS <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b22">23]</ref>. However, this is very expensive and using memory access traces of a program, we can only measure the working set size of a particular program. <ref type="bibr" target="#b23">[24]</ref> proposes a technique called access-bit tracing for measuring working set size for better resource management in scheduling virtual machines. However, as the authors mention, it has high overhead. Therefore, these techniques are not appropriate for exploiting the WSS information dynamically for effective resource management. Moreover, most of the above existing techniques are evaluated using singlethreaded programs on machines with very few cores.</p><p>In this work, we develop a simple and robust model using machine learning techniques for approximating the WSS of multithreaded programs running on multicore multiprocessor systems. Unlike the existing techniques, using this model we can approximate the WSS of multithreaded programs with negligible overhead.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>Working set size (WSS) characteristics of a multithreaded application are vital in developing techniques to optimize resources in both multicore multiprocessor systems and virtualized cloud environments. However, the existing techniques for approximating working set sizes are very expensive and therefore not appropriate for dynamically optimized resources. This work presents a simple model for approximating WSS of multithreaded programs running on multicore multiprocessor systems that incurs negligible overhead and yet achieves 96% accuracy in predicting working set sizes. Finally, we present two potential applications of this model for achieving high performance for multithreaded applications and for optimizing resources in virtualized Cloud environments.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>K</head><label></label><figDesc>Nearest Neighbor (KNN) Model (b) KNN vs RT.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: A visual summary of how the models perform in terms of normalized errors in the 10-fold CV test. The two regions (shaded and non-shaded) represents performance of different models in terms of normalized errors. While the x-coordinate of each dot represents the normalized error of a model for a test data point, the y-coordinate represents the normalized error of a different model of the same test data point.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 lists the chosen programs. The implementations of the PARSEC programs are based upon pthreads and</head><label>1</label><figDesc></figDesc><table>SPARC T4-4: 
4 × SPARC T4 Processors @3.0 GHz; 
Total 256 vCPUs (i.e., 4 × 64 vCPUS); 
L3: 4 MB; RAM: 512 GB; OS: Oracle Solaris 11 

TM 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>The description of SPARC T4-4. 

5 
10 
15 
20 

150 200 250 300 350 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>The initial six predictors of WSS (the response vari-
able) of a multithreaded application running on a multicore 
multiprocessor system. We express WSS in terms of MB. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 4 shows</head><label>4</label><figDesc></figDesc><table>the normalized root mean squared error (NRMSE) 
values and the prediction accuracies of the three models. 
Here, the prediction accuracy is expressed in terms of </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 4 : Cross-validation (10 fold) test results.</head><label>4</label><figDesc></figDesc><table></table></figure>

			<note place="foot" n="1"> Develop a linear regression model with all reasonable predictors of WSS using Training Data. 2 Select important predictors among the initial predictors using Akaike Information Criterion [15]. 3 Develop different models using the important predictors selected in step 2.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Acknowledgements</head><p>The author would like to thank Dave Dice, Timothy Farkas, Darryl Gove, Blake Jones, Bart Smaalders, and Darrin Johnson for their help throughout this work. The author would like to also thank Lorenzo Alvisi, for his feedback on earlier drafts of this manuscript.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The performance implications of locality information usage in shared-memory multiprocessors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Bellosa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Steckermeier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Parallel Distrib. Comput</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="1996-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Fast data-locality profiling of native execution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hagersten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMETRICS</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The PARSEC benchmark suite: characterization and architectural implications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bienia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PACT</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Predicting Working Set Sizes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bryant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In IBM Journal of Research and Development</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<date type="published" when="1975-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Cache performance for selected SPEC CPU2000 benchmarks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Cantin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Hill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGARCH Computer Architecture News</title>
		<imprint>
			<date type="published" when="2001-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">WSCLOCK --a simple and effective algorithm for virtual memory management</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">W</forename><surname>Carr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Hennessy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SOSP</title>
		<imprint>
			<date type="published" when="1981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Static reuse distances for localitybased optimizations in MATLAB</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chauhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICS</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Shade: a fast instruction-set simulator for execution profiling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Cmelik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Keppel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMETRICS</title>
		<imprint>
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A tool for model generation and knowledge acquisition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Cunningham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Denize</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In Artificial Intelligence and Statistics</title>
		<imprint>
			<biblScope unit="page" from="213" to="222" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The working set model for program behavior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Denning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Communications of the ACM</title>
		<imprint>
			<date type="published" when="1968-05" />
			<biblScope unit="page" from="323" to="333" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Exploiting Core Working Sets to Filter the L1 Cache with Random Sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Etsion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Feitelson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions of Computers</title>
		<imprint>
			<date type="published" when="2012-11" />
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="page" from="1535" to="1550" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Clearing the clouds: a study of emerging scale-out workloads on modern hardware</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ferdman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Adileh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Kocberber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Volos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Alisafaee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jevdjic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kaynak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Popescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ailamaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Falsafi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ASPLOS</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">CPU2006 working set size</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gove</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGARCH Computer Architecture News archive</title>
		<imprint>
			<date type="published" when="2007-03" />
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="90" to="96" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A Unified Compressed Memory Hierarchy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">G</forename><surname>Hallnor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">K</forename><surname>Reinhardt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HPCA</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The Elements of Statistical Learning: Data Mining, Inference, and Prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hastie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Tibshirani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Friedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Springer Series in Statistics</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
	<note>2nd ed.</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Unbiased Recursive Partitioning: A Conditional Inference Framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hothorn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Hornik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zeileis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In Journal of Computational and Graphical Statistics</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="651" to="674" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Distributed caching with memcached</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Itzpatrick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Linux Journal</title>
		<imprint>
			<biblScope unit="volume">124</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2004-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mauro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mcdougall</surname></persName>
		</author>
		<title level="m">Solaris Internals</title>
		<meeting><address><addrLine>Upper Saddle River, NJ, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Prentice Hall Publications</publisher>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
	<note>2nd Edition</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The effect of seance communication on multiprocessing systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mendelson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Gabbay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ACM Trans. Comput. Syst</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="252" to="281" />
			<date type="published" when="2001-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A Methodology for developing simple and robust power models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">K</forename><surname>Pusukuri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Vengerov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fedorova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WIOSCA</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">The design, implementation, and evaluation of a working set dispatcher</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Rosell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dupuy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Communications of ACM</title>
		<imprint>
			<date type="published" when="1973-04" />
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="247" to="253" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Memory behavior of the SPEC2000 benchmark suite</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Charney</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
	<note>IBM Research Report, RC 21852</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Linear-time Modeling of Program Working Set in Shared Cache</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PACT</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Fast restore of checkpointed memory using working set estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Garthwaite</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Baskakov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">C</forename><surname>Barr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VEE</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">SPEC OMP2012 are registered trademarks of the Standard Performance Evaluation Corporation. For more information, see www</title>
	</analytic>
	<monogr>
		<title level="m">SPEC and the benchmark names SPEC jbb2005</title>
		<imprint/>
	</monogr>
	<note>spec.org</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
				<ptr target="http://www.statmethods.net/" />
		<title level="m">R stepAIC() lm(), stepAIC(), vif(), ctree(), knn.reg(</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
