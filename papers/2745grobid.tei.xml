<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2020-09-29T02:51+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">On the Impact of Isolation Costs on Locality-aware Cloud Scheduling</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ankit</forename><surname>Bhardwaj</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Utah</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meghana</forename><surname>Gupta</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Utah</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Stutsman</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Utah</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">On the Impact of Isolation Costs on Locality-aware Cloud Scheduling</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Serverless applications create an opportunity for more gran-ular scheduling across machines in cloud platforms that can improve efficiency, especially if functions can be run within storage services to eliminate data movement. However, embedding code within storage services creates code isolation overheads that offset some of those savings. We argue for a new approach to serverless function scheduling that can look within serverless applications&apos; functions, profile their data movement and networking costs, and model the impact of different code placement and isolation schemes for those costs. Beyond improvements in efficiency, such an approach would fuel innovation in cloud isolation schemes and programming abstractions, since a scheduler with a modular cost modeling approach could incorporate new schemes and automatically use them to improve efficiency for pre-existing applications.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>How cloud platforms allocate, schedule, and place computation is restricting the evolution of cloud computing. The last 5 years have seen an explosion in data center network performance, a breakdown and rethinking of CPU protection mechanisms, and a move of applications from coarse, opaque virtual machines (VMs) to granular serverless functions.</p><p>These three transformations have a complex interrelationship that could enable a new era of more efficient systems and rapid evolution of both cloud abstractions and mechanisms. We expose this relationship and show that explicit automated reasoning about data movement and CPU hardware isolation costs can improve efficiency in the cloud. In reaction, we propose a new approach to compute provisioning and scheduling in the cloud that uses the emerging visibility into (serverless) applications. It breaks down static disaggregation of compute and storage by reasoning explicitly and at fine-grain about trade-offs between data movement and code isolation costs to maximize efficiency. Ultimately, we argue that such an approach can accelerate innovation by automating reasoning about the costs and trade-offs of new network transport schemes, code isolation schemes, and applications interfaces, since this yields a "pluggable" platform that can incorporate and optimize around heterogeneous workloads, datasets, isolation models, and computation models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Toward Granular Scheduling in the Cloud</head><p>Today, cloud providers avoid fixed allocations of compute (AWS EC2 and Lambda; Azure VMs and Cloud Functions) and storage resources (AWS S3, EBS, and DynamoDB; Azure Decoupling compute and storage resources lets any VM use any storage, improving utilization. However, disaggregation forces data movement over the network, which has a CPU cost and cuts into efficiency. Customer (or tenant) applications could hold storage data locally within VMs <ref type="figure" target="#fig_0">(Figure 1</ref> middle), but this creates scaling challenges when more computation is needed than a single VM can supply. Cloud providers could also allow tenants to run VMs on the same machines that hold tenants' data ( <ref type="figure" target="#fig_0">Figure 1</ref> bottom), but this doesn't work because many tenants share a set of storage servers. Thousands of tenants' data are inter-mixed across many machines to homogenize load, but running thousands of different tenants' VMs on a single machine is prohibitively inefficient. Effective efficiency is, then, determined by two things: the cost of moving data over the network and the cost of consolidating tenants' storage and compute workloads on a set of machines. Aside from heavy isolation costs, VMs are also problematic because they are coarse and only offer a handful of placement choices relative to the data they operate on (all shown in <ref type="figure" target="#fig_0">Figure 1)</ref>; they are opaque, so it is hard to assess what they compute, what their inputs/outputs are and how they interact with data. However, serverless functions have begun to change this. Serverless has shown that developers are willing to decompose and repackage applications with new abstractions that move beyond the legacy POSIX interfaces of the past several decades.</p><p>Serverless opens up several new opportunities. First, it shatters an application from a monolithic VM into tens or hundreds of relatively independent pieces of computation that can all be individually placed. Second, it creates visibility into applications; functions' inputs, outputs, and data interactions can all be observed and attributed to granular application pieces, creating opportunities for more intelligent placement. Third, the new interfaces of serverless support alternate isolation schemes that are less expensive than conventional VMs. Today, cloud providers don't exploit this flexibility, but it is an opportunity for innovation. Finally, the interface is new enough that it is malleable. Serverless has shown that developers are willing to adopt new abstractions if those abstractions ease development, deployment, and scaling. This makes the case for exploring new abstractions for computation in the cloud that are co-designed for ease of development and lowering tenant code isolation costs.</p><p>These four opportunities could all be exploited today, but today's serverless platforms, instead, favor backward compatibility and classic hardware virtualization techniques for isolation <ref type="bibr" target="#b0">[1]</ref>. A key problem is that no single "tweak" to the existing model can instantly and easily provide a massive efficiency benefit warranting complete rework of cloud providers' platforms and tenants' existing codebases. This is compounded by the fact that each small change to cloud provider isolation mechanisms or compute abstractions requires a ground-up rethinking of all costs and trade-offs. For example, if a provider created a new low-cost abstraction for embedding short functions within storage servers (for example, via eBPF <ref type="bibr" target="#b4">[5]</ref>), then data movement costs, isolation costs, and function granularities would all need to be reconsidered for this change in order to ensure it improves efficiency. Hence, the missing piece that would enable faster innovation is fully automating the reasoning needed to incorporate new abstractions for computation, new schemes for efficient data movement, and new schemes for low-cost code containment.</p><p>Our assertion is that it is time for a more principled approach to reasoning about the trade-off between data movement and code isolation costs. This paper's aim is to outline a new distributed scheduling layer for cloud platforms that transparently optimizes tenant code and data placement; such a layer could automatically execute a tenant's function code directly on a storage server when it makes sense just as it might disaggregate when isolation code costs are too great.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Challenges in Finer-grained Scheduling</head><p>Though serverless platforms open up new possibilities in scheduling compute resources to lower data movement overheads, there are several key challenges that need to be addressed to support this type of optimization. Here, we discuss these challenges, including application decomposition, workload characterization, provisioning schemes, isolation mechanism costs, and function intermediate state movement. In the following section, we outline a design that explicitly considers these issues to try to minimize cloud application data movement and isolation costs.</p><p>Granular Application Decomposition. To schedule and gain visibility at a fine-grain, applications must be specified at a fine-grain. Developers already do this today to gain the benefits of serverless computing. Serverless applications are comprised of a set of functions invoked by a set of triggers (e.g. external HTTP requests, timers, internal cloud service/storage triggers, etc.). Applications are scheduled and scaled across cloud hardware resources on demand; subsequent and proximate events for functions within an application can reuse existing application instances <ref type="bibr" target="#b25">[27]</ref>.</p><p>In the future, applications can be augmented in some simple ways that will give a scheduler more flexibility in minimizing data movement and cross-function communication/invocation costs. For example, function inter-dependencies are not specified upfront and are difficult to extract. Allowing applications to specify or give hints about their structure and chaining (for example, as a graph of dependencies between functions and external services) could allow a scheduler to run functions next to the data they plan to operate on. It could also be used to co-schedule functions to minimize context switch and communication overheads across functions within an application. Requirement 0: Granular Visibility and Placement. Today's serverless platforms are already driving developers to expose application components to cloud providers, creating the opportunity for better scheduling through better understanding of their behavior, communication, and resource needs.</p><p>Workload Characterization. Colocating functions with the data they operate on always reduces data movement, but the benefit of this colocation depends on two things. First, recent reports suggests overhead due to remote accesses occupy 22-27% of fleet-wide CPU at Google <ref type="bibr" target="#b10">[11]</ref> with Facebook reporting similar numbers <ref type="bibr" target="#b28">[30]</ref>, but the cost for moving data over a network differs for different storage platforms and networks. For example, an application with low spatial locality may spread fine-grained requests for small data records across a large set of servers; such a workload is primarily dominated by per-request CPU costs, like request dispatching costs. Other workloads may focus storage requests for larger items onto a smaller set of servers, making CPU-cost-per-byte the dominant cost factor. Complicating things, even within a single cloud platform, many forms of networking exist all with different costs. For example, one class of Azure VM has an unaccelerated networking configuration and at least three other forms of accelerated networking <ref type="bibr" target="#b18">[20,</ref><ref type="bibr" target="#b19">21]</ref>. Hence, to minimize costs in placement a scheduler needs a detailed, runtime-calibrated cost model to assess data movement costs.</p><p>Second, each cloud application consumes CPU time and interacts with storage in a unique way. Even within one application, some parts of an application may benefit from execution near storage, whereas other parts may create CPU bottlenecks at storage. <ref type="figure">Figure 2</ref> shows this; it shows the execution of a serverless-style function executing against a prototype storage system that uses accelerated networking and a low-cost function runtime <ref type="bibr" target="#b13">[14]</ref>. When the function accesses more than one data record in the store, storage server throughput is maximized when the function is run on the storage server since Context Switch Costs. Each different scheme for safely isolating and executing code and each different workload has different costs when a code execution context must be scheduled or de-scheduled. For example, a cloud tenant making requests to a serverless cloud function at a low rate will either force a CPU to remain idle in the cloud awaiting those requests, or it will force a form of context switch to handle those requests, increasing the effective CPU cost of each request. At low request rates one isolation scheme may be more efficient, and at higher requests rates another isolation scheme may be more efficient. Hence, where a particular function should be run depends not just on data movement and network CPU costs, but also on the "temporal locality" of requests coming from that tenant. That is, the "hit rate" of processing requests on a pre-existing, active context where no context switch is needed and the cost of context switch to schedule a context to handle the request when there is no active context must be considered when scheduling. Hence, to optimize, a scheduler needs to have a global view of active compute contexts, and it needs to be able to reason about the costs of dispatching to those contexts.</p><p>Beyond temporal locality, different protection schemes have different context switch costs. Today's serverless runtimes support POSIX, but practical serverless applications rarely need to run native code using legacy I/O interfaces. This creates a space where static analysis may be able to group functions into those that can run safely in lighter-weight runtimes (language-level or non-VM hardware-based isolation schemes) and those that need backward compatibility.</p><note type="other">Requirement 2: Global, Activation-and Isolation-cost-aware Scheduling. Minimizing data movement and network costs is insufficient alone if function placement results in idle CPUs or extra context switch costs per network request. Function scheduling must maintain a fine-grained view of where function contexts are scheduled in order to reduce context switch costs between protection domains</note><p>. This is a major challenge at scale, where requests and context switch can complete in a few microseconds. The scheduler must also be aware of application quality-of-service needs to understand where the scheduler can leverage request batching to amortize context switch and dispatching costs and where fast response times are needed by applications. Complicating things, the efficiency of function isolation schemes (VMs, containers, specialized hardware or software runtimes, etc.) depends on several properties of the function being contained. Specifically, for functions with high, predictable, and stable CPU use and data access patterns, VMs with dedicated hardware resources can be most cost effective. However, VMs have heavy-weight environments that make them costly to start, stop, and migrate, even for applications with (even predictably) changing resource requirements; thus, they leave hardware under-utilized. While placing a VM within a storage server might be efficient in certain cases, the disruption and resource use of migration needs to be considered <ref type="bibr" target="#b12">[13]</ref>. This makes lighter-weight runtimes like those possible for serverless platforms attractive for automatic placement tuning, especially when load is unpredictable. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">A Preliminary Design</head><p>To explore our idea, we are designing a new serverless scheduler we call Sandstorm that is tightly-coupled with the machines it schedules over. In most ways, Sandstorm is like other serverless schedulers <ref type="figure">(Figure 3</ref>). It includes a load balancer/scheduler that makes machine allocation and function placement decisions and a scheme for collecting fleet-wide metrics to assist in scheduling. Like some other works <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b26">28]</ref>, it is designed to run serverless function chains and can take into account per-function-chain-invocation hints that statically describe how functions in a particular chain are interconnected with one another. This lets it fuse or coschedule operations, and it lets the scheduler know when and where embedding the function within a storage service machine might make sense. One benefit of this approach is that cloud providers can transparently improve their utilization of compute, storage, and network infrastructure. This would allow them to consolidate more tenants on fewer machines while retaining their current pricing models, which only account for CPU and memory allocated to functions for the duration of their execution <ref type="bibr" target="#b2">[3]</ref>.</p><p>A key idea in Sandstorm is that it tries to collapse function chains into the storage tier to control data movement. However, as we have laid out, done naively this could hurt efficiency and create bottlenecks. This has led us to a design centered on aggressive collection of low-level performance data to calibrate network and isolation costs to predict load stability; to maintain a sub-millisecond-scale view of the status of each core across all machines; and to inform global sub-millisecond remapping of cores/redirection of incoming tenant requests among cores fleet-wide. This would let Sandstorm promote and demote cores at scale in a few milliseconds between several regimes of operation. For example, it can remap any core in any compute-tier or storage-tier machine to run a function on dedicated CPUs with dedicated hardware network queues (via SR-IOV); or with fast, lightweight temporal multiplexing of functions designed for software dispatching and low context switch cost; or by moving execution of the function out of a storage-tier machine to a compute-tier machine. The last option would force remote storage access to lower code containment costs or to gain access to idle compute resources. We detail some challenges and mechanisms needed to support this kind of global optimization below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Storage &amp; Internal Task Dispatching</head><p>Sandstorm is unique in executing tenant-provided functions within storage-tier servers, and this directly impacts its serverlocal task dispatching. <ref type="figure" target="#fig_2">Figure 4</ref> shows how this might work. Internally, storage-tier servers efficiently service requests for tenant data by polling queues that are directly filled by network card (NIC); similar to other kernel-bypass-based systems, this lets the NIC assist in dispatching, avoiding crosscore coordination and improving server throughput. All tenant functions can access any in-memory tenant state directly through shared memory, but data on other media can be accessed through runtime-provided interfaces. There is no predefined split between cores used for running tenant functions and simple read/write/get/put requests for stored data; servers profile offered load and dynamically re-provision cores between tenant logic and storage request processing as needed.</p><p>For tenants that only run functions at storage infrequently, the system must be able to switch between isolation contexts at low cost. Different isolation schemes have different tradeoffs, but, for example, for certain restricted functions, fast user-level protection schemes based on new hardware functionality like Intel's MPK <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b22">24,</ref><ref type="bibr" target="#b29">31]</ref> can efficiently switch between many domains on a single core even if functions are short-running and invoked millions of times per second in aggregate on a CPU core. For tenants sending the heaviest request rates to a server, it may make sense to dedicate whole cores with their own NIC hardware queues, avoiding all dispatch and context switch costs. In cases where the storage server becomes compute congested, this information propagates back to the scheduler and some fraction of tenant functions are redirected to idle compute capacity elsewhere in the the cluster. In this case, detailed data movement cost models and a function-level understanding of data access patterns is key, since this results in more data movement over the network. Hence, this should only be done when it wouldn't further increase the storage server's load.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Statistics, Scheduling, &amp; Load Prediction</head><p>To make fine-grained scheduling decisions, tenants would invoke functions through a scheduler handling a large partition of tenants. For each invocation, the scheduler decides placement, routing it to the correct core in the correct machine. This placement is based on idle compute capacity; function data access patterns; and networking, dispatch, and isolation domain context switch costs. A tightly integrated naming service tracks all pre-existing execution contexts for a given function across the fleet along with placement information for any data owned by that tenant. The scheduler looks for a cost effective place to run a particular invocation and forwards the invocation request to the correct core in the fleet. Another service predicts the stability of a function's behavior via history of its storage and network interactions and CPU cost breakdowns of those interactions. Consistently "hot" functions will trigger allocation of whole CPU cores and hardware NIC queues for future invocations; functions that suffer temporary load spikes can rely on software dispatching without triggering allocation of dedicated hardware resources.</p><p>Load prediction, naming, and cost estimation require finegrained core-and task-level visibility -providing this without creating bottlenecks and high CPU load is a challenge in itself. Doing this efficiently will require hardware-assisted metadata aggregation. One possibility is to have each machine use gather DMA to collect per-core statistics with periodic RDMA writes that push those statistics into a pre-indexed structures within the scheduler machines. Even with more than 1,000 machines pushing statistics and metadata each millisecond a single scheduler machine would be sufficient.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Work</head><p>Serverless Frameworks. Since the advent of Amazon AWS 15 years ago <ref type="bibr" target="#b3">[4]</ref>, serverless frameworks have created a new scheme for specifying and scheduling cloud applications <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr">19]</ref>. Similar open source and research frameworks have emerged <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b27">29]</ref>, but they largely keep similar, costagnostic scheduling policies to their industrial counterparts.</p><p>Memory Protection and Isolation. Recent work has explored new hardware-based memory isolation using MPK <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b22">24,</ref><ref type="bibr" target="#b29">31]</ref>. Both recent research and industry efforts have explored lighter-weight schemes for VMs and containers, especially for serverless <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b20">22]</ref>, and some works specifically address isolation schemes for computation embedded near stored data <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b24">26,</ref><ref type="bibr" target="#b31">32]</ref>. Sandstorm avoids focusing on specific memory isolation techniques; its goal is to separate mechanism and policy by trying to incorporate new mechanisms through an extensible cost model.</p><p>Scheduling. A great deal of research has focused on distributed scheduling for coarse-grained tasks like those in data parallel computational analytics frameworks. Recent works have focused on request scheduling in online applications with high variance in per-request computational costs, for example, to optimize latency/throughput trade-offs <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b21">23,</ref><ref type="bibr" target="#b23">25]</ref>. Sandstorm proposes extending these approaches to account for inter-tenant code isolation and data movement costs in distributed task scheduling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>Disaggregation drives cloud utilization today, but as Dennard scaling ends, real efficiency will be increasingly important. Future cloud platforms will need to exploit the newfound flexibility and granularity in how (serverless) applications are specified and scheduled to reduce data movement. However, this is difficult to get right: shipping all code to data creates additional costs for code isolation, scheduling, and dispatching that can more than offset the savings. In response, we offer new ideas on how a new cost-driven approach to scheduling compute resources can accelerate innovation in cloud isolation schemes and programming models by letting cloud platforms readily incorporate new schemes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion Topics</head><p>Our single machine in-memory store prototype shows gains in throughput and latency when we move compute to storage; however, showing similar benefits at scale is harder. Here are some of the open problems and reservations we have about the idea for which we seek input from the research community. Client-side Caching. Caching reduces data movement costs. Providers may get similar gains using client-side caching instead of moving compute to storage. Caching behaves poorly for write-intensive workloads where most functions modify data. Overall, the gain due caching depends on the workload and data consistency model. More knowledge about cloud-providers' workloads would help us in deciding if the caching is sufficient and for which classes of workloads co-locating computation and data dominates caching. Process Model. Dynamically placing a binary at different locations at runtime requires small program/environment sizes and limited/unified interfaces for accessing external resources. Designing a new interface that is sufficient for serverless functions is an open problem. Furthermore, standardizing execution environments for functions so that large classes of them can be executed in a small number of environments is a challenge (to prevent proliferation of one-off environments that would restrict scheduling due to high environment initialization costs). Discussion on what types of interfaces are likely to emerge and are likely to succeed for developing real applications would be a helpful point of feedback. Security risks. Many schemes can provide program or function isolation; however, verifying these schemes is hard, especially when we cannot guarantee that hardware itself is free from vulnerabilities <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b16">17]</ref>. Sandstorm's adaptive placement and adaptive protection model scheme would multiply cloud providers' attack surfaces. A key question for discussion is what software and hardware isolation schemes are likely to be trustworthy enough to depend on in realistic, secure cloud provider platforms. For example, would verified JIT runtimes like eBPF be (or eventually be) secure enough to trust with containing tenant code? Relatedly, are microarchitectural mitigations for speculative execution attacks here to stay, and what impact will they have on the costs of (lightweight) isolation schemes? If flushes of microarchitectural state dominate isolation domain switch costs, how much improvement could different isolation schemes provide? Workloads. Cloud platform research is hard with little visibility into provider infrastructure and workloads. We are always looking for input on how to validate ideas and systems like this, including feedback on what workloads to test with and where to find interesting workload traces. Pricing. There is little public information about how cloud providers decide the parameters of pricing models used to charge tenants. Insight into pricing model strategies would help in understanding how specific changes in cloud internals might affect tenants' costs.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Possible placements of code and data in the cloud. Blob, Disk, and SQL) through disaggregation (Figure 1 top). Decoupling compute and storage resources lets any VM use any storage, improving utilization. However, disaggregation forces data movement over the network, which has a CPU cost and cuts into efficiency. Customer (or tenant) applications could hold storage data locally within VMs (Figure 1 middle), but this creates scaling challenges when more computation is needed than a single VM can supply. Cloud providers could also allow tenants to run VMs on the same machines that hold tenants' data (Figure 1 bottom), but this doesn't work because many tenants share a set of storage servers. Thousands of tenants' data are inter-mixed across many machines to homogenize load, but running thousands of different tenants' VMs on a single machine is prohibitively inefficient. Effective efficiency is, then, determined by two things: the cost of moving data over the network and the cost of consolidating tenants' storage and compute workloads on a set of machines. Aside from heavy isolation costs, VMs are also problematic because they are coarse and only offer a handful of placement choices relative to the data they operate on (all shown in Figure 1); they are opaque, so it is hard to assess what they compute, what their inputs/outputs are and how they interact with data. However, serverless functions have begun to change this. Serverless has shown that developers are willing to decompose and repackage applications with new abstractions that move beyond the legacy POSIX interfaces of the past several decades. Serverless opens up several new opportunities. First, it shatters an application from a monolithic VM into tens or hundreds of relatively independent pieces of computation that can all be individually placed. Second, it creates visibility</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>(Re)provisioning and Placement.</head><label></label><figDesc>Trading off data move- ment costs of different placements of function invocations relative to data creates an NP-hard, large-scale bin packing problem. Tenants with different resource requirements (low CPU cost/high network use, high CPU cost/low network use) should be placed together to improve utilization, subject to each function's characterized costs and data access patterns.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Core-level dispatching in a Sandstorm storage server.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head></head><label></label><figDesc>Requirement 3: Explicit Workload Stationarity Modeling. VMs are efficient when workloads are stable but costly under change. Serverless runtimes pay extra software dispatch over- heads, but scale more readily. Finally, creating/destroying VMs or containers requires some initialization time and cost along with some resources. An efficient cluster scheduler should reason about the predictability of a workload and about the cost of moving the computational environment and data of applications' functions that it is placing for execution.</figDesc><table>LS 

GLOBAL SCHEDULER 

LOAD PREDICTOR 

CENTRAL 
NAMING 
SERVICE 

RESOURCE 
MANAGER 

Request 

LS 

STORAGE TIER 
COMPUTE TIER 

LS 
LS 

LS 
LS 

LS 

LS 

Local 
scheduler (ls) 

INACTIVE MACHINES 
INACTIVE MACHINES 

Figure 3: Sandstorm Architecture. 

Intermediate State. Recent serverless applications have 
mostly been stateless, where invocations of the same function 
do not share state. VMs have historically run tenant-specific 
logic, so coordinated access to shared state (e.g. held in VM 
memory) by different requests is common. Intermediate state 
that applications build up complicates placement decisions 
if consistency guarantees are made across shared state. Syn-
chronizing intermediate state and reasoning about the costs of 
synchronizing it would complicate optimization of placement. 
However, today's serverless models don't support this (well). 
Requirement 4: Stateless and Motionless Invocations. State-
less functions let each invocation of a function be placed 
separately without concern for coordinating with existing in-
vocations of the same function. This makes optimization eas-
ier since placement can be decided invocation-by-invocation, 
and it effectively eliminates the need for state migration. Func-
tions deemed to benefit from a new form of isolation or new 
placement can have new invocations run in the new configu-
ration, letting existing invocations complete in their original 
configuration. Our goal is to support an approximation of 
statefulness by moving functions that keep intermediate data 
near to the (function external) physical location where they 
store that data rather than building a new, specialized consis-
tency scheme specifically for intermediate function state. 

</table></figure>

			<note place="foot">feedback. This material is based upon work supported by the National Science Foundation under Grant No. CNS-1750558. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the National Science Foundation. This work was also supported in part by Facebook and VMware.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>Thanks to our reviewers and our shepherd, Adam Belay, for their</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Firecracker: Lightweight Virtualization for Serverless Applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandru</forename><surname>Agache</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Brooker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Iordache</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>Liguori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rolf</forename><surname>Neugebauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Piwonka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diana-Maria</forename><surname>Popa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">17th USENIX Symposium on Networked Systems Design and Implementation (NSDI 20)</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="419" to="434" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">SAND: Towards highperformance serverless computing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruichuan</forename><surname>Istemi Ekin Akkus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivica</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manuel</forename><surname>Rimac</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andre</forename><surname>Satzke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paarijaat</forename><surname>Beck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Volker</forename><surname>Aditya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hilt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 USENIX Annual Technical Conference (USENIX ATC 18)</title>
		<meeting><address><addrLine>Boston, MA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-07" />
			<biblScope unit="page" from="923" to="935" />
		</imprint>
	</monogr>
<note type="report_type">USENIX Association</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llc</forename><surname>Amazon</surname></persName>
		</author>
		<ptr target="https://aws.amazon.com/lambda/" />
	</analytic>
	<monogr>
		<title level="j">AWS Lambda -Serverless Compute -Amazon Web Services</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llc</forename><surname>Amazon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Aws News</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Blog</surname></persName>
		</author>
		<ptr target="https://aws.amazon.com/blogs/aws/amazon_ec2_beta/" />
		<imprint>
			<date type="published" when="2006-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">A thorough introduction to eBPF</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Fleming</surname></persName>
		</author>
		<ptr target="https://lwn.net/Articles/740157/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llc</forename><forename type="middle">Google</forename><surname>Google</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cloud</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Hodor: Intra-Process Isolation for HighThroughput Data Plane Libraries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Hedayati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Spyridoula</forename><surname>Gravani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ethan</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Criswell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">L</forename><surname>Scott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Marty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 USENIX Annual Technical Conference, USENIX ATC 2019</title>
		<meeting><address><addrLine>Renton, WA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="489" to="504" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Serverless Computation with OpenLambda</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Hendrickson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Sturdevant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tyler</forename><surname>Harter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Venkateshwaran</forename><surname>Venkataramani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><forename type="middle">C</forename><surname>Arpacidusseau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Remzi H Arpaci-Dusseau</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">8th USENIX Workshop on Hot Topics in Cloud Computing</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>HotCloud 16</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Intel® 64 and IA-32 Architectures Software Developer&apos;s Manual Volume 3A: System Programming Guide</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Inc</forename><surname>Intel</surname></persName>
		</author>
		<ptr target="https://www.intel.com/content/dam/www/public/us/en/documents/manuals/64-ia-32-architectures-software-developer-vol-3a-part-1-manual.pdf" />
		<imprint/>
	</monogr>
	<note>Part 1</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Shinjuku: Preemptive scheduling for µsecond-scale tail latency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kostis</forename><surname>Kaffes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Chong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jack</forename><forename type="middle">Tigar</forename><surname>Humphries</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Belay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mazières</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christos</forename><surname>Kozyrakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th USENIX Conference on Networked Systems Design and Implementation, NSDI&apos;19</title>
		<meeting>the 16th USENIX Conference on Networked Systems Design and Implementation, NSDI&apos;19<address><addrLine>USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="345" to="359" />
		</imprint>
	</monogr>
<note type="report_type">USENIX Association</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Profiling a Warehouse-Scale Computer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Svilen</forename><surname>Kanev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juan</forename><forename type="middle">Pablo</forename><surname>Darago</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kim</forename><surname>Hazelwood</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tipp</forename><surname>Parthasarathy Ranganathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Moseley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gu-Yeon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Brooks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 42nd Annual International Symposium on Computer Architecture, ISCA &apos;15</title>
		<meeting>the 42nd Annual International Symposium on Computer Architecture, ISCA &apos;15<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="158" to="169" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Spectre attacks: Exploiting speculative execution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Kocher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jann</forename><surname>Horn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Fogh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Genkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Gruss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Werner</forename><surname>Haas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Hamburg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moritz</forename><surname>Lipp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Mangard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Prescher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE Symposium on Security and Privacy (SP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Rocksteady: Fast Data Migration for Low-latency In-memory Storage</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chinmay</forename><surname>Kulkarni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aniraj</forename><surname>Kesavan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Ricci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Stutsman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Sixth ACM Symposium on Operating Systems Principles, SOSP &apos;17</title>
		<meeting>the Twenty-Sixth ACM Symposium on Operating Systems Principles, SOSP &apos;17</meeting>
		<imprint>
			<date type="published" when="2017-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Splinter: Bare-Metal Extensions for Multi-Tenant Low-Latency Storage</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chinmay</forename><surname>Kulkarni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sara</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mazhar</forename><surname>Naqvi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Ricci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Stutsman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">13th USENIX Symposium on Operating Systems Design and Implementation (OSDI 18)</title>
		<meeting><address><addrLine>Carlsbad, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-10" />
			<biblScope unit="page" from="627" to="643" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Alto: Lightweight VMs Using Virtualization-Aware Managed Runtimes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Larisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Mickens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eddie</forename><surname>Kohler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th International Conference on Managed Languages &amp; Runtimes</title>
		<meeting>the 15th International Conference on Managed Languages &amp; Runtimes</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Granular Computing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Collin</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">K</forename><surname>Ousterhout</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Hot Topics in Operating Systems, HotOS</title>
		<meeting>the Workshop on Hot Topics in Operating Systems, HotOS<address><addrLine>Bertinoro, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019-05-13" />
			<biblScope unit="page" from="149" to="154" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Meltdown: Reading kernel memory from user space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moritz</forename><surname>Lipp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Schwarz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Gruss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Prescher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Werner</forename><surname>Haas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Fogh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jann</forename><surname>Horn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Mangard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Kocher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Genkin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">27th USENIX Security Symposium (USENIX Security 18)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="973" to="990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">My VM is Lighter (and Safer) than your Container</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Filipe</forename><surname>Manco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Costin</forename><surname>Lupu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jose</forename><surname>Mendes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Kuenzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Sati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenichi</forename><surname>Yasukata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Costin</forename><surname>Raiciu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felipe</forename><surname>Huici</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th Symposium on Operating Systems Principles</title>
		<meeting>the 26th Symposium on Operating Systems Principles</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="218" to="233" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Create a Linux virtual machine with Accelerated Networking using Azure CLI</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Inc</forename><surname>Microsoft</surname></persName>
		</author>
		<ptr target="https://docs.microsoft.com/en-us/azure/virtual-network/create-vm-accelerated-networking-cli" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Enable InfiniBand with SR-IOV</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Inc</forename><surname>Microsoft</surname></persName>
		</author>
		<ptr target="https://docs.microsoft.com/en-us/azure/virtual-machines/workloads/hpc/enable-infiniband" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">SOCK: Rapid Task Provisioning with Serverless-Optimized Containers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Oakes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leon</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dennis</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Houck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tyler</forename><surname>Harter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Arpaci-Dusseau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Remzi</forename><surname>Arpaci-Dusseau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 USENIX Annual Technical Conference (USENIX ATC 18)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="57" to="70" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Shenango: Achieving High CPU Efficiency for Latency-sensitive Datacenter Workloads</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amy</forename><surname>Ousterhout</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><surname>Fried</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Behrens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Belay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hari</forename><surname>Balakrishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">16th USENIX Symposium on Networked Systems Design and Implementation (NSDI 19)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="361" to="378" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">libmpk: Software Abstraction for Intel Memory Protection Keys (Intel MPK)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soyeon</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sangho</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyungon</forename><surname>Moon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taesoo</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 USENIX Annual Technical Conference, USENIX ATC 2019</title>
		<editor>Dahlia Malkhi and Dan Tsafrir</editor>
		<meeting><address><addrLine>Renton, WA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="241" to="254" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">ZygOS: Achieving Low Tail Latency for Microsecondscale Networked Tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Prekas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marios</forename><surname>Kogias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edouard</forename><surname>Bugnion</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th Symposium on Operating Systems Principles</title>
		<meeting>the 26th Symposium on Operating Systems Principles<address><addrLine>Shanghai, China</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="325" to="341" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Malacology: A Programmable Storage System</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><surname>Sevilla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivo</forename><surname>Watkins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Jimenez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shel</forename><surname>Alvaro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Finkelstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><surname>Lefevre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Maltzahn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twelfth European Conference on Computer Systems</title>
		<meeting>the Twelfth European Conference on Computer Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="175" to="190" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Serverless in the Wild: Characterizing and Optimizing the Serverless Workload at a Large Cloud Provider</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Shahrad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodrigo</forename><surname>Fonseca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Íñigo</forename><surname>Goiri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gohar</forename><surname>Chaudhry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Batum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Cooke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduardo</forename><surname>Laureano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colby</forename><surname>Tresness</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Russinovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ricardo</forename><surname>Bianchini</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Arjun Balasubramanian</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arjun</forename><surname>Singhvi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Houck</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.09849</idno>
	</analytic>
	<monogr>
		<title level="m">Shivaram Venkataraman, and Aditya Akella. Archipelago: A Scalable Low-Latency Serverless Platform</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
		<respStmt>
			<orgName>Mohammed Danish Shaikh</orgName>
		</respStmt>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Cloudburst: Stateful functions-as-a-service</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vikram</forename><surname>Sreekanti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenggang</forename><surname>Wu Xiayue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jose</forename><forename type="middle">M</forename><surname>Faleiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><forename type="middle">E</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><forename type="middle">M</forename><surname>Hellerstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Tumanov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.04592</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">SoftSKU: Optimizing Server Architectures for Microservice Diversity @scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akshitha</forename><surname>Sriraman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Dhanotia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">F</forename><surname>Wenisch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 46th International Symposium on Computer Architecture, ISCA &apos;19</title>
		<meeting>the 46th International Symposium on Computer Architecture, ISCA &apos;19<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="513" to="526" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anjo</forename><surname>Vahldiek-Oberwagner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eslam</forename><surname>Elnikety</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Nuno</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">ERIM: Secure, Efficient In-Process Isolation with Memory Protection Keys</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Duarte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Sammler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deepak</forename><surname>Druschel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Garg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of USENIX Security Symposium</title>
		<meeting>USENIX Security Symposium</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Narrowing the Gap Between Serverless and its State with Storage Functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feifei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Stutsman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Symposium on Cloud Computing</title>
		<meeting>the ACM Symposium on Cloud Computing</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
