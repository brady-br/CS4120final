<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2020-09-29T02:51+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">DLion: Decentralized Distributed Deep Learning in Micro-Clouds</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rankyung</forename><surname>Hong</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Minnesota</orgName>
								<orgName type="institution" key="instit2">University of Minnesota</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Chandra</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Minnesota</orgName>
								<orgName type="institution" key="instit2">University of Minnesota</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">DLion: Decentralized Distributed Deep Learning in Micro-Clouds</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Deep learning is a popular technique for building models from large quantities of input data for applications in many domains. With the proliferation of edge devices such as sensor and mobile devices, large volumes of data are generated at rapid pace all over the world. Migrating large amounts of data into centralized data center(s) over WAN environments is often infeasible due to cost, performance or privacy reasons. Moreover, there is an increasing need for incremental or online deep learning over newly generated data in real-time. These trends require rethinking of the traditional training approach to deep learning. To handle the computation on distributed input data, micro-clouds-small-scale clouds deployed near edge devices in many different locations-provide an attractive alternative for data locality reasons. However , existing distributed deep learning systems do not support training in micro-clouds, due to the unique characteristics and challenges in this environment. In this paper, we examine the key challenges of deep learning in micro-clouds: computation and network resource het-erogeneity at inter-and intra micro-cloud levels and their scale. We present DLion, a decentralized distributed deep learning system for such environments. It employs techniques specifically designed to address the above challenges to reduce training time, enhance model accuracy, and provide system scalability. We have implemented a prototype of DLion in TensorFlow and our preliminary experiments show promising results towards achieving accurate and efficient distributed deep learning in micro-clouds.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Micro-clouds <ref type="bibr">[4, 11-13, 42, 44, 47]</ref> are an emerging type of infrastructure to support the exponentially growing large amounts of data generated by edge devices such as surveillance cameras <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b34">34]</ref>, mobile phones <ref type="bibr" target="#b33">[33,</ref><ref type="bibr" target="#b35">35,</ref><ref type="bibr" target="#b58">58]</ref>, or various sensors <ref type="bibr" target="#b32">[32,</ref><ref type="bibr" target="#b42">42,</ref><ref type="bibr" target="#b53">53]</ref>. Individual micro-clouds consist of a small or medium number of servers. Instead of storing and maintaining the huge amounts of data in a few monolithic public clouds, users and organizations can use micro-clouds across multiple locations, deployed close to edge devices for providing faster services with minimum latency.</p><p>Deep learning (DL) is a popular technique to build models from large quantities of input data for applications in many domains <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b48">48,</ref><ref type="bibr" target="#b56">56]</ref>. Traditionally, DL models are trained on large quantities of data assembled in cluster or data center environments. With recent advances in deep learning techniques, continuously generated data could be used for onlinelearning or incremental-learning <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b27">27,</ref><ref type="bibr" target="#b36">36,</ref><ref type="bibr" target="#b37">37,</ref><ref type="bibr" target="#b39">39,</ref><ref type="bibr" target="#b41">41,</ref><ref type="bibr" target="#b55">55]</ref>. Thus, instead of being a one-time training solution for a fixed set of training data, DL models could keep evolving using data continuously generated from a large number of edge devices across the globe. However, migrating such large amounts of data into centralized cloud(s) over WAN environments for training is likely to be prohibitive due to cost, performance or privacy reasons. For instance, such data is hard to move because of WAN bandwidth constraints, or because it could contain a lot of personal information such as pictures or videos generated by user devices or recorded using surveillance cameras as shown in <ref type="figure" target="#fig_0">Figure 1</ref>. The need for geodistributed data analysis has also been shown for many other analytics tasks <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b38">38,</ref><ref type="bibr" target="#b49">49,</ref><ref type="bibr" target="#b50">50]</ref>.</p><p>An attractive alternative is to carry out distributed deep learning across the micro-clouds, since they often provide (limited) computation and storage capabilities. Recently, there has been growing interest in using the edge for DL inference <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b30">30,</ref><ref type="bibr" target="#b52">52]</ref>, where models trained in the cloud are deployed at the edge for faster inference. In this paper, we argue for the use of micro-cloud environments for DL training to efficiently build DL models in-situ and to support online and incremental learning.</p><p>There are three major challenges of distributed deep learning in micro-clouds. 1. Compute resource heterogeneity. Different micro-clouds can have different number of servers equipped with different performance hardware. In addition, servers in the microclouds can be shared by other applications, so the available compute capacity may dynamically change. 2. Network resource heterogeneity. Servers in a microcloud communicate with each other over LAN, whereas servers in different micro-clouds are connected via WAN. Network capacities in LANs may vary due to network resource contention with other applications, while bandwidths in WANs are much more scare and fluctuating than in LANs. 3. Scale. A micro-cloud covers much smaller area than a public cloud, but the number of micro-clouds is much bigger than the number of data centers in a multi-DC public cloud. The micro-clouds are also likely to be much more geographically distributed, leading to heavy communication over WANs.</p><p>Existing distributed deep learning systems, however, do not fully address these challenges. General purpose distributed DL systems like TensorFlow <ref type="bibr" target="#b0">[1]</ref>, MXNet <ref type="bibr" target="#b5">[6]</ref> or CNTK <ref type="bibr" target="#b43">[43]</ref> do not consider the heterogeneity or scale, resulting in much longer training time due to network bottleneck issue as cluster size increases. Recent research <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b31">31,</ref><ref type="bibr" target="#b54">54]</ref> has addressed the network bottleneck issue by reducing the amounts of data transmitted over the network. As a result, models can be trained faster, potentially at the cost of loss of model accuracy as cluster size increases. Other recent research <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b23">24]</ref> tackles scalability issue by communicating with a small number of peers, but it does not consider network or compute resource heterogeneity. Thus, none of the existing systems comprehensively considers all the challenges of micro-cloud environments: compute and network heterogeneity and scale.</p><p>In this paper, we present DLion, a decentralized distributed deep learning system that is designed for deep learning in large-scale heterogeneous environments such as micro-clouds. The goals of the system are to reduce training time, improve model accuracy, and handle system scalability. It employs techniques specifically designed to address the above challenges, including compute capacity-aware batching, networkaware data exchange, and selective data propagation ( ยง 3). We have implemented a prototype of DLion on top of TensorFlow and present our preliminary results in ยง 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background and Related Work</head><p>Deep Learning. We consider supervised learning using minibatch stochastic gradient descent (SGD) <ref type="bibr" target="#b40">[40]</ref> to minimize the loss value of the function f over the training dataset x (eq. 1).</p><formula xml:id="formula_0">Learning: min xโR n f (x; w) = 1 m m โ i=1 f i (x; w t )<label>(1)</label></formula><p>A deep learning model consists of a set of parameters called weights, and operators. The meaning of training a DL model is to find the best values for the weights, which lead to the smallest loss value.</p><p>Gradient Calculation:</p><formula xml:id="formula_1">g t = 1 m m โ i=1 w f i (x; w t ) (2)</formula><p>Weight Update: w t+1 = w t โ ฮทg t</p><p>The weights are tuned by iterations of gradient g t calculation (eq. 2) and weight w t update (eq. 3) over minibatches. A minibatch is composed of m training data samples from the training data x and batch size indicates the size of a minibatch. An iteration indicates a cycle of gradient calculation and weight update over a minibatch. An epoch indicates a set of iterations trained over one pass of the whole training data. Batch size and learning rate ฮท are tunable model parameters.</p><p>Distributed Deep Learning. Weight update follows eq. 4 in distributed deep learning systems.</p><formula xml:id="formula_3">w t+1 = w t โ ฮท 1 k k โ j=1 1 m m โ i=1 w f i (x; w t )<label>(4)</label></formula><p>k workers calculate their own gradients locally based on a minibatch size of m in parallel. Weights are updated based on the average of the k gradients, where the total batch size of the model is m * k.</p><p>Distributed Deep Learning Systems. Distributed deep learning systems allow users to train their DL models using a cluster of multiple machines where training data are distributed. General purpose DL systems <ref type="bibr" target="#b7">[8]</ref>   <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b31">31]</ref> such as Ako <ref type="bibr" target="#b54">[54]</ref> synchronize models without PSs. Workers exchange their local gradients with each other, and update their local weights based on the collected gradients. The workload imposed on PSs can be offloaded to all the workers. Hybrid distributed DL systems such as Gaia <ref type="bibr" target="#b18">[19]</ref> employ the decentralized architecture to exchange gradients between PSs over WANs while learning in a centralized manner in LANs. While some of the existing systems such as Gaia and Ako have addressed network bottleneck issue by exchanging small amount of gradients or sending full gradients to a subset of peers, none of them comprehensively consider all the challenges in a micro-cloud environment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">DLion</head><p>We propose DLion, a decentralized distributed deep learning system for learning in micro-clouds. <ref type="figure" target="#fig_1">Figure 2</ref> shows the system architecture of DLion. The philosophy of decentralized architecture fits well to the heterogeneous environments of micro-clouds. In DLion, there are no centralized components such as parameter servers. Workers within a micro-cloud are connected over LANs, and those in different micro-clouds communicate over WANs. There are three major goals in DLion, which are reducing training time, improving model accuracy, and providing system scalability for deep learning in micro-clouds. In the rest of the section, we describe the techniques to deal with compute heterogeneity ( ยง 3.1), network heterogeneity ( ยง 3.2) and scalability ( ยง 3.3) encountered in micro-clouds environments. Details of the experimental setup for our exploratory and preliminary experiments are specified in section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Compute Capacity-aware Batching</head><p>We first describe how DLion makes use of heterogeneous compute resources in micro-clouds to reduce training time and adaptively increase model accuracy through consideration of available compute resources.</p><p>The idea of compute capacity-aware batching is to have different batch sizes assigned to workers based on their computation capacities. For faster learning, DLion maximizes data parallelism by assigning a batch size m j to worker j proportional to its compute capacity C j , so its time to process a minibatch,</p><formula xml:id="formula_4">T j = m j C j</formula><p>, is close to an expected global unit processing time T unit , thus balancing the load proportionally across workers. This approach could result in very large batch sizes being assigned to fast workers. However, it has been shown that accuracy in large-batch training can degrade drastically beyond a certain batch size <ref type="bibr" target="#b28">[28]</ref>. We observed this phenomenon in our experiment shown in <ref type="figure" target="#fig_2">Figure 3</ref> where the accuracy drops between total batch size of 640 and 960. To avoid this accuracy degradation, DLion makes sure the total batch size across workers โ k j=1 m j does not exceed a certain threshold T bs beyond which accuracy can drop. DLion measures the computation power of each worker through preprofiling before training, and selects different batch sizes for individual workers accordingly. The new weight update equation based on compute capacity-aware batching (eq. 5) adds two additional constraints as follow:</p><formula xml:id="formula_5">w t+1 = w t โ ฮท 1 k k โ j=1 1 m j m j โ i=1 w f i (x; w t )<label>(5)</label></formula><p>subject to |T j โ T unit | โค ฮต and โ k j=1 m j โค T bs .  Adaptive model parameter tuning. On top of compute capacity-aware batching, DLion applies techniques related to large-batch training for better model optimization such as: warm-up learning rate <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b57">57]</ref> increasing learning rate from ฮท to ฮท * k (# workers) early in the learning phase (WarmUpLR) increasing batch size <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b28">28]</ref> late in learning (SpeedUpBS) or throughout learning (IncreaseBS) decaying learning rate <ref type="bibr" target="#b46">[46]</ref> late in learning (DecayLR). DLion adaptively adjusts the DL model parameters, learning rate and batch size. There is no comprehensive and integrated existing solution for applying these techniques. Our system automatically applies them by determining when, how, and what to apply the techniques with comprehensive consideration of heterogeneous computation capacities of workers, batch size threshold T bs and learning progress. For example, we make sure the total batch size is not greater than the threshold T bs while increasing IncreaseBS or speeding up batch size SpeedUpBS. The threshold T bs is approximately 10 percents of training data size <ref type="bibr" target="#b46">[46]</ref>.</p><p>We performed exploratory experiments to see the effect of the techniques. We trained a model stated in ยง 4 with different combinations of the techniques for 10 epochs. <ref type="table" target="#tab_1">Table 1</ref> shows that the best combination WarmUpLR + SpeedUpBS + DecayLR results in faster training time and higher accuracy compared to other baselines that either do not use these techniques, or use them individually or pairwise combinations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Network-aware Data Exchange</head><p>In this section, we describe how DLion deals with heterogeneous network bandwidth resources in micro-clouds to improve model accuracy and achieve faster training times. <ref type="figure">Figure 4</ref>: When-to-do weight exchange (WE) for model synchronization; Weights are exchanged every 10 iterations during whole training (Periodic), first 2 epochs (Early), and last 2 epochs (Late). WE early in training achieves comparable result with periodic WE. Partial gradient exchange (PartialGrads) reduces training time for all cases. A model is trained until it reaches 60% accuracy.</p><p>The distributed DL model synchronization happens by exchanging data between workers during the training phase from-time-to-time. There are two types of data, gradients and weights, that workers can exchange for model synchronization. Existing decentralized systems like Ako and Gaia exchange only gradients, which can result in longer training time and accuracy drop as cluster size increases. Recent work <ref type="bibr" target="#b51">[51]</ref> has proposed a periodic weight exchange algorithm to compensate for drop in accuracy.</p><p>DLion employs this direct model synchronization across workers though weight exchange (WE) in addition to gradient exchange (GE). The key idea of network-aware data exchange is to adjust data size by controlling the quality of data and considering the available network bandwidth of individual workers in real-time. We explore several decisions to understand factors contributing to the data dissemination, as follows. When-to-do: when to exchange data, e.g., more frequently early or late in training, or periodically; what-todo: whether to exchange whole or partial data; whom-to-do: whether to exchange data with all workers or a subset of workers; and how-to-do: whether to exchange data synchronously or asynchronously.</p><p>DLion uses a system parameter to control the contribution to the model update when adjusting data size, especially for gradient exchange (GE). DLion increases the contribution threshold to reduce the size of partial gradients, but still to convey the important information by partial gradients. When workers need to send gradients over WANs, the threshold is set higher, compared to sending them over LANs. <ref type="figure">Figure 4</ref> and <ref type="figure">Figure 5</ref> show exploratory results for the four decisions regarding weight and gradient exchanges. <ref type="figure">Figure 4</ref> shows that frequent WE early in learning has a comparable performance with periodic WE with high frequency. Also, partial GE helps to reduce the training time, compared to full GE. DLion uses these insights to allocate more resources for model synchronization at the beginning of training phase, and concentrate more on gradient exchange later in the training phase. In addition, <ref type="figure">Figure 5</ref> shows the results regarding what-to-do, whom-to-do, and how-to-do. Model synchronization by WE (MS) benefits every case except for partial WE (PartialMS). In addition, exchanging weights only to the <ref type="figure">Figure 5</ref>: What-to-do, whom-to-do, and how-to-do model synchronization. Partial weight exchange does not help to improve accuracy. Rather, full weight exchange is much more effective in model optimization. A model is trained with partial gradient exchange and periodic WE for 30 minutes.</p><p>worst worker having the highest loss value (One) and asynchronous WE (Asynch) leads to higher accuracy as it was able to more iteration for a given training time because of small amount data exchange.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Selective Data Propagation</head><p>We next discuss how DLion can handle system scalability when learning over large number of micro-clouds over WANs. We explicitly consider the compute and network heterogeneity in our scalability approach as well.</p><p>In DLion, at each iteration, a subset of micro-clouds (senders) send their gradients to a subset of micro-clouds (receivers), instead of an all-to-all communication, where each micro-cloud would broadcast gradients to all micro-clouds. We use a probabilistic model to select senders and receivers based on their compute capacities. Since micro-clouds with higher capacities are more likely to generate more informative gradients over larger minibatches, they have a higher probability of being selected as senders. Similarly, micro-clouds with lower capacities are more likely to generate less informative gradients over smaller minibatches, so they are likely selected as receivers.</p><p>After the sender and receiver selection, we employ our network-aware data exchange techniques ( ยง 3.2) to reduce the data size. Moreover, the workload of the gradients delivery from a sender micro-cloud to a receiver micro-cloud is offloaded to all the workers in each location, to avoid overloading only a single worker at each location. Finally, we are also considering gossipping algorithms to more efficiently disseminate the data through the network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Evaluation</head><p>Implementation. We are implementing a prototype of DLion on TensorFlow. Each worker trains DL models by using TensorFlow. Messages are delivered via Redis, an in-memory data store, as a message broker for workers in DLion. Redis provides persistence that is necessary for dynamic cluster configurations such as fault tolerance, worker join or leave in the future. Currently, TensorFlow provides a static cluster configuration where it is hard to deal with the cluster dynamics. Experimental setup. We compared DLion with Gaia and Ako implemented in our prototype, and emulated micro-cloud environments using 4 local servers by using the linux tc and stress commands to throttle network bandwidth, and impose load on servers, respectively. Network links are set to 1Gbps for LANs, and 100 Mbps for WANs. High-performance servers have 24 cpus and low-performance servers have 8 cpus per server. All servers have 60GB available memory and run on Ubuntu 16.04 installed with TensorFlow 1.4.1. A worker runs in a server. Dataset CIFAR10 <ref type="bibr" target="#b29">[29]</ref> and a test model (2conv+2fc, model size is 17MB) are used for the purpose of preliminary experiments. The test model with CIFAR10 is converged after 10-epoch training, and takes around 30 minutes in LAN, so we use those two as training termination conditions. We use training time and accuracy as metrics to measure system performance and model optimization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Heterogeneous Computation Resources</head><p>We evaluate the usefulness of the compute capacity-aware batching feature and compare DLion with existing distributed deep learning systems, Gaia and Ako, in compute resource heterogeneous environments. We set up a cluster where there are three low-performance workers and one high-performance worker, and network resources are homogeneous. <ref type="figure" target="#fig_3">Figure 6</ref> shows the training time until reaching a target accuracy for the various systems. We use two different accuracy targets (60% accuracy for <ref type="figure" target="#fig_3">Figure 6a</ref> and 70% for <ref type="figure" target="#fig_3">Figure 6b</ref>) as Gaia and Ako were unable to reach 70% accuracy in our experiments. For Gaia, workers exchange significant partial gradients, and for Ako, workers exchange partitioned partial gradients at each iteration. <ref type="figure" target="#fig_3">Figure 6a</ref> shows the comparison results where DLion is able to reach the target accuracy 73% and 74% faster than Gaia and Ako, respectively. This is because both existing systems are unable to take advantage of compute heterogeneity and do not have any features to improve model accuracy like direct model synchronization through weight exchange and adaptive parameter tuning. As shown in <ref type="figure" target="#fig_3">Figure 6b</ref>, we see that compute capacity-aware batching technique helps to reduce the training time by 34% by fully utilizing the heterogeneous compute resource of the cluster. The highperformance worker was able to train a larger minibatch than the low-performance workers at each iteration. Thus, using compute capacity-aware batching can learn more information faster than without using it. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Heterogeneous Network Resources</head><p>We compare DLion using all four techniques with Gaia and Ako in network bandwidth heterogeneous environments. We set up two micro-clouds with three workers in a micro-cloud and a worker in another micro-cloud. All 4 workers have homogeneous compute resources. For Gaia, workers in a micro-cloud train in a centralized manner by exchanging full gradients with a PS. PSs in each micro-clouds exchange significant partial gradients according to its algorithm. For Ako, all workers exchange partitioned gradients determined based on the smallest bandwidth between micro-cloud. The test model is trained for 30 minutes for each of the three systems. <ref type="figure" target="#fig_4">Figure 7</ref> shows that DLion can achieve the highest accuracy during the same amount of training time, 42% and 25% higher than Gaia and Ako, respectively. Gaia does not take into account the available network bandwidths when determining the size of gradients. It waits until the significant gradients are delivered over WANs, resulting in more time to finish an iteration. On the other hand, Ako considers the smallest network bandwidth in calculating the size of partial gradients. As a result, it performs more iterations for a given amount of time than Gaia leading to higher accuracy. However, there is inefficiency in network resource utilization of three workers in LAN. If we selected the largest bandwidth for Ako, the accuracy would be lower due to network bottleneck issue in a WAN link between two micro-clouds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>There has been increasing need of data analytics based on deep learning in micro-clouds. However existing distributed deep learning systems do not handle the characteristics of micro-clouds environments such as compute capacity and network bandwidth heterogeneity as well as system scalability. In this paper, we have presented DLion, a decentralized deep learning system for fast learning and high accuracy in such environments. We have conducted preliminary experiments to show the effect of DLion techniques handling the compute and network heterogeneity in micro-clouds. Also, we have discussed design considerations for scalability solution. Our preliminary results are promising, and show the benefit of explicitly addressing the challenges exposed by micro-cloud environments.</p><p>In this paper, we presented promising preliminary results of DLion based on compute capacity-aware batching, adaptive model parameter tuning, network-aware data exchange features. We are actively developing details of our DLion, and plan to open-source the system. While this motivates the research on deep learning in large-scale heterogeneous environments such as micro-clouds, there are several discussion points and open issues: Large-scale system evaluation. Scale is one of the major challenges in micro-clouds. We plan to incorporate our proposed scalability solutions ( ยง 3.3) into DLion. The experiments in this paper have been performed in a small-scale local cluster with a small size of deep learning model and dataset. We plan to conduct more extensive and thorough experiments in large-scale environments where there are many micro-clouds to evaluate the scalability of DLion. We will also use multiple large-scale deep learning models such as VGG16 <ref type="bibr" target="#b45">[45]</ref> and ResNet50 <ref type="bibr" target="#b15">[16]</ref> and datasets like ImageNet <ref type="bibr" target="#b8">[9]</ref>. We expect DLion to outperform existing systems with larger models and datasets consuming larger computation and network resources because DLion carefully factors heterogeneous resources, the sizes of models and training data in training them. Training data migration. It is possible that data distribution across the micro-clouds may be skewed and may not match their compute capabilities. For instance, it may happen that micro-clouds with small computation resources have larger volumes of training data compared to other micro-clouds with large computation resources. This may require migrating training data across micro-clouds for better load balancing. We will investigate the tradeoff of input data migration vs. load balancing in future work. For instance, one approach could be to balance the size of training data for individual micro-clouds depending on their relative computation capacities by migrating small portions of training data to the closest large-capacity micro-clouds. Dynamic environments. We would like to cover dynamic environments where compute and network resources are dynamically changing over time to show the adaptability of DLion. Our system and model parameters need to be adjusted based on the changing cluster resources. We plan to exploit how the system dynamically adjusts the parameters based on environmental changes. In addition, we will put more efforts in the assessment of the prediction accuracy based on profiling and the effectiveness of runtime parameter adjustment. Fault tolerance and cluster dynamics Workers may join, leave, or fail during training, or micro-clouds may get disconnected. To support such scenarios, we plan to explore a fault tolerance and cluster dynamics features in our system. We have already separated the message passing module from the training core module based on TensorFlow to implement the feature. We will continue to study on this to support worker failure recovery and cluster dynamics in DLion.</p><p>Edge devices We assume workers as machines always powered on. If various edges devices like mobile devices connected to micro-clouds are equipped with powerful computation components, we can consider the trade-off between available power (energy) of the devices and system performance in terms of training time and test accuracy.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Distributed deep learning (DL) in micro-clouds at multiple locations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Decentralized Dlion system architecture. Workers in a micro-cloud communicate in LANs, whereas workers in different micro-clouds use limited heterogeneous network bandwidth like WANs. Individual micro-clouds have different number of servers and computation capacity.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Existence of batch size threshold indicating accuracy plunge between total batch size 640 and 960; 4-worker cluster training with different batch sizes for 10 epochs; The prediction of the threshold can be done with an epoch training.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Benefit of handling compute heterogeneity.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Model accuracy comparison to show the advantage of handling heterogeneous network bandwidth resources.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="true"><head>Table 1 : Effect of adaptive learning rate and batch size</head><label>1</label><figDesc></figDesc><table>Adaptive LB techniques 
Accuracy 
Training 
Time 
Baseline (SmallLR + StaticBS) 
0.6956 
2343 
LargeLR + StaticBS 
0.6256 
2404 
WarmUpLR + StaticBS 
0.7052 
2401 
WarmUpLR + SpeedUpBS 
0.7090 
2186 
WarmUpLR + IncreaseBS 
0.7212 
5216 
WarmUpLR + SpeedUpBS + DecayLR 
0.7220 
2183 

</table></figure>
		</body>
		<back>

			<div type="acknowledgement">
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Tensorflow: a system for large-scale machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Abadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">OSDI</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="265" to="283" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Edge enhanced deep learning system for large-scale video stream analytics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhammad</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashiq</forename><surname>Anjum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reza</forename><surname>M Usman Yaseen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Zamani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Balouek-Thomert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manish</forename><surname>Rana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Parashar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE 2nd International Conference on Fog and Edge Computing (ICFEC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.0473</idno>
		<title level="m">Neural machine translation by jointly learning to align and translate</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Potentials, trends, and prospects in edge technologies: Fog, cloudlet, mobile edge, and micro data centers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kashif</forename><surname>Bilal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Osman</forename><surname>Khalid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aiman</forename><surname>Erbad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Samee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Khan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Networks</title>
		<imprint>
			<biblScope unit="volume">130</biblScope>
			<biblScope unit="page" from="94" to="120" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">End-to-end incremental learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Francisco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Castro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolรกs</forename><surname>Manuel J Marรญn-Jimรฉnez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cordelia</forename><surname>Guil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karteek</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Alahari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="233" to="248" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Mxnet: A flexible and efficient machine learning library for heterogeneous distributed systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yutian</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naiyan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minjie</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianjun</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chiyuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1512.01274</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Empirical evaluation of gated recurrent neural networks on sequence modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyoung</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caglar</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.3555</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Large scale distributed deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajat</forename><surname>Monga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Devin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Senior</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Tucker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1223" to="1231" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Devarakonda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxim</forename><surname>Naumov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Garland</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1712.02029</idno>
		<title level="m">Adabatch: Adaptive batch sizes for training deep neural networks</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">On using micro-clouds to deliver the fog</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yehia</forename><surname>Elkhatib</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Porter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><forename type="middle">Faten</forename><surname>Heverson B Ribeiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junaid</forename><surname>Zhani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Etienne</forename><surname>Qadir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Riviรจre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Internet Computing</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="8" to="15" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Lixin Tao, and Ziliang Zong. Dynamic energy-aware cloudlet-based mobile cloud computing model for green computing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keke</forename><surname>Gai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meikang</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Network and Computer Applications</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="page" from="46" to="54" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Fog computing: Data analytics and cloud distributed processing on the network edges</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nelson Mimura</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Walter</forename><forename type="middle">Akio</forename><surname>Goya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rosangela</forename><surname>De Fatima</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Langona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Augusto</forename><surname>Erico</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tereza</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cristina Melo De Brito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><forename type="middle">Christian</forename><surname>Carvalho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan-Erik</forename><surname>Miers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Azimeh</forename><surname>Mรฅngs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sefidcon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">35th International Conference of the Chilean Computer Science Society (SCCC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sherjil</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2672" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Priya</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Dollรกr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Noordhuis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Wesolowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aapo</forename><surname>Kyrola</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.02677</idno>
	</analytic>
	<monogr>
		<title level="m">Yangqing Jia, and Kaiming He. Accurate, large minibatch sgd: Training imagenet in 1 hour</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Optimizing grouped aggregation in geodistributed streaming analytics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Heintz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Chandra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramesh</forename><forename type="middle">K</forename><surname>Sitaraman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th International Symposium on High-Performance Parallel and Distributed Computing</title>
		<meeting>the 24th International Symposium on High-Performance Parallel and Distributed Computing</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="133" to="144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Adaptive communication for distributed deep learning on commodity gpu cluster</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Yung</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan-Jan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pangfeng</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">18th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (CCGRID)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="283" to="290" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Geo-distributed machine learning approaching lan speeds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Hsieh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NSDI</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="629" to="647" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Monarch: gaining command on geo-distributed graph analytics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aurojit</forename><surname>Anand Padmanabha Iyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mosharaf</forename><surname>Panda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Chowdhury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Akella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ion</forename><surname>Shenker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Stoica</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">10th USENIX Workshop on Hot Topics in Cloud Computing</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>HotCloud 18</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Scaling video analytics systems to large camera deployments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samvit</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ganesh</forename><surname>Ananthanarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junchen</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanchao</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Gonzalez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th International Workshop on Mobile Computing Systems and Applications</title>
		<meeting>the 20th International Workshop on Mobile Computing Systems and Applications</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="9" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Ionn: Incremental offloading of neural network computations from mobile devices to edge servers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyuk-Jin</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyeon-Jae</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><forename type="middle">Hyun</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soo-Mook</forename><surname>Moon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Symposium on Cloud Computing</title>
		<meeting>the ACM Symposium on Cloud Computing</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="401" to="411" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Collaborative deep learning in fixed topology networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhanhong</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Balu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chinmay</forename><surname>Hegde</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumik</forename><surname>Sarkar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5904" to="5914" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">How to scale distributed deep learning?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiaochu</forename><surname>Peter H Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Forrest</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Iandola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Keutzer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.04581</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Multi-query optimization in wide-area streaming analytics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert</forename><surname>Jonathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Chandra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jon</forename><surname>Weissman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Symposium on Cloud Computing</title>
		<meeting>the ACM Symposium on Cloud Computing</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="412" to="425" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrej</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Toderici</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanketh</forename><surname>Shetty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rahul</forename><surname>Sukthankar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Large-scale video classification with convolutional neural networks</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1725" to="1732" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Fearnet: Braininspired model for incremental learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronald</forename><surname>Kemker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Kanan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.10563</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Jorge Nocedal</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dheevatsa</forename><surname>Nitish Shirish Keskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mudigere</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.04836</idno>
	</analytic>
	<monogr>
		<title level="m">Mikhail Smelyanskiy, and Ping Tak Peter Tang. On large-batch training for deep learning: Generalization gap and sharp minima</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>Citeseer</publisher>
		</imprint>
	</monogr>
<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Learning iot in edge: deep learning for the internet of things with edge computing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">He</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaoru</forename><surname>Ota</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mianxiong</forename><surname>Dong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Network</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="96" to="101" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Can decentralized algorithms outperform centralized algorithms? a case study for decentralized parallel stochastic gradient descent</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangru</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ce</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cho-Jui</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ji</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5330" to="5340" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Supporting ubiquitous sensor-cloudlets and context-cloudlets: Programming compositions of context-aware systems for mobile users</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Seng W Loke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Future Generation Computer Systems</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="619" to="632" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Mobile cloud computing model and big data analysis for healthcare applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A Tawalbeh</forename><surname>Lo&amp;apos;ai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rashid</forename><surname>Mehmood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="6171" to="6180" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>Elhadj Benkhlifa, and Houbing Song</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Optasia: A relational platform for efficient large-scale video analytics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yao</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aakanksha</forename><surname>Chowdhery</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srikanth</forename><surname>Kandula</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh ACM Symposium on Cloud Computing</title>
		<meeting>the Seventh ACM Symposium on Cloud Computing</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="57" to="70" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Game-theoretic analysis of computation offloading for cloudlet-based mobile cloud computing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuang</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xudong</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Congjie</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th ACM International Conference on Modeling, Analysis and Simulation of Wireless and Mobile Systems</title>
		<meeting>the 18th ACM International Conference on Modeling, Analysis and Simulation of Wireless and Mobile Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="271" to="278" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Deep online learning via meta-learning: Continual adaptation for model-based rl</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anusha</forename><surname>Nagabandi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chelsea</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1812.07671</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Autonomous deep learning: Incremental learning of denoising autoencoder for evolving data streams</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mahardhika</forename><surname>Pratama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andri</forename><surname>Ashfahani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yew</forename><forename type="middle">Soon</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Savitha</forename><surname>Ramasamy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edwin</forename><surname>Lughofer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1809.09081</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Aditya Akella, Paramvir Bahl, and Ion Stoica</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qifan</forename><surname>Pu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ganesh</forename><surname>Ananthanarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Bodik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srikanth</forename><surname>Kandula</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGCOMM Computer Communication Review</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="421" to="434" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>Low latency geo-distributed data analytics</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">icarl: Incremental classifier and representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Sylvestre-Alvise Rebuffi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georg</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><forename type="middle">H</forename><surname>Sperl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lampert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">A stochastic approximation method. The annals of mathematical statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herbert</forename><surname>Robbins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sutton</forename><surname>Monro</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1951" />
			<biblScope unit="page" from="400" to="407" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Doyen</forename><surname>Sahoo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quang</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">H</forename><surname>Steven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hoi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.03705</idno>
		<title level="m">Online deep learning: Learning deep neural networks on the fly</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Cloudlets: at the leading edge of mobile-cloud convergence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mahadev</forename><surname>Satyanarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kiryong</forename><surname>Ha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenlu</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfgang</forename><surname>Richter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Padmanabhan</forename><surname>Pillai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">6th International Conference on Mobile Computing</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Cntk: Microsoft&apos;s opensource deep-learning toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Seide</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amit</forename><surname>Agarwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2135" to="2135" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Cloudlet deployment in local wireless networks: Motivation, architectures, applications, and open challenges</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Usman</forename><surname>Shaukat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ejaz</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zahid</forename><surname>Anwar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Xia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Network and Computer Applications</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="page" from="18" to="40" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Samuel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter-Jan</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Kindermans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.00489</idno>
		<title level="m">Don&apos;t decay the learning rate, increase the batch size</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Cloud-vision: Realtime face recognition using a mobile-cloudlet-cloud acceleration architecture</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tolga</forename><surname>Soyata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajani</forename><surname>Muraleedharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Funai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minseok</forename><surname>Kwon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wendi</forename><surname>Heinzelman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2012 IEEE symposium on computers and communications (ISCC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="59" to="000066" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Going deeper with convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangqing</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Rabinovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Clarinet: Wan-aware optimization for analytics queries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raajay</forename><surname>Viswanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ganesh</forename><surname>Ananthanarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Akella</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">12th USENIX Symposium on Operating Systems Design and Implementation (OSDI16)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="435" to="450" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Wanalytics: Geo-distributed analytics for a data intensive world</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vulimiri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlo</forename><surname>Curino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><forename type="middle">Brighten</forename><surname>Godfrey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Jungblut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantinos</forename><surname>Karanasos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Padhye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Varghese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 ACM SIGMOD international conference on management of data</title>
		<meeting>the 2015 ACM SIGMOD international conference on management of data</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1087" to="1092" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Adaptive communication strategies to achieve the best error-runtime trade-off in local-update sgd</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianyu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gauri</forename><surname>Joshi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.08313</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Bandwidth-efficient live video analytics for drones via edge computing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junjue</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziqiang</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shilpa</forename><surname>George</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihir</forename><surname>Bala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Padmanabhan</forename><surname>Pillai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Shao-Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mahadev</forename><surname>Satyanarayanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE/ACM Symposium on Edge Computing (SEC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="159" to="173" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">When edge meets learning: Adaptive control for resource-constrained distributed machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiqiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tiffany</forename><surname>Tuor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theodoros</forename><surname>Salonidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Makaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE INFOCOM 2018-IEEE Conference on Computer Communications</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="63" to="71" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Ako: Decentralised deep learning with partial gradient exchange</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Watcharapichat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh ACM Symposium on Cloud Computing</title>
		<meeting>the Seventh ACM Symposium on Cloud Computing</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="84" to="97" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Error-driven incremental learning in deep convolutional neural network for large-scale image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianjun</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaxing</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuiyuan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxin</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM international conference on Multimedia</title>
		<meeting>the 22nd ACM international conference on Multimedia</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="177" to="186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Rich Zemel, and Yoshua Bengio. Show, attend and tell: Neural image caption generation with visual attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kelvin</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhudinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2048" to="2057" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Matthew D Zeiler</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1212.5701</idno>
		<title level="m">Adadelta: an adaptive learning rate method</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaoyun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Patras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hamed</forename><surname>Haddadi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.04311</idno>
		<title level="m">Deep learning in mobile and wireless networking: A survey</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
