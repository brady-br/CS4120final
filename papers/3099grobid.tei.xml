<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2020-09-29T03:00+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">EqualChance: Addressing Intra-set Write Variation to Increase Lifetime of Non-volatile Caches</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sparsh</forename><surname>Mittal</surname></persName>
							<email>mittals@ornl.gov</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Oak Ridge National Laboratory and Georgia Tech</orgName>
								<orgName type="institution">Oak Ridge National Laboratory</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><forename type="middle">S</forename><surname>Vetter</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Oak Ridge National Laboratory and Georgia Tech</orgName>
								<orgName type="institution">Oak Ridge National Laboratory</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">EqualChance: Addressing Intra-set Write Variation to Increase Lifetime of Non-volatile Caches</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Non-volatile memory</term>
					<term>ReRAM</term>
					<term>wear- leveling</term>
					<term>intra-set write variation</term>
					<term>cache lifetime</term>
					<term>write endurance</term>
				</keywords>
			</textClass>
			<abstract>
				<p>To address the limitations of SRAM such as high-leakage and low-density, researchers have explored use of non-volatile memory (NVM) devices, such as ReRAM (re-sistive RAM) and STT-RAM (spin transfer torque RAM) for designing on-chip caches. A crucial limitation of NVMs, however, is that their write endurance is low and the large intra-set write variation introduced by existing cache management policies may further exacerbate this problem, thereby reducing the cache lifetime significantly. We present EqualChance, a technique to increase cache lifetime by reducing intra-set write variation. EqualChance works by periodically changing the physical cache-block location of a write-intensive data item within a set to achieve wear-leveling. Simulations using workloads from SPEC CPU2006 suite and HPC (high-performance computing) field show that EqualChance improves the cache lifetime by 4.29×. Also, its implementation overhead is small, and it incurs very small performance and energy loss.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Recent trends of CMOS scaling have led to a large increase in the number of cores on a chip. To feed data to these cores, the size of last level cache (LLC) has also increased, for example, Intel's 22nm 15-core Xeon processor has 37.5MB SRAM LLC <ref type="bibr" target="#b0">[1]</ref>. However, since SRAM has high leakage energy and low density, caches designed with SRAM may consume a large fraction of chip area and power budget <ref type="bibr" target="#b1">[2]</ref>. To overcome the limitations of SRAM, researchers have recently explored use of NVM devices, such as ReRAM (resistive RAM), STT-RAM (spin transfer torque RAM), and PCM (phase change memory) for designing LLCs <ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref>. NVMs have several attractive features, such as near-zero leakage power consumption, high density and scalability. For example, the size of a typical SRAM cell is in the range of 125-200F 2 , while that of a ReRAM cell is in the range of 4-10F 2 , where F denotes the smallest lithographic dimension in a given technology node <ref type="bibr" target="#b6">[7]</ref><ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b9">[10]</ref>.</p><p>A crucial limitation of NVMs, however, is their small write endurance, which can significantly limit the device lifetime. For ReRAM and PCM, the write endurance values are 10 11 <ref type="bibr" target="#b10">[11]</ref> and 10 8 <ref type="bibr" target="#b6">[7]</ref>, respectively. For STT-RAM, although a write endurance value of greater than 10 15 has been predicted, the best write endurance test so far shows a value of only 4 × 10 12 <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b11">12]</ref>. Process variations may further reduce these values by an order of magnitude <ref type="bibr" target="#b12">[13]</ref>. In contrast, the write endurance values of SRAM and DRAM are more than 10 15 <ref type="bibr" target="#b6">[7]</ref>. Further, existing cache management policies are unaware of possible write-variations across the cache. Hence, these variations may significantly increase the writes to a few hotspot cache blocks, causing the devices in those blocks to experience early failures, while other blocks remain reliable. As an example, with LRU (least recently used) replacement policy, most hits are expected to occur at or near MRU (most recently used) position(s). This leads to large intra-set write variation. This is also confirmed by the previous research <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b14">15]</ref>.</p><p>To demonstrate the effect of write-variation on cache lifetime and highlight the need of a wear-leveling technique, we take the example of two SPEC CPU2006 benchmarks and compare the L2 cache lifetime when each of these benchmarks is used as a workload in a single-core system. The first benchmark is lbm, which has the highest L2 cache write-intensity among all the SPEC CPU2006 workloads ( <ref type="bibr" target="#b15">[16]</ref>, also confirmed by our experiments) and the second is povray which has the largest coefficient of inter-set and intra-set write variation among all the SPEC2006 workloads (refer Section 3 and <ref type="figure" target="#fig_1">Figure 2</ref>). We assume an L2 cache (LLC) with LRU replacement policy which does not use any wear-leveling technique. We observe that, although the total number of writes with lbm is 41 times larger than that of povray, the largest number (i.e. worst-case) of writes on a block for lbm is 20 times smaller than that of povray. This is due to the fact that with lbm benchmark, the writes are uniformly distributed to different cache blocks, while for povray benchmark, most of the writes are directed to only few cache blocks that would fail much earlier than the rest of the blocks, leading to very short overall cache lifetime.</p><p>Thus, contrary to the intuitive expectation, the limited write-endurance of NVMs poses a challenge, for not only the write-intensive workloads but also for the writeunintensive workloads since the variation in writes to cache blocks may present more severe challenge than the magnitude (i.e. number) of writes. This clearly shows that wear-leveling techniques are crucial for achieving reasonable lifetime with NVM caches and can be very effective in making NVMs the universal memory solution for future extreme-scale computing systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Contributions</head><p>In this paper, we present EqualChance, a technique for increasing lifetime of NVM caches by mitigating the intra-set write variation. EqualChance records the number of writes to each set and uses this count to periodically shift a write-intensive data item to a block having lower position (i.e. least-recent) in the LRU-stack, since this block is expected to have seen smaller number of writes in the recent execution interval (Section 3). Thus, the future writes will be redirected from a hot (i.e. frequently written) block to a cold block, which helps in achieving wear-leveling. In this paper, we take the example of a ReRAM LLC and based on the explanation, EqualChance can be easily applied to caches designed with other NVMs. In the remainder of the paper, we use the term ReRAM and NVM interchangeably for the sake of convenience.</p><p>The storage requirement of EqualChance is less than 0.2% of the L2 cache size and thus, its implementation overhead is very small (Section 4). We conduct microarchitectural simulations using an x86-64 simulator and single-core workloads from SPEC2006 suite and HPC (high-performance computing) field (Section 5). We characterize both intra-set and inter-set write-variation for our workloads for different cache configurations and show that EqualChance significantly reduces the intra-set write variation which results in improvement in the cache lifetime (Section 6.1). Also, EqualChance has minimal impact on performance and energy efficiency. Additional results show that EqualChance performs well for different system and algorithm parameters (Section 6.2) and thus, it offers flexibility to the designer to achieve a balance between the improvement in lifetime and performance/energy loss. .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background and Related Work</head><p>Techniques for improving NVM cache lifetime: Cache lifetime can be improved by using either or both of writeminimization or wear-leveling techniques. Some researchers propose write-minimization techniques which work at bit-level by avoiding redundant writes <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b17">18]</ref> and at cache-access level by using buffers or additional level of caches <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b19">20]</ref>. These techniques are orthogonal to EqualChance and hence, can be synergistically integrated with it.</p><p>Based on their granularity, the wear-leveling techniques can be further classified as cache-color level <ref type="bibr" target="#b20">[21]</ref>, set-level <ref type="bibr" target="#b21">[22]</ref>, way-level <ref type="bibr" target="#b4">[5]</ref> and memory-cell level <ref type="bibr" target="#b17">[18]</ref>. As we show in Section 6, for our workloads, intra-set write-variation for typical caches can be higher than inter-set write-variation. EqualChance works at waylevel (i.e. it addresses intra-set write variation) and can be easily combined with the set-level or memory-cell level wear-leveling techniques for further improving the cache lifetime.</p><p>To leverage the high write-endurance and performance of SRAM along with high density and low-leakage of NVMs, researchers have proposed way-based NVM-SRAM hybrid cache designs <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b22">23]</ref> where a few ways are designed using SRAM and the remaining ways are designed using NVM. EqualChance technique can be easily used in such hybrid caches also to minimize the write-variation in NVM ways and increase the number of writes in SRAM ways.</p><p>Qureshi et al. <ref type="bibr" target="#b23">[24]</ref> propose a wear-leveling technique for main memory which periodically changes the mapping between logical and physical address to uniformly distribute the writes in the main memory. Since writes to caches show both inter-set and intra-set variations <ref type="bibr" target="#b5">[6]</ref>, while those to main memory show only inter-set variation, the wear-leveling techniques proposed for main memory cannot be utilized to mitigate intra-set writevariation in caches.</p><p>Discussion of a few wear-leveling techniques: Wang et al. <ref type="bibr" target="#b4">[5]</ref> propose a technique, named probabilistic line flush (PoLF) to reduce intra-set write variation. After a fixed number of write hits in the entire cache, a write-operation on cache is skipped, instead the data item is directly written-back to memory and the cacheblock is invalidated, without updating the LRU-age information. A common limitation of cache wear-leveling techniques based on data invalidation (e.g. <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b21">22]</ref>) is that in an attempt to reduce or uniformly spread the writes to the cache, they may increase the number of writes on main memory, which increases the memory power dissi-pation and queue contention. Also, in the modern processors, the main memory itself may be designed using NVM and hence, these techniques may exacerbate the write endurance issue in the main memory. In comparison, EqualChance does not use data invalidation, rather it uses in-cache data movement approach and tries to redirect the hot data-item to a cold block in the same set. Also, EqualChance does not require offline profiling or modification of the program binary (unlike <ref type="bibr" target="#b8">[9]</ref>) or including set-index bits as part of the tag (unlike <ref type="bibr" target="#b21">[22]</ref>). Also, in EqualChance, data movement is done within the same set and not across sets (unlike <ref type="bibr" target="#b22">[23]</ref>) and hence, set-decoding and block-lookup mechanisms are not affected.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methodology</head><p>Notations: We use the following symbols. For L2 cache, N, M, L and G denote the number of sets, associativity, cache line (block) size and tag-size, respectively. In this paper, we assume L = 64B (or 512 bits) and G = 40 bits. Also, we use W avg to show the average writes on all cache blocks and w i, j to show the number of writes on a block at way j in set i. Using these, the coefficient of inter-set write variation (InterV) and coefficient of intra-set write variation (IntraV) can be defined <ref type="bibr" target="#b4">[5]</ref> as</p><formula xml:id="formula_0">InterV = 100 W avg N ∑ i=1 ( M ∑ j=1 w i, j /M −W avg ) 2 N − 1 (1) IntraV = 100 N ·W avg N ∑ i=1 M ∑ j=1 ( w i, j − M ∑ r=1 w i,r /M ) 2 M − 1 (2)</formula><p>Thus, InterV measures the CoV (coefficient of variation) of the average write count within cache sets, and IntraV measures the average of the CoV of the write counts across a cache set <ref type="bibr" target="#b4">[5]</ref>. Note that EqualChance does not require computation of IntraV or InterV. We use them only to characterize the write-variation present in workloads and as a figure of merit for evaluating effectiveness of EqualChance. We now discuss the main idea and algorithm of EqualChance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Main Idea</head><p>Based on the temporal locality principle, cache management policies such as LRU replacement policy, aim to keep the hot data in the cache as long as possible. However, if a particular data item sees frequent write hits, the number of writes on that block will increase much more than those on the other blocks.</p><p>EqualChance works on the key idea that periodically, if the physical cache-block location of a write-intensive data item is changed, future writes will occur to another cache-block, and thus, the writes can be more uniformly distributed in a cache set. EqualChance records the number of writes on each set individually and uses this count to trigger a write-redirection operation for that set. By virtue of recording per-set counters, it performs more aggressive wear-leveling for the heavily written sets, which is especially advantageous for applications which have high inter-set write variation. Unlike previous techniques (e.g., <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b8">9]</ref>) we do not use compiler analysis or extra storage to detect write-intensive blocks. Instead, we assume that, probabilistically, the data-item being shifted on a write-hit is hot, since the most frequently accessed dataitem is most likely to be chosen for redirection when the shifting is performed. This assumption has been confirmed by our experiments. For a 16-way cache, assuming that the age of the MRU-way is 0 and that of the LRU-way is 15 (and similarly for other ways), we record the average age of the data-item selected for shifting in all shifting-operations and then average it over all the workloads. This value is observed to be 0.29, which is very close to 0, the age of the MRU-way, which confirms that the MRU-way is most frequently chosen for shifting.</p><p>In a set-associative cache, any block in a set can be a candidate for write-redirection. A candidate block may store either an invalid, clean or dirty data item. We term I-shifting (resp. C-shifting) as the case when a write is redirected to an invalid (resp. clean) block. We do not redirect to another dirty block since the dirty data item itself may have write-intensive nature. I-shifting is preferred over C-shifting, since it incurs less overhead. Also, less recent (i.e. "older") blocks are expected to have seen smaller number of cache accesses than the more recent blocks in the near-past execution window. Hence, for achieving wear-leveling, EqualChance searches for the least-recent invalid or clean block.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Working of EqualChance</head><p>For each cache set, we use a numW rite counter and a FlagBit. The numW rite counter is incremented when a write-access takes place in that set. When the counter reaches a pre-determined shifting interval (ϒ), the FlagBit is turned ON and the counter is reset. When a write-access happens and the FlagBit is ON, Algorithm 1 is triggered which finally turns OFF the FlagBit. If no candidate for write-redirection is found (line 16-18) or FlagBit is OFF (line 21-23), a normal write is performed and LRU-age (i.e. cache replacement policy) information is also updated (line <ref type="bibr" target="#b23">[24]</ref><ref type="bibr" target="#b24">[25]</ref><ref type="bibr" target="#b25">[26]</ref>. In Algorithm 1 if there is no invalid (resp. clean) block in a set, a NULL value is returned in line 5 (resp. line 11). Further, on lines 9, 14 and 15, it is assumed that when data are shifted, corresponding tags are also shifted accordingly  (but LRU-age information is not updated). <ref type="figure" target="#fig_0">Figure 1</ref> presents an illustration of the working of Algorithm 1. In case 1, invalid blocks exist in the cache (p = 2 and 7), and if the FlagBit is ON, the least-recent one (p = 7 having LRU-age as 6) is selected and I-shifting is performed. If the FlagBit is OFF, a normal write is performed where the block is written and LRU-age values are updated. In case 2, no invalid block exists and hence, the algorithm searches for the clean blocks. Of the four clean blocks at indices 0, 3, 4, 6, the one with index 6 is the least-recent in LRU-position and hence, it is selected for C-shifting (q = 6). If the set had no clean block, a normal write would be performed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Implementation and Overhead Assessment</head><p>Storage Overhead: We use ϒ values less than 16 and thus, 4-bits are sufficient for the numW rite counter. We assume, C-shifting is performed using a centralized swap buffer <ref type="bibr" target="#b2">[3]</ref> or a similar scheme. Due to the inter-set write variation and the preference for I-shifting, not all sets are expected to perform C-shifting simultaneously and hence, few swap-buffer entries are sufficient. Assuming 64 swap-buffer entries (64B each) and 5-bit storage for each set (numW rite counter + FlagBit), the percentage overhead of EqualChance (Overhead), compared to the L2 cache is</p><formula xml:id="formula_1">Overhead = (N × 5) + (64 × L) N × M × (L + G) × 100<label>(3)</label></formula><p>As an example, for an 8MB, 16-way L2 cache, we find Overhead of EqualChance as merely 0.15% of L2 cache, which is very small. Effect on Latency and Energy: We assume that in the normal case, checking for FlagBit can be folded into the address decode tree of the cache and hence, the latency of normal case is not affected. Let L w denote the cache write latency in cycles and its value is shown in <ref type="table" target="#tab_1">Table 1</ref>. Then, we assume, I-shifting takes 2 + L w + 1 cycles (2 cycles for searching an invalid cache block, L w cycles for writing the data and 1 cycle for invalidating the existing block and setting appropriate valid/dirty bits). Also, C-shifting takes 2+2+4+2L w +1 cycles (2 cycles each for searching an invalid block first and then a clean block, 4 cycles for transferring a 64B block on a 32B bus to and from the swap-buffer, L w cycles for writing the clean data, L w cycles for writing the newly-arrived data and 1 cycle for setting appropriate valid/dirty bits). Compared to the baseline case, C-shifting incurs an extra write, which we include in total number of L2 writes. In addition, we assume 0.5 nJ energy overhead of each C-shifting operation.</p><p>As confirmed by the results, due to the instructionlevel parallelism present in modern processors, a small increase in the latency of LLC is easily hidden and by choosing a large ϒ value, the overhead of shifting can be amortized over a large execution window (refer Section 6.2). In Section 6.2, we also evaluate EqualChance assuming higher shifting overhead (i.e. using 'pessimistic' estimates of overhead) and find that the overhead of EqualChance still remains small. For further optimization, the search for invalid/clean blocks can be overlapped with the tag-matching.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experimental Methodology</head><p>Simulation Platform: We conduct simulation using interval core model in Sniper x86-64 simulator <ref type="bibr" target="#b24">[25]</ref>, which has been verified against real hardware. Processor frequency is 2GHz and both L1 I/D are 4-way 32KB caches with 2 cycle latency. L2 cache is a 16-way 4MB cache. L2 cache is inclusive of L1 and all caches use LRU, write-back, write-allocate policy. We find the parameters for ReRAM L2 cache using NVSim <ref type="bibr" target="#b9">[10]</ref>, assuming sequential cache access, 32nm CMOS process, 16-way set-associativity and write EDP (energy delay product) optimized cache design. These parameters are shown in <ref type="table" target="#tab_1">Table 1</ref>. Main memory latency is 220 cycles. Peak memory bandwidth is 10 GB/s and queue contention is also modeled.</p><p>Workloads: All 29 benchmarks from SPEC CPU2006 suite with ref inputs and 5 benchmarks from HPC field (shown in italics in <ref type="table" target="#tab_2">Table 2</ref>) are used as workloads. These workloads, along with their acronyms are  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>amg2013) Co(CoMD), Lu(LULESH), Mk(MCCK), Ne(Nekbone)</head><p>Evaluation Metrics: Our baseline is a ReRAM L2 cache which uses LRU replacement policy but does not use any mechanism for lifetime enhancement. We show the results on a) coefficient of inter-set write-variation (InterV, see Section 3), b) coefficient of intra-set writevariation (InterV), c) relative cache lifetime where the lifetime is defined as the inverse of maximum writes on any cache block. Further, we show d) relative performance <ref type="bibr" target="#b1">[2]</ref>, which is the ratio of IPC with EqualChance to IPC with baseline, e) percentage energy loss, f) total number of I-shifting and C-shifting operations which took place in EqualChance. We model energy of L2, main memory and algorithm execution. The values of leakage power and dynamic energy of main memory are taken as 0.18W and 70nJ/access, respectively <ref type="bibr" target="#b14">[15]</ref> and the energy parameters for L2 are shown in <ref type="table" target="#tab_1">Table 1</ref>. The energy overhead of algorithm execution includes 0.5 nJ for each C-shifting operation. We ignore the overhead of counters and buffers, since it is several orders of magnitude smaller compared to the memory subsystem (L2 + main memory). As an example, the dynamic energy of writing a 5-bit counter is 0.96pJ <ref type="bibr" target="#b25">[26]</ref>, which is 3 orders of magnitude smaller than the energy consumed in writing an L2 cache block (refer <ref type="table" target="#tab_1">Table 1</ref>).</p><p>We fast-forward the benchmarks for 10B instructions and simulate each workload for 300M instructions. Across the workloads, relative lifetime and relative performance values are averaged using geometric  mean and the remaining metrics are averaged using arithmetic mean, since they can be zero or negative. We have also computed absolute increase in MPKI (missper-kilo-instructions) and found its average value across workloads to be less than 0.04 for all configurations and hence, EqualChance does not increase off-chip accesses.</p><p>For sake of brevity, we omit the results on MPKI.</p><p>6 Results and Analysis Results on InterV and IntraV: Firstly, from <ref type="figure" target="#fig_1">Figure  2</ref>(a) and 2(b), we note that for a 16-way 4MB cache, average IntraV is larger than InterV. Note that for a fixed cache capacity, on increasing the associativity, InterV reduces and IntraV increases and vice versa (refer <ref type="table" target="#tab_4">Table   3</ref> and Section 6.2). With increasing number of cores, the associativity will also increase, since to avoid conflict misses, the cache associativity should be equal to at least the number of cores. This highlights the importance of an intra-set wear-leveling technique such as EqualChance in improving the lifetime of NVM caches. EqualChance reduces the average intra-set write variation from 141.8% to 33.8%. For several workloads, the IntraV in baseline cache is nearly 400%, for example, Ga (gamess), Po (povray) and Am (amg2013). Also, for several other workloads, the IntraV in baseline cache is more than 200%. This also underscores the necessity of using an intra-set wear-leveling technique.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Results with Default Parameters</head><p>Results on Lifetime Improvement: On average, EqualChance increases the cache lifetime by 4.29×. For several workloads, the lifetime is improved by more than 10×, for example, Ga, Nd (namd), Po, Sj (sjeng), Ze (zeusmp) and Am. Similarly, for several other workloads, the improvement in lifetime is more than 5×. The maximum increase possible in the cache lifetime depends on the variation present in the workload. Thus, the largest improvement in lifetime is obtained for workloads which show high write-variation, e.g., Ga, Po, Sj, Nd etc. Conversely, for workloads such as Lq (libquantum) and Mi (milc), the intra-set write variation in baseline is close to zero, and hence, the scope of improvement in lifetime is negligible. Cache lifetime improvement for these workloads can be achieved using other techniques such as cache bypassing, use of write-buffer, etc.</p><p>Results on Performance: The relative performance is 1.00× and thus, EqualChance has negligible effect on performance. This is due to the fact that EqualChance uses in-cache data-movement and unlike previous datainvalidation based techniques (e.g. <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b21">22]</ref>), EqualChance does not flush the data to achieve wear-leveling. Thus, EqualChance does not increase DRAM traffic significantly or cause queue-contention, or write-endurance issues at main memory. The largest loss in performance is seen for workloads such as So (soplex) where relative performance is 0.97×. This is because, soplex uses L2 cache intensely.</p><p>Results on Energy: The average loss in energy on using EqualChance is 1.97%. Thus, the effect of EqualChance on energy efficiency is small. Since, in general, the higher density and lower leakage power of NVMs help in achieving high performance and energy efficiency, a small loss in these parameters may be acceptable for addressing the crucial limitation of NVMs, viz. their limited write endurance. As we show in Section 6.2, by changing the shifting-interval (ϒ), a designer can exercise trade-off between performance/energy loss and improvement in lifetime. Further, power density minimization comes as a side-benefit of wear-leveling <ref type="bibr" target="#b26">[27]</ref>, which may reduce the chip-temperature, leakage power and the cooling requirement, thus offsetting a small energy loss incurred by EqualChance.</p><p>For some workloads, such as Mc (mcf), Sp (sphinx), Xa (xalan) etc., EqualChance leads to small saving in energy. This can be attributed to the fact that EqualChance alters the cache replacement policy and periodically shifts some blocks from the more recent position to the less recent position in the LRU stack. Since a large fraction of blocks in mcf etc. are used only once (i.e. deadon-arrival) <ref type="bibr" target="#b27">[28]</ref>, demoting them in LRU stack enables their faster eviction, which also improves the hit-rate.</p><p>Results on Shifting Operations: <ref type="table" target="#tab_4">Table 3</ref> shows the number of I and C-shifting operations on using EqualChance. On average, 199K I-shifting and 96K C-shifting operations take place. The number of these operations depends on the interaction of several factors such as cache-usage intensity, write-intensity and writevariation present in cache access behavior of a workload. The higher the write-intensity, the more frequently EqualChance algorithm is executed, but if most blocks store dirty data-item, then a candidate for shifting may not be found. Also, the higher the cache-usage intensity, the more will be the number of valid blocks in the cache and hence, the more will be the number of C-shifting operations. Similarly, if the write-variation is high, most writes are directed to only few blocks and the remaining blocks remain invalid or store clean data-item and hence, candidates for I or C-shifting can be easily found.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Parameter Sensitivity Results</head><p>We now study the sensitivity of EqualChance for different parameters. Except the parameter mentioned, all other parameters have default values as shown in Section 5. The energy/latency value for other cache configurations were computed as shown in Section 5 and are omitted for brevity. The results are summarized in <ref type="table" target="#tab_5">Table  4</ref>.</p><p>Changing Shifting Interval (ϒ): Shifting interval decides the number of writes to a cache-set after which an I-or C-shifting is performed. On increasing the shifting interval, EqualChance algorithm is executed less frequently, which is reflected in the reduction in number of I-and C-shifting operations. Thus, increasing ϒ reduces the loss in performance and energy, although it also reduces the enhancement in lifetime, since the wearleveling is performed less frequently. Note that even with ϒ = 15, the improvement in lifetime is significant. Thus, the value of ϒ can be chosen to exercise a trade-off between desired lifetime enhancement and acceptable loss in performance and energy. Also notice that on increasing ϒ from 5 (default) to 10, the total number of shifting operations are reduced by nearly half, which is expected.</p><p>Higher Shifting Overhead: To evaluate the effect of shifting overhead, we assume 3 and 9 cycles extra latency overhead of each I-shifting and C-shifting operation (respectively) over and above that mentioned in Section 4 and 0.5nJ additional energy overhead of Cshifting. The results in <ref type="table" target="#tab_5">Table 4</ref> show that the energy efficiency and performance are minimally affected and hence, EqualChance is not very sensitive to the shifting overhead. This can be easily understood by noting that shifting happens relatively infrequently and a small increase in LLC latency is easily hidden by the instructionlevel parallelism.</p><p>Changing Associativity (M): For a fixed cache capacity, reducing the associativity increases the inter-set write variation but reduces the intra-set write variation which is confirmed from the InterV and the IntraV values for baseline caches of different associativity values in <ref type="table" target="#tab_5">Table 4</ref>. This can be easily understood by considering the two extreme cases, viz. a fully-associative cache and a direct-mapped cache. A fully-associative cache has only one set and hence, its InterV will be zero and similarly, a direct-mapped cache has only a single way and hence its IntraV will be zero. From the table, we conclude that EqualChance works well for caches of all associativity values and provides lifetime improvement in proportion to the amount of write-variation present in the original workload. Specifically, it provides large improvement for the 32-way set associative caches. Comparing with the default case, the total number of shifting operations remain nearly the same, which is expected. Further, for large associativity, invalid blocks in a set can be more easily found and since I-shifting is preferred over C-shifting, the number of I-shifting operations increase with increasing associativity and vice versa.</p><p>Changing Cache size: We experiment with both double-sized and half-sized caches. The results in <ref type="table" target="#tab_5">Ta- ble 4</ref> show that on increasing the cache size, the average improvement in lifetime is also increased and viceversa. This can be explained by noting that since applications have a fixed working set size (i.e. unique number of cache lines accessed in a period of time), on increasing the cache size, the hit-rate is also increased. Hence, only few blocks are repeatedly accessed which increases the intra-set write variation and hence, the scope for improving the cache lifetime is also increased. Opposite is seen on decreasing the cache size. From the results, it is clear that for both the cache sizes, EqualChance provides significant reduction in the intra-set write variation and improvement in cache lifetime. For large cache size, larger number of invalid blocks can be found and hence, the number of I-shifting operations are also higher in the 8MB cache and opposite is seen in 2MB cache.</p><p>For all parameters, the relative performance is equal to or greater than 0.99× and the loss in energy is less than 3.30%. This confirms that EqualChance works well for a wide-range of system and algorithm parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>The limited write endurance of NVMs is a key bottleneck preventing their use in designing on-chip caches. In this paper, we presented EqualChance, a technique for mitigating intra-set write variation to improve lifetime of NVM caches. Experimental results have shown that EqualChance is effective in increasing the cache lifetime for NVM caches and works well for a wide range of parameters. Our future efforts will focus on synergistically integrating EqualChance with techniques for write minimization and inter-set write variation mitigation to improve the cache lifetime even further. We also plan to compare our technique with other techniques for addressing intra-set write-variation (e.g. <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6]</ref>) to fully evaluate and highlight the effectiveness of our technique. Finally, we are currently evaluating our technique with multicore system configurations to study how it scales with increasing number of cores.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Illustration of working of EqualChance algorithm. Updated items are highlighted as: item.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Results with EqualChance technique</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 shows</head><label>2</label><figDesc>Figure 2 shows the experimental results. We now analyze the results. Results on InterV and IntraV: Firstly, from Figure 2(a) and 2(b), we note that for a 16-way 4MB cache, average IntraV is larger than InterV. Note that for a fixed cache capacity, on increasing the associativity, InterV reduces and IntraV increases and vice versa (refer Table</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>14 Write Data[i][q] to Data[i][z] and mark clean 15 Write new data to Data[i][q] and mark dirty 16 else 17 isNormalWrite ← TRUE 18 end 19 end 20 Turn FlagBit[i] OFF 21 else 22 isNormalWrite ← TRUE 23 end 24 if isNormalWrite then 25 Write new data to Data[i][z], mark dirty and update LRU-age information 26 end</head><label>14</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="true"><head>Table 1 : Parameters for 16-way ReRAM L2 cache</head><label>1</label><figDesc></figDesc><table>2MB 4MB 8MB 
Hit Latency (ns) 5.06 5.12 5.90 
Miss Latency (ns) 1.73 1.65 1.68 
Write Latency (ns) 22.11 22.18 22.67 
Hit energy (nJ) 0.542 0.537 0.602 
Miss energy (nJ) 0.232 0.187 0.188 
Write energy (nJ) 0.876 0.827 0.882 
Leakage Power (W) 0.019 0.037 0.083 

shown in Table 2. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true"><head>Table 2 : Workloads used in the paper</head><label>2</label><figDesc></figDesc><table>As(astar), Bw(bwaves), Bz(bzip2), Cd(cactusADM) 
Ca(calculix), Dl(dealII), Ga(gamess), Gc(gcc) 
Gm(gemsFDTD), Gk(gobmk), Gr(gromacs) 
H2(h264ref), Hm(hmmer), Lb(lbm), Ls(leslie3d) 
Lq(libquantum), Mc(mcf), Mi(milc), Nd(namd) 
Om(omnetpp), Pe(perlbench), Po(povray), Sj(sjeng) 
So(soplex), Sp(sphinx), To(tonto), Wr(wrf) 
Xa(xalancbmk), Ze(zeusmp), Am(</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>0% 50% 100% 150% 200% 250% 300% 350% 400% 450% As Bw Bz Cd Ca Dl Ga Gc Gm Gk Gr H2 Hm Lb Ls Lq Mc Mi Nd Om Pe Po Sj So Sp To Wr Xa Ze Am Co Lu Mk Ne Avg</head><label></label><figDesc></figDesc><table>(a) InterV (Less is better) 
826.1 
485.9 
Baseline 

0% 

50% 

100% 

150% 

200% 

250% 

300% 

350% 

400% 

450% 

As Bw Bz Cd Ca Dl Ga Gc Gm Gk Gr H2 Hm Lb Ls Lq Mc Mi Nd Om Pe Po Sj So Sp To Wr Xa Ze Am Co Lu Mk Ne Avg 

(b) IntraV (Less is better) 
Baseline 
EqualChance 

1 

3 

5 

7 

9 

11 

13 

15 

17 

As Bw Bz Cd Ca Dl Ga Gc Gm Gk Gr H2 Hm Lb Ls Lq Mc Mi Nd Om Pe Po Sj So Sp To Wr Xa Ze Am Co Lu Mk Ne Avg 

(c) Relative Lifetime (More is better) 
EqualChance 

0.9 

0.92 

0.94 

0.96 

0.98 

1 

1.02 

As Bw Bz Cd Ca Dl Ga Gc Gm Gk Gr H2 Hm Lb Ls Lq Mc Mi Nd Om Pe Po Sj So Sp To Wr Xa Ze Am Co Lu Mk Ne Avg 

(d) Relative Performance (More is better) 
EqualChance 

-5 

0 

5 

10 

15 

20 

As Bw Bz Cd Ca Dl Ga Gc Gm Gk Gr H2 Hm Lb Ls Lq Mc Mi Nd Om Pe Po Sj So Sp To Wr Xa Ze Am Co Lu Mk Ne Avg 

(e) Percentage Loss in Energy (Less is better, negative value implies saving) 
EqualChance 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="true"><head>Table 3 : Number of I-and C-shifting operations</head><label>3</label><figDesc></figDesc><table>I-shifting C-shifting 
I-shifting C-shifting 
As 
120K 
143K 
Mi 
298K 
50K 
Bw 
1K 
61K 
Nd 
76K 
0 
Bz 
271K 
0 
Om 
4K 
2K 
Cd 
344 
86K 
Pe 
11K 
571 
Ca 
261K 
0 
Po 
107K 
0 
Dl 
63K 
0 
Sj 
45K 
0 
Ga 
133K 
0 
So 
737K 
577K 
Gc 
97K 
35K 
Sp 
361 
58K 
Gm 
217K 
517K 
To 
120K 
0 
Gk 
131K 
0 
Wr 
33K 
0 
Gr 
156K 
6K 
Xa 
34K 
66K 
H2 
47K 
0 
Ze 
625K 
0 
Hm 
176K 
0 
Am 
82K 
0 
Lb 
2580K 
1K 
Co 
71K 
33 
Ls 
51K 
595K 
Lu 
134K 
239K 
Lq 
0 
201K 
Mk 
21K 
251K 
Mc 
38K 
361K 
Ne 
8K 
0 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="true"><head>Table 4 : Parameter Sensitivity Results for EqualChance. Default values: ϒ = 5, overhead values shown in Section 4, 16-way, 4MB L2 cache (Perf. = performance).</head><label>4</label><figDesc></figDesc><table>% InterV 
% IntraV 
Relative Relative % Loss in I-shifting C-shifting 
Baseline Baseline EqualChance Lifetime 
Perf. 
Energy operations operations 
Default 
111.1 
141.8 
33.8 
4.29 
1.00 
1.97 
199K 
96K 
ϒ=10 
111.1 
141.8 
41.5 
3.79 
1.00 
1.11 
78K 
69K 
ϒ=15 
111.1 
141.8 
44.9 
3.60 
1.00 
0.75 
48K 
48K 
Higher overhead 
111.1 
141.8 
33.8 
4.29 
0.99 
2.01 
199K 
96K 
8-way L2 
154.2 
111.7 
28.8 
3.09 
0.99 
1.55 
148K 
144K 
32-way L2 
74.0 
171.6 
36.3 
5.02 
1.00 
3.29 
251K 
44K 
2MB L2 
71.9 
108.6 
25.9 
3.38 
0.99 
2.96 
157K 
139K 
8MB L2 
152.3 
181.5 
45.1 
6.20 
0.99 
2.74 
239K 
53K 

</table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgment</head><p>Support for this work was provided by U.S. Department of Energy, Office of Science, Advanced Scientific Computing Research. The work was performed at the Oak Ridge National Laboratory, which is managed by UT-Battelle, LLC under Contract No. DE-AC05-00OR22725 to the U.S. Government. Accordingly, the U.S. Government retains a non-exclusive, royalty-free license to publish or reproduce the published form of this contribution, or allow others to do so, for U.S. Government purposes. This research is sponsored by the Office of Advanced Scientific Computing Research in the U.S. Department of Energy.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Ivytown: A 22nm 15-core enterprise Xeon R ⃝ processor family</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Muljono</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ayers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Varada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Solid-State Circuits Conference Digest of Technical Papers</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="102" to="103" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">MASTER: A Multicore Cache Energy Saving Technique using Dynamic Cache Reconfiguration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mittal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on VLSI Systems</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="1653" to="1665" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Hybrid cache architecture with disparate memory technologies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Speight</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Rajamony</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGARCH Computer Architecture News</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="34" to="45" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Cache revive: architecting volatile STT-RAM caches for enhanced performance in CMPs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Jog</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Narayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Iyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename><surname>Das</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">49th Annual Design Automation Conference</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="243" to="252" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">i2WAP: Improving non-volatile cache lifetime by reducing inter-and intra-set write variations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">P</forename><surname>Jouppi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on High-Performance Computer Architecture (HPCA)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="234" to="245" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A Survey Of Architectural Approaches for Managing Embedded DRAM and Non-volatile On-chip Caches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mittal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Vetter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Parallel and Distributed Systems (TPDS)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Phase change memory: From devices to systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">K</forename><surname>Qureshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gurumurthi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Rajendran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Synthesis Lectures on Computer Architecture</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1" to="134" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A 4Mb embedded SLC Resistive-RAM macro with 7.2ns read-write random-access time and 160ns MLC-access capability</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-S</forename><surname>Sheu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-F</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-F</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-W</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-F</forename><surname>Chiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-C</forename><surname>Kuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-S</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-C</forename><surname>Chiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-P</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Solid-State Circuits Conference Digest of Technical Papers</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="200" to="202" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A software approach for combating asymmetries of non-volatile memories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on Low Power Electronics and Design</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="191" to="196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">NVsim: A circuit-level performance, energy, and area model for emerging nonvolatile memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">P</forename><surname>Jouppi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="994" to="1007" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Bi-layered RRAM with unlimited endurance and extremely uniform switching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-B</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Hur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G.-S</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U.-I</forename><surname>Chung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Symposium on VLSI Technology (VLSIT)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="52" to="53" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Spin-transfer torque MRAM (STT-MRAM): Challenges and prospects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Huai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AAPPS Bulletin</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="33" to="40" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Characterizing and mitigating the impact of process variations on phase change based memory systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on Microarchitecture</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="2" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Way adaptable D-NUCA caches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bardine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Comparetti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Foglia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gabrielli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Prete</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of High Performance Systems Architecture</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="215" to="228" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">FlexiWay: A Cache Energy Saving Technique Using Finegrained Cache Reconfiguration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mittal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Vetter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">31st IEEE International Conference on Computer Design (ICCD)</title>
		<meeting><address><addrLine>Asheville, NC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Architecting on-chip interconnects for stacked 3D STT-RAM caches in CMPs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Vijaykrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename><surname>Das</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGARCH Computer Architecture News</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="69" to="80" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Energy reduction for STT-RAM using early write termination</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/ACM International Conference o Computer-Aided Design-Digest of Technical Papers (ICCAD</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="264" to="268" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Energy-and endurance-aware design of phase change memory caches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Joo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Design, Automation and Test in Europe. European Design and Automation Association</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="136" to="141" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A novel architecture of the 3D stacked MRAM L2 cache for CMPs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 15th International Symposium on High Performance Computer Architecture (HPCA</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="239" to="249" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Lower-bits cache for low power STT-RAM caches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Symposium on Circuits and Systems (ISCAS)</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="480" to="483" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Using cache-coloring to mitigate interset write variation in non-volatile caches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Iowa State University, Tech. Rep</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">On-chip caches built on multilevel spin-transfer torque RAM cells and its optimizations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-F</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-K</forename><surname>Koh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Emerg. Technol. Comput. Syst</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">22</biblScope>
			<date type="published" when="2013-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Exploiting set-level write non-uniformity for energyefficient NVM-based hybrid cache</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">9th IEEE Symposium on Embedded Systems for Real-Time Multimedia (ESTIMedia)</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="19" to="28" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Enhancing lifetime and security of pcm-based main memory with start-gap wear leveling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">K</forename><surname>Qureshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Karidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Franceschini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lastras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Abali</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on Microarchitecture</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="14" to="23" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Sniper: Exploring the level of abstraction for scalable and accurate parallel multi-core simulations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">E</forename><surname>Carlson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Heirman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Eeckhout</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference for High Performance Computing, Networking, Storage and Analysis (SC)</title>
		<imprint>
			<date type="published" when="2011-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Exploiting program hotspots and code sequentiality for instruction cache leakage management</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Nadgir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Vijaykrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Irwin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kandemir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on LowPower Electronics and Design</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="402" to="407" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Thermal management of on-chip caches through power density minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Ku</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ozdemir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Memik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ismail</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on Microarchitecture (MICRO)</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="283" to="293" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Pseudo-LIFO: the foundation of a new family of replacement policies for last-level caches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chaudhuri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on Microarchitecture (MICRO)</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="401" to="412" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
