<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2020-09-29T04:05+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">&quot;I am uncomfortable sharing what I can&apos;t see&quot;: Privacy Concerns of the Visually Impaired with Camera Based Assistive Applications &quot;I am uncomfortable sharing what I can&apos;t see&quot;: Privacy Concerns of the Visually Impaired with Camera Based Assistive Applications</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>August 12-14, 2020</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taslima</forename><surname>Akter</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bloomington</forename><forename type="middle">;</forename></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Semaan</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taslima</forename><surname>Akter</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Dosono</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tousif</forename><surname>Ahmed</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Apu</forename><surname>Kapadia</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Semaan</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="laboratory">Tousif Ahmed and Apu Kapadia</orgName>
								<orgName type="institution" key="instit1">Indiana University Bloomington</orgName>
								<orgName type="institution" key="instit2">Bryan Dosono</orgName>
								<orgName type="institution" key="instit3">Syracuse University</orgName>
								<orgName type="institution" key="instit4">Indiana University</orgName>
								<orgName type="institution" key="instit5">Syracuse University</orgName>
								<orgName type="institution" key="instit6">Indiana University</orgName>
								<address>
									<addrLine>Bloomington</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">Syracuse University</orgName>
								<orgName type="institution" key="instit2">Indiana University</orgName>
								<address>
									<addrLine>Bloomington</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">Indiana University</orgName>
								<address>
									<addrLine>Bloomington</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">Syracuse University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">&quot;I am uncomfortable sharing what I can&apos;t see&quot;: Privacy Concerns of the Visually Impaired with Camera Based Assistive Applications &quot;I am uncomfortable sharing what I can&apos;t see&quot;: Privacy Concerns of the Visually Impaired with Camera Based Assistive Applications</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 29th USENIX Security Symposium</title>
						<meeting>the 29th USENIX Security Symposium						</meeting>
						<imprint>
							<date type="published">August 12-14, 2020</date>
						</imprint>
					</monogr>
					<note>This paper is included in the Open access to the Proceedings of the 29th USENIX Security Symposium is sponsored by USENIX.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>The emergence of camera-based assistive technologies has empowered people with visual impairments (VIP) to obtain independence in their daily lives. Popular services feature volunteers who answer questions about photos or videos (e.g., to identify a medical prescription). However, people with VIPs can (inadvertently) reveal sensitive information to these volunteers. To better understand the privacy concerns regarding the disclosure of background objects to different types of human assistants (friends, family, and others), we conducted an online survey with 155 visually impaired participants. In general, our participants had varying concerns depending on the type of assistants and the kind of information. We found that our participants were more concerned about the privacy of bystanders than their own when capturing people in images. We also found that participants were concerned about self-presentation and were more comfortable sharing embarrassing information with family than with their friends. Our findings suggest directions for future work in the development of human-assisted question-answering systems. Specifically, we discuss how humanizing these systems can give people a greater sense of personal security.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Sighted people can often take for granted the ease with which they can engage in routine activities, such as driving to the grocery store, paying bills, taking medications, using mobile devices and computers, and more. For people with impairments, these activities can be a challenge. In this paper, we focus on people with visual impairments (VIPs), i.e., people who live with impairments ranging from complete blindness to an inability to read a book when wearing corrective lenses <ref type="bibr" target="#b60">[60]</ref>. Today, it is estimated that four percent of the global population lives with visual impairments (about 285 million people) <ref type="bibr" target="#b74">[73]</ref>, and depending on the severity of their visual impairments, engaging in routine and mundane activities may require the assistance of others. For example, people with VIPs often rely on friends and family to help them accomplish daily practices, such as traveling to the market and paying bills, such that they can maintain the practices of daily life <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b37">38]</ref>.</p><p>However, there may be cases where people with VIPs do not have access to people who provide this kind of support, or they may have intermittent access to people who can assist them. As a means of addressing this issue, technological advances are leading to the rapid development of assistive technologies for people with visual impairments. With the rise of mobile cameras and advances in computer vision, 'visually aware' assistive applications are now becoming a reality for people with visual impairments. These camera-based assistive technologies simplify a wide range of everyday tasks such as navigating social spaces, 1 identifying objects or color, 2 recognizing familiar faces or facial expressions, <ref type="bibr" target="#b2">3</ref> and reading documents. <ref type="bibr" target="#b3">4</ref> In contrast to automated systems, which use computer vision and machine learning, <ref type="bibr" target="#b2">3</ref> human-powered systems leverage human assistants (volunteers, professional agents, or friends and family members) to answer questions about photos (or live video) taken by people with VIPs <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b15">16]</ref>. <ref type="bibr" target="#b4">5</ref> Since automated systems are not yet reliable <ref type="bibr" target="#b8">[9]</ref> -e.g., the user may want to know the number of calories in a can of food, but the system might simply identify the food as a "tuna can," or the system may not be able to assess whether a pair of shoes matches one's clothing -people with VIPs still find human-assisted systems more accurate and trustworthy <ref type="bibr" target="#b8">[9]</ref>. Indeed, more than 100,000 users with VIPs are currently using human-powered assistive systems such as 'Be My Eyes' <ref type="bibr" target="#b1">[2]</ref> and 'Aira' <ref type="bibr" target="#b0">[1]</ref>.</p><p>Despite their advantages, human-powered, camera-based assistive applications can pose serious privacy risks. For example, people with VIPs may inadvertently share sensitive information with a human assistant both intentionally (e.g., asking to read a credit card number) or unintentionally (e.g., a credit card may be present in the background). Such sharing can sometimes have serious consequences, e.g., sharing a credit card may lead to identity theft. Although these risks have been acknowledged in prior work <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b33">34]</ref>, they have focused mostly on identifying the kinds of sensitive content shared with volunteers. The privacy concerns of people with VIPs in the context of revealing sensitive information with different kinds of human agents, which can vary with context, is not yet well understood. A deeper understanding of these concerns can provide insight into how AI and human assistance can be leveraged to provide both trustworthy and privacy aware visual assistance to people with VIPs.</p><p>In this paper, we report on the privacy concerns of people with VIPs when using human-powered, camera-based assistive systems. We considered the privacy risks of objects both in the foreground (the objects people ask questions about) and background (other objects present in the image not directly associated with the question), and explored privacy concerns when sharing photos or video with three types of human assistants: friends, family members, and crowdworkers (professional agents, mechanical turk workers, and volunteers). We also explored the concerns of people with visual impairments in three common contexts: in the office, in a restaurant, and at home. Specifically, we focus on the following research questions:</p><p>R1: What are the privacy concerns of people with visual impairments in the context of background objects that are inadvertently captured and included in photos sent to human assistants?</p><p>R2: While using such technologies, how do their privacy concerns vary for different classes of background objects and the type of human assistants (friends, family, volunteers or crowd-workers)?</p><p>To answer these research questions, we conducted an online survey with 155 visually impaired participants examining three everyday scenarios in the context of three different types of human assistants. Participants were assigned to a between-subjects survey instrument based on the type of assistant (friend, family member, and crowd-worker). The scenarios were studied within subjects (home, office, and restaurant). We conduct a quantitative analysis of their privacy preferences as well as a qualitative analysis of the reasons participants provided for their preferences.</p><p>Our participants reported significant privacy and security concerns for information captured in the background. Their information-disclosing behaviors depended on the nature of the background objects present in the image as well as the types of human assistants. For example, participants were more concerned about maintaining a good impression with their friends compared to family. Participants, however, also reported being more concerned about sharing personally identifiable information with crowd workers compared to their friends or family members. Interestingly, participants were also more concerned about the privacy of other people compared to their own. Our findings have important implications for the design of camera based assistive devices. Despite their potential for 'good', such technologies can also violate the security and privacy of the very people being assisted. We discuss how such systems need to be 'humanized' so as to assist, and not harm, their users.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>In this section, we present related work on camera-based assistive solutions and their privacy issues.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Camera-based assistive applications</head><p>We focus on two primary design paradigms for camerabased assistive technologies: automated assistive systems and human-powered assistive systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1">Automated assistive systems</head><p>Various kinds of camera-based assistive technologies have been developed to assist people with VIPs in their daily tasks. Such technologies include object identifiers 6 <ref type="bibr" target="#b44">[45]</ref> and barcode readers, <ref type="bibr" target="#b6">7</ref> [52] text readers, 4 color readers, 2 money readers, <ref type="bibr" target="#b7">8</ref> and crowd-sourced visual question-answering systems <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref> for multiple purposes such as identifying objects, reading prescriptions, and answering subjective questions. Camerabased assistive solutions also assist people with VIPs in their social interactions by recognizing faces and facial attributes of people in the vicinity <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b49">50]</ref>. Since the hands-free nature of wearable cameras offers improved accessibility <ref type="bibr" target="#b76">[75]</ref>, researchers have also developed various camera-assisted prototypes <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b51">51,</ref><ref type="bibr" target="#b62">62]</ref> for people with VIPs on wearable and augmented reality devices. Although people with VIPs are quickly adopting automated systems, most applications work best with high-quality photos and ample lighting, rightly angled compositions, and fully captured subjects <ref type="bibr" target="#b44">[45]</ref>. Capturing such photos, however, is particularly challenging for people with VIPs. Therefore, several camera-based applications have been proposed to assist people with VIPs in taking photos. To capture a high-quality picture, these applications automatically guide users to improve the focus, lighting, or composition <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b73">72]</ref>.</p><p>Unfortunately, automated systems have their limitations; systems sometimes provide inaccurate answers and may lack detailed descriptions when expected <ref type="bibr" target="#b8">[9]</ref>. For example, the user may want to know the temperature on a thermostat whereas the automated application may just respond "thermostat." Because of the limited capabilities of automatic systems, users find communicating with a human more reliable <ref type="bibr" target="#b11">[12]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2">Human-powered visual question answering systems</head><p>To address issues with automated assistive technologies, crowd based systems are becoming more popular among people with VIPs. Visual Question Answering (VQA) seeks to automatically answer visual questions from a given image and the user's question using computer vision and natural language processing <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b31">32]</ref>. Currently, most models are trained on images taken by sighted people that are not representative of those taken in assistive systems for people with VIPs. Hence, no such VQA systems have been developed yet to assist people with VIPs. As an alternative, people with VIPs get nearly real-time visual assistance with their visual questions with the help of a human assistant <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b15">16]</ref>. Such applications allow visually impaired users to send pictures or make video calls for getting answers to their visual questions from a sighted crowd-worker or volunteer. Currently, among the two popular human-sourced services, Be My Eyes <ref type="bibr" target="#b1">[2]</ref> connects blind persons with untrained volunteers through a free service. In contrast, Aira <ref type="bibr" target="#b0">[1]</ref> connects visually impaired users with paid, trained professional agents. To provide greater support to visually impaired users, VizWiz Social <ref type="bibr" target="#b19">[20]</ref> expands the initial VizWiz application by including friend-sourced answers (using Twitter, Facebook, or email from their known contacts) along with crowd-sourced answers (Mechanical Turk, IQ Engines). Friendsourcing removes the financial cost of the crowd-sourced service and helps to improve the quality and trustworthiness of the answers received <ref type="bibr" target="#b59">[59]</ref>. Friends and family may be able to answer questions better because they know the question asker. However, 'friendsourcing' has a social cost as the users might feel they appear less independent or may want to avoid feeling like a burden on their friends and family. To address this problem, Brady et al. <ref type="bibr" target="#b17">[18]</ref> introduce the idea of social microvolunteering, a type of intermediate friendsourcing in which a volunteer who participates ask his networks of friends to answer a visual question on behalf of a visually impaired person. It also provides faster responses than friendsourcing. In our work, we consider three different types of human assistants (friends, family members, and volunteers or crowd-workers) and focus on better understanding the preferences of people with VIPs while seeking help from various types of human assistants.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Privacy concerns</head><p>We now discuss related work on privacy in the context of assistive technologies in general, camera based assistive technologies, and human assistant based assistive technologies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Privacy concerns with assistive technologies</head><p>As people with VIPs continue to leverage assistive technologies in their routine lives, this leads to the question of what privacy issues emerge and how we, as designers, can best design for the privacy of this particularly vulnerable population. Several studies report that people with VIPs have concerns about aural and visual eavesdropping when using screen readers and screen magnifiers <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b45">46]</ref>. They often use headphones and screen occlusion software to protect themselves from other people eavesdropping on their devices <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b12">13]</ref>. Prior work also discussed how simply possessing assistive devices may invite privacy-invading questions (e.g., "how did you lose your sight?") or unwanted attention <ref type="bibr" target="#b69">[68]</ref>. Ahmed et al. explored the privacy and security concerns of people with VIPs that are not solved by current technology and suggested new directions for improving camera-based assistive systems <ref type="bibr" target="#b5">[6]</ref>. Other works also investigated the physical safety concerns of individuals with VIPs <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b20">21]</ref>. Researchers also focused on the privacy challenges people with VIPs face while using digital finance technologies such as ATMs <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b70">69]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Privacy issues with cameras</head><p>More specific to video based assistive technology, camerabased assistive devices can collect rich visual information and create additional privacy risks for both the device user and bystanders. Such risks might have a much higher impact on visually impaired people because they cannot review the content of photos before sharing <ref type="bibr" target="#b5">[6]</ref> or they might be less aware of when such situations might occur <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b20">21]</ref>. Malicious parties can use malware to record photos or video of private spaces and blackmail the device owner <ref type="bibr" target="#b72">[71]</ref>. Computer vision-based technologies for assistive purposes may also impose serious privacy risks for the bystanders while recognizing faces for people with VIPs. Face recognition may lead to identity theft <ref type="bibr" target="#b3">[4]</ref> and issues of bias related to race <ref type="bibr" target="#b25">[26]</ref> and age <ref type="bibr" target="#b9">[10]</ref>. Ahmed et al. investigated the concerns of bystanders while information about them is shared through camera-based assistive technologies to a visually impaired person <ref type="bibr" target="#b6">[7]</ref>. We address the concerns people with VIPs have while sharing information about themselves and bystanders through camera-based assistive technologies. We are also interested in learning how concerned people with VIPs are about the privacy of others (i.e., the bystanders).</p><p>Privacy issues with human-assisted solutions. In real time crowd-sourced assistive systems, users are limited in the amount of time to review the content they are sharing and might capture and share sensitive information mistakenly <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b53">53]</ref>. Such incidents potentially put the user at risk of identity theft, blackmail, and other information-based attacks. <ref type="bibr">Lasecki et al.</ref> have demonstrated the risks of trusting crowd workers with sensitive information <ref type="bibr" target="#b54">[54]</ref>. They showed that workers can be engaged in potentially malicious tasks for personal gain, such as copying a credit card number from another task. Branham et al. described an incident when a visually impaired user was threatened by the volunteer who asked for her location <ref type="bibr" target="#b20">[21]</ref>. Several works reported situations when a visually impaired user inadvertently shared images containing private information with a crowd-worker, sometimes without understanding either the risk or that sensitive information is being captured <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b33">34]</ref>.</p><p>Our work addresses the latter risk when the visually impaired person unintentionally captures sensitive information and shares it with a human assistant. The images must contain the foreground objects for the human assistant to answer the question and are deliberately chosen while understanding some of the privacy risks. However, background objects (or people) can pose a much greater privacy risk since they were not intended to be shared with the volunteer. Moreover, our work provides insight into what should be shared (or not) as background objects depending on the human-sourced assistive technologies with the goal of better understanding their privacy concerns and, therefore, providing design recommendations to develop assistive devices for avoiding inadvertent sharing of private visual information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Method</head><p>We now describe our survey and data analysis procedures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Survey study</head><p>To answer our research questions, we conducted an online survey on the privacy and security concerns of people with VIPs who share images using camera-based assistive technologies. In the survey, we considered three different human-sourced assistive technologies by varying the type of human assistant (a family member, a friend, and a volunteer or crowd-worker) and conducted a between-subjects survey through random assignment based on these three types of assistants. Each of these surveys had three within-subjects (randomly ordered) scenarios (home, office, and restaurant) with each having questions about possible foreground and background objects in the image. Participants took approximately 20-30 minutes to complete the survey.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Selection of scenarios</head><p>Our surveys captured peoples' concerns related to sharing information across three different scenarios: in home (located within a residential space), office (located at the place of employment), and restaurant (located at a dining establishment) settings. These scenarios were grounded in prior studies. Church and Oliver found that more than 70 percent of mobile information seeking was performed in familiar contexts such as at home or the office <ref type="bibr" target="#b26">[27]</ref>. <ref type="bibr">Abdolrahmani et al.</ref> reported the use of mobile devices and assistive applications by people with VIPs in restaurants, home, and office scenarios <ref type="bibr" target="#b2">[3]</ref>. These scenarios are representative of real-life engagements for people with VIPs in private, semi-private, and public places respectively. Each participant was presented all three scenarios (within-subjects) in random order.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Foreground and background object selection</head><p>In the survey, we referred to the objects that users ask the question about as "foreground" objects (primary objects) and the objects which are present in the photo but not primary objects as "background" objects. To determine the list of foreground and background objects included in the survey, we first explored the VizWiz dataset <ref type="bibr" target="#b33">[34]</ref>. This dataset is derived from a natural visual question answering system where visually impaired users took images and recorded spoken questions and sent them to crowd workers. Since most camera-assisted technologies follow a similar approach, the publicly available VizWiz dataset illustrated common privacy issues that may arise while using such a service.</p><p>The dataset comprises 20,000 publicly available images and the associated questions (as text) about the images. This dataset was cleaned and released by the authors so as to remove any images with sensitive information. To reduce bias in our selection of objects, we contacted the authors and obtained these sensitive images (200). These images had the sensitive portions redacted but contained enough information about the type of object (e.g., faces were blurred). We randomly selected 1,000 images from the publicly available images along with the 200 sensitive images. Two researchers individually categorized the images into groups. They then met and came to consensus on a representative set of groups. After analyzing the dataset, we observed five major privacy violations as foreground objects or background objects in the images: address information (e.g., on envelopes), prescription labels, credit card information, contents of digital screens (e.g., computer screen), and the presence of the face or other body parts of the user (as well as of bystanders). Our selected foreground and background objects are thus representative of the objects and questions asked by people with VIPs as also observed in prior studies <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b32">33]</ref>.</p><p>In each scenario, we assumed only one foreground object in the image, since that is the typical use case when asking questions in such systems. We included objects that are the combination of sensitive, personally identifiable, financial, and miscellaneous objects that people asked questions about in the VizWiz application. Later, we listed 10 background objects that could possibly be present in the image along with the foreground object in that given scenario. The selection of the background objects for each scenario varied slightly; six objects were common to all scenarios whereas the rest were specific to the scenario description. For example, we added 'restaurant bill' for the restaurant scenario but did not include that in the other two scenarios. <ref type="table">Table 1</ref> describes background and foreground objects used in the three scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.3">Measuring privacy concern</head><p>We asked the following three questions (paraphrased) for each scenario (see Appendix A for our survey instrument):</p><p>Q1. How comfortable would you feel asking for help (about a foreground object) from a sighted assistant by sharing an image? This question varied slightly based on the scenario. Participants were asked to select from a 5-point Likert scale: (1) extremely uncomfortable (2) somewhat uncomfortable <ref type="formula">(3)</ref> neither uncomfortable nor comfortable (4) somewhat comfortable (5) extremely comfortable.</p><p>Q2. How comfortable would you feel if the following background objects were present in the image? This question varied slightly based on the foreground object and the scenario. The question used the same Likert scale mentioned above.</p><p>Q3. Please briefly explain your selection above. This was an open-form question. Participants were asked to explain their selections for feeling comfortable or uncomfortable while sharing photos or videos with a human assistant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.4">Organization of the survey</head><p>The survey consisted of 32 questions in both open-ended and close-ended form. The survey instrument was organized as follows (see Appendix A for the survey instrument):</p><p>• Consent form.</p><p>• Questions about which (if any) electronic devices and assistive technologies the participant uses, how frequently they use the camera and share images online, and questions on their level and duration of visual impairments.</p><p>• Questions about the kind of help they seek from sighted people, whether they shared images or made video calls to a sighted person for seeking help, and what questions they usually ask.</p><p>• Three scenarios, presented in random order (within subjects), each with three questions about the foreground object, background objects (in random order), and an explanation for their selections. Note that each participant was assigned to a single assistive technology (type of human assistant), and these questions were asked in the context of one kind of human assistant.</p><p>• Questions about whether they had ever shared a photo containing sensitive information and their most recent experience sharing an image with a sighted person.</p><p>• Five demographic questions (age, gender, race or nationality, education, and occupation).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.5">Recruitment</head><p>The survey was conducted on Qualtrics (an accessible survey platform) over a period of one month between August and September 2018. We shared our recruitment sign-up form through email lists of various organizations including the National Federation of the Blind (NFB) and the American Council of the Blind (ACB). We asked visually impaired assistive technology users to sign-up through a form provided if they met the following criteria: participants had to be (1) living in the United States for at least five years to help control for cultural variability <ref type="bibr" target="#b47">[48]</ref>; <ref type="formula">(2)</ref> 18 years of age or older; and (3) visually impaired. Researchers screened the qualified participants and personally emailed each participant a unique survey link. The link was not reusable, and each participant could participate in the survey only once.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.6">Sample validity considerations</head><p>The survey was shared only with a curated list of VIPs managed by reputable organizations. NFB and ACB reviewed our study information for relevance and then forwarded our recruitment email to their mailing lists. Based on organization membership and list curation our recruitment email went to only those people who had VIPs. Next, one researcher interacted with each individual participant and inquired about their level of visual impairment and blindness. Additionally, we recruited (or retained the data of) only those participants who sufficiently described their level of VIPs in their free-text responses in our survey and sign-up instruments. Finally, our compensation structure (see Section 3.1.7) was chosen in part to provide high-quality responses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.7">Compensation and ethical considerations</head><p>We recruited the participants from different organizations and could not anticipate the number of participants before initiating the survey. Therefore, we picked a random-drawing approach as opposed to a straight payment, and the participants were told upfront about the compensation in the recruitment email as well as the consent form. A raffle-based approach is also less likely to invite abuse and instead stimulate voluntary participation and high-quality answers <ref type="bibr" target="#b16">[17]</ref>. After collecting 155 responses, we performed the random drawing, selected 15 (10%) participants, and sent $20 Amazon e-gift certificates to each of them. We emailed them the link of the e-gift certificates within three days of performing the random drawing. The study and compensation scheme was approved by our institution's ethics review board (IRB).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.8">Pilot study</head><p>We conducted an in-person online survey and a follow-up interview with four male individuals to identify any accessibility issues with our survey instrument. Three of the pilot Three participants participated in the survey using computers and one from a mobile phone. They used Jaws and Google's TalkBack as screen readers. We requested them to point out any accessibility issues they faced while participating in the survey. We also requested that they suggest improvements to our survey. The pilot study took around 40-60 minutes for each participant. Participants were compensated with $20 cash for participating in the pilot. We conducted the pilot study in two phases, interviewing two participants at each phase. We identified any accessibility issues in the first phase and conducted the second phase with the revised version. In the first phase, participants reported varying levels of accessibility issues they faced in the survey, such as difficulties in navigating through the text fields, not having a progress bar, and minor confusion about the wording of some questions. We addressed the issues mentioned by the participants after the first phase and conducted the second phase one week later. At this phase, the participants did not raise any accessibility issues and thus we finalized the survey. During the follow-up interview, participants also suggested the modification of the list of objects based on the scenario, and we modified the existing objects based on their suggestions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Data analysis procedure</head><p>We now describe our quantitative and qualitative analysis procedures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Quantitative analysis</head><p>We used non-parametric versions for all of our statistical tests as our data do not meet the assumptions of parametric tests, such as normality and equal variance of errors. We have one dependent variable (comfort level for sharing information) and several independent variables (human assistants, scenarios, objects). To analyze our data, we conducted an overall Kruskal-Wallis test (for multiple groups and between subjects), a Wilcoxon rank sum test (for two groups and between subjects), a Friedman rank sum test (for multiple groups and within subjects), and a Wilcoxon signed rank test (two groups within subjects) across all conditions to see if there was any significant difference in the measured variables among the conditions. We followed the Kruskal-Wallis tests with a Dunn's post hoc test with a Benjamini-Hochberg correction, where we compared specific pairs. For the Friedman rank sum test, we performed a pairwise Wilcoxon signed rank test as the post hoc test.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Sample size power analysis</head><p>We performed a power analysis to estimate the sample size required to produce statistically significant findings. The analysis showed that 50 participants per condition would provide enough statistical power to detect 0.25 ('small') sized effects (α = 0.05,1 − β = 0.90).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3">Qualitative analysis</head><p>All qualitative answers were independently coded in a bottom up approach by two researchers. The researchers met weekly to iteratively and redundantly code a subset of open-ended responses from the survey. Each subset comprised of a combination of the audience and scenario. The researchers coded each response into one of seven reasons for their information sharing practices: 'burden' (does not want to bother family or friends), 'impression' (does not want to feel embarrassed or awkward), 'indifferent' (does not mind if information is shared), 'relevance' (does not want to share any unnecessary information), 'professionalism' (does not want to share with volunteers), 'trust' (has more faith in friends or family members), and 'security' (does not want identity to be compromised). The researchers computed Cohen's Kappa among two raters for each subset, and discussed disagreements after coding a subset of qualitative data. After two rounds of redundant coding, the researchers reached an acceptable average pairwise Cohen's Kappa score of 0.8 or greater for each subset combination of audience and scenario.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Findings: Quantitative Analysis</head><p>We now present our quantitative findings based on our statistical analyses. We first report our participants' demographics relative to their technology usage. Next we present findings about the types of content participants were selectively disclosing and concerns related to disclosure behavior. We then present findings about the audiences participants were selectively disclosing to and emergent issues related to audience and disclosure. Finally we present additional factors that affect information disclosure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Demographics and technology usage</head><p>A total of 165 people participated in our survey, although some participants did not complete the survey. After removing the incomplete responses, our final sample for the study comprised 155 participants with visual impairments. Of these participants, 54 received the 'friends' condition, 50 received the 'family' condition, and 51 received the 'volunteer or crowd-workers' condition. Of these 155 participants, 92 (59.4%) identified themselves as female and 63 (40.6%) as male. Among our participants, 44 (29.3%) were between 18-to-34 years old, 50 (33.3%) participants were between 35-to-54 years old, and 56 (37.4%) of the participants were 55 years or older. As for their professional background, 56 (37.6%) participants reported being employed full-time, 31 (20.8%) as retired, 26 (17.4%) as unemployed and looking for work, 24 (16.1%) as employed part-time, and 12 (8.1%) as a student. Among the participants, 101 (61.2%) were totally blind, whereas 64 (38.8%) live with different levels of VIP such as 'low vision' and 'blind in one eye and low vision in the other.' More than half of the participants, 96 (60.4%), were visually impaired since birth, whereas the rest became visually impaired afterward: 34 (21.4%) since childhood, 15 (9.4%) since early adulthood (18-40 years old), 11 (6.9%) since middle adulthood (41-60 years old), and 3 (1.9%) since late adulthood (61+ years old).</p><p>Participants also reported their use of various camera-based assistive technologies and their assistance-seeking behaviors. Some of the most popular assistive technologies used by the participants were Seeing AI (80%), TapTapSee (70.3%), BeMyEyes (69.6%), and KNFB Reader (65.8%). Almost all participants, 144 (96%), reported using assistive technologies for more than a year. To explore the role of human assistance in their lives, participants were asked whom they usually asked for help and their purposes of seeking help from them. The primary sighted supporters for people with VIPs are family and friends (133, 80%), although a majority of participants reported receiving help from volunteers or crowd-workers as well (100, 65%). Only four (2.4%) participants reported never seeking help from anyone, and we excluded their data from the analysis. Participants also reported how they sought help from sighted people: 122 (81.8%) for reading documents , 101 (67.7%) for identifying objects, 95 (63.7%) for identifying color, and 46 (30.8%) for seeking subjective opinions (e.g. how the participant looked in new clothing).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Selective content disclosure</head><p>To understand whether the type of background content has any effect on the sharing preference of users, we analyzed the mean comfort-level scores for two different types of content within images: 1) background objects and 2) people inadvertently captured in images (i.e., bystanders). Next, we will discuss the concerns of people with VIPs in relation to different types of objects and people in the background of images. <ref type="bibr" target="#b8">9</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Concerns with objects in the background</head><p>We categorized the background objects in our survey into four types: (1) Personally Identifiable Information or PII (credit card numbers, bills, mail showing one's address, and official documents) <ref type="bibr" target="#b55">[55]</ref>, (2) objects affecting one's impression management (mess, medical prescriptions), 10 (3) general objects (food, books), and (4) laptop screens. <ref type="figure">Figure 1</ref> illustrates participants' comfort levels for various classes of objects. As expected, we found that participants are least comfortable sharing their PII and most comfortable sharing general objects. People also show a higher concern about the objects that may impact their impression management. We conducted an overall Friedman rank-sum test and detected that at least one statistically significant difference exists between attributes (χ 2 (1) = 169.2, p &lt; 0.0001). Next, we conducted pairwise Wilcoxon Signed-Rank tests with a BH correction to detect any significant differences for background objects. For all comparisons, pairwise tests reveal significant differences. <ref type="figure">Figure 1</ref>  Overall, we can see that participants were uncomfortable with PII and impression management-related objects in the background. They were somewhat comfortable with laptop </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Concerns with people in the background</head><p>To understand the concerns with sharing photos that capture people in the background, we considered two types of content pertaining to people: 'self-disclosure' (e.g., reflection of the participant's face on the laptop screen, capturing the participant's face or body part, or a photo frame with a picture of the participant) and 'bystanders' in the photo (e.g., other people in a restaurant or the face or body part of a colleague). <ref type="figure" target="#fig_1">Figure 2</ref> shows the comfort levels for the two types of people captured in the background. Surprisingly, our analysis found that participants were more comfortable revealing themselves (µ = 3.6,σ = 1.31,95% CI [3.5,3.7]) than bystanders (µ = 3.0,σ = 1.4,95% CI [2.9,3.2]) to human assistants. A Wilcoxon signed rank test showed that this difference was statistically significant (V = 4722, p &lt; 0.001).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Selective audience disclosure</head><p>To explore the effect of the social relationship on participants' information sharing preferences, we analyzed the interaction between the different types of background information with the type of human assistant. We first conducted the Kruskal-Wallis test appropriate for between-subjects data to test for overall differences by type of human assistant. The test revealed the information-sharing preferences of our participants significantly differ for the three different human assistants (χ 2 (1) = 14.338, p &lt; 0.001). Next, we conducted Dunn's post-hoc pairwise tests with BH correction to detect any significant differences in information-sharing preferences for human assistants. Pairwise Dunn's tests showed that they were all statistically different from each other except for the difference between friends and crowd workers, meaning that participants had similar privacy concerns for friends and crowd workers. The significant difference between family and other forms of human-assistants indicates higher trust for family members in general. <ref type="figure" target="#fig_2">Figure 3</ref> shows the comfort levels for three types of human-assistants. The . Overall, participants are slightly more comfortable if family members see sensitive objects compared to other assistants.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Interaction between audience and type of person captured</head><p>To understand how sharing preferences for audience might differ based on the type of person captured, we conducted an overall Kruskal-Wallis test and detected significant differences in comfort when sharing images with different human assistants (χ 2 (1) = 8.2813, p &lt; 0.05). These differences are illustrated in <ref type="figure">Figure 4</ref>. A Dunn's post-hoc analysis similarly showed the non-significant relationship between friends and volunteers, and a slightly (and significantly) higher comfort level with family compared to the other two assistants. Looking specifically at the person categories, this difference was significant for self-information (Kruskal-Wallis ). Overall, participants were slightly more comfortable sharing images with themselves in the background with family members than with others. With bystanders, however, the type of audience did not appear to matter. Although a larger sample may have detected a difference, we expect this difference to be small.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">Interaction between audience and objects</head><p>Next we study whether sharing preferences for audience might differ based on the type of object captured in the background. We found a significant association between the sharing preference of different background objects and the type of human assistant (see <ref type="figure" target="#fig_5">Figure 5</ref>). We conducted an overall KruskalWallis test and observed significant differences in the sharing preference with audiences for PII, impression management, and general objects (PII: χ 2 (1) = 26.07, p &lt; 0.001, impression management: χ 2 (1) = 12.627, p &lt; 0.001, general: χ 2 (1) = 13.181, p &lt; 0.001). No significant relationship was found for sharing laptop screens with audiences.</p><p>Next, for all groups of objects (other than laptop screens) we conducted Dunn's post-hoc pairwise tests with BH correction to detect any significant differences for different audiences. For PII, we observed significant differences (p &lt; 0.0001) between all pairs but family and friends, with participants being much more uncomfortable with volunteers as compared to friends and family. For impression management, we found a statistically significant difference (p &lt; 0.001) only between family and friends. For the general objects, we found significant differences (p &lt; 0.01) between friends and crowd workers, and also between family and crowd workers. Overall, participants were less comfortable with volunteers when it came to inadvertent disclosures with PII, which would make sense in the context of worries about identity theft. However, in the case of impression management, they were more concerned with sharing these with friends, likely because impression management is less concerning with family and anonymous volunteers, and people might be least comfortable with friends when it came to one's living conditions or medications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Additional factors associated with information disclosure</head><p>In this section, we will report on how demographic factors such as age, gender, and severity of visual impairments impact our participants' information disclosure practices.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.1">Gender</head><p>We provided an open-text option to collect the gender of the participants in the survey. After coding the responses, we found all the participants identified themselves as either male or female. Overall, our female participants were slightly less comfortable (µ = 3.1,σ = 1.5,95% CI [3.0,3.1]) than the male participants (µ = 3.3,σ = 1.4,95% CI [3. <ref type="bibr">2,3.4]</ref>) in sharing information with human assistants. We conducted an overall Wilcoxon rank sum test (between subject, two groups) and found the difference is statistically significant (W = 1984000, p &lt; 0.001).</p><p>We also analyzed the effect of gender on the sharing preference for each group of objects. The differences in disclosing different background objects for male and female participants does not reveal any statistically significant differences except for impression management (W = 87438, p &lt; 0.0001). Female participants were less comfortable (µ = 2.6,σ = 1.3,95% CI [2. <ref type="bibr">5,2.7]</ref>) to share information that may affect their impression (e.g., mess and medical prescription) as compared to male participants (µ = 3.2,σ = 1.4,95% CI [3.0,3.3]). Overall female participants were slightly less comfortable in disclosing background information compared to male participants, although the difference was mainly attributable to information related to impression management, in which case the difference was sizeable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.2">Age</head><p>To simplify the analysis, we categorized the participants into three age groups: 18-34, 35-54, and 55 and older. Our findings suggest that the participants aged 18-34 have the least concerns about sharing background information and the group 55 to older are the most concerned. We conducted a Kruskal Wallis test (between subject, three groups), and the result shows that the concerns of disclosing background information with different audiences differs for the three age groups (χ 2 (1) = 39.534, p &lt; 0.0001). We conducted Dunn's post-hoc pairwise tests with BH correction to detect the significant differences in information sharing preferences among the age groups. We observed that the participants from age group 18-34 (µ = 3.4,σ = 1.52,95% CI We explored the interaction of age and type of background object and found a significant difference (p &lt; 0.005) for PII, self, and general objects. For all three groups, we observed the participants aged 55 or older are more concerned about disclosing information to human-assistants compared to the participants aged 18-34. Findings indicate younger participants have less privacy concerns compared to older ones.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.3">Level of visual impairment</head><p>We provided an open-text option to collect the level of visual impairments of participants in the survey and combined responses into two groups: totally blind and low vision. We conducted an overall Wilcoxon rank sum test, and the result shows that participants with low vision (µ = 3.0,σ = 1.51,95% CI [2.9,3.0]) are significantly more concerned (W = 19865004, p &lt; 0.0001) than the totally blind (µ = 3.3,σ = 1.44,95% CI [3.2,3.3]) participants.</p><p>To observe the relation between different levels of VIP and the sharing preference of different objects, we conducted Wilcoxon rank sum test for each group of objects and found significant differences (p &lt; 0.001) for PII and self-disclosure. The result indicates that participants who are low vision (µ = 2.0,σ = 1.37,95% CI [1.9,2.2]) were much more concerned than totally blind (µ = 2.6,σ = 1.51,95% CI [2.5,2.7]) participants for disclosing information related to PII.</p><p>Similarly, for self-disclosure, low-vision (µ = 3.3,σ = 1.4,95% CI [3.2,3.5]) participants were more concerned than totally blind (µ = 3.7,σ = 1.23,95% CI [3.6,3.8]) participants. We also performed another overall Wilcoxon rank sum test to observe the differences between participants who have been visually impaired since birth versus participants who became visually impaired later in their lives. We observed no statistical significance (p&gt;0.05) between the two groups.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Findings: Qualitative Analysis</head><p>We now present the results of our qualitative analysis, which shed light on the reasons behind our quantitative findings. Participants expressed privacy and security concerns about the unintended sharing of background information with humanassistants. One participant summed it up, saying, "I am uncomfortable sharing what I cannot see" (P102). A majority of the concerns (56.4%, N=83) related to sharing sensitive and personally identifiable information about the participants and the people around them. In light of these concerns, a common defensive strategy was to physically clear the exposed areas and remove the sensitive contents before using the cameras: "I would need to keep in mind who I was asking for assistance, I would also check the area to make sure it was clear of clutter and other objects. [P48]"</p><p>Thus, it was clear that participants were greatly concerned about their privacy in the context of background objects and went as far as to clear the background in some instances. We highlight interesting cases such as 'impersonal trust' and anonymous interaction in the following sections. We first present findings of the reasoning for the participants to selectively disclose the background contents present in images. We then report their reasons for selectively disclosing certain types of behavior with different audiences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Reasons for selective content disclosure</head><p>In analyzing the qualitative reasons for privacy concerns, identity theft emerged as a dominant concern among people with VIPs. Participants were largely uncomfortable with sharing their PII with human-assistants. Interestingly, however, participants (18.4%, N=27) also expressed strong concerns about being judged negatively for sharing the messiness of their surroundings. Participants mentioned feeling embarrassed, and preferred to avoid sharing a messy area: "I'm very picky about being messy, I wouldn't want people to get the wrong impression of me by watching other people's mess!"</p><p>[P144]</p><p>Prior studies reported that computer screens are one of lifeloggers' major privacy concerns as people spend a considerable amount of time in front of devices that display private information <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b48">49]</ref>. Our participants reported mixed reactions about laptop screens in the background that varied based on what might be displayed on the laptop screen. They would be more uncomfortable if it showed any private information.</p><p>"A laptop screen is seldom an issue for me, unless it provides information that can be used in identity theft."</p><p>[P114]</p><p>We sought to understand the disclosure behavior of the participants and found that participants considered sharing the image of bystanders without their consent to be a violation of their privacy.</p><p>"I have no problem having parts of myself visible, even my face, depending on the app in question. I would want camera-based technology to be discreet so I wouldn't take pictures of people at other tables, in case they would be uncomfortable."</p><p>[P34]</p><p>While participants were comfortable sharing background objects with family member, they preferred not to compromise the privacy of bystanders, even with their family.</p><p>"I have a close relationship with family, I generally don't care what they see. However, I worry about what would happen if certain data, such as other people's whereabouts, is compromised."</p><p>[P82]</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Reasons for selective audience disclosure</head><p>In our qualitative data, we found several concerns raised by the participants for their information disclosure with humanassistants, which we describe next.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1">Volunteers and agents: Institutional trust</head><p>Our participants shared extreme privacy and security concerns about volunteers and agents that varied based on impersonal trust and the anonymous nature of the interaction. Privacy and security concerns: Participants expressed strong privacy and security concerns while seeking help from the volunteer or agent-based assistive systems. They were concerned about identity theft, misuse of their information, or criminal behavior. They were not comfortable revealing private information with a total stranger whereas they were comfortable with general objects such as food items. "I would feel extremely uncomfortable with the visibility of all the items which are personal to me or to a coworker because they could be potentially misused by the stranger who is looking at the picture. Anything that has information that discloses someone's identity or contains confidential information should not be shared so that makes me extremely uneasy. Food items are common and not personal to me so I am somewhat comfortable with them being visible in the picture."</p><p>[P100]</p><p>Impersonal trust: Prior research shows that 'impersonal trust' (where trust is not based on immediate personal relationships) can influence interactions between people and institutions <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b65">65]</ref>. In our study, we also observed impersonal trust as participants mentioned trusting an agent from a professional organization more than a random volunteer. A few of our participants (6.1%, N=9) indicated relying more on a paid professional agent 11 with their sensitive information rather than a volunteer.</p><p>"I try to only share what's relevant to my question and would never intentionally share private info with a volunteer, only a paid and traceable professional."</p><p>[P140]</p><p>Participants believed that their privacy and security will be more protected with the professional agents as the organization has a privacy policy and trained agents.</p><p>"The service I use most has agents who are background checked, highly trained, and who are obligated to follow a clearly defined privacy policy. I would not allow a volunteer to see my credit card, for example, while I would let the trained agent do so without a second thought."</p><p>[P154]</p><p>Anonymous interaction: We found that participants are more comfortable sharing general objects with volunteers rather than their family members. Due to the anonymity of interactions with volunteers, participants were less concerned about sharing information, such as messy surroundings and body parts, and anticipated volunteers to be less judgmental.</p><p>"I am very comfortable with who I am and if I use such assistance I understand that the other person is there to help and not to judge my appearance or surroundings."</p><p>[P142]</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2">Family: Ultimate support and trust</head><p>Participants reported family as the most reliable source for seeking support. However, the anxieties of being a burden to the family often limited them from soliciting aid from family.</p><p>Trust and reliance: We found that family is one of the most trusted support systems for people with VIPs, and they are comfortable sharing almost any kind of information with them when seeking support. According to our participants, family members often know them and understand their requirements, hence they do not hide much from them.</p><p>"I trust my parents who I would be asking for assistance, I don't care or feel uncomfortable about them seeing anything else around me. Not like I am hiding anything or doing anything wrong." <ref type="bibr">[P61]</ref> "Considering that this is my family, I am already comfortable with them assisting me with my needs. They assist me quite frequently, and are knowledgeable and understanding to my needs."</p><p>[P73]</p><p>Social costs of burden: Previous research has shown that people can be reluctant to ask for help from their known networks to balance social costs <ref type="bibr" target="#b63">[63]</ref>. People with disabilities have enhanced concerns about appearing dependent and helpless in front of their social groups <ref type="bibr" target="#b19">[20]</ref>. We found a similar concern in our study while seeking help from family and friends. Despite trusting their family most, participants sometimes preferred not to disturb their family members. They would avoid asking help from family if could manage issues on their own or from other sources.</p><p>"I trust my family and friends but don't like to bother them if I can help it."</p><p>[P47]</p><p>Some participants felt that asking for help from family members may prove their dependency and helplessness and would prefer alternatives.</p><p>"I don't want to have to rely on my family members to tell me what things are, but that's because doing that takes away my independence."</p><p>[P59]</p><p>"I do not ask family members. I use ScripTalk for medical prescriptions. I ask Aira or BeMyEyes. I am concerned that most of these questions assume one has family around or that we'd always be comfortable asking them things. Families can often want to control things but if we use assistive technologies and agents, it's better, I think."</p><p>[P79]</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.3">Friends: Depends on the friendship</head><p>We noted concerns related to trust and impression management when disclosing information with friends. Privacy and trust: Several participants indicated trusting their friends with all types of information. They believed that friends would protect their information.</p><p>"I have complete trust in my friends, and in their reliability and keeping confidential data safe." <ref type="bibr">[P32]</ref> However, participants also expressed they might want to avoid sharing some personal information with their friends in order to protect their privacy.</p><p>"I wouldn't mind showing food or maybe myself but any private info depending who I was talking to especially a credit card with all the scams going on I wouldn't really like, though I would try to make sure that I didn't show that stuff."</p><p>[P27]</p><p>Unwanted exposure and impression management: Participants may experience unwanted exposures while sharing information with their friends. Several participants were concerned about the situations when the image can be leaked or disclosed to a wrong person other than the intended audience.</p><p>"I wouldn't really want my friends to see financial or medical information. Also, if they have a picture on their phone that contains personal info about me, this creates an opportunity for someone other than my friend to see the picture on my friend's phone (e.g., friend's family members, romantic partner), which would jeopardize the privacy and security of the information."</p><p>[P30]</p><p>He additionally expressed concerns about his identity at risk of being leaked on social media and is aware of possible security risks.</p><p>"The info in the picture could be posted on social media or used against me in some malicious way. I am very distrustful of social media." <ref type="bibr">[P30]</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Discussion</head><p>We first summarize and contextualize our key findings and then discuss broader implications for more 'humanizing' designs of assistive technologies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Key findings</head><p>Our results show that the information disclosure behaviors of people with VIPs depends on the types of objects and human assistants. Hayes et al. recently 'shadowed' people with visual impairments and studied how they obtain help from their allies in face-to-face (offline) interactions <ref type="bibr" target="#b37">[38]</ref>. Although they studied only five participants, they observed the general theme of people with VIPs being careful when selecting an ally to provide assistance, highlighting the importance to study privacy in assistive applications. In the context of image sharing by 'lifeloggers,' Hoyle et al. <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b41">42]</ref> did not study specific audiences, but they also found that participants were concerned about private information (such as screens and other objects with textual information), impression management, and the presence of bystanders in their photos. Unlike their work, however, our participants were more concerned about the privacy of bystanders than their own when it came to capturing people in images.</p><p>In the context of information sharing with specific audiences, our participants shared strong concerns about sharing personally identifiable information with crowdworkers because of concerns about identity theft. This finding is consistent with prior work showing people are more willing to share private information with stronger social ties <ref type="bibr" target="#b75">[74]</ref>. We also found that participants were more comfortable sharing concerns about self-presentation with family than with friends. However, we also found some evidence 12 that participants were more comfortable with with crowd workers (weaker ties) than with friends (stronger ties). In the same vein, Dosono et al. found that college Reserve Officers' Training Corps (ROTC) students were more comfortable sharing personal crises related to impression management (e.g., physical injuries) with family and counselors instead of their ROTC peers <ref type="bibr" target="#b27">[28]</ref>. In general, anonymous interactions have been shown to help in overcoming social stigma and may be more appropriate for private exchanges where more openness is desired <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b46">47]</ref>.</p><p>Consistent with prior work <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b67">66]</ref>, women were more concerned about their privacy than men. Female participants were more concerned than male participants when it came to objects related to impression management. Although prior work has found that older adults can show both extremes of privacy concerns <ref type="bibr" target="#b57">[57,</ref><ref type="bibr" target="#b68">67]</ref> with younger populations being more pragmatic <ref type="bibr" target="#b68">[67]</ref>, our older participants were more concerned about sharing background objects than the younger participants. In the context of level of impairment, prior work has found coping strategies such as 'acceptance' where people with visual impairments (especially the totally blind) felt they "had very little choice other than to accept the risks" <ref type="bibr" target="#b7">[8]</ref>. One might therefore expect people who are totally blind to be more concerned about or interested in protecting their privacy. Interestingly, however our totally blind participants were less concerned about their privacy than the low-vision participants. It may be that people who are totally blind are less aware of the possible privacy risks than people with low vision or are more willing to compromise their privacy because they have become accustomed to a higher need for assistance and 'acceptance' of less privacy in general.</p><p>Finally, prior work has found that people may have more trust in volunteers compared to paid workers because of a stronger perception of altruism and sincerity of the volunteer <ref type="bibr" target="#b38">[39]</ref>. Qualitative analysis showed that some participants trusted paid crowd workers more than volunteers with their private information. The role of 'impersonal trust' in such systems needs additional investigation, and how more trust may be derived from volunteers or paid agents. <ref type="bibr" target="#b11">12</ref> The statistical significance was marginal at p = 0.054.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Implications: Toward humanizing camera-based assistive technologies</head><p>Although there is a growing body of work exploring the needs of people with VIPs <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b61">61,</ref><ref type="bibr" target="#b62">62]</ref>, our study yielded novel privacy and security concerns of people with VIPs related to their sharing of information with crowd workers and human assistants using camera-based assistive systems. Many of these concerns were related to how camera-based assistive systems were creating a lack of security in people's daily lives -that is, these systems were serving to further marginalize their identities.</p><p>Broadly speaking, when populations are marginalized based on their identities, they are placed at the edge, beyond boundaries, or on the outside of what is considered normative, and individuals and groups can be marginalized on various intersections of their identity, such as their race, gender, sexual orientation, socioeconomic status, or perceived ability <ref type="bibr" target="#b64">[64]</ref>. Recent work has explored the ways in which algorithmic systems can marginalize people's identities. Systems like facial recognition software can serve to further marginalize people with gender-fluid identities, as these systems serve as gender reduction mechanisms and may misidentify people who have changed genders or who do not choose a gender <ref type="bibr" target="#b34">[35]</ref>.</p><p>In our study, the marginalization and subsequent lack of security manifested in the relationship between the systems and people's identities for people with VIPs. Our identity defines us as an individual; it is the sense of self that we refer to and that others see us as, giving us security in our daily lives <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b30">31]</ref>. At their root, camera-based assistive technologies give people with VIPs the chance to regain security. Giddens defines security as a stable mental state derived from the continuity and predictability of routines, that is, a person achieves a sense of trust and safety in their life through the enactment and habitualization of routines <ref type="bibr" target="#b29">[30]</ref>. For example, the ability to pay bills or take a prescription generates a sense of reliability in a person's life; it is this sense of stability that provides one with a sense of security about their existence.</p><p>In this context, we found that camera-based assistive technology can create insecurity. That is, through their use of these systems, our participants were concerned about identity theft and people finding out where they lived. Moreover, people were also concerned with issues related to self-concept, such as if friends caught a glimpse of their "messy" home environments. Thus, we argue that in order to create more private and secure assistive technologies, we must begin to humanize assistive technology; that is, we must train computer vision algorithms to better understand what kinds of objects people might want others to (not) see, as well as be cognizant of where we need to enforce human assistance as opposed to algorithmic assistance. As a means of generating ways in which this can be operationalized at the system's design and implementation level, to humanize assistive technology means that we must pay more attention to context. Humanizing security as humanizing context. The way in which scholarship has defined context has gone through various transformations over time. Context has often been viewed, from a positivist perspective, as the setting where action unfolds, where the setting is believed to be a static entity, stable and separate from the activities taking place therein <ref type="bibr" target="#b28">[29]</ref>. Early on, however, Suchman's <ref type="bibr" target="#b71">[70]</ref> formative work illustrated that context incorporates the activities of humans, and people's activities are neither stable nor predetermined. In building on this notion of context, Dourish <ref type="bibr" target="#b28">[29]</ref> argues that the determination of context cannot be made a priori, that is, context is an emergent property of interaction. In this view, context is actively produced throughout the course of interaction; it is determined by the people who are present and in how they generate, together, the rules and norms for their interaction. For example, if only one person is present in their home (i.e., a homeowner), they may feel free to engage in actions that they may otherwise feel uncomfortable with others present, such as taking a shower with the door open. When others are present, such as guests, the context shifts and the rules and norms also change, and this same person may not feel comfortable engaging in these same behaviors.</p><p>The continual shaping of context is related to impression management <ref type="bibr" target="#b30">[31]</ref>, where people are trying to control how they present themselves to others. In the context of social media, people's ability to engage in impression management is a burden as people tend to collapse multiple audiences into a single context <ref type="bibr" target="#b58">[58]</ref>. This process of impression management is increasingly complex for people with VIPs as how in some cases people with VIPs present themselves to others is invisible to them. In this view, systems should be designed such that they make context visible. Technical solutions should therefore not just focus on finding PII in images, but also look for situations that may affect one's social standing. One such implication is that people (as bystanders) who may be concerned about being captured by assistive devices can be made aware that other people will be removed through face detection (for example) from assistive devices. As we found, people with VIPs are highly concerned about the privacy of bystanders, and Ahmed et al. study 'up to <ref type="bibr">[what]</ref> limit' bystanders are willing to be captured in such circumstances <ref type="bibr" target="#b6">[7]</ref>.</p><p>Given that camera-based assistive technologies utilize digital images to communicate with audiences, photos often collapse several contexts together (i.e., a home environment, driver's license photo, prescription drug labels, and more). Given that some of this information was not appropriate for certain audiences, computer vision algorithms should be designed more empathetically such that they detect content deemed inappropriate for certain audiences and blur them, redact them, or generate other novel solutions that are context aware and thus sensitive to the desires of those who are using camera-based assistive technologies. For example, Li et al. <ref type="bibr" target="#b56">[56]</ref> and Hasan et al. <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b56">56]</ref> have been studying privacy transforms that are also visually appealing to the viewer. For assistive applications, further research is needed to understand how the quality of assistance might degrade with obfuscating transforms. Technologies should help to decide the appropriate audience for the type of question and take appropriate measures for detecting privacy violations for that audience, or, conversely, pick the right audience based on all subject matter in the photo (and not just the foreground object). People should be informed if PII, in particular, is present while using crowd-sourced technology whereas they should know if prescription medications are visible when seeking assistance from friends.</p><p>Finally, given that our study focused on camera-based assistive technologies, we believe that technical systems, more broadly, might be creating differential forms of insecurity in the daily lives of people with VIPs. This leads to a 'security paradox' whereby, on the one hand, these systems are being used by people with VIPs since they serve an important need in enabling them to maintain their routines, yet they are also generating insecurity as they expose them to additional vulnerabilities. Thus, we need to continue to understand where systems are creating insecurity through additional explorations of a broad range of assistive technologies amongst the visually impaired, while also uncovering new values that can drive future design.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Limitations</head><p>We note several limitations of our study, which could be addressed in future work. Our participant sample was small, limited to a few national blind foundations, and restricted to those who chose to respond to an ad about camera-based assistive technology, so it is difficult to know how well our findings generalize to the greater population. However, we also note the challenges in reaching this population, and compared to other recent studies of privacy concerns for the visually impaired, our sample size is relatively large <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b76">75]</ref>. We considered only three types of human assistants; however, other social groups may have an impact on the information sharing behaviors of people with VIPs, such as co-workers and specific categories of friends (close, distant). Our qualitative data also showed a distinction between professional crowd agents versus volunteers and should be explored in future work. In this study, we considered only the effect of background content and audiences on a user's sharing preferences. There may be other factors that affect people's preferences as well, such as the sharing context and purpose. Future research should study the privacy needs of people with VIPs for other social groups in varying situations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>To better understand the privacy concerns of people with visual impairments in the context of photo-based, humanassisted question-answering systems we conducted an online survey with 155 visually impaired people. We found that while people with visual impairments have privacy and security concerns about revealing background objects, their information disclosure preferences vary according to the types of objects and human assistants. Our findings, in some cases, were often counter-intuitive. For example, participants were more concerned with the privacy of bystanders than their own privacy and they were more comfortable sharing concerns about self-presentation with family (and possibly crowd workers) as opposed to friends. Moreover, we believe that the ways in which these systems are designed can create a lack of personal security in the lives of the people we are trying to assist. Although assistive technologies have great potential for social good, they can also potentially harm people. As designers and builders of sociotechnical systems, we must continue to understand the more positive aspects as well as the moral and ethical dilemmas that may arise when our systems are used. In doing so, we hope these systems will continue to take on more humanistic, empathetic qualities, and achieve our goals of assisting as opposed to harming others.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>indicates the mean value and 95 percent confidence intervals for each category of object. From the figure we can observe that the differences in average comfort level between PII (µ = 2.4,σ = 1.45,95% CI [2.3,2.5]) and general objects (µ = 4.0,σ = 1.16,95% CI [3.9,4.1]) is large and significant (p &lt; 0.0001). The comfort level for objects that can affect impression (µ = 2.9,σ = 1.43,95% CI [2.8,3.0]) is slightly lower than the comfort level of laptop screens (µ = 3.1,σ = 1.34,95% CI [3.0,3.3]) and the difference is sig- nificant (p &lt; 0.0001).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 1: Differences in comfort levels for objects</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Differences in comfort levels for human assistants</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>figure indicates similar comfort levels for friends (µ = 3.1,σ = 1.35,95% CI [3.0,3.2]) and crowd-workers (µ = 3.1,σ = 1.51,95% CI [3.0,3.1]), which are different (p &lt; 0.001) from family (µ = 3.3,σ = 1.53,95% CI [3.2,3.4])</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>χ 2 ( 1 ) = 9 .Figure 5 :</head><label>2195</label><figDesc>Figure 4: Interaction between type of person captured and human assistants</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5</head><label>5</label><figDesc>The figure also indicates that participants are less comfortable sharing information with their friends (µ = 2.6,σ = 1.29,95% CI [2.4,2.8]) re- lated to their impression compared to family (µ = 3.1,σ = 1.53,95% CI [2.9,3.3]) and crowd-workers (µ = 2.9,σ = 1.41,95% CI [2.7,3.0]), although the difference between friends and crowd-workers was only marginally significant (p = 0.054).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>[ 3 .</head><label>3</label><figDesc>3,3.4]) have slightly less (p &lt; 0.0001) concerns about disclosing informa- tion with human assistants compared to the group aged 35-54 (µ = 3.2,σ = 1.47,95% CI [3.1,3.3]). Similarly, participants from age group 35-54 (µ = 3.2,σ = 1.47,95% CI [3.1,3.3]) have slightly less concerns (p &lt; 0.0001) about disclosing in- formation with human assistants compared to the group 55 or older (µ = 3,σ = 1.42,95% CI [2.9,3.0]). Thus, each group was slightly less concerned than the next older age group.</figDesc></figure>

			<note place="foot" n="1"> Orcam: www.orcam.com/en/ 2 Color teller: www.brytech.com/colorteller 3 Seeing AI: www.microsoft.com/en-us/seeing-ai 4 KNFB Reader: https://knfbreader.com 5 A typical use case is for a visually impaired person to compose a photo or video and deliberately share it with a human assistant.</note>

			<note place="foot" n="6"> Aipoly: www.aipoly.com 7 i.d. mate: www.envisionamerica.com 8 LookTell: www.looktel.com</note>

			<note place="foot" n="9"> We tested for the interaction between the scenario and the concerns with background objects, and did not find statistically significant results. As we suspected, the particular scenario or foreground objects did not appear to affect comfort levels related to background objects and we omit those findings. 10 In our qualitative data, participants consistently expressed concerns about how showing a mess or one&apos;s prescription information would affect other people&apos;s opinions of them.</note>

			<note place="foot" n="11"> At the time of this writing, Aira charges $29 USD per month for 30 minutes of service.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This material is based upon work supported in part by the US National Science Foundation under awards CNS-1408730, CNS-1252697, and IIS-1657429. We thank Jeffrey P. Bigham and the VizWiz team for sharing their data with us. We thank our participants, as well as Sharon Lovering from the American Council of the Blind and Lou Ann Blake from the National Federation of the Blind, for helping recruit participants.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A The Survey</head><p>Display the consent form. Then display screening questions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Q1. What is your level of visual impairment? (Open text)</head><p>Q2. Since when do you have your visual impairment?</p><p>-Since Birth -Since Childhood -Early Adulthood (When I was 18-40 years old) -Middle Adulthood (When I was 41-60 years old) -Late adulthood (when I was 61+ old) Q3. What types of devices do you regularly use? Please select all that apply?</p><p>-Laptop or notebook computer -Smart phone -Tablet computer -Desktop computer -Smart watch -Fitness tracker -Wearable devices -Smart glasses (e.g. Google glass, Hololens) -Other (Open text) <ref type="bibr">Q4</ref>. How frequently do you use camera on your smartphone? -Never -Almost never -Occasionally sometimes -Almost every time -Frequently Q5. How frequently do you share photos online? -Never -Rarely -Sometimes -Often -Always Q6. When you need the help of a sighted person (for example, to identify an object), whom do you typically ask for help? Please select all that apply. -I ask my friends -I ask my family members -I ask random strangers -I ask professional agents or crowd workers or volunteers through assistive technology -I don't ask anyone Q7.Which of the following assistive technologies have you used so far? Please select all that apply. -To identify an object -For reading documents or screens or labels -To get a general description of a scene -To get the friend's opinion on something (e.g. How do you look like?) -Identify the color of a dress or any object -Other <ref type="table">(Open text)</ref> Q12. What types of questions would you ask to your friends if you were to ask them? Please select all that apply.</p><p>-To identify an object -For reading documents or screens or labels -To get a general description of a scene -To get the friend's opinion on something (e.g. How do you look like?) -Identify the color of a dress or any object -Other (Open text) Scenarios: Suppose there is an assistive technology where you can seek help from your friends by taking a photo of the object, recording the question and sending it to them. You can also make video calls to your friends to seek help. Now we would like to ask you about your comfort levels when using such platforms in various situations. In particular, we would like to understand how you would like to use such technologies to get help from your friends.</p><p>Q13. Suppose you went to a restaurant and were served a can of soda. You want to know the type of the soda but there is no one around to ask. If there was an assistive technology where you could ask your friends to identify the soda can by taking a picture of it, how comfortable would you feel asking them for help? We used a 5-point Likert scale (1: extremely uncomfortable, 5: extremely comfortable) Q14. Suppose while taking the picture there were some other objects captured along with the soda can. How comfortable would you feel if the following were present in the photo and visible to your friends along with the soda can? We used same 5-point Likert scale described in Q13 for each of the following options. Q15. Can you please briefly explain your selections above? (Open text) Q16. Suppose you are at your workplace and need to take your prescription medicine. But there are two similarly sized bottles of medicine, and you need to differentiate between them. You don't want to ask any of your coworkers to identify the bottles for you. If there was an assistive technology where you could ask your friends to identify the medicine bottles by taking a picture of the medicines, how comfortable would you feel asking them for help? We used a 5-point Likert scale (1: extremely uncomfortable, 5: extremely comfortable) Q17. Suppose, while taking the picture of medicine bottles there were some other objects captured along with the medicines. How comfortable would you feel if the following were present in the photo and visible to your friends along with the medicine bottles? We used same 5-point Likert scale described in Q16 for each of the following options. Q18. Can you please briefly explain your selection above? (Open text) Q19. Suppose you are preparing to attend a party and thinking of wearing the new dress/suit you just bought. Now you want to wear a scarf/tie with it but cannot decide which one will match best. There is no one around to help. If there is an assistive technology where you can ask for the opinion of your friends by taking a picture of you wearing the dress/suit and the scarf/tie, how comfortable would you feel asking them for help? We used a 5-point Likert scale (1: extremely uncomfortable, 5: extremely comfortable) Q20. Suppose, while taking the picture of the dress/suit and scarf/tie, there were some other objects captured along with the dress. How comfortable would you feel if the following were present in the photo and visible to your friends along with the dress/suit? We used same 5-point Likert scale described in Q19 for each of the following options. </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Aira</surname></persName>
		</author>
		<ptr target="https://aira.io/" />
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title/>
		<ptr target="www.bemyeyes.com" />
	</analytic>
	<monogr>
		<title level="j">Be My Eyes</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">An empirical investigation of the situationally-induced impairments experienced by blind mobile device users</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Abdolrahmani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ravi</forename><surname>Kuber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amy</forename><surname>Hurst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th Web for All Conference</title>
		<meeting>the 13th Web for All Conference</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page">21</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Face recognition and privacy in the age of augmented reality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Acquisti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frederic</forename><forename type="middle">D</forename><surname>Stutzman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Privacy and Confidentiality</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A qualitative study to support a blind photography mobile application</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dustin</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lourdes</forename><surname>Morales</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sri</forename><surname>Kurniawan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th International Conference on PErvasive Technologies Related to Assistive Environments</title>
		<meeting>the 6th International Conference on PErvasive Technologies Related to Assistive Environments</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page">25</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Privacy concerns and behaviors of people with visual impairments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tousif</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Hoyle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kay</forename><surname>Connelly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Crandall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Apu</forename><surname>Kapadia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems</title>
		<meeting>the 33rd Annual ACM Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3523" to="3532" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Up to a limit?: Privacy concerns of bystanders and their willingness to share additional information with visually impaired users of assistive technologies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tousif</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Apu</forename><surname>Kapadia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Venkatesh</forename><surname>Potluri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manohar</forename><surname>Swaminathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies</title>
		<meeting>the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">89</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Addressing physical safety, security, and privacy for people with visual impairments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tousif</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Shaffer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kay</forename><surname>Connelly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Crandall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Apu</forename><surname>Kapadia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Twelfth Symposium on Usable Privacy and Security (SOUPS 2016)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="341" to="354" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Privacy implications of artificial and human intelligence assistive tools for visually impaired people</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taslima</forename><surname>Akter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Dosono</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tousif</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Apu</forename><surname>Kapadia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Semaan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CHI Workshop on Bridging the Gap Between AI and HCI</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">An own-age bias in face recognition for children and older adults</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><forename type="middle">S</forename><surname>Anastasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><forename type="middle">G</forename><surname>Rhodes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1043" to="1047" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Vqa: Visual question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stanislaw</forename><surname>Antol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aishwarya</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiasen</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Margaret</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruv</forename><surname>Batra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devi</forename><surname>Parikh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2425" to="2433" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Remote assistance for blind users in daily life: A survey about be my eyes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mauro</forename><surname>Avila</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katrin</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anke</forename><surname>Brock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niels</forename><surname>Henze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th ACM International Conference on PErvasive Technologies</title>
		<meeting>the 9th ACM International Conference on PErvasive Technologies</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page">85</biblScope>
		</imprint>
	</monogr>
	<note>Related to Assistive Environments</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Passchords: Secure multi-touch authentication for blind people</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiri</forename><surname>Azenkot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyle</forename><surname>Rector</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Ladner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Wobbrock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th International ACM SIGACCESS Conference on Computers and Accessibility</title>
		<meeting>the 14th International ACM SIGACCESS Conference on Computers and Accessibility</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="159" to="166" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Unipass: Design and evaluation of a smart device-based password manager for visually impaired users</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Natã</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordan</forename><surname>Barbosa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Hayes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing</title>
		<meeting>the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="49" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Crowds in two seconds: Enabling realtime crowd-powered interfaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">S</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Brandt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">C</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David R</forename><surname>Karger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th annual ACM symposium on User Interface Software and Technology</title>
		<meeting>the 24th annual ACM symposium on User Interface Software and Technology</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="33" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Vizwiz: Nearly real-time answers to visual questions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><forename type="middle">P</forename><surname>Bigham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chandrika</forename><surname>Jayant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanjie</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Little</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">C</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robin</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aubrey</forename><surname>Tatarowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brandyn</forename><surname>White</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samual</forename><surname>White</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23nd Annual ACM Symposium on User Interface Software and Technology</title>
		<meeting>the 23nd Annual ACM Symposium on User Interface Software and Technology</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="333" to="342" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Prepaid and promised incentives in web surveys: An experiment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Bosnjak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tracy</forename><forename type="middle">L</forename><surname>Tuten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Social Science Computer Review</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="208" to="217" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Gauging receptiveness to social microvolunteering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erin</forename><surname>Brady</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meredith</forename><forename type="middle">Ringel</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><forename type="middle">P</forename><surname>Bigham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems</title>
		<meeting>the 33rd Annual ACM Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1055" to="1064" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Visual challenges in the everyday lives of blind people</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erin</forename><surname>Brady</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meredith</forename><forename type="middle">Ringel</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>White</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><forename type="middle">P</forename><surname>Bigham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</title>
		<meeting>the SIGCHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2117" to="2126" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Investigating the appropriateness of social network question asking as a resource for blind users</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erin</forename><forename type="middle">L</forename><surname>Brady</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meredith</forename><forename type="middle">Ringel</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><forename type="middle">P</forename><surname>Bigham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Computer Supported Cooperative Work</title>
		<meeting>the 2013 Conference on Computer Supported Cooperative Work</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1225" to="1236" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Is someone there? Do they have a gun: How visual information about others can improve personal safety management for blind individuals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stacy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Branham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Abdolrahmani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Morgan</forename><surname>Easley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erick</forename><surname>Scheuerman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amy</forename><surname>Ronquillo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hurst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th International ACM SIGACCESS Conference on Computers and Accessibility</title>
		<meeting>the 19th International ACM SIGACCESS Conference on Computers and Accessibility</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="260" to="269" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Performative acts and gender constitution: An essay in phenomenology and feminist theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judith</forename><surname>Butler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Routledgefalmer Reader in Gender &amp; Education</title>
		<imprint>
			<publisher>Routledge</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="73" to="83" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">A wearable system for mobility improvement of visually impaired people. The Visual Computer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Sylvain Cardin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frédéric</forename><surname>Thalmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vexo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="109" to="118" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A haptic ATM interface to assist visually impaired users</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brendan</forename><surname>Cassidy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gilbert</forename><surname>Cockton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lynne</forename><surname>Coventry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th International ACM SIGACCESS Conference on Computers and Accessibility</title>
		<meeting>the 15th International ACM SIGACCESS Conference on Computers and Accessibility</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Design of a mobile face recognition system for visually impaired persons</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shonal</forename><surname>Chaudhry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rohitash</forename><surname>Chandra</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1502.00756</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">An investigation of the contact hypothesis of the own-race bias in face recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Chiroro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Valentine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Quarterly Journal of Experimental Psychology Section A</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="879" to="894" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Understanding mobile web and mobile search use in today&apos;s dynamic mobile landscape</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Church</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nuria</forename><surname>Oliver</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Conference on Human Computer Interaction with Mobile Devices and Services</title>
		<meeting>the 13th International Conference on Human Computer Interaction with Mobile Devices and Services</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="67" to="76" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Challenges in transitioning from civil to military culture: Hyper-selective disclosure through ICTs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Dosono</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yasmeen</forename><surname>Rashidi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taslima</forename><surname>Akter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Semaan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Apu</forename><surname>Kapadia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the ACM on HumanComputer Interaction</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">41</biblScope>
			<date type="published" when="2017" />
			<publisher>CSCW</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">What we talk about when we talk about context. Personal Ubiquitous Computing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Dourish</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="19" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Modernity and self-identity: Self and society in the late modern age</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>Giddens</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991" />
			<publisher>Stanford University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">The presentation of self in everyday life</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erving</forename><surname>Goffman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1959" />
			<publisher>Anchor Books</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Making the V. in VQA matter: Elevating the role of image understanding in visual question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yash</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tejas</forename><surname>Khot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douglas</forename><surname>Summers-Stay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruv</forename><surname>Batra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devi</forename><surname>Parikh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2017-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Vizwizpriv: A dataset for recognizing the presence and purpose of private visual information in images taken by blind people</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danna</forename><surname>Gurari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qing</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinan</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anhong</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abigale</forename><surname>Stangl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><forename type="middle">P</forename><surname>Bigham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danna</forename><surname>Gurari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qing</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abigale</forename><forename type="middle">J</forename><surname>Stangl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anhong</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristen</forename><surname>Grauman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiebo</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><forename type="middle">P</forename><surname>Bigham</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.08218</idno>
		<title level="m">Vizwiz grand challenge: Answering visual questions from blind people</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Gender recognition or gender reductionism?: The social implications of embedded gender recognition systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Foad</forename><surname>Hamidi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Morgan</forename><forename type="middle">K</forename><surname>Scheuerman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stacy</forename><forename type="middle">M</forename><surname>Branham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CHI Conference on Human Factors in Computing Systems</title>
		<meeting>the CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Trust and the virtual organization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Handy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Long Range Planning</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="126" to="126" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Can privacy be satisfying?: On improving viewer satisfaction for privacy-enhanced photos using aesthetic transforms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rakibul</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eman</forename><surname>Hassan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kelly</forename><surname>Caine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Crandall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Apu</forename><surname>Hoyle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kapadia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems</title>
		<meeting>the 2019 CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">367</biblScope>
			<biblScope unit="page" from="1" to="367" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Cooperative privacy and security: Learning from people with visual impairments and their allies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordan</forename><surname>Hayes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Smirity</forename><surname>Kaushik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charlotte</forename><forename type="middle">Emily</forename><surname>Price</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">15th Symposium on Usable Privacy and Security (SOUPS). USENIX</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">How perceptions of altruism and sincerity affect client trust in volunteers versus paid workers. Nonprofit and Voluntary Sector Quarterly</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niek</forename><surname>Hoogervorst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judith</forename><surname>Metz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lonneke</forename><surname>Roza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eva</forename><surname>Van Baren</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="593" to="611" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Gender differences in privacy-related measures for young adult facebook users</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grubbs</forename><surname>Mariea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Hoy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Milne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Interactive Advertising</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="28" to="45" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Sensitive lifelogs: A privacy analysis of photos from wearable cameras</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Hoyle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Templeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Denise</forename><surname>Anthony</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Crandall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Apu</forename><surname>Kapadia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems</title>
		<meeting>the 33rd Annual ACM Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1645" to="1648" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Privacy behaviors of lifeloggers using wearable cameras</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Hoyle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Templeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Armes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Denise</forename><surname>Anthony</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Crandall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Apu</forename><surname>Kapadia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 ACM International Joint Conference on Pervasive and Ubiquitous Computing</title>
		<meeting>the 2014 ACM International Joint Conference on Pervasive and Ubiquitous Computing</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="571" to="582" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">The Steering Committee of The World Congress in Computer Science</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rabia</forename><surname>Jafri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Syed Abid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hamid</forename><forename type="middle">R</forename><surname>Arabnia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Information and Knowledge Engineering (IKE)</title>
		<meeting>the International Conference on Information and Knowledge Engineering (IKE)</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note>Face recognition for the visually impaired</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Supporting blind photography</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chandrika</forename><surname>Jayant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanjie</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>White</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><forename type="middle">P</forename><surname>Bigham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International ACM SIGACCESS Conference on Computers and Accessibility</title>
		<meeting>the 13th International ACM SIGACCESS Conference on Computers and Accessibility</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="203" to="210" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">People with visual impairment training personal object recognizers: Feasibility and challenges</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hernisa</forename><surname>Kacorri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kris</forename><forename type="middle">M</forename><surname>Kitani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><forename type="middle">P</forename><surname>Bigham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chieko</forename><surname>Asakawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems</title>
		<meeting>the 2017 CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5839" to="5849" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Freedom to roam: A study of mobile device adoption and accessibility for people with visual and motor disabilities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaun</forename><forename type="middle">K</forename><surname>Kane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chandrika</forename><surname>Jayant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><forename type="middle">O</forename><surname>Wobbrock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">E</forename><surname>Ladner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th International ACM SIGACCESS Conference on Computers and Accessibility</title>
		<meeting>the 11th International ACM SIGACCESS Conference on Computers and Accessibility</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="115" to="122" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Strangers on your phone: Why people use anonymous communication applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruogu</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Dabbish</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katherine</forename><surname>Sutton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th ACM Conference on Computer-Supported Cooperative Work &amp; Social Computing, CSCW &apos;16</title>
		<meeting>the 19th ACM Conference on Computer-Supported Cooperative Work &amp; Social Computing, CSCW &apos;16<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="359" to="370" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Academic sojourners, culture shock and intercultural adaptation: A trend analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Khan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Studies About Languages</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="38" to="46" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Enhancing lifelogging privacy by detecting screens</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammed</forename><surname>Korayem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Templeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dennis</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Crandall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Apu</forename><surname>Kapadia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems</title>
		<meeting>the 2016 CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="4309" to="4314" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Smartphone based face recognition tool for the blind</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Kramer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename><surname>Hedin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Rolkosky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Engineering in Medicine and Biology Society (EMBC)</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
				<title level="m">Annual International Conference of the IEEE</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="4538" to="4541" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">A systematic requirements analysis and development of an assistive device to enhance the social interaction of people who are blind or visually impaired</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Krishna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Colbry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Balasubramanian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Panchanathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Computer Vision Applications for the Visually Impaired</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Trinetra: Assistive technologies for grocery shopping for the blind</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><forename type="middle">E</forename><surname>Lanigan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><forename type="middle">M</forename><surname>Paulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">W</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Rossi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Priya</forename><surname>Narasimhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISWC</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="147" to="148" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Real-time crowd control of existing interfaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Walter</forename><forename type="middle">S</forename><surname>Lasecki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyle</forename><forename type="middle">I</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>White</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">C</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><forename type="middle">P</forename><surname>Bigham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th Annual ACM Symposium on User Interface Software and Technology</title>
		<meeting>the 24th Annual ACM Symposium on User Interface Software and Technology</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="23" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Information extraction and manipulation threats in crowdpowered systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Walter</forename><forename type="middle">S</forename><surname>Lasecki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaime</forename><surname>Teevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ece</forename><surname>Kamar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th ACM Conference on Computer Supported Cooperative Work &amp; Social Computing</title>
		<meeting>the 17th ACM Conference on Computer Supported Cooperative Work &amp; Social Computing</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="248" to="256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Human perceptions of sensitive content in photos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wyatt</forename><surname>Troutman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><forename type="middle">P</forename><surname>Knijnenburg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kelly</forename><surname>Caine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition Workshops</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1590" to="1596" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Effectiveness and users&apos; experience of obfuscation as a privacy-enhancing technology for sharing photos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nishant</forename><surname>Vishwamitra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><forename type="middle">P</forename><surname>Knijnenburg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongxin</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kelly</forename><surname>Caine</surname></persName>
		</author>
		<idno>67:1-67:24</idno>
	</analytic>
	<monogr>
		<title level="j">Proc. ACM Hum.-Comput. Interact</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<date type="published" when="2017-12" />
			<publisher>CSCW</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Privacy, technology, and aging: A proposed framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lorenzen-Huber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Boutain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Camp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Shankar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">H</forename><surname>Connelly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ageing International</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="232" to="252" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">I tweet honestly, I tweet passionately: Twitter users, context collapse, and the imagined audience</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alice</forename><forename type="middle">E</forename><surname>Marwick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danah</forename><surname>Boyd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">New Media &amp; Society</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="114" to="133" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">A comparison of information seeking using search engines and social networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meredith Ringel</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaime</forename><surname>Teevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katrina</forename><surname>Panovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">4th International AAAI Conference on Weblogs and Social Media</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">National Federation of the Blind. Blindness statistics. www.nfb.org/resources/blindness-statistics</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">iCarea user centric approach to the development of assistive devices for the blind and visually impaired</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Panchanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rush</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Iyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">15th IEEE International Conference on Tools with Artificial Intelligence</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2003" />
			<biblScope unit="page" from="641" to="648" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Social interaction assistant: A person-centered approach to enrich social interactions for individuals with visual impairments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Panchanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chakraborty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mcdaniel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Journal of Selected Topics in Signal Processing</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="942" to="951" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Estimating the social costs of friendsourcing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jeffrey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meredith Ringel</forename><surname>Rzeszotarski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Morris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</title>
		<meeting>the SIGCHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2735" to="2744" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Marginalized identities, discrimination burden, and mental health: Empirical exploration of an interpersonallevel approach to modeling intersectionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julia</forename><forename type="middle">S</forename><surname>Seng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">D</forename><surname>Lopez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mickey</forename><surname>Sperlich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lydia</forename><surname>Hamama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caroline</forename><forename type="middle">D Reed</forename><surname>Meldrum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Social Science &amp; Medicine</title>
		<imprint>
			<biblScope unit="volume">75</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2437" to="2445" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">The social control of impersonal trust</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Susan</forename><forename type="middle">P</forename><surname>Shapiro</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">American Journal of Sociology</title>
		<imprint>
			<biblScope unit="volume">93</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="623" to="658" />
			<date type="published" when="1987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">An investigation of gender differences in on-line privacy concerns and resultant behaviors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kim Bartel</forename><surname>Sheehan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Interactive Marketing</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="24" to="38" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<title level="m" type="main">Toward a typology of internet users and online privacy concerns. The Information Society</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kim Bartel</forename><surname>Sheehan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="21" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">In the shadow of misperception: assistive technology use and social interactions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristen</forename><surname>Shinohara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><forename type="middle">O</forename><surname>Wobbrock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</title>
		<meeting>the SIGCHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="705" to="714" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">PocketATM: Understanding and improving atm accessibility in India</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sudheesh</forename><surname>Singanamalla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Venkatesh</forename><surname>Potluri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Scott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Indrani</forename><surname>Medhi-Thies</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth International Conference on Information and Communication Technologies and Development</title>
		<meeting>the Tenth International Conference on Information and Communication Technologies and Development</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
		<title level="m" type="main">Plans and situated actions: The problem of human-machine communication</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucy</forename><forename type="middle">A</forename><surname>Suchman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1987" />
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<title level="m" type="main">PlaceRaider: Virtual theft in physical spaces with smartphones</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Templeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zahid</forename><surname>Rahman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Crandall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Apu</forename><surname>Kapadia</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1209.5982</idno>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">An assisted photography framework to help visually impaired users properly aim a camera</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marynel</forename><surname>Vázquez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Steinfeld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on ComputerHuman Interaction (TOCHI)</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">25</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<monogr>
		<title level="m" type="main">WHO: World Health Organization. Global data on visual impairment</title>
		<ptr target="www.who.int/blindness/publications/globaldata/en/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Are you close with me? Are you nearby?: Investigating social groups, closeness, and willingness to share</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Wiese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><forename type="middle">Gage</forename><surname>Kelley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorrie</forename><forename type="middle">Faith</forename><surname>Cranor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Dabbish</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><forename type="middle">I</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Zimmerman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Conference on Ubiquitous Computing, UbiComp &apos;11</title>
		<meeting>the 13th International Conference on Ubiquitous Computing, UbiComp &apos;11</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="197" to="206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Current and future mobile and wearable device use by people with visual impairments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meethu</forename><surname>Hanlu Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Uran</forename><surname>Malu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leah</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Findlater</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</title>
		<meeting>the SIGCHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3123" to="3132" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
