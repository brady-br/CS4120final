<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2020-09-29T02:35+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">This paper is included in the Proceedings of the 12th USENIX Conference on File and Storage Technologies (FAST &apos;14). Lifetime Improvement of NAND Flash-based Storage Systems Using Dynamic Program and Erase Scaling Lifetime Improvement of NAND Flash-based Storage Systems Using Dynamic Program and Erase Scaling</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>February 17-20, 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaeyong</forename><surname>Jeong</surname></persName>
							<email>jyjeong@davinci.snu.ac.kr</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shane</forename><surname>Hahn</surname></persName>
							<email>shanehahn@davinci.snu.ac.kr</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaeyong</forename><surname>Jeong</surname></persName>
							<email>jihong@davinci.snu.ac.kr</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Sangwook</roleName><forename type="first">Shane</forename><surname>Hahn</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungjin</forename><surname>Lee</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jihong</forename><surname>Kim</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="laboratory">Sungjin Lee, MIT/CSAIL; Jihong Kim</orgName>
								<orgName type="institution">Seoul National University</orgName>
								<address>
									<settlement>Santa Clara</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Dept. of CSE</orgName>
								<orgName type="institution" key="instit1">Seoul National University</orgName>
								<orgName type="institution" key="instit2">Seoul National University</orgName>
								<orgName type="institution" key="instit3">Massachusetts Institute of Technology</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">This paper is included in the Proceedings of the 12th USENIX Conference on File and Storage Technologies (FAST &apos;14). Lifetime Improvement of NAND Flash-based Storage Systems Using Dynamic Program and Erase Scaling Lifetime Improvement of NAND Flash-based Storage Systems Using Dynamic Program and Erase Scaling</title>
					</analytic>
					<monogr>
						<title level="m">USENIX Association 12th USENIX Conference on File and Storage Technologies</title>
						<imprint>
							<biblScope unit="page">61</biblScope>
							<date type="published">February 17-20, 2014</date>
						</imprint>
					</monogr>
					<note>Open access to the Proceedings of the 12th USENIX Conference on File and Storage Technologies (FAST &apos;14) is sponsored by</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>The cost-per-bit of NAND flash memory has been continuously improved by semiconductor process scaling and multi-leveling technologies (e.g., a 10 nm-node TLC device). However, the decreasing lifetime of NAND flash memory as a side effect of recent advanced technologies is regarded as a main barrier for a wide adoption of NAND flash-based storage systems. In this paper, we propose a new system-level approach, called dynamic program and erase scaling (DPES), for improving the lifetime (particularly, endurance) of NAND flash memory. The DPES approach is based on our key observation that changing the erase voltage as well as the erase time significantly affects the NAND endurance. By slowly erasing a NAND block with a lower erase voltage, we can improve the NAND endurance very effectively. By modifying NAND chips to support multiple write and erase modes with different operation voltages and times, DPES enables a flash software to exploit the new tradeoff relationships between the NAND endurance and erase volt-age/speed under dynamic program and erase scaling. We have implemented the first DPES-aware FTL, called aut-oFTL, which improves the NAND endurance with a negligible degradation in the overall write throughput. Our experimental results using various I/O traces show that autoFTL can improve the maximum number of P/E cycles by 61.2% over an existing DPES-unaware FTL with less than 2.2% decrease in the overall write throughput.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>NAND flash-based storage devices are increasingly popular from mobile embedded systems (e.g., smartphones and smartpads) to large-scale high-performance enterprise servers. Continuing semiconductor process scaling (e.g., 10 nm-node process technology) combined with various recent advances in flash technology (such as a TLC device <ref type="bibr" target="#b0">[1]</ref> and a 3D NAND device <ref type="bibr" target="#b1">[2]</ref>) is expected to further accelerate an improvement of the costper-bit of NAND devices, enabling a wider adoption of NAND flash-based storage systems. However, the poor endurance of NAND flash memory, which deteriorates further as a side effect of recent advanced technologies, is still regarded as a main barrier for sustainable growth in the NAND flash-based storage market. (We represent the NAND endurance by the maximum number of program/erase (P/E) cycles that a flash memory cell can tolerate while preserving data integrity.) Even though the NAND density doubles every two years, the storage lifetime does not increase as much as expected in a recent device technology <ref type="bibr" target="#b2">[3]</ref>. For example, the NAND storage lifetime was increased by only 20% from 2009 to 2011 because the maximum number of P/E cycles was decreased by 40% during that period. In particular, in order for NAND flash memory to be widely adopted in high-performance enterprise storage systems, the deteriorating NAND endurance problem should be adequately resolved.</p><p>Since the lifetime L C of a NAND flash-based storage device with the total capacity C is proportional to the maximum number MAX P/E of P/E cycles, and is inversely proportional to the total written data W day per day, L C (in days) can be expressed as follows (assuming a perfect wear leveling):</p><formula xml:id="formula_0">L C = MAX P/E × C W day × WAF ,<label>(1)</label></formula><p>where WAF is a write amplification factor which represents the efficiency of an FTL algorithm. Many existing lifetime-enhancing techniques have mainly focused on reducing WAF by increasing the efficiency of an FTL algorithm. For example, by avoiding unnecessary data copies during garbage collection, WAF can be reduced <ref type="bibr" target="#b3">[4]</ref>. In order to reduce W day , various architectural/system-level techniques were proposed. For example, data de-duplication <ref type="bibr" target="#b4">[5]</ref>, data compression <ref type="bibr" target="#b5">[6]</ref> and write traffic throttling <ref type="bibr" target="#b6">[7]</ref> are such examples. On the other hand, few system/software-level techniques were proposed for actively increasing the max-imum number MAX P/E of P/E cycles. For example, a recent study <ref type="bibr" target="#b7">[8]</ref> suggests MAX P/E can be indirectly improved by a self-recovery property of a NAND cell but no specific technique was proposed yet. In this paper, we propose a new approach, called dynamic program and erase scaling (DPES), which can significantly improve MAX P/E . The key intuition of our approach, which is motivated by a NAND device physics model on the endurance degradation, is that changing the erase voltage as well as the erase time significantly affects the NAND endurance. For example, slowly erasing a NAND block with a lower erase voltage can improve the NAND endurance significantly. By modifying a NAND device to support multiple write and erase modes (which have different voltage/speed and different impacts on the NAND endurance) and allowing a firmware/software module to choose the most appropriate write and erase mode (e.g., depending on a given workload), DPES can significantly increase MAX P/E .</p><p>The physical mechanism of the endurance degradation is closely related to stress-induced damage in the tunnel oxide of a NAND memory cell <ref type="bibr" target="#b8">[9]</ref>. Since the probability of stress-induced damage has an exponential dependence on the stress voltage <ref type="bibr" target="#b9">[10]</ref>, reducing the stress voltage (particularly, the erase voltage) is an effective way of improving the NAND endurance. Our measurement results with recent 20 nm-node NAND chips show that when the erase voltage is reduced by 14% during P/E cycles, MAX P/E can increase on average by 117%. However, in order to write data to a NAND block erased with the lower erase voltage (which we call a shallowly erased block in the paper), it is necessary to form narrow threshold voltage distributions after program operations. Since shortening the width of a threshold voltage distribution requires a fine-grained control during a program operation, the program time is increased if a lower erase voltage was used for erasing a NAND block.</p><p>Furthermore, for a given erase operation, since a nominal erase voltage (e.g., 14 V) tends to damage the cells more than necessary in the beginning period of an erase operation <ref type="bibr" target="#b10">[11]</ref>, starting with a lower (than the nominal) erase voltage and gradually increasing to the nominal erase voltage can improve the NAND endurance. However, gradually increasing the erase voltage increases the erase time. For example, our measurement results with recent 20 nm-node NAND chips show that when the initial erase voltage of 10 V is used instead of 14 V during P/E cycles, MAX P/E can increase on average by 17%. On the other hand, the erase time is increased by 300%.</p><p>Our DPES approach exploits the above two tradeoff relationships between the NAND endurance and erase voltage/speed at the firmware-level (or the software level in general) so that the NAND endurance is improved while the overall write throughput is not affected. For example, since the maximum performance of NAND flash memory is not always needed in real workloads, a DPESbased technique can exploit idle times between consecutive write requests for shortening the width of threshold voltage distributions so that shallowly erased NAND blocks, which were erased by lower erase voltages, can be used for most write requests. Idle times can be also used for slowing down the erase speed. If such idle times can be automatically estimated by a firmware/system software, the DPES-based technique can choose the most appropriate write speed for each write request or select the most suitable erase voltage/speed for each erase operation. By aggressively selecting endurance-enhancing erase modes (i.e., a slow erase with a lower erase voltage) when a large idle time is available, the NAND endurance can be significantly improved because less damaging erase operations are more frequently used.</p><p>In this paper, we present a novel NAND endurance model which accurately captures the tradeoff relationship between the NAND endurance and erase voltage/speed under dynamic program and erase scaling. Based on our NAND endurance model, we have implemented the first DPES-aware FTL, called autoFTL, which dynamically adjusts write and erase modes in an automatic fashion, thus improving the NAND endurance with a negligible degradation in the overall write throughput. In autoFTL, we also revised key FTL software modules (such as garbage collector and wear-leveler) to make them DPES-aware for maximizing the effect of DPES on the NAND endurance. Since no NAND chip currently allows an FTL firmware to change its program and erase voltages/times dynamically, we evaluated the effectiveness of autoFTL with the FlashBench emulation environment <ref type="bibr" target="#b11">[12]</ref> using a DPESenabled NAND simulation model (which supports multiple write and erase modes). Our experimental results using various I/O traces show that autoFTL can improve MAX P/E by 61.2% over an existing DPES-unaware FTL with less than 2.2% decrease in the overall write throughput.</p><p>The rest of the paper is organized as follows. Section 2 briefly explains the basics of NAND operations related to our proposed approach. In Section 3, we present the proposed DPES approach in detail. Section 4 describes our DPES-aware autoFTL. Experimental results follow in Section 5, and related work is summarized in Section 6. Finally, Section 7 concludes with a summary and future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head><p>In order to improve the NAND endurance, our proposed DPES approach exploits key reliability and performance parameters of NAND flash memory during run time. In this section, we review the basics of various reliability parameters and their impact on performance and en- Figure 1: An example of threshold voltage distributions for multi-level NAND flash memory and primary reliability parameters.</p><p>durance of NAND cells.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Threshold Voltage Distributions of NAND Flash Memory</head><p>Multi-level NAND flash memory stores 2 bits in a cell using four distinct threshold voltage levels (or states) as shown in <ref type="figure">Figure 1</ref>.  <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b13">14]</ref>, respectively. As a result, the total width W Vth of threshold voltage distributions should be carefully designed to meet all the NAND requirements.</p><p>In order for flash manufacturers to guarantee the reliability and performance requirements of NAND flash memory throughout its storage lifespan, all the reliability parameters, which are highly inter-related each other, are usually fixed during device design times under the worstcase operating conditions of a storage product. However, if one performance/reliability requirement can be relaxed under specific conditions, it is possible to drastically improve the reliability or performance behavior of the storage product by exploiting tradeoff relationships among various reliability parameters. For example, Liu et al. <ref type="bibr" target="#b12">[13]</ref> suggested a system-level approach that improves the NAND write performance when most of written data are short-lived (i.e., frequently updated data) by sacrificing M Pi 's which affect the data retention capability <ref type="bibr" target="#b0">1</ref> . Our proposed DPES technique exploits W Pi 's (which also affect the NAND write performance) so that the NAND endurance can be improved.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">NAND Program Operations</head><p>In order to form a threshold voltage distribution within a desired region, NAND flash memory generally uses the incremental step pulse programming (ISPP) scheme. As shown in <ref type="figure" target="#fig_1">Figure 2</ref>(a), the ISPP scheme gradually increases the program voltage by the V ISPP step until all the memory cells in a page are located in a desired threshold  Since the program time is proportional to the number of ISPP loops (which are inversely proportional to V ISPP ), the program time T PROG can be expressed as follows: </p><formula xml:id="formula_1">T PROG ∝ V end PGM − V start PGM V ISPP .<label>(2)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Dynamic Program and Erase Scaling</head><p>The DPES approach is based on our key observation that slowly erasing (i.e., erase time scaling) a NAND block with a lower erase voltage (i.e., erase voltage scaling) significantly improves the NAND endurance. In this section, we explain the effect of erase voltage scaling on improving the NAND endurance and describe the dynamic program scaling method for writing data to a shallowly erased NAND block (i.e., a NAND block erased with a lower erase voltage). We also present the concept of erase time scaling and its effect on improving the NAND endurance. Finally, we present a novel NAND endurance model which describes the effect of DPES on the NAND endurance based on an empirical measurement study using 20 nm-node NAND chips.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Erase Voltage Scaling and its Effect on NAND Endurance</head><p>The time-to-breakdown T BD of the oxide layer decreases exponentially as the stress voltage increases because the higher stress voltage accelerates the probability of stress-induced damage which degrades the oxide reliability <ref type="bibr" target="#b9">[10]</ref>. This phenomenon implies that the NAND endurance can be improved by lowering the stress voltage (e.g., program and erase voltages) during P/E cycles because the reliability of NAND flash memory primarily depends on the oxide reliability <ref type="bibr" target="#b8">[9]</ref>. Although the maximum program voltage to complete a program operation is usually larger than the erase voltage, the NAND endurance is mainly degraded during erase operations because the stress time interval of an erase operation is about 100 times longer than that of a program operation. Therefore, if the erase voltage can be lowered, its impact on the NAND endurance improvement can be significant. In order to verify our observation, we performed NAND cycling tests by changing the erase voltage. In a NAND cycling test, program and erase operations are repeated 3,000 times (which are roughly equivalent to MAX P/E of a recent 20 nm-node NAND device <ref type="bibr" target="#b2">[3]</ref>). Our cycling tests for each case are performed with more than 80 blocks which are randomly selected from 5 NAND chips. In our tests, we used the NAND retention BER (i.e., a BER after 10 hours' baking at 125 • C) as a measure for quantifying the wearing degree of a NAND chip <ref type="bibr" target="#b8">[9]</ref>. (This is a standard NAND retention evaluation procedure specified by JEDEC <ref type="bibr" target="#b14">[15]</ref>.) <ref type="figure" target="#fig_3">Figure 3</ref>(a) shows how the retention BER changes, on average, as the number of P/E cycles increases while varying erase voltages. We represent different erase voltages using an voltage scaling ratio r (0 ≤ r ≤ 1). When r is set to x, the erase voltage is reduced by (x × 100)% of the nominal erase voltage. The retention BERs were normalized over the retention BER after 3K P/E cycles when the nominal erase voltage was used. As shown in <ref type="figure" target="#fig_3">Figure 3(a)</ref>, the more the erase voltage is reduced (i.e., the higher r's), the less the retention BERs. For example, when the erase voltage is reduced by 14% of the nominal erase voltage, the normalized retention BER is reduced by 54% after 3K P/E cycles over the nominal erase voltage case.</p><p>Since the normalized retention BER reflects the degree of the NAND wearing, higher r's lead to less endurance degradations. Since different erase voltages degrade the NAND endurance by different amounts, we introduce a P/E cycles <ref type="bibr">[K]</ref> r=0.00 r=0.07 r=0.14 new endurance metric, called effective wearing per PE (in short, effective wearing), which represents the effective degree of NAND wearing after a P/E cycle. We represent the effective wearing by a normalized retention BER after 3K P/E cycles 2 . Since the normalized retention BER is reduced by 54% when the erase voltage is reduced by 14%, the effective wearing becomes 0.46. When the nominal erase voltage is used, the effective wearing is 1.</p><p>As shown in <ref type="figure" target="#fig_3">Figure 3</ref>(b), the effective wearing decreases near-linearly as r increases. Based on a linear regression model, we can construct a linear equation for the effective wearing over different r's. Using this equation, we can estimate the effective wearing for a different r. After 3K P/E cycles, for example, the total sum of the effective wearing with the nominal erase voltage is 3K. On the other hand, if the erase voltage was set to 14% less than the nominal voltage, the total sum of the effective wearing is only 1.38K because the effective wearing with r of 0.14 is 0.46. As a result, MAX P/E can be increased more than twice as much when the erase voltage is reduced by 14% over the nominal case. In this paper, we will use a NAND endurance model with five different erase voltage modes (as described in Section 3.5).</p><p>Since we did not have access to NAND chips from different manufacturers, we could not prove that our test results can be generalized. However, since our tests are based on widely-known device physics which have been investigated by many device engineers and researchers, we are convinced that the consistency of our results would be maintained as long as NAND flash memories use the same physical mechanism (i.e., FN-tunneling) for program and erase operations. We believe that our results will also be effective for future NAND devices as long as </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Dynamic Program Scaling</head><p>In order to write data to a shallowly erased NAND block, it is necessary to change program bias conditions dynamically so that narrow threshold voltage distributions can be formed after program operations. If a NAND block was erased with a lower erase voltage, a threshold voltage window for a program operation is reduced by the decrease in the erase voltage because the value of the erase voltage decides how deeply a NAND block is erased. For example, as shown in <ref type="figure">Figure 4</ref>, if a NAND block is shallowly erased with a lower erase voltage V small ERASE (which is lower than the nominal erase voltage V nominal ERASE ), the width of a threshold voltage window is reduced by a saved threshold voltage margin ∆W Vth (which is proportional to the voltage difference between V nominal ERASE and V small ERASE ). Since threshold voltage distributions can be formed only within the given threshold voltage window when a lower erase voltage is used, a fine-grained program control is necessary, thus increasing the program time of a shallowly erased block.</p><p>In our proposed DPES technique, we use five different erase voltage modes, EVmode 0 , ··· , EVmode 4 . EVmode 0 uses the highest erase voltage V 0 while EVmode 4 uses the lowest erase voltage V 4 . After a NAND block is erased, when the erased block is programmed again, there is a strict requirement on the minimum interval length of the program time which depends on the erase voltage mode used for the erased block. (As explained above, this minimum program time requirement is necessary to form threshold voltage distributions within the reduced threshold voltage window.) <ref type="figure" target="#fig_4">Figure 5</ref> Total sum of the effective wearing <ref type="bibr">[K]</ref> (c) M Pi scaling ratios Wmode 4 , when the program time is two times longer than the nominal T PROG , V ISPP can be maximally reduced. Dynamic program scaling can be easily integrated into an existing NAND controller with a negligible time overhead (e.g., less than 1% of T PROG ) and a very small space overhead (e.g., 4 bits per block). On the other hand, in conventional NAND chips, M Pi is kept large enough to preserve the data retention requirement under the worstcase operating condition (e.g., 1-year data retention after 3,000 P/E cycles). However, since the data retention requirement is proportional to the total sum of the effective wearing <ref type="bibr" target="#b8">[9]</ref>, M Pi can be relaxed by removing an unnecessary data retention capability. <ref type="figure" target="#fig_4">Figure 5</ref>(c) shows our M Pi scaling model over different total sums of the effective wearing based on our measurement results. In order to reduce the management overhead, we change the M Pi scaling ratio every 0.5-K P/E cycle interval (as shown by the dotted line in <ref type="figure" target="#fig_4">Figure 5</ref>(c)).  <ref type="bibr" target="#b15">[16]</ref>. As described in Section 3.1, since the probability of damage is proportional to the erase voltage, the memory cell with a high threshold voltage is damaged more than that with a low threshold voltage, resulting in unnecessarily degrading the memory cell with a high threshold voltage. In order to minimize unnecessary damage in the beginning period of an erase operation, it is an effective way to start the erase voltage with a sufficiently low voltage (e.g., 10 V) and gradually increase to the nominal erase voltage <ref type="bibr" target="#b10">[11]</ref>. For example, if we start with the erase voltage of 10 V, the memory cell whose threshold voltage is 4 V may be partially erased because the erase voltage is 14 V (i.e., 10 V plus 4 V) without excessive damage to the memory cell. As we increase the erase voltage in subsequent ISPE (incremental step pulse erasing <ref type="bibr" target="#b16">[17]</ref>) loops, the threshold voltage in the cell is reduced by each ISPE step, thus avoiding unnecessary damage during an erase operation. In general, the lower the starting erase voltage, the less damage to the cells.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Erase Time Scaling and its Effect on NAND Endurance</head><p>However, as an erase operation starts with a lower voltage than the nominal voltage, the erase time increases because more erase loops are necessary for completing the erase operation. creases. The longer the erase time (i.e., the lower the starting erase voltage), the less the effective wearing (i.e., the higher NAND endurance.). We represent the fast erase mode by ESmode f ast and the slow erase mode by ESmode slow . Our measurement results with 20 nm-node NAND chips show that if we increase the erase time by 300% by starting with a lower erase voltage, the effective wearing is reduced, on average, by 19%. As shown in <ref type="figure" target="#fig_5">Figure 6</ref>(b), the effect of the slow erase mode on improving the NAND endurance can be exploited regardless of the erase voltage scaling ratio r. Since the erase voltage modes are continuously changed depending on the program time requirements, the endurance-enhancing erase mode (i.e., the lowest erase voltage mode) cannot be used under an intensive workload condition. On the other hand, the erase time scaling can be effective even under an intensive workload condition, if slightly longer erase times do not affect the overall write throughput.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Lazy Erase Scheme</head><p>As explained in Section 3.2, when a NAND block was erased with EVmode i , a page in the shallowly erased block can be programmed using specific Wmode j 's (where j ≥ i) only because the requirement of the saved threshold voltage margin cannot be satisfied with a faster write mode Wmode k (k &lt; i). In order to write data with a faster write mode to the shallowly erased NAND block, the shallowly erased block should be erased further before it is written. We propose a lazy erase scheme which additionally erases the shallowly erased NAND block, when necessary, with a small extra erase time (i.e., 20% of the nominal erase time). Since the effective wearing mainly depends on the maximum erase voltage used, erasing a NAND block by a high erase voltage in a lazy fashion does not incur any extra damage than erasing it with the initially high erase voltage <ref type="bibr" target="#b2">3</ref> . Since a lazy erase  cancels an endurance benefit of a shallow erase while introducing a performance penalty, it is important to accurately estimate the write speed of future write requests so that correct erase modes can be selected when erasing NAND blocks, thus avoiding unnecessary lazy erases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">NAND Endurance Model</head><p>Combining erase voltage scaling, program time scaling and erase time scaling, we developed a novel NAND endurance model that can be used with DPES-enabled NAND chips. In order to construct a DPES-enabled NAND endurance model, we calculate saved threshold voltage margins for each combination of write modes (as shown in <ref type="figure" target="#fig_4">Figure 5</ref>(b)) and M Pi scaling ratios (as shown in <ref type="figure" target="#fig_4">Figure 5(c)</ref>). Since the effective wearing has a nearlinear dependence on the erase voltage and time as shown in <ref type="figure" target="#fig_3">Figures 3(b) and 6(b)</ref>, respectively, the values of the effective wearing for each saved threshold voltage margin can be estimated by a linear equation as described in Section 3.1. All the data in our endurance model are based on measurement results with recent 20 nm-node NAND chips. For example, when the number of P/E cycles is less than 500, and a block is slowly erased before writing with the slowest write mode, a saved threshold voltage margin can be estimated to 1.06 V (which corresponds to the erase voltage scaling ratio r of 0.14 in <ref type="figure" target="#fig_5">Fig- ure 6(b)</ref>). As a result, we can estimate the value of the effective wearing as 0.45 by a linear regression model for the solid line with squared symbols in <ref type="figure" target="#fig_5">Figure 6(b)</ref>. <ref type="figure" target="#fig_7">Figure 7</ref> shows our proposed NAND endurance model with five erase voltage modes (i.e., EVmode 0 ∼ EVmode 4 ) and two erase speed modes (i.e., ESmode slow and ESmode f ast ). EVmode 0 (which uses the largest erase voltage) supports the fastest write mode (i.e., Wmode 0 ) with no slowdown in the write speed while EVmode 4 similar fashion as why the erase time scaling is effective in improving the NAND endurance as discussed in the previous section. The endurance gain from using two different starting erase voltages is higher than the endurance loss from a longer erase time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Utilization</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Write Request</head><p>Logical-to-Physical Mapping </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Design and Implementation of AutoFTL</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Overview</head><p>Based on our NAND endurance model presented in Section 3.5, we have implemented autoFTL, the first DPES-aware FTL, which automatically changes write and erase modes depending on write throughput requirements. AutoFTL is based on a page-level mapping FTL with additional modules for DPES support. <ref type="figure">Fig- ure 8</ref> shows an organizational overview of autoFTL. The DPES manager, which is the core module of autoFTL, selects a write mode Wmode i for a write request and decides both an appropriate erase voltage mode EVmode j and erase speed mode ESmode k for each erase operation. In determining appropriate modes, the mode selector bases its decisions on the estimated write throughput requirement using a circular buffer. AutoFTL maintains per-block mode information and NAND setting information as well as logical-to-physical mapping information in the extended mapping table. The per-block mode table keeps track of the current write mode and the total sum of the effective wearing for each block. The NAND setting table is used to choose appropriate device settings for the selected write and erase modes, which are sent to NAND chips via a new interface DeviceSettings between autoFTL and NAND chips. AutoFTL also extends both the garbage collector and wear leveler to be DPES-aware. </p><formula xml:id="formula_2">u &gt; 80% Wmode 0 60% &lt; u ≤ 80% Wmode 1 40% &lt; u ≤ 60% Wmode 2 20% &lt; u ≤ 40% Wmode 3 u ≤ 20% Wmode 4</formula><p>As semiconductor technologies reach their physical limitations, it is necessary to use cross-layer optimization between system software and NAND devices. As a result, some of internal device interfaces are gradually opened to public in the form of additional 'user interface'. For example, in order to track bit errors caused by data retention, a new 'device setting interface' which adjusts the internal reference voltages for read operations is recently opened to public <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b18">19]</ref>. There are already many set and get functions for modifying or monitoring NAND internal configurations in the up-todate NAND specifications such as the toggle mode interface and ONFI. For the measurements presented here, we were fortunately able to work in conjunction with a flash manufacturer to adjust erase voltage as we wanted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Write Mode Selection</head><p>In selecting a write mode for a write request, the Wmode selector of the DPES manager exploits idle times between consecutive write requests so that autoFTL can increase MAX P/E without incurring additional decrease in the overall write throughput. In autoFTL, the Wmode selector uses a simple circular buffer for estimating the maximum available program time (i.e., the minimum required write speed) for a given write request. <ref type="table" target="#tab_7">Table 1</ref> summarizes the write-mode selection rules used by the Wmode selector depending on the utilization of a circular buffer. The circular buffer queues incoming write requests before they are written, and the Wmode selector adaptively decides a write mode for each write request. The current version of the Wmode selector, which is rather conservative, chooses the write mode, Wmode i , depending on the buffer utilization u. The buffer utilization u represents how much of the circular buffer is filled by outstanding write requests. For example, if the utilization is lower than 20%, the write request in the head of the circular buffer is programmed to a NAND chip with </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Extended Mapping Table</head><p>Since erase operations are performed at the NAND block level, the per-block mode table maintains five linked lists of blocks which were erased using the same erase voltage mode. When the DPES manager decides a write mode for a write request, the corresponding linked list is consulted to locate a destination block for the write request. Also, the DPES manager informs a NAND chip how to configure appropriate device settings (e.g., ISPP/ISPE voltages, the erase voltage, and reference voltages for read/verify operations) for the current write mode using the per-block mode table. Once NAND chips are set to a certain mode, an additional setting is not necessary as long as the write and the erase modes are maintained. For a read request, since different write modes require different reference voltages for read operations, the perblock mode table keeps track of the current write mode for each block so that a NAND chip changes its read references before serving a read request.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Erase Voltage Mode Selection</head><p>Since the erase voltage has a significant impact on the NAND endurance as described in Section 3.1, selecting a right erase voltage is the most important step in improving the NAND endurance using the DPES technique. As explained in Section 4.2, since autoFTL decides a write mode of a given write request based on the utilization of the circular buffer of incoming write requests, when deciding the erase voltage mode of a victim block, autoFTL takes into account of the future utilization of the circular buffer. If autoFTL could accurately predict the future utilization of the circular buffer and erase the victim block with the erase voltage that can support the future write mode, the NAND endurance can be improved without a lazy erase operation. In the current version, we use the average buffer utilization of 10 5 past write requests for predicting the future utilization of the circular buffer. In order to reduce the management overhead, we divide 10 5 past write requests into 100 subgroups where each subgroup consists of 1000 write requests. For each subgroup, we compute the average utilization of 1000 write requests in the subgroup, and use the average of 100 subgroup's utilizations to calculate the estimate of the future utilization of the buffer.</p><p>When a foreground garbage collection is invoked, since the write speed of a near-future write request is already chosen based on the current buffer utilization, the victim block can be erased with the corresponding erase voltage mode. On the other hand, when a background garbage collection is invoked, it is difficult to use the current buffer utilization because the background garbage collector is activated when there are no more write requests waiting in the buffer. For this case, we use the estimated average buffer utilization of the circular buffer to predict the buffer utilization when the next phase of write requests (after the background garbage collection) fills in the circular buffer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Erase Speed Mode Selection</head><p>In selecting an erase speed mode for a block erase operation, the DPES manager selects an erase speed mode which does not affect the write throughput. An erase speed mode for erasing a NAND block is determined by estimating the effect of a block erase time on the buffer utilization. Since write requests in the circular buffer cannot be programmed while erasing a NAND block, the buffer utilization is effectively increased by the block erase time. The effective buffer utilization u ′ considering the effect of the block erase time can be expressed as follows:</p><formula xml:id="formula_3">u ′ = u + ∆u erase ,<label>(3)</label></formula><p>where u is the current buffer utilization and ∆u erase is the increment in the buffer utilization by the block erase time. In order to estimate the effect of a block erase operation on the buffer utilization, we convert the block erase time to a multiple M of the program time of the current write mode. ∆u erase corresponds to the increment in the buffer utilization for these M pages. For selecting an erase speed mode of a NAND block, the mode selector checks if ESmode slow can be used. If erasing with ESmode slow does not increase u ′ larger than 100% (i.e., no buffer overflow), ESmode slow is selected. Otherwise, the fast erase mode ESmode f ast is selected. On the other hand, when the background garbage collection is invoked, ESmode slow is always selected in erasing a victim block. Since the background garbage collection is invoked when an idle time between consecutive write requests is sufficiently long, the overall write throughput is not affected even with ESmode slow .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">DPES-Aware Garbage Collection</head><p>When the garbage collector is invoked, the most appropriate write mode for copying valid data to a free block is determined by using the same write-mode selection rules summarized in <ref type="table" target="#tab_7">Table 1</ref> with a slight modification to computing the buffer utilization u. Since the write requests in the circular buffer cannot be programmed while copying valid pages to a free block by the garbage collector, the buffer utilization is effectively increased by the number of valid pages in a victim block. By using the information from the garbage collector, the mode selector recalculates the effective buffer utilization u * as follows:</p><formula xml:id="formula_4">u * = u + ∆u copy ,<label>(4)</label></formula><p>where u is the current buffer utilization and ∆u copy is the increment in the buffer utilization taking the number of valid pages to be copied into account. The mode selector decides the most appropriate write mode based on the write-mode selection rules with u * instead of u. After copying all the valid pages to a free block, a victim block is erased by the erase voltage mode (selected by the rules described in Section 4.4) with the erase speed (chosen by the rules described in Section 4.5). For example, as shown in the case 1 of <ref type="table" target="#tab_2">Table 2</ref>, if garbage collection is invoked when u is 70%, and the number of valid pages to be copied is 30 (i.e., ∆u copy = 30/200 = 15%), Wmode 0 is selected because u * is 85% (= 70% + 15%), and</p><p>ESmode slow is selected because erasing with ESmode slow does not overflow the circular buffer. (We assume that ∆u erase for ESmode slow and ∆u erase for ESmode f ast are 8% and 2%, respectively.) On the other hand, as shown in the case 2 of <ref type="table" target="#tab_2">Table 2</ref>, when the number of valid pages to be copied is 50 (i.e., ∆u copy = 50/200 = 25%), ESmode slow cannot be selected because u ′ becomes larger than 100%. As shown in the case 1, ESmode slow can still be used even when the buffer utilization is higher than 80%. When the buffer utilization is higher than 80% (i.e., an intensive write workload condition), the erase voltage scaling is not effective because the highest erase voltage is selected. On the other hand, even when the buffer utilization is above 90%, the erase speed scaling can be still useful.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7">DPES-Aware Wear Leveling</head><p>Since different erase voltage/time affects the NAND endurance differently as described in Section 3.1, the reliability metric (based on the number of P/E cycles) of the existing wear leveling algorithm <ref type="bibr" target="#b19">[20]</ref> is no longer valid in a DPES-enabled NAND flash chip. In autoFTL, the DPES-aware wear leveler uses the total sum of the effective wearing instead of the number of P/E cycles as a reliability metric, and tries to evenly distribute the total sum of the effective wearing among NAND blocks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experimental Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experimental Settings</head><p>In order to evaluate the effectiveness of the proposed autoFTL, we used an extended version of a unified development environment, called FlashBench <ref type="bibr" target="#b11">[12]</ref>, for NAND flash-based storage devices. Since the efficiency of our DPES is tightly related to the temporal characteristics of write requests, we extended the existing FlashBench to be timing-accurate. Our extended FlashBench emulates the key operations of NAND flash memory in a timing-accurate fashion using high-resolution timers (or hrtimers) (which are available in a recent Linux kernel <ref type="bibr" target="#b20">[21]</ref>). Our validation results on an 8-core Linux server system show that the extended FlashBench is very accurate. For example, variations on the program time and erase time of our DRAM-based NAND emulation models are less than 0.8% of T PROG and 0.3% of T ERASE , respectively.</p><p>For our evaluation, we modified a NAND flash model in FlashBench to support DPES-enabled NAND flash chips with five write modes, five erase voltage modes, and two erase speed modes as shown in <ref type="figure" target="#fig_7">Figure 7</ref>. Each NAND flash chip employed 128 blocks which were composed of 128 8-KB pages. The maximum number of P/E cycles was set to 3,000. The nominal page program time (i.e., T PROG ) and the nominal block erase time (i.e., T ERASE ) were set to 1.3 ms and 5.0 ms, respectively.</p><p>We evaluated the proposed autoFTL in two different environments, mobile and enterprise environments. Since the organizations of mobile storage systems and enterprise storage systems are quite different, we used two FlashBench configurations for different environments as summarized in <ref type="table" target="#tab_9">Table 3</ref>. For a mobile environment, FlashBench was configured to have two channels, and each channel has a single NAND chip. Since mobile systems are generally resource-limited, the size of a circular buffer for a mobile environment was set to 80 KB only (i.e., equivalently 10 8-KB pages). For an enterprise environment, FlashBench was configured to have eight channels, each of which was composed of four NAND chips. Since enterprise systems can utilize more resources, the size of a circular buffer was set to 32 MB (which is a typical size of data buffer in HDD) for enterprise environments.</p><p>We carried out our evaluations with two different techniques: baseline and autoFTL. Baseline is an existing DPES-unaware FTL that always uses the highest erase voltage mode and the fast erase mode for erasing NAND blocks, and the fastest write mode for writing data to NAND blocks. AutoFTL is the proposed DPES-aware FTL which decides the erase voltage and the erase time depending on the characteristic of a workload and fully utilizes DPES-aware techniques, described in Sections 3 and 4, so it can maximally exploit the benefits of dynamic program and erase scaling. Our evaluations were conducted with various I/O traces from mobile and enterprise environments. (For more details, please see Section 5.2). In order to replay I/O traces on top of the extended FlashBench, we developed a trace replayer. The trace replayer fetches I/O commands from I/O traces and then issues them to the extended FlashBench according to their inter-arrival times to a storage device. After running traces, we measured the maximum number of P/E cycles, MAX P/E , which was actually conducted until flash memory became unreliable. We then compared it with that of baseline. The overall write throughput is an important metric that shows the side-effect of autoFTL on storage performance. For this reason, we also measured the overall write throughput while running each I/O trace.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Benchmarks</head><p>We used 8 different I/O traces collected from Androidbased smartphones and real-world enterprise servers. The m down trace was recorded while downloading a system installation file (whose size is about 700 MB) using a mobile web-browser through 3G network. The m p2p1 trace included I/O activities when downloading multimedia files using a mobile P2P application from a lot of rich seeders. Six enterprise traces, hm 0, proj 0, prxy 0, src1 2, stg 0, and web 0, were from the MSCambridge benchmarks <ref type="bibr" target="#b21">[22]</ref>. However, since enterprise traces were collected from old HDD-based server systems, their write throughputs were too low to evaluate the performance of modern NAND flash-based storage systems. In order to partially compensate for low write throughput of old HDD-based storage traces, we accelerated all the enterprise traces by 100 times so that the peak throughput of the most intensive trace (i.e., src1 2) can fully consume the maximum write throughput of our NAND configuration. (In our evaluations, therefore, all the enterprise traces are 100x-accelerated versions of the original traces.)</p><p>Since recent enterprise SSDs utilize lots of interchip parallelism (multiple channels) and intra-chip parallelism (multiple planes), peak throughput is significantly higher than that of conventional HDDs. We tried to find appropriate enterprise traces which satisfied our requirements to (1) have public confidence; (2) can fully consume the maximum throughput of our NAND configura- tion; (3) reflect real user behaviors in enterprise environments; (4) are extracted from under SSD-based storage systems. To the best of our knowledge, we could not find any workload which met all of the requirements at the same time. In particular, there are few enterprise SSD workloads which are opened to public. <ref type="table" target="#tab_10">Table 4</ref> summarizes the distributions of inter-arrival times of our I/O traces. Inter-arrival times were normalized over T e f f ective PROG which reflects parallel NAND operations supported by multiple channels and multiple chips per channel in the extended FlashBench. For example, for an enterprise environment, since up to 32 chips can serve write requests simultaneously, T e f f ective PROG is about 40 us (i.e., 1300 us of T PROG is divided by 32 chips.). On the other hand, for a mobile environment, since there are only 2 chips can serve write requests at the same time, T e f f ective PROG is 650 us. Although the mobile traces collected from Android smartphones (i.e., m down <ref type="bibr">[23]</ref> and m p2p1) exhibit very long inter-arrival times, normalized inter-arrival times over T e f f ective PROG are not much different from the enterprise traces, except that the mobile traces show distinct bimodal distributions which no write requests in 1 &lt;t≤ 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Endurance Gain Analysis</head><p>In order to understand how much MAX P/E is improved by DPES, each trace was repeated until the total sum of the effective wearing reached 3K. Measured MAX P/E values were normalized over that of baseline. <ref type="figure" target="#fig_10">Figure 9</ref> shows normalized MAX P/E ratios for eight traces with two different techniques. Overall, the improvement on MAX P/E is proportional to inter-arrival times as summarized in <ref type="table" target="#tab_10">Table 4</ref>; the longer inter-arrival times are, the more likely slow write modes are selected.</p><p>AutoFTL improves MAX P/E by 69%, on average, over baseline for the enterprise traces. For proj 0 and src1 2 traces, improvements on MAX P/E are less than 50% because inter-arrival times of more than 40% of write requests are shorter than T e f f ective PROG so that it is difficult to Avg. +69% +50% +76% +82% +78% +80% +39% +37%</p><p>Avg. +38% </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Baseline AutoFTL</head><p>Normalized overall write throughput -2.17%</p><p>Avg. -0.91% -0.66% -0.64% -1.49% -0.14% -0.36% -0.09% -0.03%</p><p>Avg. -0.06% On the other hand, for the mobile traces, AutoFTL improves MAX P/E by only 38%, on average, over baseline. Although more than 50% of write requests have interarrival times twice longer than T e f f ective PROG , autoFTL could not improve MAX P/E as much as expected. This is because the size of the circular buffer is too small for buffering the increase in the buffer utilization caused by the garbage collection. For example, when a NAND block is erased by the fast speed erase mode, the buffer utilization is increased by 40% for the mobile environment while the effect of the fast erase mode on the buffer utilization is less than 0.1% for the enterprise environment. Moreover, by the same reason, the slow erase speed mode cannot be used in the mobile environment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Overall Write Throughput Analysis</head><p>Although autoFTL uses slow write modes frequently, the decrease in the overall write throughput over baseline is less than 2.2% as shown in <ref type="figure" target="#fig_11">Figure 10</ref>. For proj 0 trace, the overall write throughput is decreased by 2.2%. This is because, in proj 0 trace, the circular buffer may become full by highly clustered write requests. When the circular buffer becomes full, if the foreground garbage collection should be invoked, the write response time of NAND chips can be directly affected. Although interarrival times in prxy 0 trace are relatively long over other enterprise traces, the overall write throughput is degraded more than the other enterprise traces. This is because almost all the write requests exhibit inter-arrival times shorter than 10 ms so that the background garbage collection is not invoked at all <ref type="bibr" target="#b3">4</ref> . As a result, the foreground garbage collection is more frequently invoked, thus increasing the write response time.</p><p>We also evaluated if there is an extra delay from a host in sending a write request to the circular buffer because of DPES. Although autoFTL introduced a few extra queueing delay for the host, the increase in the average queueing delay per request was negligible compared to T e f f ective PROG . For example, for src1 2 trace, 0.4% of the total programmed pages were delayed, and the average queueing delay per request was 2.6 us. For stg 0 trace, less than 0.1% of the total programmed pages were delayed, and the average queueing delay per request was 0.1 us.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Detailed Analysis</head><p>We performed a detailed analysis on the relationship between the erase voltage/speed modes and the improvement of MAX P/E . <ref type="figure" target="#fig_12">Figure 11</ref> presents distributions of EVmode's used for eight I/O traces. Distributions of EVmode's exactly correspond to the improvements of MAX P/E as shown in <ref type="figure" target="#fig_10">Figure 9</ref>; the more frequently a low erase voltage mode is used, the higher the endurance gain is. In our evaluations for eight I/O traces, lazy erases are rarely used for all the traces. <ref type="figure" target="#fig_1">Figure 12</ref>(a) shows distributions of ESmode's for eight I/O traces. Since the slow erase mode is selected by using the effective buffer utilization, there are little chances for selecting the slow erase mode for the mobile traces because the size of the circular buffer is only 80 KB. On the other hand, for the enterprise environment, there are more opportunities for selecting the slow erase mode. Even for the traces with short inter-arrival times such as proj 0 and src1 2, only 5%∼10% of block erases used the fast erase mode.</p><p>We also evaluated the effect of the slow erase mode on the improvement of MAX P/E . For this for evaluation, <ref type="bibr" target="#b3">4</ref> In our autoFTL setting, the background garbage collection is invoked when a idle time between two consecutive requests is longer than 300 ms.  we modified our autoFTL so that ESmode f ast is always used when NAND blocks are erased. (We represent this technique by autoFTL − .) As shown in <ref type="figure" target="#fig_1">Figure 12(b)</ref>, the slow erase mode can improve the NAND endurance gain up to 18%. Although the slow erase mode can increase the buffer utilization, its effect on the write throughput was almost negligible.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related Work</head><p>As the endurance of recent high-density NAND flash memory is continuously reduced, several system-level techniques which exploit the physical characteristics of NAND flash memory have been proposed for improving the endurance and lifetime of flash-based storage systems <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b22">24,</ref><ref type="bibr" target="#b23">25]</ref>. Mohan et al. investigated the effect of the damage recovery on the SSD lifetime for enterprise servers <ref type="bibr" target="#b7">[8]</ref>. They showed that the overall endurance of NAND flash memory can be improved with its recovery nature. Our DPES technique does not consider the self-recovery effect, but it can be easily extended to exploit the physical characteristic of the self-recovery of flash memory cells.</p><p>Lee et al. proposed a novel lifetime management technique that guarantees the lifetime of storage devices by intentionally throttling write performance <ref type="bibr" target="#b6">[7]</ref>. They also exploited the self-recovery effect of NAND devices, so as to lessen the performance penalty caused by write throttling. Unlike Lee's work (which sacrifices write performance for guaranteeing the storage lifetime), our DPES technique improves the lifetime of NAND devices without degrading the performance of NAND-based stor-age systems.</p><p>Wu et al. presented a novel endurance enhancement technique that boosts recovery speed by heating a flash chip under high temperature <ref type="bibr" target="#b22">[24]</ref>. By leveraging the temperature-accelerated recovery, it improved the endurance of SSDs up to five times. The major drawback of this approach is that it requires extra energy consumption to heat flash chips and lowers the reliability of a storage device. Our DPES technique improves the endurance of NAND devices by lowering the erase voltage and slowing down the erase speed without any serious side effect.</p><p>Jeong et al. proposed an earlier version of the DPES idea and demonstrated that DPES can improve the NAND endurance significantly without sacrificing the overall write throughput <ref type="bibr" target="#b23">[25]</ref>. Unlike their work, however, our work treats the DPES approach in a more complete fashion, extensively extending the DPES approach in several dimensions such as the erase speed scaling, shallow erasing and lazy erase scheme. Furthermore, more realistic and detailed evaluations using the timingaccurate emulator are presented in this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions</head><p>We have presented a new system-level approach for improving the lifetime of flash-based storage systems using dynamic program and erase scaling (DPES). Our DPES approach actively exploits the tradeoff relationship between the NAND endurance and the erase voltage/speed so that directly improves the NAND endurance with a minimal decrease in the write performance. Based on our novel NAND endurance model and the newly defined interface for changing the NAND behavior, we have implemented autoFTL, which changes the erase voltage and speed in an automatic fashion. Moreover, by making the key FTL modules (such as garbage collection and wear leveling) DPES-aware, autoFTL can significantly improve the NAND endurance. Our experimental results show that autoFTL can improve the maximum number of P/E cycles by 69% for enterprise traces and 38% for mobile traces, on average, over an existing DPES-unaware FTL.</p><p>The current version of autoFTL can be further improved in several ways. For example, we believe that the current mode selection rules are rather too conservative without adequately reflecting the varying characteristics of I/O workload. As an immediate future task, we plan to develop more adaptive mode selection rules that may adaptively adjust the buffer utilization boundaries for selecting write modes.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>V</head><label></label><figDesc>ISPP scaling ratio Normalized T PROG Increasing W Pi Decreasing W Pi (b) Normalized T PROG variations over different V ISPP scaling ratios.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: An overview of the incremental step pulse programming (ISPP) scheme for NAND flash memory. voltage region. While repeating ISPP loops, once NAND cells are verified to have been sufficiently programmed, those cells are excluded from subsequent ISPP loops. Since the program time is proportional to the number of ISPP loops (which are inversely proportional to V ISPP ), the program time T PROG can be expressed as follows:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: The effect of lowering the erase voltage on the NAND endurance.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: The relationship between the erase voltage and the minimum program time, and V ISPP scaling and M Pi scaling for dynamic program scaling. erased block would need at least twice longer program time than the nominal program time. On the other hand, if a NAND block were erased by EVmode 0 , where the erase voltage is same as the nominal erase voltage, the erased block can be programmed with the same nominal program time. In order to satisfy the minimum program time requirements of different EVmode i 's, we define five different write modes, Wmode 0 , ··· , Wmode 4 where Wmode i satisfies the minimum program time requirement of the blocks erased by EVmode i . Since the program time of Wmode j is longer than that of Wmode i (where j &gt; i), Wmode k , Wmode (k+1) , ··· , Wmode 4 can be used when writing to the blocks erased by EVmode k . Figure 5(b) shows how V ISPP should be scaled for each write mode so that the minimum program time requirement can be satisfied. The program time is normalized over the nominal T PROG . In order to form threshold voltage distributions within a given threshold voltage window, a fine-grained program control is necessary by reducing M Pi 's and W Pi 's. As described in Section 2.2, we can reduce W Pi 's by scaling V ISPP based on the program time requirement. Figure 5(b) shows the tradeoff relationship between the program time and V ISPP scaling ratio based on our NAND characterization study. The program time is normalized over the nominal T PROG . For example, in the case of</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 (</head><label>6</label><figDesc>Figure 6: The effect of erase time scaling on the NAND endurance.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>Mode index i of a EVmode i (b) The endurance model for ESmode slow .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: The proposed NAND endurance model for DPES-enabled NAND blocks.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>Baseline AutoFTL Normalized MAX P/E ratio +46%</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Comparisons of normalized MAX P/E ratios for eight traces.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 10 :</head><label>10</label><figDesc>Figure 10: Comparisons of normalized overall write throughputs for eight traces. use the lowest erase voltage mode. For the other enterprise traces, MAX P/E is improved by 79%, on average, over baseline. On the other hand, for the mobile traces, AutoFTL improves MAX P/E by only 38%, on average, over baseline. Although more than 50% of write requests have interarrival times twice longer than T</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 11 :</head><label>11</label><figDesc>Figure 11: Distributions of EVmode's used.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head></head><label></label><figDesc>(b) The effect of ESmode slow on improving MAX P/E .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 12 :</head><label>12</label><figDesc>Figure 12: Distributions of ESmode's used and the effect of ESmode's on MAX P/E .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>M P1 W P1 M P2 W P2 M P3 W P3 11 10 00 01</head><label></label><figDesc></figDesc><table>W Vth 

V Read 

Vth 
M Read 

V Ref0 
V Ref1 
V Ref2 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>0 , V Re f 1 and V Re f 2 . The threshold voltage gap M Pi between two adjacent states and the width W Pi of</head><label></label><figDesc>a threshold voltage distribution are mainly affected by data retention and program time re- quirements</figDesc><table>Four states are distinguished by dif-
ferent reference voltages, V Re f </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Figure 2 (b) shows normalized T PROG variations over dif- ferent V ISPP scaling ratios. (When a V ISPP scaling ratio is set to x%, V ISPP is reduced by x% of the nominal V ISPP .</head><label>2</label><figDesc></figDesc><table>) 
When a narrow threshold voltage distribution is needed, 
V ISPP should be reduced for a fine-grained control, thus 
increasing the program time. Since the width of a thresh-
old voltage distribution is proportional to V ISPP [14], for 
example, if the nominal V ISPP is 0.5 V and the width of a 
threshold voltage distribution is reduced by 0.25 V, V ISPP 
also needs to be reduced by 0.25 V (i.e., a V ISPP scaling 
ratio is 0.5), thus increasing T PROG by 100%. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Threshold voltage window V Read Vth Threshold voltage window Vth</head><label></label><figDesc></figDesc><table>V Read 

Saved 
threshold voltage 
margin 

MPi 
WPi 

MPi WPi 

( W Vth ) 

Erasing with a nominal erase voltage, 

Erasing with a small erase voltage, 

&gt; 

V 

nominal 
ERASE 

V 

small 
ERASE 

V 

nominal 
ERASE 

V 

small 
ERASE 

Figure 4: An example of program voltage scaling for 
writing data to a shallowly erased NAND block. 

their operations are based on the FN-tunneling mecha-
nism. It is expected that current 2D NAND devices will 
gradually be replaced by 3D NAND devices, but the ba-
sis of 3D NAND is still the FN-tunneling mechanism. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table NAND Flash MemoryExtended Mapping Table DeviceSettings Mode Selector</head><label>NAND</label><figDesc></figDesc><table>Wear 
Leveler 

DPES Manager 
Garbage 
Collector 

Background 

Foreground 

Number of 
pages 
to be copied 

Per-Block 
Mode Table 
NAND 
Setting Table 

EVmode j , ESmode k 

NAND Endurance 
Model 
Circular 
Buffer 

Program 
Erase 

Wmode 
Selector 
Emode 
Selector 

Wmode i 

Read 

Figure 8: An organizational overview of autoFTL. 

(which uses the smallest erase voltage) supports only the 
slowest write mode (i.e., Wmode 4 ) with the largest wear-
ing gain. Similarly, ESmode f ast is the fast erase mode 
with no additional wearing gain while ESmode slow rep-
resents the slow erase mode with the improved wearing 
gain. Our proposed NAND endurance model takes ac-
count of both V ISPP scaling and M Pi scaling described in 
Figures 5(b) and 5(c). 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 1 : The write-mode selection rules used by the DPES manager. Buffer utilization u Write mode</head><label>1</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" validated="false"><head>Table 2 : Examples of selecting write and erase modes in the garbage collector assuming that the circular buffer has 200 pages and the current buffer utilization u is 70%. (Case 1) The number of valid pages in a victim block is 30.</head><label>2</label><figDesc></figDesc><table>u copy 
u  *  
∆u erase 
u ′ 
Selected 
modes 

15% 
85% 
Slow 
8% 
93% 
EVmode 0 &amp; ESmode slow 
Fast 
2% 
87% 
Wmode 0 

(Case 2) The number of valid pages in a victim block is 50. 

u copy 
u  *  
∆u erase 
u ′ 
Selected 
modes 

25% 
95% 
Slow 
8% 
103% 
EVmode 0 &amp; ESmode f ast 
Fast 
2% 
97% 
Wmode 0 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" validated="false"><head>Table 3 : Summary of two FlashBench configurations.</head><label>3</label><figDesc></figDesc><table>Environments 
Channels 
Chips 
Buffer 

Mobile 
2 
2 
80 KB 

Enterprise 
8 
32 
32 MB 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10" validated="false"><head>Table 4 : Normalized inter-arrival times of write requests for 8 traces used for evaluations.</head><label>4</label><figDesc></figDesc><table>Trace 
Distributions of normalized 
inter-arrival times t over T 

e f f ective 
PROG 

[%] 

t ≤ 1 
1 &lt;t≤ 2 
t &gt; 2 

proj 0 
40.6% 
47.0% 
12.4% 

src1 2 
41.0% 
55.6% 
3.4% 

hm 0 
14.2% 
72.1% 
13.7% 

prxy 0 
8.9% 
34.6% 
56.5% 

stg 0 
7.1% 
81.5% 
11.4% 

web 0 
5.4% 
36.7% 
56.9% 

m down 
45.9% 
0.0% 
54.1% 

m p2p1 
49.5% 
0.0% 
50.5% 

</table></figure>

			<note place="foot" n="1"> Since short-lived data do not need a long data retention time, M Pi &apos;s are maintained loosely so that the NAND write performance can be improved.</note>

			<note place="foot" n="2"> In this paper, we use a linear approximation model which simplifies the wear-out behavior over P/E cycles. Our current linear model can overestimate the effective wearing under low erase voltage scaling ratios while it can underestimate the effective wearing under high erase voltage scaling ratios. We verified that, by the combinations of over-/under-estimations of the effective wearing in our model, the current linear model achieves a reasonable accuracy with an up to 10% overestimation [16] while supporting a simple software implementation.</note>

			<note place="foot" n="3"> Although it takes a longer erase time, the total sum of the effective wearing by lazily erasing a shallowly erased block is less than that by erasing with the initially high erase voltage. This can be explained in a</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We would like to thank Erik Riedel, our shepherd, and anonymous referees for valuable comments that greatly improved our paper. This work was supported by the National Research Foundation of Korea (NRF) grant funded by the Ministry of Science, ICT and Future Planning (MSIP) (NRF-2013R1A2A2A01068260). This research was also supported by Next-Generation Information Computing Development Program through NRF funded by MSIP <ref type="bibr">(No. 2010-0020724)</ref>. The ICT at Seoul National University and IDEC provided research facilities for this study.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A New 3-bit Programming Algorithm Using SLC-to-TLC Migration for 8 MB/s High Performance TLC NAND Flash Memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-H</forename><surname>Shin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Symp. VLSI Circuits</title>
		<meeting>IEEE Symp. VLSI Circuits</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">3D Approaches for Non-volatile Memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Symp. VLSI Technology</title>
		<meeting>IEEE Symp. VLSI Technology</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Moore&apos;s Law: The First Ending and A New Beginning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Chien</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page" from="2012" to="2018" />
		</imprint>
		<respStmt>
			<orgName>Dept. of Computer Science, the Univ. of Chicago</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Tech. Report</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Efficient Identification of Hot Data for Flash Memory Storage Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-W</forename><surname>Hsieh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Storage</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="22" to="40" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">CAFTL: A Content-Aware Flash Translation Layer Enhancing the Lifespan of Flash Memory Based Solid State Drives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. USENIX Conf. File and Storage Tech</title>
		<meeting>USENIX Conf. File and Storage Tech</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Improving Performance and Lifetime of Solid-State Drives Using Hardware-Accelerated Compression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Consum. Electron</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1732" to="1739" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Lifetime Management of FlashBased SSDs Using Recovery-Aware Dynamic Throttling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. USENIX Conf. File and Storage Tech</title>
		<meeting>USENIX Conf. File and Storage Tech</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">How I Learned to Stop Worrying and Love Flash Endurance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Mohan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. USENIX Workshop Hot Topics in Storage and File Systems</title>
		<meeting>USENIX Workshop Hot Topics in Storage and File Systems</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Bit Error Rate in NAND Flash Memories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Mielke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Reliability Physics Symp</title>
		<meeting>IEEE Int. Reliability Physics Symp</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Effects of Temperature and Defects on Breakdown Lifetime of Thin SiO 2 at Very Low Voltages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">F</forename><surname>Schuegraf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Electron Devices</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1227" to="1232" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Improving NAND Flash Memory Reliability with SSD Controllers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Flash Memory Summit</title>
		<meeting>Flash Memory Summit</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">FlashBench: A Workbench for a Rapid Development of Flash-Based Storage Devices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Symp. Rapid System Prototyping</title>
		<meeting>IEEE Int. Symp. Rapid System Prototyping</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Optimizing NAND Flash-Based SSDs via Retention Relaxation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R.-S</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. USENIX Conf. File and Storage Tech</title>
		<meeting>USENIX Conf. File and Storage Tech</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A 3.3 V 32 Mb NAND Flash Memory with Incremental Step Pulse Programming Scheme</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-D</forename><surname>Suh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE J. Solid-State Circuits</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1149" to="1156" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Stress-Test-Driven Qualification of Integrated Circuits</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jedec</forename><surname>Standard</surname></persName>
		</author>
		<idno>JESD47H.01</idno>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Dynamic Program and Erase Scaling in NAND Flash-based Storage Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<ptr target="http://cares.snu.ac.kr/download/TR-CARES-01-14" />
		<imprint>
			<date type="published" when="2014" />
		</imprint>
		<respStmt>
			<orgName>Seoul National Univ</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Tech. Report</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The Operation Algorithm for Improving the Reliability of TLC (Triple Level Cell) NAND Flash Characteristics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-W</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Memory Workshop</title>
		<meeting>IEEE Int. Memory Workshop</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">High-Efficiency SSD for Reliable Data Storage Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Flash Memory Summit</title>
		<meeting>Flash Memory Summit</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Data Integrity on 20 nm NAND SSDs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Frickey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Flash Memory Summit</title>
		<meeting>Flash Memory Summit</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">On Efficient Wear Leveling for Large-Scale Flash-Memory Storage Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-P</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM Symp. Applied Computing</title>
		<meeting>ACM Symp. Applied Computing</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title/>
		<ptr target="http://www.ibm.com/developerworks/library/l-timers-list/" />
	</analytic>
	<monogr>
		<title level="j">Kernel APIs</title>
		<imprint/>
	</monogr>
	<note>Part 3: Timers and Lists in the 2.6 Kernel</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Write Off-Loading: Practical Power Management for Enterprise Storage</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Narayanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. USENIX Conf. File and Storage Tech</title>
		<meeting>USENIX Conf. File and Storage Tech</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Exploiting Heat-Accelerated Flash Memory Wear-Out Recovery to Enable SelfHealing SSDs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. USENIX Workshop Hot Topics in Storage and File Systems</title>
		<meeting>USENIX Workshop Hot Topics in Storage and File Systems</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Improving NAND Endurance by Dynamic Program and Erase scaling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jeong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. USENIX Workshop Hot Topics in Storage and File Systems</title>
		<meeting>USENIX Workshop Hot Topics in Storage and File Systems</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
