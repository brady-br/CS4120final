<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2020-09-29T02:49+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Impression Store: Compressive Sensing-based Storage for Big Data Analytics</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaxing</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Microsoft Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Yan</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Microsoft Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Liang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Microsoft Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minjie</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Microsoft Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Microsoft Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Moscibroda</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Microsoft Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Microsoft Research</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Impression Store: Compressive Sensing-based Storage for Big Data Analytics</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>For many big data analytics workloads, approximate results suffice. This begs the question, whether and how the underlying system architecture can take advantage of such relaxations, thereby lifting constraints inherent in today&apos;s architectures. This position paper explores one of the possible directions. Impression Store is a distributed storage system with the abstraction of big data vectors. It aggregates updates internally and responds to the retrieval of top-K high-value entries. With proper extension , Impression Store supports various aggregations, top-K queries, outlier and major mode detection. While restricted in scope, such queries represent a substantial and important portion of many production workloads. In return, the system has unparalleled scalability; any node in the system can process any query, both reads and updates. The key technique we leverage is compres-sive sensing, a technique that substantially reduces the amount of active memory state, IO, and traffic volume needed to achieve such scalability.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Data volume has been increasing at an unprecedented pace. Systems for storing and querying big data have developed from a single server to thousands of commodity machines, with no end in sight to this growth. Such drastic changes bring many challenges to system design; deep complexities are baked into the ever-increasing cloud of machines. Yet, performance is often lame, limiting both the system's and the data's usefulness.</p><p>For example, an analysis of hundreds of daily inproduction data mining jobs on Microsoft's SCOPE <ref type="bibr" target="#b5">[7,</ref><ref type="bibr" target="#b20">22]</ref> platform-a large-scale data processing engine that combines MapReduce's explicit parallel executions and SQL's declarative query constructs-reveals that they consume two thousand machine-hours on average, and some jobs take up to 10 hours. Such performance numbers highlight the limits of today's brute-force, heavy provisioning approach; despite consisting of thousands of machines, applications can issue only a low volume of queries toward these systems.</p><p>In this paper, we investigate the benefits of a radically different approach. We postulate that, by and large, the complexity of today's systems is a result of an architecture that neither anticipates nor accommodates the particular needs of big data analytics. There is a clear division of labor between storage and processing. The responsibility of storage is to store data reliably and to provide as much IO-bandwidth to the data as possible, while the one of processing is to handle query logics. However, applications are rarely interested in raw data records. Instead, they typically issue queries against aggregated values (e.g. sum...group by...), which can be understood by humans. Of most interest to users are analytics that "query impressions", i.e., high-value statistics such as majority, mode, top-K and outliers. For such queries, there is even more potential for reducing storage, IObandwidth requirements and communication. This is especially the case for high-dimensional data, a combination of numerous data attributes that can typically be represented in a sparse form at little loss of fidelity. Sparsity implies that when "querying impressions", the majority of mass concentrates on the heads of the distribution, a characteristic that we can exploit for efficient processing.</p><p>In this paper, we show that for this category of big data analytics-cases such as top-K analysis and outlier detection that constitutes a large portion of production workloads as we observed-new system-level abstractions can yield fundamental improvements in performance and scalability. Specifically, we adopt an application-driven approach to re-design an architecture, in which we intentionally blur the boundary of storage and processing. The insight is that we do not need to store all data accurately, as long as the system can return application-defined elite components successfully. This saves storage capacity and IO bandwidth, and allows for efficient and scalable parallel updates and queries.</p><p>Different from a traditional key-value store <ref type="bibr" target="#b6">[8]</ref>, Impression Store provides an abstraction of a big data vector that aggregates value updates to each element and only supports the retrieval of top-K components. This abstraction may seem constrained, but supports a wide array of applications we have in mind. In return, we obtain a system that is simpler, more efficient and fundamentally more scalable. In particular, in Impression Store any node can process any query (including updates) concurrently within bounded response time. Since the delay between updates and queries is shrunk dramatically, the system can provide continuous snapshots against a standing query. As a result, our design can also be an alternative to scalable streaming processing, again with a radically different architecture.</p><p>One key enabling technology in our design is Compressive Sensing (CS). CS is an efficient technique of sampling high-dimensional data that has an underlying sparse structure. In the context of our work, we can regard CS as a technique that provides a compressed snapshot (or sketch) of data. CS is essentially a lossy compression, but the corresponding decompression algorithm discriminates components in data vectors by their values. Consequently, it is possible to prioritize the accuracy of principal components with high values. This property fits our target applications well, because elite components, such as top-K components and outliers, can be represented as high values by appropriate modelling and/or transformations. Furthermore, we show that CS naturally supports increments on compressed data. Increments are commutative and associative, allowing for parallel processing at a massive scale. This property is important because applications' target data, such as query or click logs, is continuously changing.</p><p>The system architecture of Impression Store is shown in <ref type="figure">Figure 1</ref>. Instead of storing the entirety or portions of the original data vector, each node in the store maintains a compressed snapshot of the complete data vector. These snapshots are obtained by CS-techniques with a compression ratio that is necessary to recover only the application-defined principal components. Queries are issued through the Impression Store's API: A read-only query can be processed by any node over its local snapshot; an update query can be issued against the compressed snapshot in a random selected node. Updates are further aggregated, compressed, and propagated to other nodes following an anti-entropy protocol. These attributes ensure that the system's throughput is essentially proportional to its scale. Since both the state stored on each node, as well as that of the anti-entropy protocol are compressed, storage, IO bandwidth requirements and communication overhead is drastically reduced. This reduction relieves the pressure on the underlying hardware infrastructure, making the system easier to scale.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Related Work</head><p>Many distributed stores are off the shelf <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b6">8,</ref><ref type="bibr" target="#b13">15]</ref> for general-purpose applications by keeping all the data precisely. In contrast, Impression Store is designed to serve statistical queries, which leads to more economic storage and communication.</p><p>Compressive Sensing (CS) is a breakthrough in the signal processing community. Its basic ideas and mathematical foundations have been established in <ref type="bibr" target="#b3">[5,</ref><ref type="bibr" target="#b4">6,</ref><ref type="bibr" target="#b10">12,</ref><ref type="bibr" target="#b16">18]</ref>. CS is an efficient approach to sample and reconstruct sparse data, with many applications (e.g., photography <ref type="bibr" target="#b11">[13]</ref>, image reconstruction and recognition <ref type="bibr" target="#b17">[19]</ref>, and network traffic monitoring <ref type="bibr" target="#b19">[21]</ref>). In our work, we use CS to compress and recover sparse data vectors.</p><p>Traditional lossless and lossy compression techniques <ref type="bibr">[2,</ref><ref type="bibr" target="#b1">3,</ref><ref type="bibr" target="#b8">10,</ref><ref type="bibr" target="#b9">11,</ref><ref type="bibr" target="#b21">23]</ref> have been developed for many decades. However, they are either inefficient for continuouslychanging big data or only fit for some specific domains such as images and videos. Data sketches <ref type="bibr" target="#b7">[9,</ref><ref type="bibr" target="#b14">16]</ref> in databases provide compressed snapshots of big data. CS compressed data can be viewed as a special form of data sketches, with high accuracy on principal components.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Compressive Sensing for Big Data</head><p>We introduce Compressive Sensing (CS) and show why it is a good fit for "querying impressions". A data vector x = [x 1 , x 2 , ...x N ] T ∈ R N is sparse if there are only a few high-value principal components over other minor ones.</p><formula xml:id="formula_0">In compression, given an M × N (M &lt; N) measurement matrix Φ = [ϕ 1 , ϕ 2 , ..., ϕ N ]</formula><p>, each of whose column vectors ϕ i is randomly generated, the data vector x is compressed to a measurement vector y by y = Φx.</p><p>Due to the linearity in the compression, CS is uniquely suited for data that is (i) distributed in different locations, and (ii) updated frequently. When the global data vector x is an aggregation of multiple local data vectors x l distributed on different nodes by x = ∑ l x l , we first do the compression on each individual node and then aggregate local measurements together for the global measurement on x. That is,</p><formula xml:id="formula_1">y = Φx = ∑ l Φx l = ∑ l y l .</formula><p>Similarly, when there is an update vector ∆x updating x to x + ∆x, we can first compress the update and add that to the original measurement incrementally: Φ(x+∆x) = y+Φ∆x = y + ∆y. Overall, the linearity in CS allows us to avoid decompressing compressed data for aggregation or updates, scenarios in which traditional compression techniques often face challenges and may not be applicable.</p><p>To reconstruct the sparse data vector from the measurements, one of the most widely used recovery algorithms is Orthogonal Matching Pursuit (OMP) <ref type="bibr" target="#b15">[17,</ref><ref type="bibr" target="#b16">18]</ref>, which is a greedy approach. Starting from a residual r = y and an empty selection set Ψ, OMP in each iteration selects the column vector φ ∈ Φ that has the largest Issue to any node <ref type="figure">Figure 1</ref>: Architecture of Impression Store inner product with the current residual r, and inserts it into Ψ. y is projected to the subspace spanned by Ψ to get its projection y , and the residual is updated by r = y−y . When OMP is finished, the projected coefficients are the estimation of the principal components in x. Due to its greedy nature, OMP has unique advantages when used on distributed big data, where measurement and recovery can pose significant IO-bandwidth, network traffic and computational overhead. OMP naturally recovers the top-K components in the first few iterations. Thus, for many impression queries, OMP can be stopped early. Also, OMP requires much fewer measurements to recover the top-K components, as compared to when recovering the entire data. Also, OMP can be extended to Bias OMP (BOMP) <ref type="bibr" target="#b18">[20]</ref> to retrieve the majority (mode) and outliers from non-sparse data. <ref type="figure" target="#fig_0">Figure 2</ref> shows an experiment on the recovery of a large-scale production revenue data set with 12891 advertisement groups (see Section 4 for details). The measurement size M must be bigger than 800 to recover the top-50 components. However, if we are only interested in the top-20 components, M = 300 is enough for high accuracy reconstruction using OMP. We observe that M N (in our case M = 2.3%N) and K M (K = 6.3%M) holds qualitatively for sparse data. This is the underlying reason for the performance savings of Impression Store.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Design</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Data Model and Architecture</head><p>The overall architecture of Impression Store is illustrated in <ref type="figure">Figure 1</ref>. It is the responsibility of the client of Impression Store to map a table into data vectors by flattening the interesting values. The keys for these values are organized into a dictionary that is persistently stored and cached on the client. A translation module in the client is responsible for translating the SQL-like queries to operations on these data vectors. For ease of exposition, we describe the main Impression Store APIs of one data vector x. Other than miscellaneous operations such as setting up and destroying the vectors, there are two main operators: Update(i,∆x) adds or subtracts the value ∆x at index i of x. For retrieval, Query(K) returns the top-K values in x. The first operator mutates the vector entries, whereas the second one is a read-only query. Any of the queries can be issued to any node in the system. Using BOMP, Impression Store also provides OutlierAnalysis(K) to return the majority and top-K outliers in x. Each node works on three tasks continuously: (1) Aggregate and Compress Data Updates. The accumulated client-side update ∆x l results in the corresponding measurement, ∆y l = Φ∆x l . Φ is an M × N measurement matrix that all nodes agree on and can be generated on the fly. (2) Update Synchronization, to be described in more details shortly, propagates the changes throughout the system so that y l (the snapshot at l) is as close to the global oracle measurement y = ∑ l ∆y l as possible. <ref type="formula">(3)</ref> Top-K Recovery. When any node l receives Query(K), it reconstructs the top-K values from y l using OMP, and returns the index-value pairs. Throughout the system, both the amount of state and traffic volume are bounded by O(M), a small fraction of the original data size N. Compression and recovery takes computation power, but they involve only standard matrix computations that can be greatly accelerated with GPUs, which are themselves commodities. It is insightful to consider an alternative design that achieves the any-query-any-node scaling property by spreading updates across all nodes and then aggregating them. Such an alternative would require an N/M-fold increase of state space and network bandwidth, but it could return the approximate value at any position (which our applications do not require), and perform top-K queries with O(N log K) computation complexity (non-trivial for large N). Therefore, Impression Store can be viewed as a design that trades off computation for scalability.</p><p>One may argue that the above comparison is unfair, since Impression Store performs lossy compression, whereas the other alternative is more expensive simply because it pays the cost of being lossless. Such baseline can indeed be relaxed, by keeping M higher ranked entries and returning the top-K among them. One problem is that it is unlikely that each node agrees on the position of the M entries to keep. Even if the distribution is uniform enough, not recording any information other than the M top entries runs the risk that some entries outside them may eventually catch up and enter the competition, a scenario that is not at all unlikely. The root of the problem is that in this case the baseline is losing too much. As we will show in Section 4, Impression Store can cope with such dynamics much more effectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Update Synchronization</head><p>In Impression Store, updates are randomly issued at any node. The compressed measurement of the client-side updates received at node l, ∆y l , needs to be propagated and aggregated. At any given point of time, there is a global oracle measurement y = ∑ l ∆y l , and the goal of the synchronization protocol is to let every node's local version, y l , converge to y quickly and eventually. A conventional approach is to perform in-network aggregation, deriving y at the root of the tree, which is then propagated downwards. Generalizing that idea and eliminating the single root bottleneck, we describe an alternative design that works for any loop-free topology.</p><p>We use N (l) to denote the neighbors of node l. y l , the local version of the global measurement at node l, is y l = ∆y l + ∑ q∈N (l) ψ q→l . Intuitively, ψ q→l represents the contribution of the neighbour q and its sub-tree from l's point of view. This state has the master copy at q and a mirror copy at l, denoted by ψ q q→l and ψ l q→l respectively. At quiescent time they are equal, and if the master copy ψ q q→l advances, anti-entropy between the two will update the mirror copy ψ l q→l . If y l is changed due to an update of ∆y l or from its neighbours, then it re-computes ψ l l→p = y l − ψ l p→l , and triggers anti-entropy. The protocol can be proved to achieve eventual consistency. Therefore all nodes in Impression Store will converge to the same measurement vector eventually. Since the only requirement of the protocol is loop-free topology, it is more flexible. A single-level tree with one node fans out to all others implements a master-slave architecture and converges in two hops, whereas a chain topology ( <ref type="figure">Figure 1</ref>) converges with O(L) speed but has even loads. Anything in between works equally well, except with different convergence and load-balance trade-offs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Fault Tolerance</head><p>It is very expensive to prevent a distributed system from losing any updates when some nodes suffer permanent failure. It is not our design goal that Impression Store does not lose any updates. When a node l fails and is replaced by a new one, the major loss is the updates that are applied to l but not yet propagated to its neighbors. For the scenario we target, we believe such loss is tolerable. As long as the switch-over is rapid and update frequency high enough, the chance of messing up the rank is low.</p><p>Our failover protocol tries to recover various states on a single failed node l. We first restore the invariance ψ l p→l ≡ ψ p p→l and ψ l l→p ≡ ψ p l→p by copying the relevant states from every neighbor p. Then we recover ∆y l by computing ψ l l→p − ∑ N (l)/p ψ l q→l for each neighbor p and pick the one with largest version number as the restored ∆y l . Finally, we re-compute all ψ l l→p and trigger the anti-entropy protocol to synchronize with their mirror copies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Optimization</head><p>The computation complexity of the standard OMP algorithm is O(M 2 * N), i.e., it is costly to recover the top k on a data vector with big size N. However, there has been work to accelerate the recovery algorithms by GPU with 30X ∼ 40X speed-up <ref type="bibr" target="#b2">[4,</ref><ref type="bibr" target="#b12">14]</ref>. Using an off-the-shelf device NVIDIA GTX480, OMP on a data vector with tens of thousands of components takes only about 1 second <ref type="bibr" target="#b12">[14]</ref>.</p><p>The OMP algorithm could be further optimized for continuously updated data. In our optimized OMP, it keeps remembering the positions of the selected column vectors. These position correspond to the principal components in current data vector x, and do not change a lot over a short period. Then, our OMP prioritizes those positions for the next recovery with only O(M 3 ) complexity. Due to limitation of space, we skip more details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Preliminary Results</head><p>In this section, we focus on evaluating recovery quality in Impression Store using simulation, driven by real product data of the revenue on advertisement (Ads) entries in Bing search engine. Updates of these entries are spread across different machines, and are grouped by the type of the hosting-page that is described by a tuple (Market,Vertical,QueryClass,...). After removing the trivial zeros, the aggregated revenues on all the Ads groups construct a data vector with size 12891. Taking a snapshot x of the data vector, we test the top-K Here, x I and˜x˜Iand˜ and˜xand˜x˜ and˜x˜I are vectors of the entries specified by I and˜Iand˜ and˜I, respectively.</p><p>We first evaluate the effect of measurement size M on the top-K result quality. For each (M, K) pair, we run our compression and recovery algorithm 100 times, each with random measurement matrices; the maximum E P and E V of these runs are the error bounds. The effect on E P is illustrated in <ref type="figure" target="#fig_1">Figure 3(a)</ref>. We can see that, M increases roughly linearly with K to keep the same error bound. With E P = 20%, to get top-10 values, there needs only 300 measurements, 2.3% × N. The effect on E V are demonstrated in <ref type="figure" target="#fig_1">Figure 3(b)</ref>. The accuracy of the recovered top-K values is stable with the increase of K for a given M. When M = 3% × N, Impression Store can return top-100 values with E V ≤ 5%.</p><p>Next, we evaluate the robustness of Impression Store with a fixed measurement size M. The setting is such that there is one entry below rank 300, which continuous to receive positive updates, whereas all other entries gets random updates. The correct behavior of the system should be that this entry is gradually captured, and gets increasingly accurate. We compare against a traditional store which keeps the top-300 list only, and therefore an entry can enter the list if only if a one-time update bumps it into the top-300 list. As shown in <ref type="figure" target="#fig_2">Fig- ure 4</ref>, after several updates, this entry gets captured by Impression Store and is recovered more and more accurately after t = 20. In contrast, in the traditional store, this entry makes it into top-300 only after one lucky update, and its prior history was completely forgotten, resulting in a constant error. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion and Future Work</head><p>Designing an efficient and scalable system infrastructure for massive-scale big data analytics is a tremendous challenge. While analytics algorithms are increasingly relying on sophisticated mathematical techniques to exploit the sparsity of the data, the underlying system infrastructure has largely remained unchanged. In this paper, we argue that there are substantial benefits in not only adapting data processing, but the entire system architecture. If data is sparse and queries are mostly focusing on dominant components, a distributed system architecture that tightly integrates with Compressive Sensing can fundamentally increase performance and scalability. There are numerous avenues for future work. Our current prototype builds on a narrow subset of CS theory. By exploiting CS techniques more thoroughly, Impression Store can support more sophisticated queries. For example, it is possible to directly recover a linear transformation from the data vector, without changing the measurement. In this way, Impression Store could return aggregations on a key A from a table keyed on (A,B).</p><p>Another extension is sampling. In the current design, the original data is not kept. However, the raw data on each node is effectively a sample of the entire data. These samples can be used to answer queries other than those covered by CS. Multiple parallel queries to different nodes can help to improve confidence.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: An example of OMP recovery for top-K components. Only the top-50 components are shown. The two figures use different measurement size M.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: M v.s. K over different error bounds recovery accuracy by comparing the ground-truth top-K list I versus the recovered one˜Ione˜ one˜I. There are two errors that are of interests, captured by the following metrics: Error on Position : E P = 1 − |I ∩ ˜ I|/K. Error on Value : E V = ˜ x ˜ I − x I 2 /x I 2 . Here, x I and˜x˜Iand˜ and˜xand˜x˜ and˜x˜I are vectors of the entries specified by I and˜Iand˜ and˜I, respectively. We first evaluate the effect of measurement size M on the top-K result quality. For each (M, K) pair, we run our compression and recovery algorithm 100 times, each with random measurement matrices; the maximum E P and E V of these runs are the error bounds. The effect on E P is illustrated in Figure 3(a). We can see that, M increases roughly linearly with K to keep the same error bound. With E P = 20%, to get top-10 values, there needs only 300 measurements, 2.3% × N. The effect on E V are demonstrated in Figure 3(b). The accuracy of the recovered top-K values is stable with the increase of K for a given M. When M = 3% × N, Impression Store can return top-100 values with E V ≤ 5%. Next, we evaluate the robustness of Impression Store with a fixed measurement size M. The setting is such that there is one entry below rank 300, which continuous to receive positive updates, whereas all other entries gets random updates. The correct behavior of the system should be that this entry is gradually captured, and gets increasingly accurate. We compare against a traditional store which keeps the top-300 list only, and</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Estimation of increasing revenue on a Ads group</figDesc></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hadoop</surname></persName>
		</author>
		<ptr target="http://hadoop.apache.org/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mpeg</surname></persName>
		</author>
		<ptr target="http://mpeg.chiariglione.org/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Fast gpu implementation of sparse signal recovery from random projections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrecut</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Engineering Letters</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="151" to="158" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Robust uncertainty principles: Exact signal reconstruction from highly incomplete frequency information. Information Theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cand`escand` Cand`es</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Romberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="489" to="509" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Near-optimal signal recovery from random projections: Universal encoding strategies. Information Theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Candes</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="5406" to="5425" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Scope: easy and efficient parallel processing of massive data sets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaiken</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Jenkins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Larson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-Ra</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramsey</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Shakib</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Weaver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhou</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PVLDB</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Bigtable: A distributed storage system for structured data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">C</forename><surname>Wal-Lach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Burrows</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chandra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Fikes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gruber</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">E</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Computer Systems (TOCS)</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">An overview of query optimization in relational systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaudhuri</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PODS</title>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="34" to="43" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Data compression using adaptive coding and partial string matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cleary</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Witten</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Communications</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="396" to="402" />
			<date type="published" when="1984" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">DEFLATE compressed data format specification version</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deutsch</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename></persName>
		</author>
		<ptr target="http://www.ietf.org/rfc/rfc1951.txt" />
		<imprint>
			<date type="published" when="1951" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Compressed sensing. Information Theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donoho</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">L</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1289" to="1306" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Singlepixel imaging via compressive sampling. Signal Processing Magazine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duarte</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">F</forename><surname>Davenport</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Takhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Laska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">N</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">F</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baraniuk</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">G</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="83" to="91" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Gpu implementation of orthogonal matching pursuit for compressive sensing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2011 IEEE 17th International Conference on Parallel and Distributed Systems</title>
		<meeting>the 2011 IEEE 17th International Conference on Parallel and Distributed Systems<address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1044" to="1047" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The google file system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ghemawat</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gobioff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leung</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGOPS Operating Systems Review</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2003" />
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="29" to="43" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A survey of top-k query processing techniques in relational database systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilyas</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">F</forename><surname>Beskales</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Soliman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys (CSUR)</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page">11</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Orthogonal matching pursuit: Recursive function approximation with applications to wavelet decomposition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pati</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">C</forename><surname>Rezaiifar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Krishnaprasad</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Signals, Systems and Computers, 1993. 1993 Conference Record of The TwentySeventh Asilomar Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1993" />
			<biblScope unit="page" from="40" to="44" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Signal recovery from random measurements via orthogonal matching pursuit. Information Theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tropp</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gilbert</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page" from="4655" to="4666" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Robust face recognition via sparse representation. Pattern Analysis and Machine Intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wright</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ganesh</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="210" to="227" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Distributed outlier detection using compressive sensing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaxing</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">H J M Z Z</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moscibroda</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename></persName>
		</author>
		<ptr target="http://research.microsoft.com/apps/pubs/default.aspx?id=217534" />
		<imprint>
			<date type="published" when="2014-05" />
		</imprint>
	</monogr>
<note type="report_type">Tech. rep., Microsoft Research</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Spatio-temporal compressive sensing and internet traffic matrices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Roughan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Willinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiu</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ACM SIGCOMM Computer Communication Review</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="267" to="278" />
			<date type="published" when="2009" />
			<publisher>ACM</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Scope: parallel databases meet mapreduce</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhou</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bruno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-C</forename><surname>Larson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-Ra</forename><surname>Chaiken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shakib</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">VLDB J</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Compression of individual sequences via variable-rate coding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziv</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lempel</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Theory</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="530" to="536" />
			<date type="published" when="1978" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
