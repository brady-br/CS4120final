<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2020-09-29T02:46+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">An analysis of automatic image filtering on WeChat Moments</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Knockel</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">The Citizen Lab</orgName>
								<orgName type="department" key="dep2">Munk School of Global Affairs</orgName>
								<orgName type="institution">University of Toronto</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lotus</forename><surname>Ruan</surname></persName>
							<email>lotusruan@citizenlab.ca</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">The Citizen Lab</orgName>
								<orgName type="department" key="dep2">Munk School of Global Affairs</orgName>
								<orgName type="institution">University of Toronto</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masashi</forename><surname>Crete-Nishihata</surname></persName>
							<email>masashi@citizenlab.ca</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">The Citizen Lab</orgName>
								<orgName type="department" key="dep2">Munk School of Global Affairs</orgName>
								<orgName type="institution">University of Toronto</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">An analysis of automatic image filtering on WeChat Moments</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We report results from a series of experiments that uncover mechanisms used to filter images on WeChat, the most popular social media platform in China. Our results inform strategies for evading image filtering on the application. By performing tests on a collection of politically sensitive images filtered by WeChat, we found that WeChat uses two different algorithms to filter, an Optical Character Recognition (OCR)-based algorithm that filters images containing sensitive text, and a visual-based algorithm that filters images that are visually similar to those on an image blacklist. The OCR-based algorithm has implementation similarities to many common OCR algorithms that allow us to create text images that evade filtering. We found that the visual-based algorithm does not use any machine learning approach that uses high level classification of an image to determine whether it is sensitive; however, we discovered multiple implementation details of the visual-based algorithm that inform the creation of images that are visually similar to those blacklisted but that evade filtering. This study is the first in-depth technical analysis of image filtering on WeChat, and we hope that our methods will serve as a road map for studying image censorship on other platforms.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>WeChat is the most popular social media platform in China and the fourth largest in the world <ref type="bibr" target="#b6">[7]</ref>. Users in China spend a third of their online time on WeChat and typically return to the app ten times a day or more <ref type="bibr" target="#b34">[34]</ref>. The application is owned and operated by Tencent, one of the largest technology companies in China. One of its most frequently used functions is WeChat Moments <ref type="bibr" target="#b33">[33]</ref>, a feature similar to the Facebook Timeline in which users can share images and other content.</p><p>Any application operating in China is subject to government mandated information controls and companies are expected to invest in technology and personnel to carry out content regulations <ref type="bibr" target="#b27">[28]</ref>. Prior work on WeChat has analyzed keyword-based filtering <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b31">31]</ref>, censorship of Public Posts (a platform designed for companies and users to make public blog posts requiring manual approval for account registration) <ref type="bibr" target="#b24">[25]</ref>, and has reported cases of image filtering <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b29">30]</ref>. Missing from the literature is an in-depth analysis of how image filtering is technically implemented. We address this gap through a series of experiments. By performing tests on a collection of politically sensitive images filtered by WeChat, we uncover mechanisms WeChat uses to filter images, and through these results we identify multiple evasion strategies.</p><p>We found that WeChat Moments uses two different algorithms to filter images, an Optical Character Recognition (OCR)-based algorithm that filters images containing sensitive text, and a visual-based algorithm that filters images that are visually similar to those on an image blacklist. We found that the OCR-based algorithm has implementation similarities to many common OCR algorithms that allow us to create image text that evades filtering. We found that the visual-based algorithm is not based on any machine learning approach that uses high level classification of an image to determine whether it is sensitive or not; however, we identified multiple implementation details of the visual-based algorithm that allow us to create images that are visually similar to those blacklisted but that evade filtering.</p><p>Through our findings we provide a better understanding of how image filtering is implemented on an application with over one billion users. We hope that our methods will generalize and serve as a road map for studying image censorship on other platforms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>Content censorship can be implemented client-side (i.e., on an application itself) or server-side (i.e., on a remote server). In a client-side implementation, the rules to perform censorship are inside of the application running on a user's device. An application with client-side keyword censorship will often have a built-in list of keywords, which can be updated when the client connects with a server. If any banned keywords are present in a user's message before the message is sent, the message is not sent. In a server-side implementation the rules to perform censorship are on a remote server. When a message is sent, it passes through the server which checks if banned keywords are present and, if detected, blocks the message.</p><p>Prior work on applications that implement client-side censorship has used reverse engineering techniques to extract keyword lists used to trigger censorship on chat apps <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b11">12]</ref>, live streaming services <ref type="bibr" target="#b17">[18]</ref>, and online games <ref type="bibr" target="#b18">[19]</ref>. Studies of server-side censorship generally rely on sample testing in which researchers either (1) develop a set of content suspected to be blocked by a platform, send the sample to the platform, and record the results <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b31">31]</ref>; or (2) select public posts and monitor them for deletion <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b38">38,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b2">3]</ref>.</p><p>WeChat hosts user-generated content through three main features: chat functions, WeChat Moments, and the Public Account platform. Previous research has documented censorship on all of these features <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b31">31]</ref>. WeChat implements filtering server-side and only enables censorship for users with accounts registered to mainland China phone numbers <ref type="bibr" target="#b31">[31]</ref>. Censorship on WeChat is not transparent: the message or post containing sensitive content simply does not appear on the receiver's end and no notice is given to the sender that their message is blocked or why it was blocked. Previous research <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b35">35]</ref> has reported incidents of images being blocked on WeChat but has not systematically investigated the technical mechanism used to implement image filtering. Our study contributes to the literature with the first in-depth technical analysis of image filtering on WeChat.</p><p>Neural network-based image classifiers are known to be vulnerable to adversarial examples, i.e., images with minor modifications that cause them to be misclassified <ref type="bibr" target="#b32">[32,</ref><ref type="bibr" target="#b9">10]</ref>. While early work in generating adversarial examples assumed a whitebox threat model where all implementation details including the trained gradients of the target network were known, more recent work <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b12">13]</ref> is capable of generating adversarial examples by estimating the network's gradients. However, the work assuming the most restrictive threat model <ref type="bibr" target="#b12">[13]</ref> is limited in that it still assumes that the attacker can acquire probability scores for the top k categories for arbitrary images. In our work, we have found that not only does WeChat not use a machine learning approach for filtering images but, even if it did, the threat model for evading a censorship filter is even more restrictive than that currently assumed in the adversarial example literature, as the only signal available is whether or not an uploaded image is filtered. Our work differs from that in the adversarial example literature in that we construct evasion techniques by discovering and exploiting other important implementation details of the filtering algorithm that are effective independently of whether the filter uses machine learning classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Analysis</head><p>We measured which images were automatically filtered on WeChat Moments by posting images using an account registered to a non-Chinese phone number and measuring whether they were visible using an account registered to a Chinese phone number. We found that WeChat uses two different filtering mechanisms to filter images: an OCR-based approach that searches images for sensitive text and a visual-based approach that visually compares an uploaded image against a list of blacklisted images. In this section we describe how testing for and understanding implementation details of both of these filtering methods led to effective evasion techniques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">OCR-based filtering</head><p>We found that one approach that Tencent uses to filter sensitive images is to use OCR technology to detect sensitive text inside the image. In this section we outline ways to evade WeChat's OCR filtering discovered by identifying two different stages of the OCR algorithm. To restrict our analysis to automated filtering, we only considered images filtered within 60 seconds of being posted, as we found that images filtered using OCR were typically removed in 5 to 30 seconds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Grayscale conversion</head><p>OCR algorithms may use different strategies to recognize text. However, at a high level, we found that WeChat's OCR algorithm shares implementation details with other algorithms. As most OCR algorithms do not operate directly on color images, the first step they take is to convert a color image to grayscale so that it only consists of black, white, and intermediate shades of gray, as this largely simplifies text recognition since the algorithms only need to operate on one channel.</p><p>To test if WeChat's OCR filtering algorithm grayscaleconverted color images, we designed test images that would evade filtering if the OCR algorithm converted uploaded images to grayscale. We designed the images to contain text hidden in the hue of an image in such a way that it is easily legible by a person reading it in color but such that once it is converted to grayscale, the text disappears and is invisible to the OCR algorithm. If the image evaded censorship, then the OCR algorithm converts images to grayscale (see <ref type="figure">Figure A.</ref>1 for an illustration) <ref type="bibr" target="#b0">1</ref> .</p><p>As we did not know which formula the OCR algorithm used to convert color images to grayscale, we evaluated multiple possibilities. In principle, the gray intensity of a color pixel could be calculated according to any function of its red, green, and blue intensities. We evaluated three different formulas, the average [36, Chapter 9], lightness [36, <ref type="bibr">Chapter 9]</ref>, and luminosity <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b21">22]</ref> formulas: is the color in RGB colorspace and 1.0 is the highest intensity of each channel. These six colors were chosen because they have maximum saturation in the HSL colorspace and a simple representation in the RGB colorspace. For each color (r, g, b) and for grayscale formula f , we created an image whose text was color (r, g, b) and whose background was the gray color <ref type="bibr">(Y, Y, Y )</ref>, where Y = f (r, g, b). We chose for the text content of each image a selection of 25 keyword combinations randomly chosen from a set of keywords we found from testing to be filtered via OCR filtering (see <ref type="figure">Figure A.</ref>2 for an illustration). We used the same text content for each image.</p><formula xml:id="formula_0">• average(r, g, b) = 1 3 (r + g + b) • lightness(r, g, b) = 1 2 max(r, g, b) + 1 2 min(r, g, b) • luminosity(r, g, b) = 0.299r + 0.587g + 0.114b.</formula><p>After performing this test, we found that only when choosing the intensity of the gray background as given by the luminosity formula could we consistently evade filtering for every tested color. The other formulas failed to evade censorship with most colors. The averaging algorithm only evaded filtering when using red or cyan text, and the lightness algorithm only evaded when using green or magenta text.</p><p>To confirm that using the luminosity formula to choose the text's background color consistently evaded WeChat's OCR filtering, we performed a more extensive test using only that algorithm. We selected five lists of 25 randomly chosen keywords we found from testing to be blocked. We also selected five lists of 10, 5, 2, and 1 keyword(s) chosen at random. For each of these lists, we created six images, one for each of the same six colors we used in the previous experiment. Our results were that all 150 images evaded filtering. These results show that we can consistently evade WeChat's filtering by hiding colored text on a gray background chosen by the luminosity of the text and that WeChat's OCR algorithm uses the same or similar formula for grayscale conversion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Blob merging</head><p>After converting a colored image to grayscale, another step in most OCR algorithms is to apply a thresholding algorithm to the grayscale image to convert each pixel, which may be some shade of gray, to either completely black or completely white such that there are no shades of gray in between. Then, after thresholding, some OCR algorithms perform a step called blob merging. In order to recognize each character, these algorithms try to determine which blobs in an image correspond to each character. Many characters such as the English letter "i" are made up of unconnected components. In languages such as Chinese, individual characters can be made up of many unconnected components (e.g., 診). OCR algorithms use a variety of algorithms to try to combine these blobs into characters and to evaluate which combinations produce the most recognizable characters.</p><p>To test whether WeChat's OCR filtering performed blob merging, we experimented with uploading images that could be easily read by a person but that would be difficult to read by an algorithm piecing together blobs. To do this, we experimented with using two different patterns to fill text instead of using solid colors. Specifically, we used a tiled square pattern and a tiled letter pattern (see <ref type="figure">Figure A.</ref>3), both black on white. Using these patterns causes most characters to be made up of a large number of disconnected blobs in a way that is easily readable by most people but that is difficult for OCR algorithms performing blob merging. The second pattern that tiles English letters was designed to especially confuse an OCR algorithm by tricking it into finding the letters in the tiles as opposed to the larger characters that they compose.</p><p>To test if blobs of this type affected the OCR algorithm, we created a series of test images. We selected five lists of 25 randomly chosen keywords we knew to be blocked. We also selected five lists of 10, 5, 2, and 1 keyword(s) chosen at random. For each of these lists, we created two images, one with the text patterned in squares and another patterned in letters. For images with a large number of keywords, we decreased the font size to ensure that the generated images fit within a 1000×1000 pixel image. This is to ensure that images did not become too large and to ensure that they would not be downscaled, as we had previously experienced some images larger than 1000×1000 downscaled by WeChat. We did this to control for any effects that downscaling the images could have on our experiment such as blurring the text.</p><p>Our results were that square-patterned text evaded fil-tering in 92% of our tests, and letter-patterned text evaded filtering in 100% of our tests. Two tests of the square pattern failed to evade filtering. Both of them were test images containing 25 keywords. The reason for this failure is not clear, but we consider two possibilities. One is that the higher number of keywords per image increased the probability that at least one of those keywords would not evade filtering. The second is that images with a larger number of keywords used a smaller font size, and so there were fewer blobs per character, reducing the effectiveness of the evasion strategy. Letters were more effective in evading filtering. This result may be because of the previously suggested hypothesis that the OCR filter would be "distracted" by the letters in the pattern and thus miss the characters in which they collectively form, but it may also be because the letters are less dense insofar as they have fewer black pixels per white. Overall, these results suggest that WeChat's OCR filtering algorithm considers blobs when performing text recognition and that splitting characters into blobs is an effective evasion strategy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Visual-based filtering</head><p>In addition to OCR-based filtering, to censor images that do not contain text, we found that WeChat uses another filtering algorithm that works by comparing an image's visual similarity to those on a list of blacklisted images. We performed modifications to politically sensitive images blacklisted by WeChat to test different hypotheses concerning how the filter operated and to inform strategies for evading the visual-based filter. Like when testing WeChat's OCR-based filtering, to restrict our analysis to automated filtering, we again only considered images filtered within 60 seconds of being posted, although we found that images filtered using visual-based methods were typically removed within only 10 seconds, often so quickly that they were never visible in our other account's view. As we found that the visual-based method typically takes less time than the OCR-based one, their visualbased algorithm would appear to be less computationally expensive than the one used for OCR filtering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Grayscale conversion</head><p>Similar to our testing of the OCR-based algorithm, we performed an experiment determining if and how the visual-based algorithm converts images to grayscale. Unlike when testing the OCR-based algorithm where the foreground consisted of text, for testing the visual-based algorithm our foreground consisted of the white pixels of a black-and-white image. We took a political cartoon featuring the Hong Kong and PRC flags and thresholded it to black and white. After verifying that the thresholded version of the image was still filtered, we used the white pixels of the image as the foreground and the black pixels of the image as the background (see <ref type="figure">Figure A</ref>.4 for an illustration). For each of the six different foreground colors, we again selected the background according to three grayscale algorithms, and found that, like when testing the OCR algorithm, only when using the luminosity formula were the images consistently filtered.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Machine learning classification</head><p>Machine learning can be used to classify images into high level categories such as "cat" or "dog" depending on the contents of the image. If WeChat chose to use a machine learning classification approach, they could attempt to train a network to recognize whether an image may lead to government reprimands. However, training a network against such a nebulous and nuanced category would be rather difficult considering the vagueness of Chinese content regulations and the fluidity of what is considered sensitive <ref type="bibr" target="#b20">[21]</ref>. Instead, they might identify certain categories of images that would be potentially sensitive, such as images of Falun Gong practitioners or of Liu Xiaobo, the late Nobel prize-winning dissident, and then classify whether images belong to these sensitive categories.</p><p>In our analysis, we found ample evidence that they do not use such a categorization system. We investigated different transformations to 15 images that we found from testing to be filtered on WeChat (see <ref type="figure">Figure A</ref>.5). For instance, many image transformations such as mirroring typically preserve the semantic meaning of an image (e.g., a mirrored image of a cat is still a cat). However, when we mirrored the 15 images, we found that none of them were filtered after mirroring (see <ref type="figure">Figure A.</ref>6 for an illustration). Other semantic-preserving operations such as cropping or adding whitespace to an image also evaded filtering. These and other results suggest that no sort of high level machine learning classification system is being used to trigger the observed filtering on WeChat. Rather, these results suggest that there is a specific blacklist of images being maintained by WeChat that each image uploaded is somehow being compared against using some similarity metric.</p><p>While many Internet technology companies are known to use machine learning to flag pornographic content <ref type="bibr" target="#b37">[37,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b15">16]</ref>, in this study we focus on content automatically filtered on WeChat for political reasons. For this type of content, a blacklist approach may be desirable as it allows WeChat to quickly censor specific sensitive images that may be trending or that they are otherwise asked to censor by a government official regardless of the topic or category of the image. However, as we found, this approach also allows one to evade the filter by simple image transformations like mirroring since the filter has no semantic understanding of what the contents of images are.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3">Edge detection</head><p>Edges may be used to compare image similarity. Intuitively, edges represent the boundaries of objects and other features in images. There are generally two approaches to edge detection. The first approach, as taken by (e.g.) a Sobel filter, involves taking the differences between adjacent pixels. One weakness of this approach is that by signifying small differences as low intensity and larger differences as high intensity, it still does not specify in a 0-or-1 sense which are the "real" edges and which are not. A different approach is to use a technique like Canny edge detection which uses a number of filtering and heuristic techniques to reduce each pixel of a Sobelfiltered image to either black (no edge) or white (an edge is present) (see <ref type="figure">Figure A.</ref>7 for an illustration). As this reduces each pixel to one bit, it is more computationally efficient to use as an image feature.</p><p>There is some reason to think that WeChat's filtering may incorporate edge detection. When we searched online patents for references to how Tencent may have implemented their image filtering, we found that in June 2008 Tencent filed a patent in China called "图片检测 系统及方法" (System and method for detecting a picture) <ref type="bibr" target="#b39">[39]</ref>. In it they describe a real-time system for detecting blacklisted images after being uploaded that performs Canny edge detection before generating a fingerprint.</p><p>We found designing experiments to test for the use of Canny edge detection difficult. The algorithm is highly parameterized, and the parameters are often determined dynamically using heuristics based on the contents of an image. Moreover, unlike many image transformations such as grayscale conversion, Canny edge detection is not idempotent, i.e., the canny edge detection of a canny edge detection is not the same as the original canny edge detection. This means that we cannot simply upload an edge-detected image and see if it gets filtered. Instead, we created test images by removing as many potentially relevant features of an image as possible while preserving the edges of an image. We used thresholding to reduce each pixel to either black or white, eliminating any gray pixels from the image, while hopefully largely preserving the edges in the image (see <ref type="figure">Figure A.</ref>8 for an illustration). We performed this technique on the 15 images we tested in the previous section (see <ref type="figure">Figure A</ref>.5) using a threshold dynamically chosen according to Otsu's method <ref type="bibr" target="#b26">[27]</ref>. We found that all but two of the images were still filtered after being thresholded. Among the two images that were not filtered, one was the image of Liu Xiaobo's empty chair ( ). This result may be because thresholding does not preserve edges well with backgrounds with gradients, as thresholding will typically create an erroneous edge where none actually exists.</p><p>As an additional test, we took the 15 images thresholded using Otsu's method and inverted them. This technique would preserve the location of all edges while radically altering the intensity of many pixels. We found that among the thirteen images that were filtered after applying Otsu's method, only four images were filtered after they were additionally inverted (see <ref type="figure">Figure A</ref>.5 images 5, 6, 7, and 10). The two images that were not filtered before were also not filtered after being inverted. This result suggests that, if edge detection is used, it is either in addition to other features of the image, or the edge detection algorithm is not one such as the Canny edge detection algorithm which only tracks edges not their "sign", i.e., whether the edge is going from lighter to darker versus darker to lighter.</p><p>After our experiment eliminating as many potentially relevant features as possible except for edges, we tried the opposite experiment by eliminating edges by blurring them while keeping other features untouched. We proportionally resized each image such that its smallest dimension(s) is/are 200 pixels (see Section 3.2.4 for why we resized this way). Then we applied a normalized box filter to blur the image, increasing the kernel size until the image is sufficiently blurred to evade filtering.</p><p>In general, we saw that for most images WeChat's filter was not robust to blurring (see <ref type="figure">Figure A</ref>.9 for full results). Non-photographic images were generally the easiest to evade filtering by blurring, possibly because they generally have sharper and more well-defined edges.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.4">Resizing</head><p>Up until this point, we have been mostly concerned with experimenting with images that have the same aspect ratios. In this section we test how changing images' dimensions affected WeChat's ability to recognize them. For instance, we found WeChat's filter clearly had the ability to filter sensitive images regardless of scale so long as the aspect ratio had been preserved. We wanted to explore whether WeChat normalizes the dimensions of uploaded images to a canonical size, and, if so, how.</p><p>To answer these questions, we decided to test five different hypotheses: (1) Images are proportionally resized such that their width is some value such as 100. <ref type="formula">(2)</ref> Images are proportionally resized such that their height is some value such as 100. <ref type="formula">(3)</ref> Images are proportionally resized such that their largest dimension is some value such as 100. <ref type="formula">(4)</ref> Images are proportionally resized such that their smallest dimension is some value such as 100. (5) Both dimensions are resized according to two param-eters to some fixed size and proportion such as 100×100.</p><p>If the last hypothesis is correct, then we would expect WeChat's filter to be robust to modifications to a sensitive image's aspect ratio, as any aspect ratio changes would be removed when the image is resized to a fixed aspect ratio. To test this hypothesis, we tested stretching the fifteen images from <ref type="figure">Figure A</ref>.5. We tested stretching each image 30% thinner and 30% shorter. We found that stretching the images was highly effective at evading the filter, as all of the images stretched shorter evaded filtering as well as all of the thinner images except for a drawing of Liu Xiaobo and his wife <ref type="bibr">(Figure A.5 Image #11)</ref>. This suggests that the last hypothesis is incorrect.</p><p>To test hypotheses 1 through 4, we made the following corresponding predictions: <ref type="formula">(1)</ref>  To test these predictions, we chose a set of ten filtered images, five such that their height is no more than 2 3 of their width, which we call the wide images, and five such that their width is no more than 2 3 of their height, which we call the tall images (see <ref type="figure">Figure A.10)</ref>. We then modified each of the images by adding blank black space the size of 50% of their width to their left and right sides (see <ref type="figure">Figure A</ref>.11 for an example) and again by adding black space the size of 50% of their height to their top and bottom sides. We repeated these again except by using 200% of the respective dimensions.</p><p>We found that wide images with space added to their width and tall images with space added to their height were always filtered. This is consistent with hypothesis 4, that WeChat resizes based on an uploaded image's shortest dimension, as this hypothesis predicts that adding space in this matter will not change the scale of the original image contents after the image is resized. We also found that 4 out of 5 wide images with space added to their height and 3 out of 5 tall images with space added to their width evaded filtering, suggesting that this caused the uploaded image to be further downscaled compared to the corresponding one on the blacklist.</p><p>The results between adding 50% and 200% extra space were fairly consistent, with only one fewer tall image being filtered. This consistency is to be expected, since according to the shortest dimension hypothesis, adding extra space past when the image has already become square will not affect its scaling.</p><p>It is not clear why some images-two tall images with extra width and one wide image with extra height-were still filtered. It is possible that WeChat's filtering algorithm has some robustness to changes in scale. However, it is also possible that variants of these images with extra space or some other border or content added in these areas are also on the blacklist. For example, the only wide image with extra height to still be filtered is the famous and highly reproduced Tank Man photo taken during the Tiananmen Square protests of 1989 (see <ref type="figure">Figure A.</ref>10 Wide Image #4). A reverse Google Image search found that there are many images with similar spacing added to them already in circulation on the Internet. Nevertheless, adding height to wide images or width to tall images was generally an effective strategy for evading filtering while preserving the image's visual appearance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.5">Sliding window</head><p>In the previous section, we tested how we could evade WeChat's filtering by extending the canvases of sensitive images in different ways depending on their aspect ratios. In the instances extending the canvas did not evade the filter, such as by adding height to a tall image or width to a wide image, this suggested that WeChat's filter exhibits translational invariance, i.e., the ability for WeChat's filter to find an image if its canvas has been extended.</p><p>Translational invariance only requires that the filter recognize the image when the extended space is blank or black. What if the added content is not blank? Can that allow us to evade the filter? In this section we are concerned with whether the algorithm is not simply translationally invariant but whether it can find an image inside of another image regardless of its surrounding contents.</p><p>In our testing we found that WeChat's server-side image compression would increase compression for larger images and that the resulting compression artifacts could cause uploaded images to evade filtering. We carefully designed our experiment to control for this. Taking our five wide and five tall images used in the previous section (see <ref type="figure">Figure A.</ref>10), we extended their canvases on each side in their largest dimension by i · n, for a total of 2 · i · n, for each i in {1, 2, . . . , 5}, where n is the size of the largest dimension. We first extended their canvases with blackness. As many image operations such as thresholding and edge detection are sensitive to an image's distribution of pixel intensities, to control for this, we also extended their canvases with a duplicate copy of the image itself so that the distribution of pixel intensities is not affected (see <ref type="figure">Figure A</ref>.12 for an illustration). To account for WeChat's compression, for any image we generated, if it evades filtering, we download the image and crop out the extended canvas, restoring it to its original size. If this image still evades filtering when uploaded, then we conclude that this is from the additional compression artifacts and not necessarily from the contents of the extended canvas.</p><p>We found that images extended with their own duplicates evaded filtering after a sufficiently large number of duplicates were added, and none of these evasions could be explained by image compression (see <ref type="figure">Figure A</ref>.13 for full results). Conversely, in all but one test, images extended with blank canvases were either filtered or their evasion could be explained by image compression. These results suggest that, even when we add additional contents to an uploaded image such that its distribution of pixel intensities do not change, these contents affect the ability of WeChat to recognize the uploaded image as sensitive. This finding suggests that WeChat may not use a sliding window approach that ignores contents outside of that window to compare images. Instead, the images appear to be compared as a whole and that adding complex patterns outside of a blacklisted image's original canvas can evade filtering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.6">Summary of visual-based filtering findings</head><p>In this section we have described a number of characteristics of WeChat's visual-based filtering. Our understanding of some of its mechanics has informed multiple strategies for evading the filter. However, the entire algorithm used by the filter is still unclear and understanding more about how the algorithm works may inform additional evasion strategies.</p><p>Our finding that the filter exhibits translational invariance may be the most informative clue in understanding the complete algorithm used by the filter. The use of template matching <ref type="bibr" target="#b1">[2]</ref> would explain translational invariance. However, it is typically used to find images inside of other images as opposed to image comparison in itself. Moreover, template matching typically finds matches in a sliding window, which is incompatible with our finding that adding complex content outside of the window can evade the filter.</p><p>Perceptual hashing is a technique to reduce an image to a hash such that similar images have either equal <ref type="bibr" target="#b19">[20]</ref> or similar <ref type="bibr" target="#b14">[15]</ref> hashes to facilitate efficient comparison. It is used by many social media companies such as Facebook, Microsoft, Twitter and YouTube <ref type="bibr" target="#b7">[8]</ref> to filter illegal content. Spectral methods can be used to achieve a hash exhibiting translational invariance. The popular open source implementation pHash <ref type="bibr" target="#b14">[15]</ref> computes a hash using the discrete cosine transform, which is not translationally invariant. However, an alternative spectral computation that would exhibit translational invariance would be to calculate the image's amplitude spectrum by computing the absolute magnitude of the discrete Fourier transform of the image, as translation only affects the phase, not the magnitude, of the image's frequencies <ref type="bibr">[11, page 126]</ref>. The use of a hash based on this computation would be consistent with our findings, but more work is needed to test if this technique, in possible combination with other image processing algorithms, is used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>An effective image filter evasion strategy is one that modifies a sensitive image so that it (1) no longer resembles a blacklisted image to the filter but (2) still resembles a blacklisted image to people reading it. The two ways we present to evade WeChat's OCR filter, via its implementations of grayscale conversion and blob merging, meet both of these requirements, as the resulting text is still easily legible to people but baffles the filter.</p><p>Regarding evading the visual-based filter, we discovered multiple evasion techniques, each with tradeoffs.</p><p>Since the filter has no semantic understanding of the image, simple transformations like mirroring the image evade filtering. However, these may reverse text or otherwise fail to preserve meaningful details of the image. In our tests, edges appeared to be important features to WeChat's filter, as blurring would quickly evade the filter. However, edges are perceptually important to people too, so blurring may be undesirable. Based on how the filter resizes images to a canonical size, we found the conditions under which one may extend the canvas with a black border and have the image evade filtering. This option generally preserves the important perceptual qualities of an image except for adding a black border to it in one or more dimensions. Finally, we found that if the border is not black but contains some sufficiently complex patterns, then it does not matter which side(s) the border is added to. Generally though, it is simpler to add a black (or other simple) border according to the conditions we identified based on how WeChat resizes images.</p><p>In this work we presented experiments uncovering implementation details of WeChat's image filter and multiple effective evasion strategies. While the focus of this work has been WeChat, due to common implementation details between image filter implementations, we hope that our methods will serve as a road map for future research studying image censorship on other platforms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Supplementary material</head><p>This section includes supplementary visualizations and data. These figures are referenced in the paper to help illustrate different image transformations and to provide the complete results of our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm Result</head><p>Original Average Lightness Luminosity <ref type="figure">Figure A</ref>.1: An image with green text and a background color of gray with the same shade as the text according to the luminosity formula for grayscale and how the text would appear to an OCR algorithm according to three different grayscale algorithms. If the OCR algorithm uses the same grayscale algorithm that we used to determine the intensity of the gray background, then the text effectively becomes invisible to the algorithm. 2 <ref type="bibr" target="#b1">2</ref> The figures in this section are generally intended to be displayed in color. If displayed in grayscale, then the image features in the color examples in this figure may disappear depending on how the display or printer converts color to grayscale, and the color examples may appear as solid gray rectangles. This is not unlike how these image's features are hidden from WeChat's filter when it converts them to grayscale.      With one exception, all images extended with blank canvases that evaded filtering did so due to compression artifacts, whereas when extending an image with duplicates of itself, none of the filtering evasion can be explained by compression artifacts.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>To evaluate each formula, we created images contain- ing filtered text in six different colors: red, (</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure A. 5</head><label>5</label><figDesc>Image #2). This result may be because the threshold chosen by Otsu's method did not distinguish the stripes on the chair. The other was a photograph of Liu Xiaobo and his wife clanging coffee cups (Figure A.5 Image #9</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>If images are propor- tionally resized based on their width, then adding extra space to their width would evade filtering but adding it to their height would not. (2) If images are proportion- ally resized based on their height, then adding extra space to their height would evade filtering. (3) If images are proportionally resized based on their largest dimension, then adding extra space to that dimension would evade filtering. (4) If images are proportionally resized based on their smallest dimension, then adding extra space to that dimension would evade filtering.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure A. 2 :</head><label>2</label><figDesc>Figure A.2: Each of the six colors of text tested. Here the background color of each of the above images was chosen according to the luminosity of the text's color. 2</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure A. 4 :Figure A. 5 :</head><label>45</label><figDesc>Figure A.4: Each of the six colors tested. Here the intensity of the gray background of each image was chosen according to the luminosity of the foreground color. 2</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure A. 6 :</head><label>6</label><figDesc>Figure A.6: Left, an image of Liu Xiaobo. Right, the mirrored image. Despite both images showing a depiction of the deceased Liu Xiaobo, only the original image on the left is filtered.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure A. 7 :</head><label>7</label><figDesc>Figure A.7: Two kinds of edge detection. Left, the original image. Center, the image with a Sobel filter applied. Right, the Canny edge detection algorithm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure A. 8 :Figure A. 9 :</head><label>89</label><figDesc>Figure A.8: Left, the original image. Center, the image in grayscale. Right, the image thresholded according to Otsu's method. All three images are filtered.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure A. 12 :Figure A. 13 :</head><label>1213</label><figDesc>Figure A.12: Above, an image extended with i = 2 blank canvases to the left and right. Below, an image extended with i = 2 duplicates of itself.</figDesc></figure>

			<note place="foot" n="1"> Due to the volume of illustrations and data, all figures are in Appendix A.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This research was supported by the Open Society Foundations. We would like to thank our reviewers for insightful feedback.</p><p>Image testing data and source code is available at https://github. com/citizenlab/chat-censorship/tree/ master/wechat/image-filtering.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Censorship and deletion practices in Chinese social media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bamman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>O&amp;apos;connor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">First Monday</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Template Matching Techniques in Computer Vision: Theory and Practice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Brunelli</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>John Wiley &amp; Sons</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Why autocrats sometimes relax online censorship of sensitive issues: A case study of microblog discussion of air pollution in china</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Cairns</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Plantan</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Midwest Political Science Association Annual Conference</title>
		<meeting><address><addrLine>Chicago, IL</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-04" />
			<biblScope unit="volume">8</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Zeroth Order Optimization Based Black-box Attacks to Deep Neural Networks without Training Substitute Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-J</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zoo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security</title>
		<meeting>the 10th ACM Workshop on Artificial Intelligence and Security</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="15" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Chat program censorship and surveillance in China: Tracking TOM-Skype and Sina UC</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Crandall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Crete-Nishihata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Knockel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mckune</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Senft</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tseng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wiseman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">First Monday</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">7</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Analyzing censorship of the death of Liu Xiaobo on WeChat and Weibo</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Crete-Nishihata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Knockel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Q</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ruan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Tsui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">Remebering</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Liu Xiaobo</surname></persName>
		</author>
		<ptr target="https://citizenlab.ca/2017/07/analyzing-censorship-of-the-death-of-liu-xiaobo-on-wechat-and-weibo/" />
		<imprint>
			<date type="published" when="2017" />
		</imprint>
		<respStmt>
			<orgName>Citizen Lab, University of Toronto</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Tech. rep.</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Tencent&apos;s WeChat hits 1 billion milestone as Lunar New Year boosts monthly active users</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Deng</surname></persName>
		</author>
		<ptr target="http://www.scmp.com/tech/apps-gaming/article/2135690/tencents-wechat-hits-1-billion-milestone-lunar-new-year-boost" />
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Partnering to Help Curb Spread of Online Terrorist Content</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Facebook</surname></persName>
		</author>
		<ptr target="https://newsroom.fb.com/news/2016/12/partnering-to-help-curb-spread-of-online-terrorist-content/" />
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Assessing Censorship on Microblogs in China: Discriminatory Keyword Analysis and the Real-Name Registration Policy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chau</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Internet Computing</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="42" to="50" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6572</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">Explaining and Harnessing Adversarial Examples. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Computer Image Processing and Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hall</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1979" />
			<publisher>Elsevier</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Investigating Regionally-based Keyword Censorship in LINE</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">Asia</forename><surname>Hardy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chats</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
		<respStmt>
			<orgName>Citizen Lab, University of Toronto</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Tech. rep.</note>
	<note>Available at https</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ilyas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Engstrom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Athalye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lin</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1804.08598</idno>
		<title level="m">Black-box Adversarial Attacks with Limited Queries and Information</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">How Censorship in China Allows Government Criticism but Silences Collective Expression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>King</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Roberts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Political Science Review</title>
		<imprint>
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="page" from="326" to="343" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">The open source perceptual hash library</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Klinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Starkweather</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Phash</surname></persName>
		</author>
		<ptr target="http://phash.org/" />
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Twitter&apos;s Artificial Intelligence Knows What&apos;s Happening in Live Video Clips</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Knight</surname></persName>
		</author>
		<ptr target="https://www.technologyreview.com/s/601284/twitters-artificial-intelligence-knows-whats-happening-in-live-video-clips/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Three researchers, five conjectures: An empirical analysis of TOM-Skype censorship and surveillance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Knockel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Crandall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Saia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">FOCI&apos;11 (USENIX Workshop on Free and Open Communications on the Internet</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Every Rose Has Its Thorn: Censorship and Surveillance on Social Video Platforms in China</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Knockel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Crete-Nishihata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Q</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Senft</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Crandall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">5th USENIX Workshop on Free and Open Communications on the Internet (FOCI 15</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Measuring Decentralization of Chinese Keyword Censorship via Mobile Games</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Knockel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ruan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Crete-Nishihata</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">7th USENIX Workshop on Free and Open Communications on the Internet</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Robust perceptual image hashing via matrix invariants</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Kozat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Venkatesan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">K</forename><surname>Mihçak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Image Processing, 2004. ICIP&apos;04. 2004 International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2004" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="3443" to="3446" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">China&apos;s &quot;Networked Authoritarianism</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mackinnon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Democracy</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="32" to="46" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Convert RGB image or colormap to grayscale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mathworks</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>Available at https</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Simple Black-Box Adversarial Perturbations for Deep Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Narodytska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">P</forename><surname>Kasiviswanathan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1612.06299</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Blocked on Weibo -Search result logs and full list of banned words</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Q</forename><surname>Ng</surname></persName>
		</author>
		<ptr target="http://blockedonweibo.tumblr.com/post/12729333782/search-result-logs-and-full-list-of-banned-words" />
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Tracking Censorship on WeChat&apos;s</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Q</forename><surname>Ng</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Open Source Computer Vision library. Miscellaneous Image Transformations</title>
		<ptr target="https://docs.opencv.org/2" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A Threshold Selection Method from GrayLevel Histograms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Otsu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on systems, man, and cybernetics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="62" to="66" />
			<date type="published" when="1979" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Journey to the heart of Internet censorship</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Reporters Without Borders</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>China</surname></persName>
		</author>
		<ptr target="http://www.rsf.org/IMG/pdf/Voyage_au_coeur_de_la_censure_GB.pdf" />
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
<note type="report_type">Tech. rep.</note>
	<note>Reporters Without Borders</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Filtering inappropriate content with the Cloud Vision API</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Robinson</surname></persName>
		</author>
		<ptr target="https://cloud.google.com/blog/big-data/2016/08/filtering-inappropriate-content-with-the-cloud-vision-api" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ruan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Knockel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cretenishihata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>We</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">709</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Crackdown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Discussions Blocked on Weibo and WeChat. Tech. rep</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
		<respStmt>
			<orgName>Citizen Lab, University of Toronto</orgName>
		</respStmt>
	</monogr>
	<note>Available at https</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Two Systems: How WeChat uses one censorship policy in China and another internationally</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ruan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Knockel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Q</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">One</forename><surname>Cretenishihata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>App</surname></persName>
		</author>
		<ptr target="https://citizenlab.ca/2016/11/wechat-china-censorship-one-app-two-systems/" />
		<imprint>
			<date type="published" when="2016" />
		</imprint>
		<respStmt>
			<orgName>Citizen Lab, University of Toronto</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Tech. rep.</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fergus</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6199</idno>
		<title level="m">Intriguing properties of neural networks</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tencent</surname></persName>
		</author>
		<ptr target="http://tech.qq.com/a/20160321/030364.htm" />
		<title level="m">微信&quot;影响力报告： 用数据读懂微信五 大业务. Available at</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">WeChat&apos;s world</title>
		<ptr target="https://www.economist.com/business/2016/08/06/wechats-world" />
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>The Economist</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Why Does Emperor Xi Dislike Winnie the Pooh and Scrambled Eggs? Avail</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Ullrich</surname></persName>
		</author>
		<ptr target="https://isc.sans.edu/forums/diary/Why+Does+Emperor+Xi+Dislike+Winnie+the+Pooh+and+Scrambled+Eggs/23395/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Van Gumster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Shimonski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bible</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>John Wiley and Sons</publisher>
			<biblScope unit="volume">616</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Open nsfw model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yahoo</surname></persName>
		</author>
		<ptr target="https://github.com/yahoo/open_nsfw" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">The Velocity of Censorship: High-fidelity Detection of Microblog Post Deletions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Phipps</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Pridgen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Crandall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename><surname>Wallach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd USENIX Conference on Security</title>
		<meeting>the 22nd USENIX Conference on Security</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="227" to="240" />
		</imprint>
	</monogr>
	<note>USENIX Association</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">陈</forename><forename type="middle">波</forename><surname>图 片 检 测 系 统 及 方 法</surname></persName>
		</author>
		<ptr target="https://encrypted.google.com/patents/CN101303734A?cl=tr" />
	</analytic>
	<monogr>
		<title level="j">CN Patent App. CN</title>
		<imprint>
			<biblScope unit="volume">200</biblScope>
			<biblScope unit="page">798</biblScope>
			<date type="published" when="2008-12" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
