<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2020-09-29T02:14+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">ParaFS: A Log-Structured File System to Exploit the Internal Parallelism of Flash Devices ParaFS: A Log-Structured File System to Exploit the Internal Parallelism of Flash Devices</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>June 22-24. 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiacheng</forename><surname>Zhang</surname></persName>
							<email>zhang-jc13@mails.tsinghua.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="laboratory">Tsinghua National Laboratory for Information Science and Technology</orgName>
								<orgName type="institution" key="instit1">Tsinghua University</orgName>
								<orgName type="institution" key="instit2">Tsinghua University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwu</forename><surname>Shu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="laboratory">Tsinghua National Laboratory for Information Science and Technology</orgName>
								<orgName type="institution" key="instit1">Tsinghua University</orgName>
								<orgName type="institution" key="instit2">Tsinghua University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youyou</forename><surname>Lu</surname></persName>
							<email>luyouyou@tsinghua.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="laboratory">Tsinghua National Laboratory for Information Science and Technology</orgName>
								<orgName type="institution" key="instit1">Tsinghua University</orgName>
								<orgName type="institution" key="instit2">Tsinghua University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiacheng</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="laboratory">Tsinghua National Laboratory for Information Science and Technology</orgName>
								<orgName type="institution" key="instit1">Tsinghua University</orgName>
								<orgName type="institution" key="instit2">Tsinghua University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwu</forename><surname>Shu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="laboratory">Tsinghua National Laboratory for Information Science and Technology</orgName>
								<orgName type="institution" key="instit1">Tsinghua University</orgName>
								<orgName type="institution" key="instit2">Tsinghua University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youyou</forename><surname>Lu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="laboratory">Tsinghua National Laboratory for Information Science and Technology</orgName>
								<orgName type="institution" key="instit1">Tsinghua University</orgName>
								<orgName type="institution" key="instit2">Tsinghua University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">ParaFS: A Log-Structured File System to Exploit the Internal Parallelism of Flash Devices ParaFS: A Log-Structured File System to Exploit the Internal Parallelism of Flash Devices</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2016 USENIX Annual Technical Conference (USENIC ATC &apos;16)</title>
						<meeting>the 2016 USENIX Annual Technical Conference (USENIC ATC &apos;16) <address><addrLine>Denver, CO, USA</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="volume">87</biblScope>
							<date type="published">June 22-24. 2016</date>
						</imprint>
					</monogr>
					<note>This paper is included in the Open access to the Proceedings of the 2016 USENIX Annual Technical Conference (USENIX ATC &apos;16) is sponsored by USENIX. https://www.usenix.org/conference/atc16/technical-sessions/presentation/zhang USENIX Association</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>File system designs are undergoing rapid evolution to exploit the potentials of flash memory. However, the internal parallelism, a key feature of flash devices, is hard to be leveraged in the file system level, due to the semantic gap caused by the flash translation layer (FTL). We observe that even flash-optimized file systems have serious garbage collection problems, which lead to significant performance degradation, for write-intensive workloads on multi-channel flash devices. In this paper, we propose ParaFS to exploit the internal parallelism while ensuring efficient garbage collection. ParaFS is a log-structured file system over a simplified block-level FTL that exposes the physical layout. With the knowledge of device information, ParaFS first proposes 2-D data allocation, to maintain the hot/cold data grouping in flash memory while exploiting channel-level parallelism. ParaFS then coordinates the garbage collection in both FS and FTL levels, to make garbage collection more efficient. In addition, ParaFS schedules read/write/erase requests over multiple channels to achieve consistent performance. Evaluations show that ParaFS effectively improves system performance for write-intensive workloads by 1.6× to 3.1×, compared to the flash-optimized F2FS file system.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Flash memory has been widely adopted across embedded systems to data centers in the past few years. In the device level, flash devices outperform hard disk drives (HDDs) by orders of magnitude in terms of both latency and bandwidth. In the system level, the latency benefit has been made visible to the software by redesigning the I/O stack <ref type="bibr" target="#b5">[8,</ref><ref type="bibr" target="#b40">43,</ref><ref type="bibr" target="#b19">22,</ref><ref type="bibr" target="#b8">11]</ref>. But unfortunately, the bandwidth benefit, which is mostly contributed by the * Corresponding author: Jiwu Shu (shujw@tsinghua.edu.cn).</p><p>internal parallelism of flash devices <ref type="bibr" target="#b10">[13,</ref><ref type="bibr" target="#b15">18,</ref><ref type="bibr" target="#b7">10,</ref><ref type="bibr" target="#b12">15]</ref>, is underutilized in system softwares.</p><p>Researchers have made great efforts in designing a file system for flash storage. New file system architectures have been proposed, to either improve data allocation performance, by removing redundant functions between FS and FTL <ref type="bibr" target="#b17">[20,</ref><ref type="bibr" target="#b42">45]</ref>, or improve flash memory endurance, by using an object-based FTL to facilitate hardware/software co-designs <ref type="bibr" target="#b30">[33]</ref>. Features of flash memory have also been leveraged to redesign efficient metadata mechanisms. For instance, the imbalanced read/write feature has been studied to design a persistence-efficient file system directory tree <ref type="bibr" target="#b29">[32]</ref>. F2FS, a less aggressive design than the above-mentioned designs, is a flashoptimized file system and has been merged into the Linux kernel <ref type="bibr" target="#b25">[28]</ref>. However, the internal parallelism has not been well studied in these file systems.</p><p>Unfortunately, internal parallelism is a key design issue to improve file system performance for flash storage. Even though it has been well studied in the FTL level, file systems cannot always gain the benefits. We observe that, even though the flash-optimized F2FS file system outperforms the legacy file system Ext4 when write traffic is light, its performance does not scale well with the internal parallelism when write traffic is heavy (48% of Ext4 in the worst case, more details in Section 4.3 and <ref type="figure" target="#fig_4">Figure 6</ref>).</p><p>After investigating into file systems, we have the following three observations. First, optimizations in both FS and FTL are made but may collide. For example, data pages 1 are grouped into hot/cold groups in some file systems, so as to reduce garbage collection (GC) overhead. FTL stripes data pages over different parallel units (e.g., channels) to achieve parallel performance, but breaks up the hot/cold groups. Second, duplicated log-structured data management in both FS and FTL leads to inefficient garbage collection. FS-level garbage collection is unable to erase physical flash blocks, while FTL-level garbage collection is unable to select the right victim blocks due to the lack of semantics. Third, isolated I/O scheduling in either FS or FTL results in unpredictable I/O latencies, which is a new challenge in storage systems on lowlatency flash devices.</p><p>To exploit the internal parallelism while keeping low garbage collection overhead, we propose ParaFS, a logstructured file system over simplified block-level FTL. The simplified FTL exposes the device information to the file system. With the knowledge of the physical layout, ParaFS takes the following three approaches to exploit the internal parallelism. First, it fully exploits the channel-level parallelism of flash memory by page-unit striping, while ensuring data grouping physically. Second, it coordinates the garbage collection processes in the FS and FTL levels, to make GC more efficient. Third, it optimizes the request scheduling on read, write and erase requests, and gains more consistent performance. Our major contributions are summarized as follows:</p><p>• We observe the internal parallelism of flash devices is underutilized when write traffic is heavy, and propose ParaFS, a parallelism-aware file system over a simplified FTL.</p><p>• We propose parallelism-aware mechanisms in the ParaFS file system, to mitigate the parallelism's conflicts with hot/cold grouping, garbage collection, and I/O performance consistency.</p><p>• We implement ParaFS in the Linux kernel. Evaluations using various workloads show that ParaFS has higher and more consistent performance with significant lower garbage collection overhead, compared to legacy file systems including the flashoptimized F2FS. The rest of this paper is organized as follows. Section 2 analyses the parallelism challenges and motivates the ParaFS design. Section 3 describes the ParaFS design, including the 2-D allocation, coordinated garbage collection and parallelism-aware scheduling mechanisms. Evaluations of ParaFS are shown in Section 4. Related work is given in Section 5 and the conclusion is made in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Motivation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Flash File System Architectures</head><p>Flash devices are seamlessly integrated into legacy storage systems by introducing a flash translation layer (FTL). Though NAND flash has low access latency and high I/O bandwidth, it has several limitations, e.g., erase-before-write and write endurance (i.e., limited program/erase cycles). Log-structured design is supposed to be a friendly way for flash memory. It is adopted in both the file system level (e.g., F2FS <ref type="bibr" target="#b25">[28]</ref>, and NILFS <ref type="bibr" target="#b24">[27]</ref>) and the FTL level <ref type="bibr" target="#b7">[10,</ref><ref type="bibr" target="#b33">36]</ref>. The FTL hides the flash limitations by updating data in a log-structured way using an address mapping table. It exports the same I/O interface as HDDs. With the use of the FTL, legacy file systems can directly run on these flash devices, without any changes. This architecture is shown in <ref type="figure" target="#fig_0">Figure 1(a)</ref>. While FTL is good at abstracting the flash memory as a block device, it widens the semantic gap between file systems and flash memory. As shown in <ref type="figure" target="#fig_0">Figure 1(a)</ref>, the FS and FTL run independently without knowing each other's behaviours, resulting in inefficient storage management. Even worse, the two levels have redundant functions, e.g., space allocation, address mapping, and garbage collection, which further induce performance and endurance overhead.</p><p>Object-based FTL (OFTL) <ref type="bibr" target="#b30">[33]</ref> is a recently proposed architecture to bridge the semantic gap between file systems and FTLs, as shown in <ref type="figure" target="#fig_0">Figure 1(b)</ref>. However, it requires dramatic changes of current I/O stack, and is difficult to be adopted currently, either in the device due to complexity or in the operating system due to rich interfaces required in the drivers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Challenges of Internal Parallelism</head><p>In a flash device, a number of flash chips are connected to the NAND flash controller through multiple channels. I/O requests are distributed to different channels to achieve high parallel performance, and this is known as the internal parallelism. Unfortunately, this feature has not been well leveraged in the file systems for the following three challenges.</p><p>Hot/Cold Grouping vs. Internal Parallelism. With the use of the FTL, file systems allocate data pages in a one-dimension linear space. The linear space works fine for HDDs, because a hard disk accesses sectors serially due to the mechanical structure, but not for flash devices.</p><p>In flash-based storage systems, a fine hot/cold grouping reduces the number of valid pages in victim flash blocks during garbage collection. Some file systems separate data into groups with different hotness for GC efficiency. Meanwhile, the FTL trys to allocate flash pages from different parallel units, aiming at high bandwidth. Data pages that belong to the same group in the file system may be written to different parallel units. Parallel space allocation in FTL breaks hot/cold data groups. As such, the hot/cold data grouping in the file system collides with the internal parallelism in the FTL.</p><p>Garbage Collection vs. Internal Parallelism. Logstructured file systems are considered to be flash friendly. However, we observe that F2FS, a flash-optimized logstructured file system, performs worse than Ext4 on multi-channel flash devices when write traffic is heavy. To further analyse this inefficiency, we implement a page-level FTL and collect the GC statistics in the FTL, including the number of erased flash blocks and the percentage of invalid pages in each erased block (i.e., GC efficiency). Details of the page-level FTL and evaluation settings are introduced in Section 4. As shown in <ref type="figure" target="#fig_1">Figure 2</ref>, for the random update workload in YCSB <ref type="bibr" target="#b11">[14]</ref>, F2FS has increasing number of erased flash blocks and decreasing GC efficiency when the number of channels increases.</p><p>The reason lies in the incoordinate garbage collections in FS and FTL. When the log-structured file system cleans a segment in the FS level, the invalid flash pages are actually scattered over multiple flash parallel units. The more channels the device has, the more diverse the invalid pages are. This degrades the GC efficiency in the FTL. At the same time, the FTL gets pages' invalidation only after receiving the trim commands from the logstructured file system, due to the no in-place update. As we observed in the experiments, a large number of pages which are already invalidated in the file system are migrated to the clean flash blocks during the FTL's erase process. Therefore, garbage collections in FS and FTL levels collide and damage performance. Consistent Performance vs. Internal Parallelism. Read or write requests may be blocked by erase operations in the FTL. Since erase latency is much higher than read/write latency, this causes latency spikes, making I/O latency unpredictable. It is known as the inconsistent performance, which is a serious issue for low-latency storage devices. Parallel units offer an opportunity to remove latency spikes by carefully scheduling I/O requests. Once a file system controls read, write and erase operations, it can dynamically schedule requests to make performance more consistent.</p><p>To address the above-mentioned challenges, we propose a new architecture (as shown in <ref type="figure" target="#fig_2">Figure 3</ref>) to exploit the internal parallelism in the file system. In this architecture, we use a simplified FTL to expose the physical layout to the file system. Our designed ParaFS maximizes the parallel performance in the file system level while achieving physical hot/cold data grouping, lower garbage collection overhead and more consistent performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Design</head><p>ParaFS is designed to exploit the internal parallelism without compromising other mechanisms. To achieve this goal, ParaFS uses three key techniques:</p><p>• 2-Dimension Data Allocation to stripe data pages over multiple flash channels at page granularity while maintaining hot/cold data separation physically.</p><p>• Coordinated Garbage Collection to coordinate garbage collections in FS and FTL levels and lower the garbage collection overhead.</p><p>• Parallelism-Aware Scheduling to schedule the read/write/erase requests to multiple flash channels for more consistent system performance. In this section, we introduce the ParaFS architecture first, followed by the description of the above-mentioned three techniques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">The ParaFS Architecture</head><p>ParaFS reorganizes the functionalities between the file system and the FTL, as shown in <ref type="figure" target="#fig_2">Figure 3</ref>. In the ParaFS architecture, ParaFS relies on a simplified FTL (annotated as S-FTL). S-FTL is different from traditional FTLs in three aspects. First, S-FTL uses a static block-level mapping table. Second, it performs garbage collection by simply erasing the victim flash blocks without moving any pages, while the valid pages in the victim blocks are migrated by ParaFS in the FS level. Third, S-FTL exposes the physical layout to the file system using three values, i.e., the number of flash channels 2 , the flash page size and the flash block size. These three values are passed to the ParaFS file system through ioctl interface,  In S-FTL, the block mapping is different from those in legacy block-based FTLs. S-FTL uses static blocklevel mapping. For normal writes, the ParaFS file system updates data pages in a log-structured way. There is no in-place update in the FS level. For these writes, S-FTL doesn't need to remap the block. S-FTL updates its mapping entries only for wear leveling or bad block remapping. In addition, ParaFS tracks the valid/invalid statuses of pages in each segment, whose address is aligned to the flash block in flash memory. The file system migrates valid pages in the victim segments during garbage collection, and the S-FTL only needs to erase the corresponding flash blocks afterwards. As such, the simplified block mapping, simplified garbage collection and reduced functionalities make S-FTL a lightweight implementation, which has nearly zero overhead. The ParaFS file system is a log-structured file system. To avoid the "wandering tree" problem <ref type="bibr" target="#b35">[38]</ref>, file system metadata is updated in place, by introducing a small page-level FTL. Since we focus on the data management, we omit discussions of this page-level FTL for the rest of the paper. In contrast, file system data is updated in a log-structured way and sent to the S-FTL. The ParaFS file system is able to perform more effective data management with the knowledge of the internal physical layout of flash devices. Since the file system is aware of the channel layout, it allocates space in different channels to exploit the internal parallelism and meanwhile keeps the hot/cold data separation physically (details in Section 3.2). ParaFS aligns the segment of log-structured file system to the flash block of the device. Since it knows exactly the valid/invalid statuses of data pages, it performs garbage collection in the file system with the coordination of the FTL erase operations (details in Section 3.3). With the channel information, ParaFS is also able to optimize the scheduling on read/write/erase requests in the file system and make system performance more consistent (details in Section 3.4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">2-D Data Allocation</head><p>The first challenge as described in Section 2.2 is the conflict between data grouping in the file system and internal parallelism in the flash device. Intuitively, the easiest way for file system data groups to be aligned to flash blocks, is using block granularity striping in the FTL. The block striping maintains data grouping while parallelizing data groups to different channels in block units. However, the block-unit striping fails to fully exploit the internal parallelism, since the data within one group needs to be accessed sequentially in the same flash block. We observe in our systems that block-unit striping has significantly lower performance than page-unit striping (i.e., striping in page granularity), especially in the small synchronous write situations, like mail server. Some codesigns employ a super block unit which contains flash blocks from different flash channels <ref type="bibr" target="#b39">[42,</ref><ref type="bibr" target="#b9">12,</ref><ref type="bibr" target="#b26">29]</ref>. The writes can be striped in a page granularity within the super block and different data groups are maintained in different super blocks. However, the large recycle size of the super block incurs higher overhead in the garbage collection. Therefore, we propose 2-D allocation in ParaFS that uses small allocation units to fully exploit channel-level parallelism while keeping effective data grouping. Tabel 1 summaries the characteristics of these data allocation schemes and compares them with 2-D allocation used in ParaFS. <ref type="figure" target="#fig_3">Figure 4</ref> shows the 2-D allocation in ParaFS. With the device information from S-FTL, ParaFS is able to allocate and recycle space that aligned to the flash memory below. The data space is divided into multiple regions. A region is an abstraction of a flash channel in the device. The number and the size of regions equal to those of flash channels. Each region contains multiple segments and each segments contains multiple data pages. The segment is the unit of allocation and garbage collection  There are multiple allocator heads and a free segment list in each region. The allocator heads point to data groups with different hotness within the region. They are assigned a number of free segments and they allocate free pages to the written data with different hotness, in a log-structured way. The free segments of the region are maintained in the free segment list. The 2-D allocation consists of channel-level dimension and hotness-level dimension. ParaFS delays space allocation until data persistence. Updated data pages are first buffered in memory. When a write request is going to be dispatched to the device, ParaFS starts the 2-D scheme to allocate free space for the request.</p><p>First, in the channel-level dimension, ParaFS divides the write request into pages, and then stripes these pages over different regions. Since the regions match the flash channels one-to-one, the data in the write request is sent to different flash channels in a page-size granularity, so as to exploit the channel-level parallelism in the FS level. After dividing and striping the data of the write request over regions, the allocation process goes to the second dimension.</p><p>Second, in the hotness-level dimension, ParaFS groups data pages into groups with different hotness in a region, and sends the divided write requests to their proper groups. There are multiple allocator heads with different hotness in the region. The allocator head, which has similar hotness to the written data, is selected. Finally, the selected allocator head allocates a free page to the written data. The data is sent to the device with the address of the allocated page. Since the segments of allocator heads are aligned to the flash blocks, the data pages with different hotness are assigned to different allocator heads, thereby placed in separated flash blocks. The hotness-level dimension ensures the effective data grouping physically.</p><p>In implementation, ParaFS uses six allocators in each region. The data is divided into six kinds of hotness, i.e., hot, warm, and cold, respectively for metadata and regular data. The hotness classification uses the same hints as in F2FS <ref type="bibr" target="#b25">[28]</ref>. Each allocator is assigned ten segments each time. The address of the segments and the offset of the allocator heads are recorded in the FS checkpoint in case of system crash.</p><p>Crash Recovery.</p><p>After the crash, legacy logstructured file systems will recover itself to the last checkpoint, which maintains the latest consistent state of the file system. Some file systems <ref type="bibr" target="#b30">[33]</ref>[28] will do the roll-forward recovery to restore changes after last checkpoint. ParaFS differs slightly during the recovery. Since ParaFS directly accesses and erases flash memory through statically mapped S-FTL, it has to detect the written pages after last checkpoint. These written pages need to be detected so that the file system does not overwrite these pages, which otherwise causes overwrite errors in flash memory.</p><p>To solve this problem, ParaFS employs an update window similar to that in OFSS <ref type="bibr" target="#b30">[33]</ref>. An update window consists of segments from each region that are assigned to allocator heads after last checkpoint. Before a set of segments are assigned to allocator heads, their addresses are recorded first. During recovery, ParaFS first recovers itself to the last checkpoint. Then, ParaFS does the roll-forward recovery with the segments in the update window in each region, since all written pages after last checkpoint fall in this window. After recovering the valid pages in the window, other pages will be considered as invalid, and they will be erased by the GC threads in the future.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Coordinated Garbage Collection</head><p>The second challenge as described in Section 2.2 is the mismatch of the garbage collection processes in FS and FTL levels. Efforts in either side are ineffective in reclaiming free space. ParaFS coordinates garbage collection in the two levels and employs multiple GC threads to leverage the internal parallelism. This tech-nique improves both the GC efficiency (i.e., the percent of invalid pages in victim blocks) and the space reclaim efficiency (i.e., time used for GC).</p><p>The coordinated garbage collection contains the GC process from FS level and FTL level. We use the terms "paraGC" and "flashGC" to distinguish them. In the FS level, the paraGC is triggered when free space drops below a threshold (i.e., foreground paraGC) or file system is idle (i.e., background paraGC). The unit of garbage collection is the segment, as we described in Section 3.2. The foreground paraGC employs greedy algorithm to recycle the segments quickly and minimize the latency of I/O threads. The background paraGC uses cost-benefit algorithm <ref type="bibr" target="#b35">[38]</ref> that selects victim segments not only based on the number of invalid data pages, but also their "age". When the paraGC thread is triggered, it first selects victim segments using the algorithms above. Then, the paraGC thread migrates the valid pages in the victim segments to the free space. If the migration is conducted by foreground paraGC, these valid pages are striped to the allocator heads with similar hotness in different regions. If the migration is conducted by background paraGC, these valid pages are considered to be cold, and striped to the allocator heads with low hotness. After the valid pages are written to the device, the victim segments are marked erasable and they will be erased after checkpoint. The background paraGC exits after the migration while the foreground paraGC does the checkpoint and sends the erase requests to S-FTL by trim.</p><p>In the FTL level, the block recycling is simplified, since the space management and garbage collection are moved from FTL level to FS level. The segments in the FS level match the flash blocks one to one. After paraGC migrates valid pages in the victim segments, the corresponding flash blocks can be erased without additional copies. When S-FTL receives trim commands from the ParaFS, flashGC locates the flash blocks that victim segments mapped to, and directly erases them. After the flash blocks are erased, S-FTL informs the ParaFS by the callback function of the requests. The coordinated GC migrates the valid pages in FS level, and invalidates the whole flash block to the S-FTL. No migration overhead is involved during the erase process in the S-FTL.</p><p>Coordinated GC also reduces the over-provisioning space of the device and brings more user available capacity. Traditional FTLs need to move the valid pages from the victim blocks before erasing. They keeps large overprovisioning space to reduce the overhead of garbage collection. The spared space in FTL decreases the user visible capacity. Since the valid pages are already moved by ParaFS, the flashGC in S-FTL can directly erase the victim blocks without any migration. S-FTL needn't spare space for garbage collection. The overprovisioning space of S-FTL is much smaller than the traditional ones. The spared blocks are only used for bad block remapping and block mapping table storage. S-FTL also needn't track and maintain the flash page status and flash block utilization, which also reduces the size of spared space.</p><p>ParaFS optimizes the foreground GC by employing multiple GC threads. Legacy log-structured file systems perform foreground GC in one thread <ref type="bibr" target="#b25">[28]</ref>, or none <ref type="bibr" target="#b24">[27]</ref>. Since all operations are blocked during checkpointing. Multiple threads cause frequent checkpoint and decrease the performance severely. However, one or less foreground GC thread is not enough under write intensive workloads which consume the free segments quickly. ParaFS assigns one GC thread to each region and employs an additional manager thread. The manager checks the utilization of each region, and wakes up the GC thread of the region when it's necessary. After GC threads migrate the valid data pages, the manager will do the checkpoint, and send the erase requests asynchronously. This optimization avoids multiple checkpoints, and accelerates the segment recycling under heavy writes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Parallelism-Aware Scheduling</head><p>The third challenge as described in Section 2.2 is the performance spikes. To address this challenge, ParaFS proposes to schedule the read/write/erase requests in the file system level while exploiting the internal parallelism. In ParaFS, the 2-D allocation selects the target flash channels for the write requests, and the coordinated GC manages garbage collection in the FS level. These two techniques offer an opportunity for ParaFS to optimize the scheduling on read, write and erase requests. ParaFS employs parallelism-aware scheduling to provide more consistent performance under heavy write traffic.</p><p>Parallelism-aware scheduling consists of request dispatching phase and request scheduling phase. In the dispatching phase, it optimizes the write requests. The scheduler maintains a request queue for each flash channel of the device, shown in <ref type="figure" target="#fig_2">Figure 3</ref>. The target flash channels of read and erase requests are fixed, while the target channel of writes can be adjusted due to the late allocation. In the channel-level dimension of 2-D allocation, ParaFS splits the write requests into data pages, and selects a target region for each page. The region of ParaFS and the flash channel below are oneto-one correspondence. Instead of a Round-Robin selection, ParaFS selects the region to write, whose corresponding flash channel is the least busy in the scheduler. Due to the asymmetric read and write performance of the flash drive, the scheduler assigns different weights (W read , W write ) to read and write requests in the request queues. The weights are obtained by measuring the corresponding latency of the read and write requests. Since the write latency is 8× of the read latency in our device, the W read and W write are set to 1 and 8 in the evaluation. The channel with the smallest weight calculated by the Formula 1 will be selected. Size read and Size write represent the size of read and write requests in the request queue. The erase requests in the request queue are not considered in the formula, because the time, when they are sent to the device, is uncertain.</p><formula xml:id="formula_0">W channel = ∑ (W read × Size read ,W write × Size write ) (1)</formula><p>In the scheduling phase, the scheduler optimizes the erase requests scheduling. Considering the fairness, the parallelism-aware scheduler assigns a time slice for read requests and a same-size slice for write/erase requests. The scheduler works on each request queue individually. In the read slice, the scheduler schedules read requests to the channel. When the slice ends or no read request is left in the queue, the scheduler determines to schedule write or erase request in next slice by Formula 2. The f is the percent of free blocks in the flash channel. N e is the percent of flash channels that are processing the erase requests at this moment. The a and b represents the weight of these parameters.</p><formula xml:id="formula_1">e = a × f + b × N e<label>(2)</label></formula><p>If e is higher than 1, the scheduler sends write requests in the time slice. Otherwise, the scheduler sends erase requests in that time slice. After the write/erase slice, the scheduler turns to read slice again. In current implementation, a and b are respectively set to 2 and 1, which implies that erase requests are scheduled only after the free space drops below 50%. This scheme gives higher priority to erase requests when the free space is not enough. Meanwhile, it prevents too many channels erasing at the same time, which helps to ease the performance wave under heavy write traffic. With the employment of these two optimizations, the parallelism-aware scheduler helps to provide both high and consistent performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Evaluation</head><p>In this section, we evaluate ParaFS to answer the following three questions:</p><p>1 </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experimental Setup</head><p>In the evaluation, we compare ParaFS with Ext4 <ref type="bibr" target="#b1">[2]</ref>, BtrFS <ref type="bibr" target="#b0">[1]</ref> and F2FS <ref type="bibr" target="#b25">[28]</ref>, which respectively represent the in-place-update, copy-on-write, and flash-optimized log-structured file systems. ParaFS is also compared to a revised F2FS (annotated as F2FS SB) in addition to conventional F2FS (annotated as F2FS). F2FS organizes data into segment, which is the GC unit in FS and is the same size as flash block. F2FS SB organizes data into super blocks. A super block consists of multiple adjacent segments. The number of the segments equals to the number of channels in the flash device. In F2FS SB, a super block is the unit of allocation and garbage collection, and can be accessed in parallel.</p><p>We customize a raw flash device to support programmable FTLs. Parameters of the flash device are listed in <ref type="table" target="#tab_3">Table 2</ref>. To support the file systems above, we implement a page-level FTL, named PFTL, based on DFTL <ref type="bibr" target="#b14">[17]</ref> with lazy indexing technique <ref type="bibr" target="#b30">[33]</ref>. PFTL stripes updates over different channels in a page size unit, to fully exploit the internal parallelism. S-FTL is implemented based on PFTL. It removes the allocation function, replaces the page-level mapping with static block-level mapping, and simplifies the GC process, as described in Section 3.1. In both FTLs, the number of flash channels and the capacity of the device are configurable. With the help of these FTLs, we collect the information about flash memory operations, like the number of erase operations and the number of pages migrated during garbage collection. The low-level information is helpful for comprehensive analysis of file system implications. The experiments are conducted on an X86 server with Intel Xeon E5-2620 processor, clocked at 2.10GHz, and 8G memory of 1333MHz. The server runs with Linux kernel 2.6.32, which is required by the customized flash device. For the target system, we back-port F2FS from the 3.15-rc1 main-line kernel to the 2.6.32 kernel. ParaFS is implemented as a kernel module based on F2FS, but differs in data allocation, garbage collection, and I/O scheduling. Workloads. <ref type="table" target="#tab_4">Table 3</ref> summarizes the four workloads used in the experiments. Two of them run directly on file  <ref type="bibr" target="#b16">[19]</ref> is a benchmark tool for measuring the performance of file IO and DB operations. In the evaluation, it issues random update operations to the SQLite <ref type="bibr" target="#b6">[9]</ref>, which runs with FULL synchronous and WAL journal mode. YCSB <ref type="bibr" target="#b11">[14]</ref> is a framework to stress many popular data serving systems. We use the workload-A of YCSB on MySql <ref type="bibr" target="#b4">[7]</ref>, which consists of 50% random reads and 50% random updates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Evaluation with Light Write Traffic</head><p>In this section, we compare ParaFS with other file systems under light write traffic. We choose 8 and 32 channels for this evaluation, which respectively represent SATA SSDs <ref type="bibr" target="#b3">[6,</ref><ref type="bibr">4,</ref><ref type="bibr" target="#b2">5]</ref> and PCIe SSDs <ref type="bibr" target="#b2">[5,</ref><ref type="bibr" target="#b38">41]</ref>. The device capacity is set to 128GB. <ref type="figure">Figure 5</ref> shows the throughput of evaluated file systems, and results are normalized against F2FS's performance in 8-channel case. From the figure, we have two observations.</p><p>(1) ParaFS outperforms other file systems in all cases, and achieves 13% higher over F2FS for postmark workload in the 32-channel case. In the evaluated file systems, BtrFS performs poorly, especially for database benchmarks that involve frequent syncs. The update propagation (i.e., "wandering tree" problem <ref type="bibr" target="#b35">[38]</ref>) of copyon-write brings intensive data writes in BtrFS during the sync calls (7.2× for mobibench, 3.0× for YCSB). F2FS mitigates this problem by updating the metadata in place <ref type="bibr" target="#b25">[28]</ref>. Except BtrFS, other file systems perform roughly similar under light write traffic. F2FS only outperforms Ext4 by 3.5% in fileserver with 32 channels, which is consistent to the F2FS evaluations on PCIe SSD <ref type="bibr" target="#b25">[28]</ref>. The performance bottleneck appears to be moved, due to the fast command processing and high random access ability of the PCIe drive. F2FS SB shows nearly the same performance to F2FS. Since PFTL stripes the requests over all flash channels with a pagesize unit, larger allocation unit in F2FS SB doesn't gain more benefit in parallelism. The GC impact of larger block recycling is also minimized due to the light write pressure. The impact will be seen under heavy write traffic evaluations in Section 4.3. ParaFS uses cooperative designs in both FS and FTL levels, eliminates the duplicate functions, and achieves the highest performance.</p><p>(2) Performance gains in ParaFS grow when the number of channels is increased. Comparing the two figures in <ref type="figure">Figure 5</ref>, all file systems have their performance improved when the number of channels is increased. Among them, ParaFS achieves more. It outperforms F2FS averagely by 1.53% in 8-channel cases and 6.29% in 32-channel cases. This also evidences that ParaFS spends more efforts in exploiting the internal parallelism.</p><p>In all, ParaFS has comparable or better performance than the other evaluated file systems when the write traffic is light.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Evaluation with Heavy Write Traffic</head><p>Since ParaFS is designed to address the problems of data grouping and garbage collection while exploiting the internal parallelism, evaluations using heavy write traffic are much more important. In this evaluation, we limit the capacity of flash device to 16GB and increase the benchmark sizes. The write traffic sizes in the four evaluated benchmarks are set to 2× ∼ 3× of the flash device capacity, to trigger the garbage collection actions. <ref type="figure" target="#fig_4">Figure 6</ref> shows the throughput of evaluated file systems for the heavy write traffic cases, with the number of channels varied from 1 to 32. Results are normalized against F2FS's throughput in 1-channel case. From the figure, we have three observations. (1) Ext4 outperforms F2FS for three out of the four evaluated workloads, which is different from that in the light write traffic evaluation. The performance gap between Ext4 and F2FS tends to be wider with more flash channels. The reason why the flash-optimized F2FS file system has worse performance than Ext4 is the side effects of internal parallelism. In F2FS, the hot/cold data grouping and the aligned segments are broken when data pages are distributed to multiple channels in the FTL. Also, the invalidation of a page is known in the FTL only after it is recycled in the F2FS, due to the no inplace update. Unfortunately, a lot of invalid pages have been migrated during garbage collection before their statuses are passed to the FTL. Both reasons lead to high GC overhead in FTL, and the problem gets more serious with increased parallelism. In Ext4, the inplace update pattern is more accurate in telling FTLs the page invalidation than F2FS. The exceptional case is the postmark workload, which contains a lot of create and delete operations. Ext4 spreads the inode allocation in all of the block groups for load balance. This causes the invalid pages distributed evenly in the flash blocks and results in higher garbage collection overhead than F2FS (18.5% higher on average). In general, the observation that flash-optimized file system is not good at exploiting internal parallelism under heavy write traffic motivates our ParaFS design.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Performance</head><p>(2) F2FS SB shows improved performance than F2FS for the four evaluated workloads, and the improvement grows with more channels. This is also different from results in the light write traffic evaluation. The performance of F2FS improves quickly when the number of channels is increased from 1 to 8, but the improvement is slowed down afterward. For fileserver, postmark and YCSB workloads, F2FS gains little improvement in the 32-channel case over the 16-channel case. The main cause is the increasing GC overhead, which will be seen in next section. In contrast, allocation and recycling in super block units of F2FS SB ease the GC overhead caused by unaligned segments. The trim commands sent by F2FS SB contain larger address space, and are more effective in telling the invalid pages to the FTL. However, selecting victims in larger units also decreases the GC efficiency. As such, the internal parallelism using super block methods <ref type="bibr" target="#b9">[12,</ref><ref type="bibr" target="#b39">42]</ref> is still not effective.</p><p>(3) ParaFS outperforms other file systems in all cases. ParaFS outperforms Ext4 from 1.0× to 1.7× in the 8-channel case, and to 2.5× in the 32-channel case. ParaFS outperforms F2FS from 1.6× to 1.9× in the 8-channel case, and from 1.7× to 3.1× in the 32-channel case. ParaFS outperforms F2FS SB from 1.2× to 1.5× in both cases. ParaFS keeps the aligned flash block erase units while using page-unit striping in 2-D allocation.</p><p>The coordinated multi-threaded GC is also helpful in reducing the GC overhead. And thus, ParaFS is effective in exploiting the internal parallelism under heavy write traffic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">Write Traffic and Garbage Collection</head><p>To further understand the performance gains in ParaFS, we collect the statistics of garbage collection and write traffic from both FS and FTL levels. We select the fileserver workload as an example due to space limitation. The other workloads have similar patterns and are omitted. For fairness, we revise the fileserver benchmark to write fixed-size data. In the evaluation, the write traffic size in fileserver is set to 48GB, and the device capacity is 16GB. ParaFS has the lowest garbage collection overhead and highest GC efficiency among all evaluated file systems under four benchmarks. For the fileserver evaluation, it achieves the lowest recycled block count (62.5% of F2FS on average) and the highest GC efficiency (91.3% on average). As the number of channels increases, the number of recycled blocks in F2FS increases quickly. This is due to the unaligned segments and uncoordinated GC processes of both sides (as analyzed in Section 4.3.1). It is also explained with the GC efficiency degradation in <ref type="figure" target="#fig_5">Figure 7</ref>(b). The GC efficiency of Ext4, BtrFS, ParaFS trends to drop a little with more flash channels. Because the adjacent pages are more scattered when the device internal parallelism increases, and they tend to be invalidated together. F2FS SB acts different from other file systems. In F2FS SB, when the number of channels is increased from 8 to 32, the number of recycled blocks decreases and the GC efficiency increases. The reason is that the super block has better data grouping and alignments, and this advantage becomes increasingly evident with higher degree of parallelism. F2FS SB also triggers FS-level GC threads more frequently with larger allocation and GC unit. More trim commands with larger address space help to decrease the number of invalid pages migrated by GC process in the FTL level. ParaFS further utilizes fine-grained data grouping and GC unit, and has the lowest garbage collection overhead. that FTLs write to the flash memory. Write traffic in either level comes from not only the file system data and metadata but also the page migrated during garbage collection in FS or FTL level. The write traffic from FS in Ext4, BtrFS and F2FS are stable for different parallelism levels, because the increase of the flash channels in the device is transparent to them. ParaFS writes more in the file system than Ext4, F2FS and F2FS SB, but less than them in the FTL. Because all the page migration during the garbage collection is done in the FS level. Similarly, F2FS SB has higher write traffic from FS and lower from FTL than F2FS, as the number of channels is increased from 8 to 32. This results from the improved GC efficiency as mentioned above. The FTL write traffic in F2FS is higher than F2FS SB, which explains why F2FS SB has better performance than F2FS in <ref type="figure" target="#fig_4">Figure 6</ref>. ParaFS coordinates garbage collections in the two levels, and is more effective in space recycling. Compared to F2FS, ParaFS decreases the write traffic to the flash memory by 31.7% ∼ 54.7% in 8-channel case, and 37.1% ∼ 58.1% in 32-channel case. Compared to F2FS SB, ParaFS decreases it by 14.9% ∼ 48.4% in 8-channel case, and 15.7% ∼ 32.5% in 32-channel case.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Performance Consistency Evaluation</head><p>To evaluate the performance consistency in ParaFS, we monitor the throughput wave during each run of experiments. ParaFS aims at more consistent performance using multi-threaded GC and parallelism-aware scheduling. In this evaluation, we use four versions of ParaFS. The baseline (annotated as ParaFS Base) is the ParaFS version without the above-mentioned two optimizations. ParaFS PS and ParaFS MGC respectively stand for the version with parallelism-aware scheduling and multithreaded GC. ParaFS is the fully-functioned version.</p><p>The fileserver and postmark have different phases in the evaluation, which also cause fluctuation in the aggregate throughput (in terms of IOPS). We choose mobibench as the candidate for performance consistency evaluation. Mobibench performs random asynchronous reads and writes to pre-allocated files. In this evaluation, the write traffic of mobibench is set to be 2× of the device capacity. <ref type="figure">Figure 8</ref> shows the process of each run using four versions of ParaFS. We compare ParaFS MGC and ParaFS Base to analyse the impact of multi-threaded GC. ParaFS MGC and ParaFS Base have similar performance in the first 1000 seconds, during which no garbage collection is involved. After that, the performance of ParaFS MGC waves. The performance peaks appear after the GC starts in multiple threads. ParaFS MGC finishes the experiments earlier than ParaFS Base by 18.5%.</p><p>The parallelism-aware scheduling contains two major methods, the write request dispatching and the erase request scheduling. The effectiveness of write request dispatching can be seen by comparing ParaFS PS and ParaFS Base. For the first 1000 seconds when there is no garbage collection, ParaFS PS outperforms ParaFS Base by nearly 20%. This benefit comes from the write dispatching in the parallelism-aware scheduling technique, which allocates pages and sends requests to the least busy channels. The effectiveness of erase request scheduling can be observed between ParaFS and ParaFS MGC. In the latter part of each run when the GC processes are frequently triggered, ParaFS using parallelism-aware scheduling performs more consistently than ParaFS MGC.</p><p>In conclusion, the FS-level multi-threaded garbage collection as implemented in ParaFS is more effective in reclaiming free space, and the FS-level parallelismaware scheduling makes performance more consistent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Work</head><p>Data Allocation. In the FTL or flash controller, internal parallelism has been extensively studied. Recent researches <ref type="bibr" target="#b10">[13,</ref><ref type="bibr" target="#b15">18,</ref><ref type="bibr" target="#b18">21]</ref> have conducted extensive experiments on page allocation with different levels (i.e., channel-level, chip-level, die-level and plane-level) of internal parallelism. Gordon <ref type="bibr" target="#b9">[12]</ref> introduces a 2-D striping to leverage both channel-level and die-level parallelism. But note that, 2-D striping in Gordon is different from 2-D data allocation in ParaFS. 2-D striping is designed in the flash controller, which places data to leverage multiple levels of parallelism. 2-D data allocation is designed in file system, which organizes data into different groups using metrics of parallelism and hotness. In addition, aggressive parallelism in the device level scatters data addresses, breaking up the data organization in the system level. P-OFTL <ref type="bibr" target="#b39">[42]</ref> has pointed out this problem and found that increased parallelism leads to higher garbage overhead, which in turn can decrease the overall performance.</p><p>In the file system level, DirectFS <ref type="bibr" target="#b17">[20]</ref> and Nameless Write <ref type="bibr" target="#b42">[45]</ref> propose to remove data allocation functions from file systems and leverage the data allocations in the FTL or storage device, which can have better decisions with detailed knowledge of hardware internals. OFSS <ref type="bibr" target="#b30">[33]</ref> proposes an object-based FTL, which enables hardware/software codesign with both knowledge of file semantics and hardware internals. However, these file systems pay little attention to internal parallelism, which is the focus of ParaFS in this paper. Garbage Collection. Garbage collection has a strong impact on system performance for log-structured designs. Researchers are trying to pass more file semantics to FTLs to improve GC efficiency. For instance, trim is a useful interface to inform FTLs the data invalidation, in order to reduce GC overhead in migrating invalid pages. Also, Kang et al. <ref type="bibr" target="#b22">[25]</ref> found that FTLs can have more efficient hot/cold data grouping, which further reduces GC overhead, if the expected lifetime of written data is passed from file systems to FTLs. In addition, Yang et al. <ref type="bibr" target="#b41">[44]</ref> found log-structured designs in both levels of system software and FTLs have semantic gaps, which make garbage collection in both levels inefficient. In contrast, ParaFS proposes to bridge the semantic gap and coordinate garbage collection in the two levels.</p><p>In the file system level, SFS <ref type="bibr" target="#b31">[34]</ref> uses a sophisticated hot/cold data grouping algorithm using both access count and age of the block. F2FS <ref type="bibr" target="#b25">[28]</ref> uses a static data grouping method according to the file and data types. However, these grouping algorithms suffer when grouped data are spread out in the FTL. Our proposed ParaFS aims to solve this problem and keep physical hot/cold grouping while exploiting the internal parallelism.</p><p>A series of research works use large write block size to align the flash block and decrease the GC overhead <ref type="bibr" target="#b37">[40,</ref><ref type="bibr" target="#b28">31,</ref><ref type="bibr" target="#b27">30,</ref><ref type="bibr" target="#b32">35]</ref>. RIPQ <ref type="bibr" target="#b37">[40]</ref> and Pannier <ref type="bibr" target="#b28">[31]</ref> aggregate small random writes in memory, divide them into groups according to the hotness, and evict the groups in flash block size. Nitro <ref type="bibr" target="#b27">[30]</ref> deduplicates and compresses the writes in RAM and evicts them in flash block size. Nitro proposes to modify the FTL to support block-unit striping that ensures the effective of the block-size write optimization.</p><p>SDF <ref type="bibr" target="#b32">[35]</ref> employs block-unit striping which is tightly coupled with key-value workloads. ParaFS uses pagesize I/O unit and aims at file system workloads. I/O Scheduling. In flash storage, new I/O scheduling policies have been proposed to improve utilization of internal parallelism <ref type="bibr" target="#b21">[24,</ref><ref type="bibr" target="#b20">23,</ref><ref type="bibr" target="#b13">16]</ref> or fairness <ref type="bibr" target="#b34">[37,</ref><ref type="bibr" target="#b36">39]</ref>. These scheduling policies are designed in the controller, the FTL or the block layer. In these levels, addresses of requests are determined. In comparison, systemlevel scheduling can schedule write requests before data allocation, which is flexible.</p><p>LOCS <ref type="bibr" target="#b38">[41]</ref> is a key-value store that schedules I/O requests in the system level upon open-channel SSDs. With the use of log-structured merge tree (LSM-tree), data is organized into data blocks aligned to flash blocks. LOCS schedules the read, write and erase operations to minimize the response time.</p><p>Our proposed ParaFS is a file system that schedules I/O requests in the system level. Different from keyvalue stores, file systems have irregular reads and writes. ParaFS exploits the channel-level parallelism with pageunit striping. Moreover, its goal is in making performance more consistent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>ParaFS is effective in exploiting the internal parallelism of flash storage, while keeping physical hot/cold data grouping and low garbage collection overhead. It also takes the parallelism opportunity to schedule read, write and erase requests to make system performance more consistent. ParaFS's design relies on flash devices with customized FTL that exposes physical layout, which can be represented by three values. The proposed design bridges the semantic gap between file systems and FTLs, by simplifying FTL and coordinating functions of the two levels. We implement ParaFS on a customized flash device. Evaluations show that ParaFS outperforms the flash-optimized F2FS by up to 3.1×, and has more consistent performance.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: FS Architectures on Flash Storage</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: GC Statistics under Heavy Traffic</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: The ParaFS Architecture</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: 2-D Allocation in ParaFS in ParaFS. Its size and address are aligned to the physical flash block. The data page in the segments represents the I/O unit to the flash and is aligned to the flash page. There are multiple allocator heads and a free segment list in each region. The allocator heads point to data groups with different hotness within the region. They are assigned a number of free segments and they allocate free pages to the written data with different hotness, in a log-structured way. The free segments of the region are maintained in the free segment list. The 2-D allocation consists of channel-level dimension and hotness-level dimension. ParaFS delays space allocation until data persistence. Updated data pages are first buffered in memory. When a write request is going to be dispatched to the device, ParaFS starts the 2-D scheme to allocate free space for the request. First, in the channel-level dimension, ParaFS divides the write request into pages, and then stripes these pages over different regions. Since the regions match the flash channels one-to-one, the data in the write request is sent to different flash channels in a page-size granularity, so as to exploit the channel-level parallelism in the FS level. After dividing and striping the data of the write request over regions, the allocation process goes to the second dimension. Second, in the hotness-level dimension, ParaFS groups data pages into groups with different hotness in a region, and sends the divided write requests to their proper groups. There are multiple allocator heads with different hotness in the region. The allocator head, which has similar hotness to the written data, is selected. Finally, the selected allocator head allocates a free page to the written data. The data is sent to the device with the address of the allocated page. Since the segments</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Performance Evaluation (Heavy Write Traffic)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Garbage Collection and Write Traffic Evaluation (Fileserver)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 (</head><label>7</label><figDesc>a) and Figure 7(b) respectively give the re- cycled block count and the garbage collection efficiency of evaluated file systems with varied number of flash channels. The recycled block count is the number of flash blocks that are erased in flash memory. The GC efficiency is measured using the average percentage of invalid pages in a victim flash block.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7 (</head><label>7</label><figDesc>Figure 7(c) shows the write traffic that file systems write to FTLs. Figure 7(d) shows the write traffic</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="true"><head>Table 1 : Data Allocation Schemes</head><label>1</label><figDesc></figDesc><table>Parallelism 
Garbage Collecion 
Stripe Granularity Parallelism Level 
GC Granulariy 
Grouping Effect GC Overhead 
Page Stripe 
Page 
High 
Block 
No 
High 
Block Stripe 
Block 
Low 
Block 
Yes 
Low 
Super Block 
Page 
High 
Multiple Blocks 
Yes 
Medium 
2-D Allocation 
Page 
High 
Block 
Yes 
Low 

Alloc. 
Space 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head></head><label></label><figDesc>. How does ParaFS perform compared to other file systems under light write traffic? 2. How does ParaFS perform under heavy write traf- fic? And, what are the causes behind? 3. What are the benefits respectively from the pro- posed optimizations in ParaFS?</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="true"><head>Table 2 : Parameters of the Customized Flash Device</head><label>2</label><figDesc></figDesc><table>Host Interface 
PCIe 2.0 x8 
Number of Flash Channel 
34 
Capacity per Channel 
32G 
NAND Type 
25nm MLC 
Page Size 
8KB 
Block Size 
2MB 
Read Bandwidth per Channel 49.84 MB/s 
Write Bandwidth per Channel 
6.55 MB/s 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="true"><head>Table 3 : Workload Characteristics</head><label>3</label><figDesc></figDesc><table>Name 
Description 
# of Files I/O size Threads 
R/W 
fsync 
Fileserver 
File server workload: random read and write files 
60,000 
1MB 
50 
33/66 
N 
Postmark 
Mail server workload: create, delete, read and append files 
10,000 
512B 
1 
20/80 
Y 
MobiBench 
SQLite workload: random update database records 
N/A 
4KB 
10 
1/99 
Y 
YCSB 
MySQL workload: read and update database records 
N/A 
1KB 
50 
50/50 
Y 

(a) channel = 8 
(b) channel = 32 

Figure 5: Performance Evaluation (Light Write Traffic) 

systems and the other two run on databases. Fileserver 
is a typical pre-defined workload in Filebench [3] to 
emulate the I/O behaviors in file servers. It creates, 
deletes and randomly accesses files in multiple threads. 
Postmark [26] emulates the behavior of mail servers. 
Transactions, including create, delete, read and append 
operations, are performed to the file systems. Mo-
bibench </table></figure>

			<note place="foot" n="1"> In this paper, we use data pages instead of data blocks, in order not to be confused with flash blocks.</note>

			<note place="foot" n="2"> Currently, ParaFS exploits only the channel-level parallelism, while finer level (e.g., die-level, plane-level) parallelism can be exploited in the FTL by emulating large pages or blocks.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank our shepherd Haryadi Gunawi and anonymous reviewers for their feedbacks and suggestions. This work is supported by the National Natural Science </p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Btrfs</surname></persName>
		</author>
		<ptr target="http://btrfs.wiki.kernel.org" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ext4</surname></persName>
		</author>
		<ptr target="https://ext4.wiki.kernel.org/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Intel ssd 750 pcie ssd review</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Intel x25-m and x18-m mainstream sata solid-state drives</title>
		<ptr target="ftp://download.intel.com/newsroom/kits/ssd/pdfs/X25-M34nmProductBrief.pdf" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mysql</surname></persName>
		</author>
		<ptr target="https://www.mysql.com/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">FusionIO Virtual Storage Layer</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sqlite</surname></persName>
		</author>
		<ptr target="http://www.sqlite.org/" />
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Design tradeoffs for SSD performance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Prabhakaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wobber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Manasse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Panigrahy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 2008 USENIX Annual Technical Conference (USENIX ATC)</title>
		<meeting>2008 USENIX Annual Technical Conference (USENIX ATC)<address><addrLine>Berkeley, CA</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX</publisher>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Linux block io: introducing multi-queue ssd access on multi-core systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bjørling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Axboe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Nellans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th International Systems and Storage Conference (SYSTOR)</title>
		<meeting>the 6th International Systems and Storage Conference (SYSTOR)</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page">22</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Using flash memory to build fast, power-efficient clusters for data-intensive applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Caulfield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">M</forename><surname>Grupp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Swanson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gordon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS)</title>
		<meeting>the 14th International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="217" to="228" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Essential roles of exploiting internal parallelism of flash memory based solid state drives in high-speed data processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th IEEE International Symposium on High Performance Computer Architecture (HPCA)</title>
		<meeting>the 17th IEEE International Symposium on High Performance Computer Architecture (HPCA)</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="266" to="277" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Benchmarking cloud serving systems with ycsb</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">F</forename><surname>Cooper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Silberstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Tam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ramakrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sears</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st ACM symposium on Cloud computing</title>
		<meeting>the 1st ACM symposium on Cloud computing</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="143" to="154" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The performance of pc solid-state disks (ssds) as a function of bandwidth, concurrency, device architecture, and system organization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dirik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Jacob</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th annual International Symposium on Computer Architecture (ISCA</title>
		<meeting>the 36th annual International Symposium on Computer Architecture (ISCA</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Exploiting parallelism in i/o scheduling for access conflict minimization in flash-based solid state drives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">H</forename><surname>Sha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Mass Storage Systems and Technologies (MSST)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1" to="11" />
		</imprint>
	</monogr>
	<note>30th Symposium on</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">DFTL: A flash translation layer employing demand-based selective caching of page-level address mappings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Urgaonkar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS)</title>
		<meeting>the 14th International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="229" to="240" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Performance impact and interplay of ssd parallelism through advanced commands, allocation strategy and data granularity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Supercomputing (ICS)</title>
		<meeting>the International Conference on Supercomputing (ICS)</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="96" to="107" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Framework for analyzing android i/o stack behavior: from generating the workload to analyzing the trace</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Won</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Future Internet</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="591" to="610" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">DFS: A file system for virtualized flash storage</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">K</forename><surname>Josephson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Bongo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Flynn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th USENIX Conference on File and Storage Technologies (FAST)</title>
		<meeting>the 8th USENIX Conference on File and Storage Technologies (FAST)<address><addrLine>Berkeley, CA</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX</publisher>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">An evaluation of different page allocation strategies on high-speed ssds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kandemir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th USENIX conference on Hot Topics in Storage and File Systems</title>
		<meeting>the 4th USENIX conference on Hot Topics in Storage and File Systems</meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="9" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Revisiting widely held ssd expectations and rethinking system-level implications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kandemir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the fifteenth international joint conference on Measurement and modeling of computer systems (SIGMETRICS)</title>
		<meeting>the fifteenth international joint conference on Measurement and modeling of computer systems (SIGMETRICS)</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="203" to="216" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Sprinkler: Maximizing resource utilization in many-chip solid state disks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">T</forename><surname>Kandemir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">High Performance Computer Architecture (HPCA)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="524" to="535" />
		</imprint>
	</monogr>
	<note>IEEE 20th International Symposium on</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Physically addressed queueing (paq): improving parallelism in solid state disks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">H</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iii</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kandemir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 39th ACM/IEEE International Symposium on Computer Architecture (ISCA)</title>
		<meeting>the 39th ACM/IEEE International Symposium on Computer Architecture (ISCA)</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="404" to="415" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">The multistreamed solid-state drive</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-U</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hyun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Maeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th USENIX conference on Hot Topics in Storage and File Systems</title>
		<meeting>the 6th USENIX conference on Hot Topics in Storage and File Systems</meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="13" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Postmark: A new file system benchmark</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Katcher</surname></persName>
		</author>
		<idno>TR3022</idno>
	</analytic>
	<monogr>
		<title level="j">Network Appliance</title>
		<imprint>
			<date type="published" when="1997" />
		</imprint>
	</monogr>
<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">The linux implementation of a log-structured file system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Konishi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Amagai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hifumi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kihara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Moriai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGOPS Operating Systems Review</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="102" to="107" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">F2FS: A new file system for flash storage</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th USENIX Conference on File and Storage Technologies (FAST)</title>
		<meeting>the 13th USENIX Conference on File and Storage Technologies (FAST)<address><addrLine>Santa Clara, CA</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX</publisher>
			<date type="published" when="2015-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Applicationmanaged flash</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arvind</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th Usenix Conference on File and Storage Technologies (FAST)</title>
		<meeting>the 14th Usenix Conference on File and Storage Technologies (FAST)<address><addrLine>Santa Clara, CA</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="339" to="353" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Nitro: A capacity-optimized ssd cache for primary storage</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Shilane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Douglis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Shim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Smaldone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wallace</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 2014 USENIX Annual Technical Conference (USENIX ATC)</title>
		<meeting>2014 USENIX Annual Technical Conference (USENIX ATC)<address><addrLine>Philadelphia, PA</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2014-06" />
			<biblScope unit="page" from="501" to="512" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Pannier: A container-based flash cache for compound objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Shilane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Douglis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wallace</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th Annual Middleware Conference</title>
		<meeting>the 16th Annual Middleware Conference<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="50" to="62" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">ReconFS: A reconstructable file system on flash storage</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th USENIX Conference on File and Storage Technologies (FAST)</title>
		<meeting>the 12th USENIX Conference on File and Storage Technologies (FAST)<address><addrLine>Berkeley, CA</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="75" to="88" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Extending the lifetime of flash-based storage through reducing write amplification from file systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th USENIX Conference on File and Storage Technologies (FAST)</title>
		<meeting>the 11th USENIX Conference on File and Storage Technologies (FAST)<address><addrLine>Berkeley, CA</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX</publisher>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">SFS: random write considered harmful in solid state drives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-W</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">I</forename><surname>Eom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th USENIX Conference on File and Storage Technologies (FAST)</title>
		<meeting>the 10th USENIX Conference on File and Storage Technologies (FAST)<address><addrLine>Berkeley, CA</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX</publisher>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">SDF: Software-defined flash for web-scale internet storage systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS)</title>
		<meeting>the 19th International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="471" to="484" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Beyond block I/O: Rethinking traditional storage primitives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Nellans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Wipfel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Flynn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">K</forename><surname>Panda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th IEEE International Symposium on High Performance Computer Architecture (HPCA)</title>
		<meeting>the 17th IEEE International Symposium on High Performance Computer Architecture (HPCA)</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="301" to="311" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Fios: a fair, efficient flash i/o scheduler</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th USENIX Conference on File and Storage Technologies (FAST)</title>
		<meeting>the 10th USENIX Conference on File and Storage Technologies (FAST)<address><addrLine>Berkeley, CA</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX</publisher>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">The design and implementation of a log-structured file system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rosenblum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">K</forename><surname>Ousterhout</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Computer Systems (TOCS)</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="26" to="52" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Flashfq: A fair queueing i/o scheduler for flash-based ssds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Park</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 2013 USENIX Annual Technical Conference (USENIX ATC)</title>
		<meeting>2013 USENIX Annual Technical Conference (USENIX ATC)<address><addrLine>Berkeley, CA</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="67" to="78" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Ripq: Advanced photo caching on flash for facebook</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Lloyd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th USENIX Conference on File and Storage Technologies (FAST)</title>
		<meeting>the 13th USENIX Conference on File and Storage Technologies (FAST)<address><addrLine>Santa Clara, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-02" />
			<biblScope unit="page" from="373" to="386" />
		</imprint>
	</monogr>
	<note>USENIX Association</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">An efficient design and implementation of LSM-tree based key-value store on open-channel SSD</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth European Conference on Computer Systems (EuroSys)</title>
		<meeting>the Ninth European Conference on Computer Systems (EuroSys)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="1" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">p-OFTL: an object-based semanticaware parallel flash translation layer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Design, Automation and Test in Europe (DATE)</title>
		<meeting>the Conference on Design, Automation and Test in Europe (DATE)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page">157</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">When poll is better than interrupt</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">B</forename><surname>Minturn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hady</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th USENIX Conference on File and Storage Technologies (FAST)</title>
		<meeting>the 10th USENIX Conference on File and Storage Technologies (FAST)<address><addrLine>Berkeley, CA</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX</publisher>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Dont stack your log on my log</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Plasson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gillis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Talagala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sundararaman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">USENIX Workshop on Interactions of NVM/Flash with Operating Systems and Workloads (INFLOW)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">De-indirection for flash-based SSDs with nameless writes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">P</forename><surname>Arulraj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Arpaci-Dusseau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">H</forename><surname>Arpacidusseau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th USENIX Conference on File and Storage Technologies (FAST)</title>
		<meeting>the 10th USENIX Conference on File and Storage Technologies (FAST)<address><addrLine>Berkeley, CA</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX</publisher>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
