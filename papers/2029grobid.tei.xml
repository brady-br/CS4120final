<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2020-09-29T02:22+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">EdgEWisE: A Better Stream Processing Engine for the Edge EDGEWISE: A Better Stream Processing Engine for the Edge</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>July 10-12, 2019</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinwei</forename><surname>Fu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Virginia Tech</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Talha</forename><surname>Ghaffar</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Virginia Tech</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">C</forename><surname>Davis</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Virginia Tech</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongyoon</forename><surname>Lee</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Virginia Tech</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Virginia</forename><surname>Tech</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Virginia Tech</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinwei</forename><surname>Fu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Virginia Tech</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Virginia</forename><surname>Tech</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Virginia Tech</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Talha</forename><surname>Ghaffar</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Virginia Tech</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Virginia</forename><surname>Tech</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Virginia Tech</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">C</forename><surname>Davis</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Virginia Tech</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Virginia</forename><surname>Tech</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Virginia Tech</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongyoon</forename><surname>Lee</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Virginia Tech</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">EdgEWisE: A Better Stream Processing Engine for the Edge EDGEWISE: A Better Stream Processing Engine for the Edge</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2019 USENIX Annual Technical Conference</title>
						<meeting>the 2019 USENIX Annual Technical Conference <address><addrLine>Renton, WA, USA</addrLine></address>
						</meeting>
						<imprint>
							<date type="published">July 10-12, 2019</date>
						</imprint>
					</monogr>
					<note>This paper is included in the Open access to the Proceedings of the 2019 USENIX Annual Technical Conference is sponsored by USENIX. https://www.usenix.org/conference/atc19/presentation/fu</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Many Internet of Things (IoT) applications would benefit if streams of data could be analyzed rapidly at the Edge, near the data source. However, existing Stream Processing Engines (SPEs) are unsuited for the Edge because their designs assume Cloud-class resources and relatively generous throughput and latency constraints. This paper presents EDGEWISE, a new Edge-friendly SPE, and shows analytically and empirically that EDGEWISE improves both throughput and latency. The key idea of EDGEWISE is to incorporate a congestion-aware scheduler and a fixed-size worker pool into an SPE. Though this idea has been explored in the past, we are the first to apply it to modern SPEs and we provide a new queue-theoretic analysis to support it. In our single-node and distributed experiments we compare EDGEWISE to the state-of-the-art Storm system. We report up to a 3x improvement in throughput while keeping latency low.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Internet of Things (IoT) applications are growing rapidly in a wide range of domains, including smart cities, healthcare, and manufacturing <ref type="bibr" target="#b29">[33,</ref><ref type="bibr" target="#b38">43]</ref>. Broadly speaking, IoT systems consist of Things, Gateways, and the Cloud. Things are sensors that "read" from the world and actuators that "write" to it, and Gateways orchestrate Things and bridge them with the Cloud.</p><p>At the moment, IoT systems rely on the Cloud to process sensor data and trigger actuators. In principle, however, Things and Gateways could perform some or all data analysis themselves, moving the frontier of computation and services from the network core, the Cloud <ref type="bibr" target="#b13">[17]</ref>, to its Edge <ref type="bibr" target="#b17">[21,</ref><ref type="bibr" target="#b62">67]</ref>, where the Things and Gateways reside. In this paper we explore the implications of this paradigm in a promising use case: stream processing.</p><p>Stream processing is well suited to the IoT Edge com- puting setting. Things generate continuous streams of data that often must be processed in a timely fashion; stream processing performs analysis on individual data points (tuples) rather than batches <ref type="bibr" target="#b20">[24,</ref><ref type="bibr" target="#b64">69]</ref>. As shown in <ref type="figure" target="#fig_0">Figure 1</ref>, stream processing is described by a directed acyclic graph, called a topology, whose vertices are data processing operations and edges indicate data flow. Modern Stream Processing Engines (SPEs) such as Storm <ref type="bibr">[15]</ref>, Flink <ref type="bibr" target="#b10">[13]</ref>, and Heron <ref type="bibr" target="#b44">[49]</ref> have mostly been designed for the Cloud, assuming powerful computing resources and plenty of memory. However, these assumptions do not hold at the Edge. In particular, these SPEs use a simple One Worker Per Operation Architecture (OWPOA). Given a dataflow topology and the degree of parallelism of each operation, OWPOA-style SPEs assign a dedicated worker thread to each operation instance, and link the worker-operation pairs with queues. Then, they rely on the operating system (OS) scheduler to choose which worker (operation) to schedule next, leading to lost scheduling opportunities: data propagates haphazardly through the topology because the scheduling of worker threads is left to the congestion-oblivious OS. With Cloud-scale resources these inefficiencies are amortized, but at the Edge they cannot be.</p><p>The database community studied efficient operation scheduling about a decade before modern SPEs came into vogue <ref type="bibr" target="#b14">[18,</ref><ref type="bibr" target="#b21">25]</ref>. Sadly, however, lessons learned from this early research were not carried into the design of modern SPEs, leading to a sub-optimal performance when the existing OWPOA-style SPEs are used at the Edge setting. Existing IoT computing literature (e.g. <ref type="bibr" target="#b53">[58,</ref><ref type="bibr" target="#b59">64]</ref>) has ignored this history and has been building Edge computing platforms based on unmodified modern SPEs. This paper explores the impact of applying to modern SPEs these "lost lessons" of operation scheduling.</p><p>We present EDGEWISE, an Edge-friendly SPE that revives the notion of engine-level operation scheduling to optimize data flows in a multiplexed (more operations than processor cores) and memory-constrained Edge environment. EDGEWISE re-architects SPE runtime design and introduces an engine-level scheduler with a fixed-size worker pool where existing profiling-guided scheduling algorithms <ref type="bibr" target="#b14">[18,</ref><ref type="bibr" target="#b21">25]</ref> may be used. EDGEWISE also proposes a queue-length-based congestion-aware scheduler that does not require profiling yet achieves equivalent (or better) performance improvement. EDGEWISE monitors the numbers of pending data in queues, and its scheduler determines the highest-priority operation to process next, optimizing the flow of data through the topology. In addition, the EDGEWISE's worker pool avoids unnecessary threading overheads and decouples the data plane (operations) from the control plane (workers).</p><p>We show analytically and empirically that EDGEWISE outperforms Apache Storm <ref type="bibr">[15]</ref>, the exemplar of modern SPEs, on both throughput and latency. EDGEWISE is a reminder of both the end-to-end design principle <ref type="bibr" target="#b60">[65]</ref> and the benefits of applying old lessons in new contexts <ref type="bibr" target="#b56">[61]</ref>.</p><p>This paper provides the following contributions:</p><p>• We study the software architecture of existing SPEs and discuss their limitations in the Edge setting ( §3).</p><p>To the best of our knowledge, this paper is the first to observe the lack of operation scheduling in modern SPEs, a forgotten lesson from old SPE literature.</p><p>• We present EDGEWISE, a new Edge-friendly SPE.</p><p>EDGEWISE learns from past lessons to apply an engine-level scheduler, choosing operations to optimize data flows and leveraging a fixed-size worker pool to minimize thread contention ( §4).</p><p>• Using queuing theory, we argue analytically that our congestion-aware scheduler will improve both throughput and latency ( §5). To our knowledge, we are the first to mathematically show balancing the queue sizes lead to improved performance in stream processing.</p><p>• We demonstrate EDGEWISE's throughput and latency gains on IoT stream benchmarks ( §7).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background: Stream Processing</head><p>This section provides background on the stream processing programming model ( §2.1) and two software architectures used in existing SPEs ( §2.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Dataflow Programming Model</head><p>Stream processing uses the dataflow programming model depicted in the center of <ref type="figure" target="#fig_0">Figure 1</ref>  <ref type="bibr" target="#b20">[24,</ref><ref type="bibr" target="#b64">69]</ref>. Data tuples flow through a directed acyclic graph (topology) from sources to sinks. Each inner node is an operation that performs arbitrary computation on the data, ranging from simple filtering to complex operations like ML-based classification algorithms. In the Edge context a source might be an IoT sensor, while a sink might be an IoT actuator or a message queue to a Cloud service.</p><p>Though an operation can be arbitrary, the preferred idiom is outer I/O, inner compute. In other words, I/O should be handled by source and sink nodes, and the inner operation nodes should perform only memory and CPU-intensive operations <ref type="bibr">[3,</ref><ref type="bibr">41]</ref>. This idiom is based on the premise that the more unpredictable costs of I/O will complicate the scheduling and balancing of operations.</p><p>After defining the topology and the operations, data engineers convert the logical topology into a physical topology that describes the number of physical instances of each logical operation. In a distributed setting engineers can also indicate preferred mappings from operations to specific compute nodes. An SPE then deploys the operations onto the compute node(s), instantiates queues and workers, and manages the flow of tuples from one operation to another.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Stream Processing Engines</head><p>Starting from the notion of active databases <ref type="bibr" target="#b50">[55,</ref><ref type="bibr" target="#b71">76]</ref>, early-generation SPEs were proposed and designed by the database community in the early 2000s: e.g. Aurora <ref type="bibr" target="#b20">[24]</ref>, TelegraphCQ <ref type="bibr" target="#b23">[27]</ref>, Stream <ref type="bibr" target="#b12">[16]</ref>, and Borealis <ref type="bibr" target="#b4">[7,</ref><ref type="bibr" target="#b24">28]</ref>. Interest in SPEs led to work on performance optimization techniques such as operation scheduling <ref type="bibr" target="#b14">[18,</ref><ref type="bibr" target="#b21">25]</ref> and load shedding <ref type="bibr" target="#b31">[35,</ref><ref type="bibr" target="#b65">70]</ref>. We will revisit these works shortly ( §3.4).</p><p>The second generation of "modern SPEs" began with Apache Storm <ref type="bibr">[15]</ref> (2012) as part of the democratization of big data. Together with Apache Flink <ref type="bibr" target="#b10">[13]</ref> and Twitter's Heron <ref type="bibr" target="#b44">[49]</ref>, these second-generation SPEs have been mainly developed by practitioners with a focus on scalable Cloud computing. They have achieved broad adoption in industry.</p><p>Under the hood, these modern SPEs are based on the One Worker Per Operation Architecture (OWPOA, <ref type="figure" target="#fig_1">Fig- ure 2)</ref>. In the OWPOA, the operations are connected by queues in a pipelined manner, and processed by its  own workers. Some operations may be mapped onto different nodes for distributed computing or to take advantage of heterogeneous resources (GPU, FPGA, etc.). In addition, the OWPOA monitors the health of the topology by checking the lengths of the per-operation queues. Queue lengths are bounded by a backpressure mechanism <ref type="bibr" target="#b28">[32,</ref><ref type="bibr" target="#b44">49]</ref>, during which the source(s) buffer input until the operation queues clear.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Edge SPE Requirements Analysis</head><p>Stream processing is an important use case for Edge computing, but as we will show, existing SPEs are unsuited for the Edge. This section discusses our Edge SPE requirements analysis and the drawbacks of existing SPEs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Our Edge Model</head><p>We first present our model for the Edge.</p><p>Hardware. Like existing IoT frameworks (e.g. <ref type="bibr">Kura [36]</ref>, EdgeX <ref type="bibr" target="#b1">[2]</ref>, and OpenFog <ref type="bibr" target="#b3">[5]</ref>), we view the Edge as a distributed collection of IoT Gateways that connect Things to the Cloud. We consider Edge stream processing on IoT Gateways that are reasonably stable and well connected, unlike mobile drones or vehicles. We further assume these IoT Gateways have limited computing resources compared to the Cloud: few-core processors, little memory, and little permanent storage <ref type="bibr" target="#b13">[17,</ref><ref type="bibr" target="#b62">67]</ref>. However, they have more resources than those available to embedded, wireless sensor networks <ref type="bibr" target="#b45">[50]</ref>, and thus can afford reasonably complex software like SPEs. For example, Cisco's IoT Gateways come with a quad-core processor and 1GB of RAM <ref type="bibr" target="#b27">[31]</ref>.</p><p>Applications. Edge topologies consume IoT sensor data and apply a sequence of reasonably complex operations: e.g. SenML <ref type="bibr" target="#b39">[44]</ref> parsers, Kalman filters, linear regressions, and decision tree classifications. For example, FarmBeats <ref type="bibr" target="#b67">[72]</ref>, a smart farm platform, uses IoT Gateways to collect data from various sensors and drones, to create summaries before sending them to the Cloud for long-term and cross-farm analytics, and to perform timesensitive local data processing. We therefore assume a diverse set of workloads ranging from simple extractiontransform-load (ETL) and statistical summarization to predictive model training and classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Edge SPE Requirements</head><p>Every SPE aims for high throughput, and Edge SPEs are no exception. In addition, we see the following unique requirements for the Edge:</p><p>(1) Multiplexed. An Edge SPE must support an arbitrary topology on limited resources. We particularly focus on supporting a single topology in which there are more operations than processors, such that operation executions must be multiplexed on limited processors. Where a server-class machine can use threads unconcernedly, an Edge-class machine must be wary of unnecessary overheads.</p><p>(2) Low latency. An Edge SPE must offer low latency, else system architects should simply transmit raw data to the Cloud for analysis.</p><p>(3) No backpressure. The backpressure mechanism in Cloud SPEs is inadvisable at the Edge for two reasons. First, it is a "stop the world" scheme that destroys system latency, but latency is critical for Edge workloads. Second, it assumes that a data source can buffer pending data. While the Cloud can assume a persistent data source such as Kafka <ref type="bibr" target="#b2">[4]</ref>, at the Edge there is nowhere to put this data. Modern "real-time" SPEs such as Storm and Flink do not support file I/O based buffering. As a result the SPE must be congestion-aware to ensure queue lengths do not exceed available memory.</p><p>(4) Scalable. The SPE must permit scaling across multiprocessors within an IoT Gateway and across multiple Gateways, especially to take advantage of locality or heterogeneity favorable to one operation or another.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Shortcomings of OWPOA-style SPEs</head><p>The OWPOA naturally takes advantage of intra-node and inter-node parallelism, especially when data engineers make a good logical-to-physical mapping. In the OWPOA, however, multiplexing becomes challenging in complex topologies, because each logical operation must have at least one worker and there may be more workers than cores on a compute node. If there are too many workers assigned to one compute node the poor scheduling of workers will artificially limit performance.</p><p>Let us explain the issue in detail. The OWPOA relies on the OS scheduler to decide which worker-operation pair to schedule next. If the input rate is low enough that most queues are empty (i.e. the SPE is over-provisioned), there is no harm in such an approach. Only some operations will have work to do and be scheduled, while the remainder will sleep.</p><p>But if the input rate rises (equivalently, if the SPE becomes less provisioned) then the SPE will become saturated, i.e. most or all queues will contain tuples. In this case any operation might be scheduled by the OS. As some operations take longer than others, a typical round-robin OS scheduler will naturally imbalance the queue lengths and periodically trigger backpressure. For example, in <ref type="figure" target="#fig_1">Figure 2</ref>, although Queue 2 is full, the OS may unwisely schedule the other worker-operation pair first, triggering backpressure unnecessarily and leading to significantly high latency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">A Lost Lesson: Operation Scheduling</head><p>As noted earlier ( §2.2), the database community has studied different profiling-guided priority-based operation scheduling algorithms <ref type="bibr" target="#b14">[18,</ref><ref type="bibr" target="#b21">25]</ref> in the context of multiple operations and a single worker, before the modern OWPOA-style SPEs were born. For instance, Carney et al. <ref type="bibr" target="#b21">[25]</ref> proposed a "Min-Latency" algorithm which assigns higher (static) priority on latter operations than earlier operations in a topology and processes old tuples in the middle of a topology before newly arrived tuples, with a goal to minimize average latency. For a topology with multiple paths, the tie is broken by the profiled execution time and input-output ratio of each operation. With a goal to minimize queue memory sizes, Babcock et al. <ref type="bibr" target="#b14">[18]</ref> proposed a "Min-Memory" algorithm (called Chain) which favors operations with higher input-output reduction and short execution time (e.g., faster filters).</p><p>Unfortunately, however, modern OWPOA-style SPEs (e.g. Storm <ref type="bibr">[15]</ref>, Flink <ref type="bibr" target="#b10">[13]</ref>, Heron <ref type="bibr" target="#b44">[49]</ref>) have not adopted these research findings when designing multi-core multiworker SPEs and simply relied on the congestionoblivious OS scheduler. This paper argues that Edge SPEs should be rearchitected to regain the benefits of engine-level operation scheduling to optimize data flows in a multiplexed Edge environment. In particular, we compare the effectiveness of both profiling-based (old) and dynamic balancing (new) scheduling algorithms, and report that all offer significant throughput and latency improvements over modern SPEs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Design of EDGEWISE</head><p>This section presents EDGEWISE, an Edge-friendly SPE, that leverages a congestion-aware scheduler ( §4.1) and a fixed-size worker pool ( §4.2), as illustrated in <ref type="figure" target="#fig_2">Figure 3</ref>. EDGEWISE achieves higher throughput and low latency by balancing the queue lengths, with the effect of pushing the backpressure point to a higher input rate. Thus EDGEWISE achieves higher throughput without degrading latency (no backpressure). We later analyze the improved performance mathematically in §5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Congestion-Aware Scheduler</head><p>EDGEWISE addresses the scheduling inefficiency of the OWPOA by incorporating a user-level scheduler to make wiser choices. In the OWPOA design, physical operations are coupled to worker threads and are scheduled according to the OS scheduler policy. The EDGEWISE scheduler separates the threads (execution) from the operations (data). Prior work has proposed using profiling-based operation scheduling algorithms <ref type="bibr" target="#b14">[18,</ref><ref type="bibr" target="#b21">25]</ref>. Instead, we propose a profiling-free dynamic approach that balances queue sizes by assigning a ready thread to the operation with the most pending data.</p><p>The intuition behind EDGEWISE is shown in <ref type="figure" target="#fig_3">Figure 4</ref>, which compares the behavior of an OWPOA-style SPE to EDGEWISE in a multiplexed environment. We believe EDGEWISE's congestion-aware scheduler would be beneficial to the Cloud context, as an intranode optimization. In practice, however, we expect that EDGEWISE will have greater impact in the Edge setting, where (1) with few cores, there are likely more operators than cores, (2) latency is as critical as throughput, and <ref type="formula" target="#formula_4">(3)</ref> memory is limited. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Fixed-size Worker Pool</head><p>EDGEWISE's scheduler decouples data from execution, requiring some changes in how EDGEWISE realizes the physical topology supplied by data engineers. Rather than dedicating a worker to each operation as in the OW-POA, EDGEWISE processes data on a fixed set of workers in the worker pool ( <ref type="figure" target="#fig_2">Figure 3</ref>). These workers move from operation to operation as assigned by the scheduler. EDGEWISE could in principle work solely from the logical topology, in effect dynamically rearranging the physical topology (# workers assigned to each operation). However, this would violate any assumptions about thread safety or physical topology embedded in the logical topology. Thus, EDGEWISE uses the existing physical topology to bound the number of workers assigned to any operation at one time.</p><p>The worker pool size is configurable. By default it is set to the number of processors, because we assume that most operations are CPU-intensive per the recommended stream programming model ( §2.1). If there are many I/O-bound operations, a fixed-size worker pool may lead to sub-optimal performance, requiring users to tune the pool size. Putting it together. The scheduler dynamically chooses which operation a worker should perform. When a worker is ready, it asks the scheduler for an assignment, and the scheduler directs it to the operation with the longest pending data queue. Without work, it sleeps. When new data arrives, the scheduler wakes up the worker. The worker non-preemptively 1 completes the operation, and EDGEWISE directs the output to the downstream operation queue(s). Different operations may run in parallel: e.g., operations 2 and N in <ref type="figure" target="#fig_2">Figure 3</ref>. However, for FIFO guarantees, EDGEWISE schedules at most one worker to any operation instance (i.e. to any queue).</p><p>EDGEWISE supports three different data consumption policies for each scheduling turn: (1) All consumes all the tuples in the queue; (2) Half consumes half of the tuples in the queue; and (3) At-most-N consumes at most N tuples in the queue. Intuitively, in a saturated system, consuming a small constant number in each quantum will cause the scheduler to make more decisions overall. As our scheduler is fast, the more decisions it makes the better it should approximate the ideal schedule (evaluated in §7.4). Such consumption policies are not possible in OWPOA-style SPEs.</p><p>EDGEWISE meets the Edge SPE design goals, listed in §3.2. EDGEWISE retains the achievements of the OW-POA, and to these it adds the multiplexed, low-latency, and no-backpressure requirements. EDGEWISE's scheduler allows it to balance queue lengths, improving average latency and avoiding the need for backpressure by keeping heavier operations from lagging behind.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Performance Analysis of EDGEWISE</head><p>This section shows analytically that EDGEWISE will achieve higher throughput ( §5.1) and lower latency ( §5.2) than OWPOA. Lastly, in §5.3 we discuss how to measure relevant runtime metrics for the performance analysis. To the best of our knowledge, we are the first to apply queueing theory to analyze the improved performance in the context of stream processing. Prior scheduling works in stream processing either provide no analysis <ref type="bibr" target="#b21">[25]</ref> or focus only on memory optimization <ref type="bibr" target="#b14">[18]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Higher Throughput</head><p>First we show that maximum end-to-end throughput depends on scheduling heavier operations proportionally more than lighter operations. This is impossible to guarantee in the scheduler-less modern SPEs, but easy for EDGEWISE's scheduler to accomplish.</p><p>Our analysis interprets a dataflow topology as a queuing network <ref type="bibr" target="#b34">[38,</ref><ref type="bibr" target="#b41">46]</ref>: a directed acyclic graph of stations. Widgets (tuples) enter the network via the queue of the first station. Once the widget reaches the front of a station's queue, a server (worker) operates on it, and then it advances to the next station. The queuing theory model allows us to capture the essential differences between EDGEWISE and the OWPOA. In the rest of this section we draw heavily on <ref type="bibr" target="#b34">[38,</ref><ref type="bibr" target="#b41">46]</ref>, and we discuss the model's deviations from real topology behavior at the end. Modeling. Given the input rate λ i and the service rate µ i of a server i, the server utilization ρ i (fraction of time it is busy) is defined as:</p><formula xml:id="formula_0">ρ i = λ i µ i<label>(1)</label></formula><p>A queuing network is stable when ρ i &lt; 1 for all servers i. If there is a station to which widgets arrive more quickly than they are serviced, the queue of that station will grow unbounded. In an SPE, unbounded queue growth triggers the backpressure mechanism, impacting system latency.</p><p>Suppose we want to model a topology with M operations in this way. We can represent the input and server rates of each operation as a function of λ 0 and µ 0 , the input and service rates of the first operation, respectively. We are particularly interested in λ 0 as it is the input rate to the system; higher λ 0 means higher throughput. Expressing the input scaling factors and relative operation costs for an operation i as q i and r i , we can write the input rate λ i and the service rate µ i for operation i as:</p><formula xml:id="formula_1">λ i = q i · λ 0 µ i = r i · µ 0</formula><p>In queuing theory, each node is assumed to have an exclusive server (worker). However, in the Edge, there may be fewer servers (processor cores) than stations (operations). If there are C processor cores, we can model processor contention by introducing a scheduling weight w i , subject to ∑ M i w i = C, yielding the effective service rate µ i ′ :</p><formula xml:id="formula_2">µ i ′ = w i · µ i = w i · (r i · µ 0 )</formula><p>For instance, when one core is shared by two operations, a fair scheduler halves the service rate (w 1 = w 2 = 1 2 ) as the execution time doubles. The constraint ∑ M i w i = C reflects the fact that C processor cores are shared by M operations.</p><p>Similarly, the effective server utilization ρ i ′ can be redefined based on µ i ′ . To keep the system stable (eliminate backpressure), we want ρ i ′ to be less than one:</p><formula xml:id="formula_3">∀i, ρ i ′ = λ i µ i ′ = q i · λ 0 w i · r i · µ 0 &lt; 1<label>(2)</label></formula><p>which can be rearranged as</p><formula xml:id="formula_4">∀i, λ 0 &lt; w i · r i q i · µ 0<label>(3)</label></formula><p>Optimizing. Remember, λ 0 represents the input rate to the system and is under our control; a higher input rate means higher throughput (e.g. the system can sample sensors at a higher rate). Assuming that µ 0 , r i , and q i are constants for a given topology, the constraint of Equation (3) implies that the maximum input rate λ 0 that an SPE can achieve is upper-bounded by the minimum of w i · r i q i over all i. Thus, our optimization objective is to:</p><formula xml:id="formula_5">maximize min i (w i · r i q i ) subject to M ∑ i w i = C<label>(4)</label></formula><p>It is straightforward to show that the maximum input rate can be achieved when w i · r i q i are equal to each other for all i: i.e.,</p><formula xml:id="formula_6">w 1 : w 2 : · · · : w N = q 1 r 1 : q 2 r 2 : · · · : q M r M</formula><p>In other words, the scheduling weight w i should be assigned proportional to q i r i</p><p>. This is indeed very intuitive. An operation becomes heavy-loaded when it has a higher input rate (higher q i ) and/or a lower service rate (lower r i ). Such an operation should get more turns.</p><p>Scheduling. EDGEWISE's scheduler dynamically identifies heavily loaded operations and gives them more turns. The queue of an operation with higher input rate and higher compute time (lower service rate) grows faster than the others. By monitoring queue sizes, we can identify and favor the heavy-loaded operations with more frequent worker assignments.</p><p>Compare this behavior to that of the OWPOA. There, the "fair" OS scheduler blindly ensures that w i is the same for each operation, unaware of relative input and service rates, leading to suboptimal throughput. Once saturated, one of the heavy operations will reach the utilization cap of ρ i = 1, become a bottleneck in the topology, and eventually trigger backpressure and latency collapse. Data engineers can attempt to account for this by profiling their topologies and specifying more workers for heavier operations. Fundamentally, however, this is an ad hoc solution: the OS scheduler remains blind.</p><p>In our evaluation ( §7.3.1) we show that EDGEWISE achieves w i · r i q i equality across operations at runtime, leading to an optimal balanced effective server utilization ρ i ′ . In contrast, we report that in the OWPOA approach, increasing the input rate leads to increasingly unbalanced ρ i ′ across operations.</p><p>Runtime deviations from the model. Our queuing theory model captures real SPE behavior in the essentials, but it deviates somewhat in the particulars. We give two prominent examples. The first deviation is that our queuing theory model assumes predictable widget fan-in and fan-out ratios at each operator (i.e. constant q i and r i ).</p><p>In reality these are distributions. For example, an operation that splits a sentence into its constituent words  <ref type="figure">gray box)</ref>, the operation i processes a pending tuple. A tuple j can be in one of three states: waiting in the middle of the queue (T Q ), at the head of the queue waiting to be scheduled (T S ), or being computed (T C ). Later in §7.3.2, we show that T Q dominates the per-operation latency in a saturated system.</p><p>will emit one tuple for "Please", two tuples for "Please accept", and so on. The second deviation is that we assumed that operations have constant costs. In reality it will take such a sentence-splitting operation more time to process longer sentences. Considering these deviations, the difficulty data engineers face when generating physical topologies for a OWPOA SPE is clear: it is difficult to identify a single integer quantity of workers to assign to each operation, and even then balance will only be achieved probabilistically over many scheduling cycles. In contrast, EDGEWISE automatically balances the assignment of workers to operations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Lower Latency</head><p>Now we show that EDGEWISE can achieve lower endto-end latency than the OWPOA without compromising throughput. Our analysis hinges on the observation that unbalanced queue lengths have an outsized effect on latency, so that balancing queue lengths leads to an overall improvement in latency.</p><p>The total latency for a completed tuple equals the sum of the latencies paid at each operation it visited on its way from source to sink, plus communication latencies outside of our control:</p><formula xml:id="formula_7">Latency = M ∑ i (L i +Comm.) ≈ M ∑ i L i<label>(5)</label></formula><p>In stream processing, the per-operation latency consists of (1) the queue time T Q , waiting in the queue; (2) the schedule time T S , waiting for a turn at the head of the queue; and (3) the (pure) compute time T C , being processed. As illustrated in <ref type="figure" target="#fig_5">Figure 5</ref>, these times come at a different form. In OWPOA (a), the preemptive OS scheduler makes T S and T C interleaved. In EDGEWISE (b), the non-preemptive scheduler makes clear distinction because an operation is not scheduled until a worker is available, and when scheduled, it completes its work.</p><p>In a saturated system, we treat T S and T C as constants, while T Q will grow with the input rate to dominate L i .</p><formula xml:id="formula_8">L i = T Q + (T S + T C ) ≈ T Q<label>(6)</label></formula><p>Assuming that the input and service rates, λ and µ, can be modeled as exponential random variables 2 , Gross et al. <ref type="bibr" target="#b34">[38]</ref> show that the queue time T Q can be expressed as</p><formula xml:id="formula_9">T Q = ρ µ − λ = λ µ(µ − λ)<label>(7)</label></formula><p>Note that T Q has a vertical asymptote (approaches ∞) at µ = λ, and a horizontal asymptote (approaches 0) when µ &gt;&gt; λ. In other words, for a given λ, a tuple will wait longer in the queues of heavier operations, and crucially the growth in wait time is non-linear (accelerates) as µ approaches λ. This means that heavier operations have a much larger T Q and thus L i (Equation (6)) than lighter operations, and an outsized impact on overall latency (Equation <ref type="formula" target="#formula_7">(5)</ref>).</p><p>Though the effect of heavy operations may be dire when using the OWPOA's random scheduler, EDGEWISE's congestion-aware scheduler can avoid this problem by giving more hardware resources (CPU turns) to heavier operations over lighter ones. In effect, EDGEWISE balances the T Q of different operations, reducing the T Q of tuples waiting at heavy operations but increasing the T Q of tuples waiting at lighter operations. According to <ref type="bibr">Gross et al.'</ref>s model this balancing act is not a zero-sum game: we expect that the lighter operations sit near the horizontal asymptote while the heavier operations sit near the vertical asymptote, and balancing queue times will shift the entire latency curve towards the horizontal asymptote. In our evaluation we support this analysis empirically ( §7.3.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Measuring Operation Utilization</head><p>In our evaluation we compare EDGEWISE with a stateof-the-art OWPOA. For a fine-grained comparison, in addition to throughput and latency we must compare the operation utilization ρ = λ µ discussed in §5.1. This section describes how we can fairly compare EDGEWISE against a baseline OWPOA system in this regard.</p><p>We want to compare the server (operation) utilization of EDGEWISE and the baseline. As argued in §5.1, an ideal result is a balanced utilization vector consisting of equal values 1 − ε, with ε chosen based on latency requirements. As operation utilization may change over the lifetime of an SPE run (e.g. as it reaches "steadystate"), we incorporate a time window T w into the metric given in Equation (1).</p><p>During a time window T w , an operation might be performed on N tuples requiring a total of T E CPU time. The input rate for this operation during this window is λ w = N T w and the service rate is µ w = 1</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>T E</head><p>, so we have windowed utilization ρ w as:</p><formula xml:id="formula_10">ρ w = λ w µ w = T E · N T w<label>(8)</label></formula><p>Unsurprisingly, we found that this is the utilization metric built into Storm <ref type="bibr">[15]</ref> 3 , the baseline system in our evaluation.</p><p>In the OWPOA, computing ρ w is easy. T w is fixed, N is readily obtained, and T E can be calculated by monitoring the beginning and ending time of performing the operation on each tuple:</p><formula xml:id="formula_11">T E = 1 N N ∑ j (T end ( j) − T begin ( j))<label>(9)</label></formula><p>Equation <ref type="formula" target="#formula_11">(9)</ref> would suffice to measure ρ w for the OW-POA, but for a fair comparison between the OWPOA and EDGEWISE we need a different definition. Note that T end ( j)−T begin ( j) captures the total time a worker spends applying an operation to a tuple, and in the OWPOA <ref type="figure" target="#fig_5">(Fig- ure 5 (a)</ref>) this calculation includes both T C (pure computation) and T S (worker contention). As EDGEWISE's scheduler is non-preemptive ( <ref type="figure" target="#fig_5">Figure 5 (b)</ref>), measuring T E in this way would capture only EDGEWISE's T C . Doing so would ignore its T S , the time during which EDGEWISE's scheduler decides not to schedule an operation with a non-empty queue in favor of another operation with a longer queue. This would artificially decrease T E and thus ρ w for this operation.</p><p>To capture T S for an operation in EDGEWISE, we can instead amortize the schedule time T S across all completed tuples, and describe the operation's time during <ref type="bibr">3</ref> In Apache Storm this metric is called the operation's capacity.</p><p>this window as spent either executing or idling with an empty queue:</p><formula xml:id="formula_12">T w = T E · N + T emptyQ<label>(10)</label></formula><p>Solving Equation <ref type="formula" target="#formula_0">(10)</ref> for T E and substituting into Equation <ref type="formula" target="#formula_10">(8)</ref>, we can compute ρ w in EDGEWISE:</p><formula xml:id="formula_13">ρ w = 1 − T emptyQ T w<label>(11)</label></formula><p>The windowed utilization metric ρ w given in Equation (11) applies equally well to SPEs that use the OW-POA or EDGEWISE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Implementation</head><p>We implemented EDGEWISE on top of Apache Storm <ref type="bibr">[15]</ref> (v1.1.0). Among modern SPEs, Storm was the most popular for data science in 2018 <ref type="bibr" target="#b16">[20]</ref> and has the lowest overall latency <ref type="bibr" target="#b25">[29]</ref>. We made three major modifications: (1) We implemented the congestion-aware scheduler ( §4.1), and added two data structures: a list of operations with non-empty queues as scheduling candidates; and a list of running operations to ensure FIFO per queue; (2) We removed the per-operation worker threads, and added one worker pool of (configurable) K worker threads ( §4.2); and (3) We introduced two queuing-related metrics, T emptyQ and T Q , for server utilization and latency breakdown analysis ( §5.3).</p><p>EDGEWISE can be applied to other OWPOA-style SPEs such as Flink <ref type="bibr" target="#b10">[13]</ref> and Heron <ref type="bibr" target="#b44">[49]</ref>. In Flink, multiple operators may be grouped in a single Task Slot, but each operator (called "subtask") still has its own worker thread. Task Slot separates only the managed "memory" of tasks, but there is no CPU isolation. As a result, worker threads will still contend and cause congestion if there are more operators than CPUs. Thus, EDGEWISE's congestion-aware scheduler and fixed-size worker pool will be equally beneficial for Flink.</p><p>The EDGEWISE prototype is available at https: //github.com/VTLeeLab/EdgeWise-ATC-19. It adds 1500 lines of Java and Clojure across 30 files.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Evaluation</head><p>Our evaluation first shows EDGEWISE's throughputlatency performance on representative Edge stream processing workloads ( §7.2), followed by detailed performance analysis ( §7.3). Then we present a sensitivity study on different consumption policies ( §7.4), and a distributed (inter-node) performance study ( §7.5).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">General Methodology</head><p>Hardware. EDGEWISE is designed for the Edge, so experiments use an intermediate-class computing device representative of IoT Edge devices ( §3.1): weaker than Cloud-class servers but stronger than typical embedded systems. Specifically, we use Raspberry Pi 3 Model B devices (raspbis), which have a 1.2GHz quad-core ARM Cortex-A53 with 1GB of RAM and run Raspbian GNU/Linux 8.0 v4.1.18.</p><p>Baseline. We used Storm <ref type="bibr">[15]</ref> as the OWPOA baseline. We set up Storm's dependencies, Nimbus and a Zookeeper server, on a desktop machine, and placed the Storm supervisors (compute nodes) on the raspbis. Because EDGEWISE optimizes the performance of a single compute node, all but our distributed experiment ( §7.5) use a single raspbi. As our raspbis are quad-core, EDGEWISE uses four worker threads.</p><p>Schedulers. In addition to EDGEWISE's queue-lengthbased approach, we also evaluated implementations of the Min-Memory <ref type="bibr" target="#b14">[18]</ref> and Min-Latency <ref type="bibr" target="#b21">[25]</ref> schedulers, as well as a Random scheduler. All schedulers used our At-most-50 data consumption policy ( §4.2), based on our sensitivity study §7.4.</p><p>Benchmarks. We used the RIoTBench benchmark suite <ref type="bibr" target="#b63">[68]</ref>, a real-time IoT stream processing benchmark implemented for Storm <ref type="bibr" target="#b2">4</ref> . The RIoTBench benchmarks perform various analyses on a real-world Smart Cities data stream <ref type="bibr" target="#b18">[22]</ref>. Each input tuple is 380 bytes. The sizes of intermediate tuples vary along the topology. <ref type="figure" target="#fig_6">Figure 6</ref> shows RIoTBench's four topologies. We identified each physical topology using a search guided by the server utilization metric ( §5.1), resulting in physical topologies with optimal latency-throughput curves on our raspbi nodes <ref type="bibr" target="#b36">[40]</ref>. We used the same physical topologies for both Storm and EDGEWISE.</p><p>We made three modifications to the RIoTBench benchmarks: (1) We patched various bugs and inefficiencies. (2) We replaced any Cloud-based services with lab-based ones; (3) To enable a controlled experiment, we implemented a timer-based input generator that reads data from <ref type="bibr" target="#b2">4</ref> Other benchmarks <ref type="bibr">[6,</ref><ref type="bibr" target="#b48">53]</ref> seemed too unrealistic for our use case.</p><p>a replayed trace at a configurable input rate. To be more specific, the Smart Cities data <ref type="bibr" target="#b18">[22]</ref> is first loaded into the memory, and a timer periodically (every 100 ms) feeds a fixed-size batch of them into Spout, the source operator in Storm. We changed the batch size to vary the input rate. This simulates a topology measuring sensor data at different frequencies, or measuring different number of sensors at a fixed frequency. Metrics. Measurements were taken during the one minute of steady-state runs, after discarding couple minutes of initial phase. We measured throughput by counting the number of tuples that reach the MQTT Publish sink. Measuring throughput at the sink results in different throughput rates for each topology at a given input rate, since different topologies have input-output tuple ratios: e.g., 1:2 in PRED, 1:5 in STATS. We measured latency by sampling 5% of the tuples, assigning each tuple a unique ID and comparing timestamps at source and the same sink used for the throughput measurement. We measured operation utilization using ρ w (Equation (11)). Each experiment was performed 5 times with each configuration. The error bars indicate one standard deviation from the average. Most data points had small variances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Throughput-Latency Performance</head><p>We measured the throughput-latency performance curve for each of the RIoTBench applications on one raspbi across a range of input rates. The curves for PRED, STATS, and ETL are shown in <ref type="figure">Figure 7</ref>; the curve for the TRAIN application (not shown) looks like that of the ETL application. In general, both Storm and EDGEWISE have excellent performance when the system is under-utilized (low throughput). Latency performance collapses at high throughput rates as a result of frequent backpressure.</p><p>The results show that an SPE with an engine-level operation scheduler and a worker pool (WP) significantly outperforms Storm (an OWPOA-based SPE) at the Edge, in effect shifting the Storm throughput-latency curve down (lower latency) and to the right (higher throughput). First, the gaps between Storm and WP+Random indicate the benefit of avoiding unnecessary contentions in OW-POA. More importantly, the engine-level schedulers in effect push the backpressure point to a higher input rate, allowing the SPEs to achieve higher throughput at a low latency. The high variance in the Storm curves at higher throughput rates indicate early, random backpressure. Among the variants that use a scheduler and WP, EDGEWISE's queue-length-based scheduler matches or outperforms WP+MinLat on latency and throughput, while WP+MinMem leads to improved (but not the best) performance as it is optimized for memory. Note that EDGEWISE does not require profiling per-operation execution time and input-output ratio as do MinLat and MinMem. For PRED, while keeping the latency low (say ≤100 ms), EDGEWISE improves its throughput by 57% (from 2800 to 4400). EDGEWISE is particularly effective in the STATS, where it achieves a 3x throughput improvement with low latency. For ETL, EDGEWISE improves throughput from 1000 to 1350 under 50ms latency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3">Detailed Performance Breakdown</head><p>This experiment investigates the underlying causes of the throughput and latency gains described in §7.2, lending empirical support to our analysis in §5. We use the PRED application as a case study, though results were similar in the other RIoTBench applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3.1">Fine-Grained Throughput Analysis</head><p>Our analysis of throughput in §5.1 predicted that balancing effective server (operation) utilization would yield gains in throughput. To measure the extent to which Storm and EDGEWISE balance server utilization, in this experiment we calculated the windowed utilization ρ w of each operation using Equation <ref type="formula" target="#formula_0">(11)</ref> and then computed the coefficient of variation (CV = stddev avg ) of this vector. A lower utilization CV means more balanced server utilization. <ref type="figure">Figure 8</ref> plots the coefficient of variation for Storm and EDGEWISE for different input rates. As the input rate (and thus output throughput) increases, the utilization CV increases in Storm, indicating that the operations become unbalanced as Storm becomes saturated. In contrast, in EDGEWISE the utilization CV decreases for larger input rates (and the raw ρ w values approach 1). As predicted, EDGEWISE's throughput gains are explained by its superior ρ w balancing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3.2">Fine-Grained Latency Analysis</head><p>Our analysis of latency in §5.2 noted that in a congestionblind scheduler, heavier operations would develop longer queues, and that the queuing time at these operations would dominate end-to-end latency. We showed that an SPE that reduced queuing times at heavy operations, even at the cost of increased queuing times at lighter operations, would obtain an outsized improvement in latency. In this experiment we validate this analysis empirically.</p><p>For this experiment we break down per-operation latency into its constituent parts (Equation <ref type="formula" target="#formula_8">(6)</ref>) and analyze the results in light of our analysis. <ref type="figure" target="#fig_8">Figure 9</ref> shows the per-operation latency for the 6 nonsource operations in the PRED topology in the baseline Storm. Its logical and physical topology is shown in <ref type="figure" target="#fig_6">Fig- ure 6 (a)</ref>. Where our physical topology has multiple instances of an operation (two instances of O1, three of O6), we show the average queuing latency across instances.</p><p>Note first that the queue time T Q dominates the peroperation latency L i . Then, as the input rate increases from L(ow) to H(igh), the queues of heavier operations (O1, O6) grow much longer than those of lighter operations, and the queue time at these operations dominates the overall latency. Also note that the latency of lighter operations may decrease at high throughput, as tuples are Figure 10: In EDGEWISE, as the throughput increases, the queuing latency of heavy operations (e.g., <ref type="bibr">O1</ref> and O6) increases slowly.</p><formula xml:id="formula_14">L M H L M H L M H L M H L M H L M</formula><p>mostly waiting in the queue of heavy operations, reflecting the effects of the non-deterministic OS scheduler. In contrast, we observed different behavior for EDGEWISE as shown in <ref type="figure" target="#fig_0">Figure 10</ref>. The heaviest operation O1 is still noticeable but its queue time under High input rate is only 15 ms, much smaller than the 25 ms of Storm. Of course this penalizes the lighter operations, but as we argued in §5.2 this is not a zero-sum game; the improvement in end-to-end latency outweighs any small per-operation latency increase.</p><p>The schedule time T S includes both the scheduling overhead and the waiting time due to contention. Across all throughput rates and operations, T S remains very small, implying that the overhead of EDGEWISE's scheduler is negligible.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.4">Data Consumption Policy</head><p>In this experiment we explored the sensitivity of EDGEWISE's performance to its data consumption policies: a constant number (At-most-N) or a number proportional to the queue length (All, Half).</p><p>In <ref type="figure" target="#fig_0">Figure 11</ref> you can see the effect of these rules in the STATS topology, as well as the Storm performance for comparison. As expected, the constant consumption rules consistently performed well in STATS. The PRED showed the trend similar to the STATS. The TRAIN and ETL topologies were not sensitive to the consumption policy. The At-most-50 rule (solid black line) offers good latency with the highest throughput for all, so we used it in our other experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.5">Performance on Distributed Edge</head><p>Streaming workloads can benefit from scaling to multiple compute nodes, and supporting scaling was one of our design goals ( §3.2). In this experiment we show that EDGEWISE's intra-node optimizations benefit an internode (distributed) workload.</p><p>We deployed the PRED application across 2, 4, and 8 raspbis connected on a 1G Ethernet lab network, simply increasing the physical operation instances proportional to the number of raspbis and assigning them uniformly across nodes. Identifying an optimal distributed topology (and optimal partitioning across nodes) is out of scope for our work, which focuses on the optimal scheduling of the topology deployed on a single node. Experiments on visionary hundred-or thousand-node cases are left for future work. We used the same methodology as in §7.2 to collect metrics.</p><p>As expected, EDGEWISE's intra-node optimizations prove beneficial in an inter-node setting. <ref type="figure" target="#fig_0">Figure 12</ref> shows the maximum throughput achieved by Storm and EDGEWISE with latency less than 100 ms. The scalability curve shows about 2.5x throughput improvement with 8 nodes, suggesting that a combination of networking costs and perhaps a non-optimal topology keep us from realizing the full 8x potential improvement. On this particular physical topology, EDGEWISE achieves an 18-71% improvement over Storm's maximum throughput, comparable to the 57% improvement obtained in the 1-node experiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Related Work</head><p>To the best of our knowledge, Edgent <ref type="bibr" target="#b9">[12]</ref> is the only other SPE tailored for the Edge. Edgent is designed for data preprocessing at individual Edge devices rather than The maximum throughput achieved with the latency less than 100 ms, using the PRED topology with 1, 2, 4, and 8 distributed nodes (log-scale). EDGEWISE's intra-node optimizations extend to a distributed setting.</p><p>full-fledged distributed stream processing. We believe the Edge is powerful enough for more intelligent services, and thus EDGEWISE targets a more expressive SPE language with balanced throughput and latency. Targeting distributed Cloud settings, a variety of academic <ref type="bibr" target="#b22">[26,</ref><ref type="bibr" target="#b35">39,</ref><ref type="bibr" target="#b47">52,</ref><ref type="bibr" target="#b57">62,</ref><ref type="bibr" target="#b68">73]</ref> and industry/open-source <ref type="bibr">[15,</ref><ref type="bibr" target="#b44">49,</ref><ref type="bibr" target="#b61">66]</ref> SPEs have been proposed. Some <ref type="bibr" target="#b5">[8,</ref><ref type="bibr" target="#b6">9,</ref><ref type="bibr" target="#b8">11,</ref><ref type="bibr" target="#b10">13,</ref><ref type="bibr" target="#b11">14]</ref> support both stream and batch processing. Most use the OWPOA design and differentiate themselves on largescale distributed processing and fault tolerance. None has our notion of an engine-level scheduler.</p><p>Researchers have studied distributed "job placement" schedulers for Storm <ref type="bibr" target="#b7">[10,</ref><ref type="bibr" target="#b19">23,</ref><ref type="bibr" target="#b55">60,</ref><ref type="bibr" target="#b72">77]</ref> and Spark Streaming <ref type="bibr" target="#b42">[47,</ref><ref type="bibr" target="#b46">51]</ref>. They determine where to distribute computing workloads across nodes in the Cloud. EDGEWISE does not focus on how to partition a physical topology for distributed computing.</p><p>Recent single-node SPE solutions leverage modern many-core and heterogeneous architectures. For example, <ref type="bibr">GStream [78]</ref> describes an SPE tailored to GPUs, while Saber <ref type="bibr" target="#b43">[48]</ref> is a hybrid SPE for mixed CPU/GPU computing that schedules operations on different hardware depending on where they perform better. <ref type="bibr">Stream- Box [56]</ref> explores the high-end server space, demonstrating high throughput by extracting pipeline parallelism on a state-of-the-art 56-core NUMA server. StreamBox uses a worker pool (like EDGEWISE) to maximize CPU utilization, but does not maintain a queue for each operation, making it hard to apply the Storm-like distributed stream processing model. EDGEWISE targets the opposite end of the spectrum: a compute cluster composed of Edge-class devices where intra-node scale-up is limited but inter-node scale-out is feasible. Thus, EDGEWISE adopts the general distributed streaming model (scaleout) and enables additional intra-node scale-up.</p><p>The Staged Event Driven Architecture (SEDA) <ref type="bibr" target="#b70">[75]</ref> was proposed to overcome the limitations of threadbased web server architectures (e.g., Apache Httpd <ref type="bibr" target="#b0">[1]</ref>): namely, per-client memory and context-switch overheads. EDGEWISE shares the same observation and proposes a new congestion-aware scheduler towards a more efficient EDA, considering how to stage (schedule) stream processing operations.</p><p>Mobile Edge Computing (MEC) <ref type="bibr" target="#b37">[42,</ref><ref type="bibr" target="#b54">59]</ref> uses mobile devices to form an Edge. Unlike EDGEWISE, they focus on mobile-specific issues: e.g., mobility, LTE connections, etc. Two works support stream processing on mobile devices. Mobile Storm <ref type="bibr" target="#b52">[57]</ref> ported Apache Storm as is. <ref type="bibr">MobiStreams [74]</ref> focuses on fault tolerance when a participating mobile disappears. On the other hand, Mobile-Cloud Computing (MCC) <ref type="bibr" target="#b26">[30,</ref><ref type="bibr" target="#b30">34,</ref><ref type="bibr" target="#b33">37,</ref><ref type="bibr" target="#b40">45,</ref><ref type="bibr" target="#b58">63]</ref> aims to offload computation from mobile to the Cloud. There will be a good synergy between EDGEWISE and MEC/MCC. EDGEWISE could be viewed as a local cloud to which they can offload computations.</p><p>Lastly, queueing theory has been used to analyze stream processing. The chief difference between previous analyses and our own lies in the assumption about worker sharing. In traditional queueing theory, each operation is assumed to fairly share the workers. For example, Vakilinia et al. <ref type="bibr" target="#b66">[71]</ref> uses queueing network models to determine the smallest number of workers under the latency constraint, under the assumption that workers are uniformly shared among operations. The same is true for the analyses of Mak et al. <ref type="bibr" target="#b49">[54]</ref> for series-parallel DAG and Beard et al. <ref type="bibr" target="#b15">[19]</ref> for heterogeneous hardware. On the other hand, our analysis identifies the benefit of a non-uniform scheduling weight, assigning more workers to heavy-loaded operations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Conclusion</head><p>Existing stream processing engines were designed for the Cloud and behave poorly in the Edge context. This paper presents EDGEWISE, a novel Edge-friendly stream processing engine. EDGEWISE improves throughput and latency thanks to its use of a congestion-aware scheduler and a fixed-size worker pool. Some of the ideas behind EDGEWISE were proposed in the past but forgotten by modern stream processing engines; we enhance these ideas with a new scheduling algorithm supported by a new queuing-theoretic analysis. Sometimes the answers in system design lie not in the future but in the past.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The Edge connects Things to the Cloud, and can perform local data stream processing.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: One Worker Per Operation Architecture (OW-POA). It assigns a worker thread for each operation. The example shows the case with N operations. Q represents a queue where a gray box means a pending data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: EDGEWISE Architecture ( §4). The scheduler picks which operation to run. In this example, operation 2 and operation N had the longest queues, so they were scheduled.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 (</head><label>4</label><figDesc>a) shows the unwise choice that may be made by the random scheduler of the OWPOA, leading to backpressure (high latency). Figure 4(b) contrasts this with the choice made by EDGEWISE's congestion-aware scheduler, evening out the queue lengths to avoid backpressure.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: A scheduling example with two operations, multiplexed on a single core. The Q(ueue) size is two. Initially, Q1 has one tuple and Q2 is full. (a) The random OS scheduler in OWPOA lets Op(eration) 1 process tuples ③ and (newly coming) ④ first, overflowing Q2 and triggering unnecessary backpressure. (b) EDGEWISE knows Q2 has more pending data, and thus schedules the more critical Op2 first, avoiding congestion.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: A per-operation latency breakdown example of (a) OWPOA, and (b) EDGEWISE. Incoming data tuples ①, ②, and ③ are being queued. When scheduled (dark gray box), the operation i processes a pending tuple. A tuple j can be in one of three states: waiting in the middle of the queue (T Q ), at the head of the queue waiting to be scheduled (T S ), or being computed (T C ). Later in §7.3.2, we show that T Q dominates the per-operation latency in a saturated system.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Tested Topologies in RIoTBench [68]: (a) PREDictive analytics, (b) model TRAINinig, (c) Extract, Transform, and Load, and (d) STATistical summarization. The (tuned) number of physical operations are shown as the overlapped, multiple rectangles: e.g., 3 MQTT Publish operations in (a).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7 :Figure 8 :</head><label>78</label><figDesc>Figure 7: Throughput-latency of (a) PRED, (b) STATS, and (c) ETL topologies.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: In Storm, as the throughput increases from L(ow) to M(edium) to H(igh), the queuing latency of heavy operations (e.g., O1 and O6) increases rapidly.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 11 :</head><label>11</label><figDesc>Figure 11: Sensitivity study on various consumption policies with STATS topology.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 12 :</head><label>12</label><figDesc>Figure 12: The maximum throughput achieved with the latency less than 100 ms, using the PRED topology with 1, 2, 4, and 8 distributed nodes (log-scale). EDGEWISE's intra-node optimizations extend to a distributed setting.</figDesc></figure>

			<note place="foot" n="1"> More precisely, it is non-preemptive at the engine level. EDGEWISE can still be preempted by the underlying OS scheduler.</note>

			<note place="foot" n="2"> For λ and µ with general distributions, the curve in the λ &lt; µ region is similar. The exponential model simplifies the presentation.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We are grateful to the anonymous reviewers and to our shepherd, Dilma Da Silva, for their thoughts and guidance. This work was supported in part by the National Science Foundation, under grant CNS-1814430.</p></div>
			</div>

			<div type="annex">
			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">The apache http server</title>
		<ptr target="http://httpd.apache.org" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edgex</forename><surname>Foundry</surname></persName>
		</author>
		<ptr target="https://www.edgexfoundry.org/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Kafka -A distributed Streaming Platform</title>
		<ptr target="https://kafka.apache.org/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Openfog</surname></persName>
		</author>
		<ptr target="https://www.openfogconsortium.org/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The design of the borealis stream processing engine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanif</forename><surname>Daniel J Abadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Magdalena</forename><surname>Ahmad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ugur</forename><surname>Balazinska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitch</forename><surname>Cetintemel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeonghyon</forename><surname>Cherniack</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfgang</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anurag</forename><surname>Lindner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Maskey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Esther</forename><surname>Rasin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ryvkina</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Cidr</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="277" to="289" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Millwheel: fault-tolerant stream processing at internet scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tyler</forename><surname>Akidau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Balikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaya</forename><surname>Bekiro˘ Glu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slava</forename><surname>Chernyak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josh</forename><surname>Haberman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reuven</forename><surname>Lax</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Mcveety</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Mills</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Nordstrom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Whittle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB Endowment</title>
		<meeting>the VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="1033" to="1044" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The dataflow model: A practical approach to balancing correctness, latency, and cost in massive-scale, unbounded, out-of-order data processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tyler</forename><surname>Akidau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Bradshaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Craig</forename><surname>Chambers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slava</forename><surname>Chernyak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rafael</forename><forename type="middle">J</forename><surname>Fernández-Moctezuma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reuven</forename><surname>Lax</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Mcveety</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Mills</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frances</forename><surname>Perry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Whittle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB Endowment</title>
		<meeting>the VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="1792" to="1803" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Adaptive online scheduling in storm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonardo</forename><surname>Aniello</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Baldoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonardo</forename><surname>Querzoni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th ACM international conference on Distributed event-based systems</title>
		<meeting>the 7th ACM international conference on Distributed event-based systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="207" to="218" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Apache</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Beam</surname></persName>
		</author>
		<ptr target="https://flink.apache.org/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Apache Edgent -A Community for Accelerating Analytics at the Edge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Apache</surname></persName>
		</author>
		<ptr target="https://edgent.apache.org/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Apache</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Apache</surname></persName>
		</author>
		<ptr target="https://flink.apache.org/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Apache spark. a fast and general engine for large-scale data processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Apache</surname></persName>
		</author>
		<ptr target="http://spark.apache.org/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Stream: The stanford stream data manager (demonstration description)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arvind</forename><surname>Arasu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Babcock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shivnath</forename><surname>Babu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mayur</forename><surname>Datar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keith</forename><surname>Ito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Itaru</forename><surname>Nishizawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Rosenstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennifer</forename><surname>Widom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2003 ACM SIGMOD International Conference on Management of Data, SIGMOD &apos;03</title>
		<meeting>the 2003 ACM SIGMOD International Conference on Management of Data, SIGMOD &apos;03<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2003" />
			<biblScope unit="page" from="665" to="665" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Ion Stoica, and Matei Zaharia. A view of cloud computing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Armbrust</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armando</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rean</forename><surname>Griffith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><forename type="middle">D</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Randy</forename><surname>Katz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andy</forename><surname>Konwinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gunho</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Patterson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ariel Rabkin</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="50" to="58" />
			<date type="published" when="2010-04" />
		</imprint>
	</monogr>
	<note>Commun. ACM</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Operator scheduling in data stream systems. The VLDB Journal-The International Journal on Very Large Data Bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Babcock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shivnath</forename><surname>Babu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mayur</forename><surname>Datar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajeev</forename><surname>Motwani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilys</forename><surname>Thomas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="333" to="353" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Analysis of a simple approach to modeling performance for streaming data applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Jonathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Beard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Roger D Chamberlain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2013 IEEE 21st International Symposium on Modelling, Analysis and Simulation of Computer and Telecommunication Systems</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="345" to="349" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Ranking popular distributed computing packages for data science</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sean</forename><surname>Boland</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Fog computing and its role in the internet of things</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Flavio</forename><surname>Bonomi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodolfo</forename><surname>Milito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiang</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sateesh</forename><surname>Addepalli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Edition of the MCC Workshop on Mobile Cloud Computing, MCC &apos;12</title>
		<meeting>the First Edition of the MCC Workshop on Mobile Cloud Computing, MCC &apos;12</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="13" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Sense your city: Data art challenge</title>
		<ptr target="http://datacanvas.org/sense-your-city/" />
		<imprint/>
	</monogr>
	<note>Data Canvas</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Distributed qosaware scheduling in storm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Valeria</forename><surname>Cardellini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincenzo</forename><surname>Grassi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francesco</forename><forename type="middle">Lo</forename><surname>Presti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matteo</forename><surname>Nardelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th ACM International Conference on Distributed Event-Based Systems</title>
		<meeting>the 9th ACM International Conference on Distributed Event-Based Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="344" to="347" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Monitoring streams: a new class of data management applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Don</forename><surname>Carney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ugur</forename><surname>Cetintemel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitch</forename><surname>Cherniack</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Convey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sangdon</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Seidman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Stonebraker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nesime</forename><surname>Tatbul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stan</forename><surname>Zdonik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th international conference on Very Large Data Bases</title>
		<meeting>the 28th international conference on Very Large Data Bases</meeting>
		<imprint>
			<publisher>VLDB Endowment</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="215" to="226" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Operator scheduling in a data stream manager</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Don</forename><surname>Carney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Gur Çetintemel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stan</forename><surname>Rasin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitch</forename><surname>Zdonik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Cherniack</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Stonebraker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th international conference on Very large data bases</title>
		<meeting>the 29th international conference on Very large data bases</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="838" to="849" />
		</imprint>
		<respStmt>
			<orgName>VLDB Endowment</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Integrating scale out and fault tolerance in stream processing using operator state management</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raul</forename><surname>Castro Fernandez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matteo</forename><surname>Migliavacca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evangelia</forename><surname>Kalyvianaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Pietzuch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 ACM SIGMOD International Conference on Management of Data, SIGMOD &apos;13</title>
		<meeting>the 2013 ACM SIGMOD International Conference on Management of Data, SIGMOD &apos;13<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="725" to="736" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Telegraphcq: Continuous dataflow processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sirish</forename><surname>Chandrasekaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Owen</forename><surname>Cooper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amol</forename><surname>Deshpande</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Franklin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><forename type="middle">M</forename><surname>Hellerstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sailesh</forename><surname>Krishnamurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><forename type="middle">R</forename><surname>Madden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fred</forename><surname>Reiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehul</forename><forename type="middle">A</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2003 ACM SIGMOD International Conference on Management of Data, SIGMOD &apos;03</title>
		<meeting>the 2003 ACM SIGMOD International Conference on Management of Data, SIGMOD &apos;03<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2003" />
			<biblScope unit="page" from="668" to="668" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Scalable distributed stream processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitch</forename><surname>Cherniack</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hari</forename><surname>Balakrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Magdalena</forename><surname>Balazinska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donald</forename><surname>Carney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ugur</forename><surname>Cetintemel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stanley B</forename><surname>Zdonik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIDR</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="257" to="268" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Benchmarking streaming computation engines: Storm, flink and spark streaming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanket</forename><surname>Chintapalli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Derek</forename><surname>Dagit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bobby</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reza</forename><surname>Farivar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Holderbaugh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuo</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyle</forename><surname>Nusbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kishorkumar</forename><surname>Patil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boyang</forename><forename type="middle">Jerry</forename><surname>Peng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Parallel and Distributed Processing Symposium Workshops</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1789" to="1792" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Clonecloud: Elastic execution between mobile device and cloud</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sunghwan</forename><surname>Byung-Gon Chun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petros</forename><surname>Ihm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mayur</forename><surname>Maniatis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashwin</forename><surname>Naik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Patti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth Conference on Computer Systems, EuroSys &apos;11</title>
		<meeting>the Sixth Conference on Computer Systems, EuroSys &apos;11<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="301" to="314" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Kinetic Edge &amp; Fog Processing Module (EFM)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cisco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cisco</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Flexible filters: load balancing through backpressure for stream programs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Rebecca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Luca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Carloni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the seventh ACM international conference on Embedded software</title>
		<meeting>the seventh ACM international conference on Embedded software</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="205" to="214" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">The internet of things: Mapping the value beyond the hype</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">&amp;amp;</forename><surname>Mckinsey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Company</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Making smartphones last longer with code offload</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduardo</forename><surname>Cuervo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aruna</forename><surname>Balasubramanian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dae-Ki</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Wolman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Saroiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ranveer</forename><surname>Chandra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paramvir</forename><surname>Bahl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Maui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th International Conference on Mobile Systems, Applications, and Services, MobiSys &apos;10</title>
		<meeting>the 8th International Conference on Mobile Systems, Applications, and Services, MobiSys &apos;10<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="49" to="62" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Approximate join processing over data streams</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinandan</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Gehrke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirek</forename><surname>Riedewald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2003 ACM SIGMOD International Conference on Management of Data, SIGMOD &apos;03</title>
		<meeting>the 2003 ACM SIGMOD International Conference on Management of Data, SIGMOD &apos;03<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2003" />
			<biblScope unit="page" from="40" to="51" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Eclipse kura. open-source framework for iot</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Eclipse</surname></persName>
		</author>
		<ptr target="http://www.eclipse.org/kura/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Comet: Code offload by migrating execution transparently</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><forename type="middle">S</forename><surname>Gordon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">Anoushe</forename><surname>Jamshidi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Mahlke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><forename type="middle">Morley</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th USENIX Conference on Operating Systems Design and Implementation, OSDI&apos;12</title>
		<meeting>the 10th USENIX Conference on Operating Systems Design and Implementation, OSDI&apos;12<address><addrLine>Berkeley, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="93" to="106" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Fundamentals of queueing theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donald</forename><surname>Gross</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<publisher>John Wiley &amp; Sons</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Streamcloud: An elastic and scalable data streaming system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincenzo</forename><surname>Gulisano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ricardo</forename><surname>Jimenez-Peris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marta</forename><surname>Patino-Martinez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claudio</forename><surname>Soriente</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Valduriez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Parallel and Distributed Systems</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2351" to="2365" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hortonworks</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Mobile edge computing-a key technology towards 5g</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun Chao</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milan</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dario</forename><surname>Sabella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nurit</forename><surname>Sprecher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Valerie</forename><surname>Young</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>ETSI White Paper</publisher>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="1" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">International Electrotechnical Commission (IEC)</title>
		<ptr target="http://www.iec.ch/whitepaper/pdf/iecWP-loT2020-LR.pdf" />
		<imprint/>
	</monogr>
	<note>Iot 2020: Smart and secure iot platform</note>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Media types for sensor markup language (senml)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Jennings</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Shelby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Arkko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Keranen</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Neurosurgeon: Collaborative intelligence between the cloud and mobile edge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiping</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johann</forename><surname>Hauswald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cao</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Austin</forename><surname>Rovinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Mudge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Mars</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingjia</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Second International Conference on Architectural Support for Programming Languages and Operating Systems, ASPLOS &apos;17</title>
		<meeting>the Twenty-Second International Conference on Architectural Support for Programming Languages and Operating Systems, ASPLOS &apos;17<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="615" to="629" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Queueing systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonard</forename><surname>Kleinrock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer applications</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<date type="published" when="1976" />
			<publisher>wiley</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Dens: Data center energy-efficient network-aware scheduling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Kliazovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Bouvry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samee Ullah</forename><surname>Khan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cluster Computing</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="65" to="75" />
			<date type="published" when="2013-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Saber: Window-based hybrid stream processing for heterogeneous architectures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandros</forename><surname>Koliousis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Weidlich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raul</forename><forename type="middle">Castro</forename><surname>Fernandez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">L</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Costa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Pietzuch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 International Conference on Management of Data, SIGMOD &apos;16</title>
		<meeting>the 2016 International Conference on Management of Data, SIGMOD &apos;16<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="555" to="569" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Twitter heron: Stream processing at scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Kulkarni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikunj</forename><surname>Bhagat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vikas</forename><surname>Kedigehalli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Kellogg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sailesh</forename><surname>Mittal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jignesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karthik</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siddarth</forename><surname>Ramasamy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Taneja</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data</title>
		<meeting>the 2015 ACM SIGMOD International Conference on Management of Data</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="239" to="250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Wireless sensor networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Franck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lewis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">46</biblScope>
		</imprint>
	</monogr>
	<note>Smart environments: technologies, protocols, and applications</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Bandwidth-guaranteed resource allocation and scheduling for parallel jobs in cloud data center</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaocheng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dandan</forename><surname>Ning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qihang</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiping</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Qiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Symmetry</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">134</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Streamscope: Continuous reliable distributed processing of big data streams</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haochuan</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengping</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junwei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sen</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingren</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lidong</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NSDI</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="439" to="453" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Stream bench: Towards benchmarking modern distributed stream computing frameworks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruirui</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingtong</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 IEEE/ACM 7th International Conference on Utility and Cloud Computing, UCC &apos;14</title>
		<meeting>the 2014 IEEE/ACM 7th International Conference on Utility and Cloud Computing, UCC &apos;14<address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="69" to="78" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Predicting performance of parallel computations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Victor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><forename type="middle">F</forename><surname>Mak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lundstrom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Parallel and Distributed Systems</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="257" to="270" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">The architecture of an active database management system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dennis</forename><surname>Mccarthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Umeshwar</forename><surname>Dayal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1989 ACM SIGMOD International Conference on Management of Data, SIG-MOD &apos;89</title>
		<meeting>the 1989 ACM SIGMOD International Conference on Management of Data, SIG-MOD &apos;89<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1989" />
			<biblScope unit="page" from="215" to="224" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Streambox: Modern stream processing on a multicore machine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyu</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heejin</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myeongjae</forename><surname>Jeon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gennady</forename><surname>Pekhimenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kathryn</forename><forename type="middle">S</forename><surname>Mckinley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix Xiaozhu</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 USENIX Conference on Usenix Annual Technical Conference, USENIX ATC &apos;17</title>
		<meeting>the 2017 USENIX Conference on Usenix Annual Technical Conference, USENIX ATC &apos;17<address><addrLine>Berkeley, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="617" to="629" />
		</imprint>
	</monogr>
<note type="report_type">USENIX Association</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Mobile storm: Distributed real-time stream processing for mobile clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qian</forename><surname>Ning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chien-An</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Stoleru</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Congcong</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 4th International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="139" to="145" />
		</imprint>
	</monogr>
	<note>Cloud Networking (CloudNet)</note>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Edge-computing-aware deployment of stream processing tasks based on topology-external information: Model, algorithms, and a storm-based prototype</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Papageorgiou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Poormohammady</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE International Congress on Big Data</title>
		<imprint>
			<publisher>BigData Congress</publisher>
			<date type="published" when="2016-06" />
			<biblScope unit="page" from="259" to="266" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milan</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Naughton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sprecher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Abeta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Neal</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>et al. Mobile-edge computing introductory technical white paper. White Paper, Mobile-edge Computing (MEC) industry initiative</note>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">R-storm: Resource-aware scheduling in storm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boyang</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Hosseini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhihao</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reza</forename><surname>Farivar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roy</forename><surname>Campbell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th Annual Middleware Conference</title>
		<meeting>the 16th Annual Middleware Conference</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="149" to="161" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Rethinking the library os from the top down</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Donald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silas</forename><surname>Porter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jon</forename><surname>Boyd-Wickizer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reuben</forename><surname>Howell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Galen C</forename><surname>Olinsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hunt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ACM SIGPLAN Notices</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="291" to="304" />
			<date type="published" when="2011" />
			<publisher>ACM</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Timestream: Reliable stream computation in the cloud</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengping</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunzhi</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuojie</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyu</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taizhi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lidong</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th ACM European Conference on Computer Systems, EuroSys &apos;13</title>
		<meeting>the 8th ACM European Conference on Computer Systems, EuroSys &apos;13<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Odessa: Enabling interactive perception applications on mobile devices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anmol</forename><surname>Moo-Ryong Ra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lily</forename><surname>Sheth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Padmanabhan</forename><surname>Mummert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Pillai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramesh</forename><surname>Wetherall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Govindan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th International Conference on Mobile Systems, Applications, and Services, MobiSys &apos;11</title>
		<meeting>the 9th International Conference on Mobile Systems, Applications, and Services, MobiSys &apos;11<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="43" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Spanedge: Towards unifying stream processing over central and near-the-edge data centers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">P</forename><surname>Sajjad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Danniswara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Al-Shishtawy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vlassov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE/ACM Symposium on Edge Computing (SEC)</title>
		<imprint>
			<date type="published" when="2016-10" />
			<biblScope unit="page" from="168" to="178" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">End-to-end arguments in system design</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jerome</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Saltzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David D</forename><surname>David P Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Computer Systems (TOCS)</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="277" to="288" />
			<date type="published" when="1984" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Lowsynchronization, mostly lock-free, elastic scheduling for streaming runtimes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun-Lung</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGPLAN Notices</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="648" to="661" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Edge computing: Vision and challenges</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Internet of Things Journal</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="637" to="646" />
			<date type="published" when="2016-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m" type="main">Riotbench: a real-time iot benchmark for distributed stream processing platforms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anshu</forename><surname>Shukla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shilpa</forename><surname>Chaturvedi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yogesh</forename><surname>Simmhan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1701.08530</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">The 8 requirements of real-time stream processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Stonebraker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Uˇguruˇgur</forename><surname>Çetintemel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stan</forename><surname>Zdonik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGMOD Record</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="42" to="47" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Load shedding in a data stream manager</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nesime</forename><surname>Tatbul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stan</forename><surname>Gur Çetintemel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitch</forename><surname>Zdonik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Cherniack</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Stonebraker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th International Conference on Very Large Data Bases</title>
		<meeting>the 29th International Conference on Very Large Data Bases</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="309" to="320" />
		</imprint>
		<respStmt>
			<orgName>VLDB Endowment</orgName>
		</respStmt>
	</monogr>
	<note>VLDB &apos;03</note>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Analysis and optimization of big-data stream processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shahin</forename><surname>Vakilinia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongyu</forename><surname>Qiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE global communications conference (GLOBECOM)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Farmbeats: An iot platform for datadriven agriculture</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deepak</forename><surname>Vasisht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zerina</forename><surname>Kapetanovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jongho</forename><surname>Won</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinxin</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ranveer</forename><surname>Chandra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Sudipta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Madhusudhan</forename><surname>Kapoor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sean</forename><surname>Sudarshan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Stratman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NSDI</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="515" to="529" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Benjamin Recht, and Ion Stoica. Drizzle: Fast and adaptable stream processing at scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shivaram</forename><surname>Venkataraman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aurojit</forename><surname>Panda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kay</forename><surname>Ousterhout</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Armbrust</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Ghodsi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Franklin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th Symposium on Operating Systems Principles, SOSP &apos;17</title>
		<meeting>the 26th Symposium on Operating Systems Principles, SOSP &apos;17<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="374" to="389" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Mobistreams: A reliable distributed stream processing system for mobile devices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huayong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Shiuan</forename><surname>Peh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Parallel and Distributed Processing Symposium</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="51" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Seda: An architecture for well-conditioned, scalable internet services</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Welsh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Culler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Brewer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighteenth ACM Symposium on Operating Systems Principles, SOSP &apos;01</title>
		<meeting>the Eighteenth ACM Symposium on Operating Systems Principles, SOSP &apos;01<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2001" />
			<biblScope unit="page" from="230" to="243" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
		<title level="m" type="main">Active database systems: Triggers and rules for advanced database processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennifer</forename><surname>Widom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Ceri</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996" />
			<publisher>Morgan Kaufmann</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">T-storm: Traffic-aware online scheduling in storm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jielong</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenhua</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sen</forename><surname>Su</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Distributed Computing Systems (ICDCS)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="535" to="544" />
		</imprint>
	</monogr>
	<note>IEEE 34th International Conference on</note>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Gstream: A general-purpose data streaming framework on gpu clusters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongpeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Mueller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Parallel Processing (ICPP), 2011 International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="245" to="254" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
