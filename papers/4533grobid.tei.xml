<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2020-09-29T04:24+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">The data, they are a-changin&apos;</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Missier</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computing Science</orgName>
								<orgName type="institution">Newcastle University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacek</forename><surname>Cala</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computing Science</orgName>
								<orgName type="institution">Newcastle University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eldarina</forename><surname>Wijaya</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computing Science</orgName>
								<orgName type="institution">Newcastle University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">The data, they are a-changin&apos;</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>data change</term>
					<term>data refresh</term>
					<term>big data analytics</term>
					<term>prove- nance</term>
				</keywords>
			</textClass>
			<abstract>
				<p>The cost of deriving actionable knowledge from large datasets has been decreasing thanks to a convergence of positive factors: low cost data generation, inexpensively scalable storage and processing infrastructure (cloud), software frameworks and tools for massively distributed data processing, and parallelisable data analytics algorithms. One observation that is often overlooked, however, is that each of these elements is not immutable, rather they all evolve over time. As those datasets change over time, the value of their derivative knowledge may decay, unless it is preserved by reacting to those changes. Our broad research goal is to develop models, methods , and tools for selectively reacting to changes by balancing costs and benefits, i.e. through complete or partial re-computation of some of the underlying processes. In this paper we present an initial model for reasoning about change and re-computations, and show how analysis of detailed provenance of derived knowledge informs re-computation decisions. We illustrate the main ideas through a real-world case study in genomics, namely on the interpretation of human variants in support of genetic diagnosis.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Many of the large datasets used to derive knowledge evolve over time. This causes problems as changes in the datasets invalidate some of the insight derived from them. The problem is relevant in data-intensive science, where experimental results often come from computational pipelines or simulations that rely on observational data. In these settings, not only the underlying data, but also the algorithms and external reference data sources used in the analysis evolve. These changes may represent both a threat, i.e. when a stale model is used to make decisions, and an opportunity, namely to upgrade derived knowledge by performing the analysis again. When the processes are computationally expensive and the available budget for re-doing old work is limited, it is important to be able to determine when re-computation, partial or complete, of the underlying analytic tasks in reaction to changes is beneficial.</p><p>The potential for exploiting provenance records for partial recomputation has been studied before, in the specific context of database operations. In the Panda system ( <ref type="bibr" target="#b3">Ikeda et al. 2011</ref>; Ikeda Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. and Widom 2010), for instance, one can determine precisely the fragment of a data-intensive program that needs to be re-executed in order to refresh stale results. However, this requires the assumption that very granular data provenance can be collected for database operations, and that the semantics of these operations is well understood.</p><p>In contrast, in this paper we take a broader view and consider a more general scenario where (i) the computation involves any program P that has dependencies on external data resources, (ii) the program structure and details of its execution may be only partially observable (coarse vs fine-grained provenance), and (iii) the program may have been executed many times over many inputs, producing a (large) history H of past computations and results.</p><p>Changes in the content of the external resources may invalidate some, but not all, of the results in H. Also, as noted in the Panda system, when attempting to refresh the results that are affected, it may be possible to re-compute P only partially. In this paper we show how provenance records from past computations, of varying granularity, can be used to select the precise subset of H that becomes invalid when the content of external resources changes (re-comp scope). We also show how the starting point for a partial re-computation of P can be pinpointed.</p><p>Our specific contributions are as follows: (i) a formalisation of a re-computation framework under our assumptions, (ii) a discussion of the role of provenance and of how granular provenance translates into efficient re-computation through precise selection of the recomp scope, and (iii) an illustration of the framework in action on a real-world process of analysis of human genetic variants.</p><p>This research is part of the ReComp project, which aims to offer models for estimating the impact of changes in input and external data on the outcome of a program, in order to prioritise recomputation over the affected population vis-` a-vis a limited budget. This short paper should be read as an extended abstract. A more complete tech report is available online: https://arxiv.org/ abs/1604.06412.</p><p>Related Work. As mentioned, Panda ( <ref type="bibr" target="#b3">Ikeda et al. 2011</ref>) collects and exploits provenance to enable data refresh, by selecting the fragments of a data-intensive workflow that must be reexecuted. The focus here is on white box computations which involve database operations, which are documented using perfect and granular provenance records. A formal definition of correctness and minimality of a provenance trace with respect to a data-oriented workflow is proposed by members of the same group ( <ref type="bibr" target="#b4">Ikeda et al. 2013</ref>), leading to a notion of logical provenance. Although this may become a potentially useful building block for a future version of this work, it completely ignores the PROV data model ( <ref type="bibr" target="#b7">Moreau et al. 2012</ref>) which, instead, we regard as a practical foundation to enable interoperability of any provenance-based re-computation framework.</p><p>A similar perspective to Panda is taken in the Archived Metadata and Provenance Manager (AM&amp;PM) ( <ref type="bibr" target="#b1">Gao and Zaniolo 2012)</ref>, with a focus on database provenance and where the main evolving element is not the data but the database schema. Accordingly, the provenance of schema evolution is captured and can be queried, along with the provenance of the data in the current and past versions of a database.</p><p>Using the Prism schema evolution language ( <ref type="bibr" target="#b0">Curino et al. 2008)</ref>) leads to a formal definition of what here we call a diff function, aimed at quantifying the difference between two schemas. That research is vaguely related to our work, which does not specifically address database operations, placing schema evolution out of scope.</p><p>Also loosely related to the problem of determining the scope of re-computation is the idea of reusing some of the results and thus effort from past computations, using memoization <ref type="bibr">(Pugh and Teitelbaum 1989)</ref>.</p><p>Finally, as an infrastructure mechanism to enable selective recomputation, the strong links approach of ( <ref type="bibr" target="#b5">Koop et al. 2010</ref>) is relevant in this context.</p><p>Example: analysis of human genetic variants. The Simple Variant Interpretation (SVI), process, which we implemented in the Cloud-eGenome project ( <ref type="bibr" target="#b6">Missier et al. 2015</ref>), provides a simple interpretation of human variants to facilitate clinical diagnosis of genetic diseases. A variant is a single nucleotide mutation that occurs on a gene. Variants are identified by processing a patient's exome using a sequence of algorithmic steps that, essentially, compare it to a reference genome. SVI takes all variants found in the patient's exome (about 25,000) and a set of terms that describe the patient's phenotype, which indicates the patient's disease hypothesis (presumed disorder). It selects a small subset of the variants which are relevant for the phenotype, and associates a degree of estimated deleteriousness to each of them. To do this it uses knowledge from reference databases, namely the ClinVar (www.ncbi. nlm.nih.gov/clinvar) and OMIM Gene Map (www.ncbi.nlm. nih.gov/omim) databases, described in more detail later.</p><p>While the presence of deleterious variants may represent conclusive evidence in support of the disease hypothesis, the diagnosis is often not conclusive due to missing information about the variants, or to lack of knowledge in the reference databases about their association with the hypothesis. Thus, the diagnosis is dependent on the content of the reference databases. As this knowledge evolves and these resources are updated, there are opportunities to revisit past inconclusive diagnoses, and thus to consider re-computation of the associated analysis. To appreciate the effect of changes in the reference knowledge, in the Appendix <ref type="figure">(Fig. A)</ref> we show how new additions to OMIM and ClinVar would have affected the ability to carry out a conclusive diagnosis on a cohort of patients. The charts show the number of genes and variants within a gene, respectively, known to researchers and which would have been relevant for those patients. The charts in <ref type="figure">Fig. 3</ref> provide a similar view of the evolution over time of the genes known to be implicated in Parkinson's and Alzheimer's diseases.</p><p>The ReComp problem in this use case involves (i) selecting the cases that are likely to benefit from re-computation, (ii) deciding whether complete or partial re-computation is required, and (iii) actually reproducing the original process, possibly requiring a new deployment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Re-computation framework</head><p>We now present the main ReComp framework elements.</p><p>Computation. Consider program P executing on a set x = {x1 . . . xn} of inputs and producing outputs y = {y1 . . . ym}, which also makes use of external data resources, or data dependencies D = {D1 . . . Dm} where each Di is a dataset, Di = {di1, di2 . . . }. We also associate a version v to each execution. This indicates a timestamp and uniquely identifies one execution of P , denoted by:</p><formula xml:id="formula_0">y v = P v (x v |D v )<label>(1)</label></formula><p>Transparency. The transparency of P is the level of detail available in observing a computation of P . This includes (a) details on the internal structure of P , and (b) details on which subset of each Di are used. At one end of the "transparency spectrum", no details are available for either (a) or (b): P is a black box providing no details about its internal structure, and all we know about Di are coarse-grain statements like "ClinVar was used". On the opposite end of the spectrum, P is a white-box, described for instance by function composition P ≡ Pr • . . .</p><p>• P1, and we also understand the semantics of each subprocess Pj and know the subset of Di that was used by any Pj.</p><p>Provenance. The provenance of an output y, denoted prov (y), is a PROV document that describes the derivation of y from x through P using elements of D. The granularity of PROV assertions depends on the transparency of P . In the most granular case, when P is a white box we can for instance express the usage of any single element dij ∈ Di ∈ D by an activity P k , i.e. using statements of the form: 1</p><formula xml:id="formula_1">used(P k , d ij , [prov:role = 'dep'])<label>(2)</label></formula><p>where the role indicates that dij is a dependency. Similarly, for inputs xi (or intermediate values) we can write:</p><formula xml:id="formula_2">used(P k , x i , [prov:role = 'input'])<label>(3)</label></formula><p>In a completely black box scenario, on the other hand, the assertions will be of the form: </p><p>In addition to producing prov (y), each computation of the form (1) also generates history record h:</p><formula xml:id="formula_4">h(y, v) = P v , D v , x v , prov (y v ), cost(y v )<label>(6)</label></formula><p>where it is expected that prov (y v ) contains statements that make references to P v , x v , and D v . Over time, statements of the form (6) form a History database H . Note that we also record the cost(y) of computing y by executing P on x. In practice this will be expressed as a monetary cost (e.g. when P is executed on a public cloud), execution time, resource usage or as a combination of those.</p><p>Change detection. ReComp relies on the ability to detect and quantify changes between any two versions of x and D, i.e.</p><formula xml:id="formula_5">x v → x v , D v → D v .</formula><p>Thus, we assume there exist three families of diff functions that are needed to compare two versions of the elements of x, D, and y.</p><formula xml:id="formula_6">input diff: {diff in (x v i , x v i )|x v i ∈ x v , x v i ∈ x v } dependency diff: {diff d (D v i , D v i )|D v i ∈ D v , D v i ∈ D v } output diff: {diff out (y v i , y v i )|y v i ∈ y v , y v i ∈ y v }</formula><p>These operate independently on each input, dependency, and output component. Each of these functions will have a different signature, and produce a summary of changes found in its inputs, in a format that may vary depending on the types of x and D. For</p><formula xml:id="formula_7">instance, diff d (D v i , D v i ) typically computes the symmetric differ- ence (D v i \ D v i ) ∪ (D v i \ D v i ).</formula><p>Other types of diff functions can be defined for specific use cases. Note that, although changes in the structure of program P are also relevant and are within the general ReComp framework, for simplicity we are going to assume that P does not change.</p><p>Role of the H database and of provenance. Upon detecting changes, i.e. using the diff functions, the first steps in making recomputation decisions include (i) scoping rules, that is selecting the subset H ⊂ H of the computations described in H that are affected by these changes, and (ii) defining the starting point of a partial re-computation of P , which we call the starting component Ps of P . This is the component of P mentioned in the earliest usage of a changed dataset (input or dependency), and it is not necessarily the same as the start of the whole of P . Note that partial re-computation is only possible if the input to Ps is available, i.e. not only should the input be explicitly mentioned in prov (y), but it must also have been cached in a data store. In a white box scenario, both steps can be addressed by querying the provenance documents in H . We distinguish the case of a change in inputs x from the case of a change in a dependency Di ∈ D. These correspond to the two patterns <ref type="formula" target="#formula_2">(3)</ref> and <ref type="formula" target="#formula_1">(2)</ref>  </p><formula xml:id="formula_8">ii) dij ∈ diff d (D v i , D v i ).</formula><p>Next, within the scope determined as above, we need to determine the starting component Ps of each P . The provenance patterns <ref type="formula" target="#formula_2">(3)</ref> and <ref type="formula" target="#formula_1">(2)</ref> suggest that Ps is the activity Pj that appears in the earliest occurrence of a usage statement involving a changed input or dependency.</p><p>Finally, note that in a black box scenario, with either limited visibility of process structure and/or of data input granularity, the scoping rules cannot be used, i.e. the default scope is the whole of H, and total (as opposed to partial) re-computation of P is required.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Detailed use case: SVI re-computation</head><p>We now illustrate the framework in use on our SVI case study. One execution of SVI, illustrated in <ref type="figure" target="#fig_4">Fig. 1</ref>, is carried out for each patient within a large cohort. SVI is an example of process P with inputs:</p><formula xml:id="formula_9">x = [varset, ph]</formula><p>where varset is the set of variants associated with the patient, and ph = {dt1, dt2, . . . } is the phenotype expressed using disease terms dti from the OMIM vocabulary, for example Alzheimer's. SVI is a classifier that associates a class label to each input variant depending on their estimated deleteriousness, using a simple "traffic light" notation, i.e.: y = {(v, class)|v ∈ varset, class ∈ {red, amber, green}} SVI's data dependencies D consist of the two reference databases, OMIM and Clinvar, along with their version v:</p><formula xml:id="formula_10">D v = [OM v , CV v ]</formula><p>and subject to periodic revisions. OMIM maps human disorder terms dt to genes that are known to be broadly involved in the disease, denoted genes (dt, OM v ). ClinVar maintains a catalogue V of variants, and it associates a status to each variant var ∈ V , denoted varstatus(var , CV v ) ∈ {unknown, benign, pathogenic}.</p><p>SVI uses versions OM v and CV v of OMIM and ClinVar to investigate a patient's disease, as shown in <ref type="figure" target="#fig_4">Fig. 1</ref>. Firstly, the terms in ph are used to determine the set of target genes that are relevant for the disease hypothesis. These are defined as the union of all the genes in genes(dt, OM v ) for each disease term dt ∈ ph.</p><p>Secondly, a variant var ∈ varset is selected if it is located on the target genes. Finally, the selected variants are classified as red, amber, or green depending on varstatus <ref type="bibr">(var , CV v )</ref>.</p><p>To illustrate the process consider two patients, Patient 1 diagnosed with Alzheimer's, while Patient 2 is presumably affected by Parkinson's. Since the 90s, two genes have been known to be loosely implicated in these diseases, PSEN2 and PARK2, respectively:</p><p>PSEN2 ∈ genes <ref type="bibr">(Alzheimer's, OM 1995</ref>  </p><formula xml:id="formula_11">Diff functions. For OMIM, diff OM (OM v , OM v</formula><p>) returns the set of terms t ∈ T for which the mapping to genes has changed:</p><formula xml:id="formula_12">diff OM (OM v , OM v ) = {t ∈ DT |genes(t, OM v ) = genes(t, OM v )} while diff CV (CV v , CV v )</formula><p>returns set of variants var ∈ V with changed status, as well as new variants, or removed variants:</p><formula xml:id="formula_13">diff CV (CV v , CV v ) = {var ∈ V |varstatus(var , CV v ) = varstatus(var , CV v )} ∪ CV v \ CV v ∪ CV v \ CV v</formula><p>Use of provenance. The provenance from each SVI tool execution is recorded in the H database. In our white box scenario, the relevant PROV assertions generated from an execution of SVI, with block names as in <ref type="figure">Fig</ref> Note that the used assertions are of the form (2) and (3), respectively. These provenance statements can be used to define scoping rules and starting components, as follows.</p><p>Re-comp scope due to OMIM changes. The executions h in the re-comp scope following change OM v → OM v include those where phenotype ph includes terms in diff OM <ref type="bibr">(OM v , OM v</ref> ), i.e., those with changes to their gene mappings. The phenotype is found in (12), while the version of OMIM for computing diff is found using (11). As (11) contains the earliest mention of om, PtG is also the starting component for re-computation.</p><p>Re-comp scope due to ClinVar changes. Similarly, following change CV v → CV v , the executions in scope are those that include selected variants on target genes and which appear in diff CV <ref type="bibr">(CV v , CV v</ref> ). Using the provenance fragment above, the  <ref type="formula" target="#formula_0">(14)</ref>, and the version of CV for computing diff is found using <ref type="bibr">(13)</ref>. In this case, vClass is the starting component for re-computation following a change in ClinVar.</p><p>Example, continued. Consider again variants 227083249 and 161807855. Because they are both located on genes that have been known to OMIM, these variants are selected as candidates for testing against ClinVar. As mentioned, until 2014 they were both classified as 'amber'. Having been added to ClinVar in 2015, however, they both appear in the latest diff between the 2014 and 2015 versions of ClinVar:</p><formula xml:id="formula_14">{227083249, 161807855} ⊂ diff CV (CV 2014 , CV 2015 )</formula><p>According to the scoping rule above, the executions of H where the provenance mentions 227083249 and 161807855 are now in scope, and these include patients 1 and 2 (possibly along with many others for whom these variants are relevant). As 227083249 is catalogued as "probably pathogenic, uncertain significance", the diagnosis for patient 1 is still inconclusive. For Patient 2, on the other hand, we can rule out variant 161807855 as a cause of their disease, as this variant is now known to be benign.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Conclusions</head><p>Knowledge assets derived from data analytics computations may decay and become obsolete as the datasets or the content of reference data resources used to produce it change over time. While this suggests that re-computation of such knowledge assets may be needed, deciding precisely which of them should be re-computed is not a trivial problem; it requires meta-knowledge about their dependencies on the inputs and on the reference datasets. In this paper we have discussed the role of provenance in supporting re-computation decisions when results from data-intensive processes are progressively invalidated by the evolution of the underlying data. We have presented a simple reference framework in which data is versioned and functions are available to compute the differences between any two versions. We have clarified how finegrained and coarse-provenance can be used to assess the impact of such differences on a history of past computations, with different precision, suggesting which past computations should be performed anew. We have illustrated these ideas through a detailed example, concerning the automated classification of human variants for clinical diagnosis. A more complete account of the approach is available online: https://arxiv.org/abs/1604.06412.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>TaPP 2016 ,</head><label>2016</label><figDesc>June 8-9, 2016, Washington, DC. Copyright remains with the owner/author(s).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>used(P,</head><label></label><figDesc>D, [prov:role = 'dep']) (use of dependency) (4) used(P, x, [prov:role = 'input']) (use of input)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>above. Specifically, if the change x v i → x v i involves any of the inputs xi ∈ x, the scope H is simply the set of records h in which x v i is used as input, i.e. all h(y, v) such that prov (y v ) includes the pattern of form (3). Regarding dependency change D v i → D v i , the affected records are those where the computation involved elements in diff d (D v i , D v i ). These are the h(y, v) such that: (i) prov (y v ) includes the pattern of form (2) involving data element dij, and (</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>), PARK ∈ genes (Parkinson's, OM 1995 ) However, it was not until 2015 that two specific variants situated on those genes, at position 227083249 and 161807855, respectively have been studied and added to ClinVar. Thus, until 2014 we had varstatus(227083249, CV 2014 ) = amber, varstatus(161807855, CV 2014 ) = amber because neither variants were known to ClinVar.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>. 1 ,</head><label>1</label><figDesc>are as follows: entity(om, [prov:type = 'OMIM', version = 'v']) (7) entity(ph, [prov:type = 'prov:collection']) (8) entity(cv, [prov:type = 'CV', version = 'v']) (9) entity(vars, [prov:type = 'prov:collection']) (10) used(PtG, om, [prov:role = 'dep']) (11) used(PtG, ph, [prov:role = 'input']) (12) used(vClass, cv, [prov:role = 'dep']) (13) used(vClass, vars, [prov:role = 'input']) (14)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. White box SVI, with inputs x = [varset, ph] and data dependencies D = [OMIM, ClinVar]</figDesc></figure>

			<note place="foot" n="1"> PROV also allows to express that the d ij are members of a collection D i .</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work is funded in part by UK EPSRC grant no. EP/N01426X/1.</p></div>
			</div>

			<div type="annex">
			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Graceful Database Schema Evolution: The PRISM Workbench</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">A</forename><surname>Curino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">J</forename><surname>Moon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zaniolo</surname></persName>
		</author>
		<idno type="doi">2150-8097.doi:10.14778/1453856.1453939</idno>
	</analytic>
	<monogr>
		<title level="m">Proc. VLDB Endow</title>
		<meeting>VLDB Endow</meeting>
		<imprint>
			<date type="published" when="2008-08" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="761" to="772" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Provenance Management in Databases Under Schema Evolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gao</surname></persName>
			<affiliation>
				<orgName type="collaboration">iii</orgName>
			</affiliation>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zaniolo</surname></persName>
			<affiliation>
				<orgName type="collaboration">iii</orgName>
			</affiliation>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th USENIX Conference on Theory and Practice of Provenance</title>
		<meeting>the 4th USENIX Conference on Theory and Practice of Provenance</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Panda: A system for provenance and data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ikeda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Widom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd USENIX Workshop on the Theory and Practice of Provenance TaPP10</title>
		<meeting>the 2nd USENIX Workshop on the Theory and Practice of Provenance TaPP10</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Provenance-based refresh in dataoriented workflows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ikeda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Salihoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Widom</surname></persName>
		</author>
		<idno type="doi">doi:10.1145/2063576.2063816</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th ACM international conference on Information and knowledge management</title>
		<meeting>the 20th ACM international conference on Information and knowledge management</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1659" to="1668" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Logical provenance in dataoriented workflows?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ikeda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Das</forename><surname>Sarma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Widom</surname></persName>
		</author>
		<idno type="doi">doi:10.1109/ICDE.2013.6544882</idno>
	</analytic>
	<monogr>
		<title level="m">2013 IEEE 29th International Conference on Data Engineering (ICDE)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013-04" />
			<biblScope unit="page" from="877" to="888" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Bridging workflow and data provenance using strong links</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Koop</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Troyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Freire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">T</forename><surname>Silva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Scientific and statistical database management</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="397" to="415" />
		</imprint>
	</monogr>
	<note>ISBN 3642138179</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">SVI: a simple singlenucleotide Human Variant Interpretation tool for Clinical Use</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Missier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Wijaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kirby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Keogh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Procs. 11th International conference on Data Integration in the Life Sciences</title>
		<meeting>s. 11th International conference on Data Integration in the Life Sciences<address><addrLine>Los Angeles, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Moreau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Missier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Belhajjame</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>B&amp;apos;far</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cheney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Coppens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cresswell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Groth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Klyne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lebo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mccusker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Miles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Myers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sahoo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Tilmes</surname></persName>
		</author>
		<title level="m">PROV-DM: The PROV Data Model</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
<note type="report_type">Technical report</note>
	<note>World Wide Web Consortium</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Incremental Computation via Function Caching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Pugh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Teitelbaum</surname></persName>
		</author>
		<idno type="doi">1989.ACM.ISBN0-89791-294-2.doi:10.1145/75277.75305</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, POPL &apos;89</title>
		<meeting>the 16th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, POPL &apos;89<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<biblScope unit="page" from="315" to="328" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
