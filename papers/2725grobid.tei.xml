<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2020-09-29T02:50+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Reinventing Video Streaming for Distributed Vision Analytics</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chrisma</forename><surname>Pakha</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aakanksha</forename><surname>Chowdhery</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Google/Princeton</orgName>
								<address>
									<country># Microsoft</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junchen</forename><surname>Jiang</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">University of Chicago</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Reinventing Video Streaming for Distributed Vision Analytics</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Driven by the ubiquity of camera-equipped devices and the prohibitive cost of modern vision techniques, we see a growing need for a custom video streaming protocol that streams videos from cameras to cloud servers to perform neural-network-based video analytics. In the past decade, numerous efforts have optimized video streaming protocols to provide better quality-of-experience to users. In this paper, we call upon this community to similarly develop custom streaming protocols for better an-alytics quality (accuracy) of vision analytics (deep neu-ral networks). We highlight new opportunities to substantially improve the tradeoffs between bandwidth usage and inference accuracy. The key insight is that existing streaming protocols are essentially client (camera)-driven; in contrast, by letting the analytics server decide what/when to stream from the camera, the new protocols can directly optimize the inference accuracy while minimizing bandwidth usage. Preliminary evaluation shows that a simple protocol can reduce bandwidth consumption by 4-23x compared to traditional streaming protocols and other distributed video analytics pipelines while maintaining at least 95% inference accuracy.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>With the proliferation of connected cameras in smart homes, smart cities, industrial IoT, and wearable cameras, we are seeing an increased demand to generate real-time insights (e.g., traffic monitoring, video summarization, intruder detection) on the live video feeds of the cameras. Over the past decade, the accuracy of many vision tasks has improved dramatically by Deep Neural Networks (DNNs) <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b21">[22]</ref><ref type="bibr" target="#b22">[23]</ref><ref type="bibr" target="#b23">[24]</ref><ref type="bibr" target="#b31">32]</ref> but at the high computational cost of running the vision pipelines. The resulting tradeoff between accuracy and computation complexity has necessitated distributed processing pipelines, in which complex inferences are offloaded to cloud servers, and (processed) videos are streamed between cameras and servers <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b33">34]</ref>.</p><p>Prior work (e.g., <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b13">14]</ref>) has focused on offloading vision tasks from mobile to the cloud, but we argue that it has missed a crucial aspect that the video streaming stack integrates the requirements of video analytics itself ( §2). Traditional encoding and streaming protocols (e.g., <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b30">31]</ref>) are designed to stream all frames at high resolution so that viewers can watch the video uninterrupted. Video analytics, in contrast, focus only on specific video segments with queried objects of interest. Thus, a streaming protocol is optimal as long as the frames with the queried objects of interest are sent at sufficiently high resolution. These requirements of vision tasks open up new opportunities to greatly reduce bandwidth usage while achieving high analytics accuracy.</p><p>We first set out to understand the full potential of customizing streaming protocols for vision analytics ( §3). We show that the optimal streaming protocol (under idealized assumptions) could achieve almost 100% accuracy and save bandwidth by about 50-1000× over traditional streaming protocols and early examples of custom protocols <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b35">36]</ref>  <ref type="figure" target="#fig_0">(Figure 2</ref>). The insight underlying the unexploited potential is that the existing solutions rely only on client-side bandwidth-filtering techniques that are agnostic to the server-side DNN-based analytics logic.</p><p>Inspired by these observations, we then present a new server-driven framework that enables the serverside analytics logic to determine how the video should be streamed ( §4). We demonstrate its practical benefits by first casting it into an active learning process and then showing that a simple design point can greatly outperform the existing streaming protocols from prior work; reducing bandwidth consumption by 4-23× with similar accuracy ( <ref type="figure" target="#fig_3">Figure 5</ref>). We end the paper by highlighting open questions, and call upon the research community to develop custom streaming protocols for vision analytics to truly unleash its full potential ( §5).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">What's new about video streaming in vision analytics?</head><p>Vision research has made rapid advances leading to many new commercial applications that extract insights in realtime videos from ubiquitously available cameras. Some queries for traffic monitoring applications include 'count cars moving in a specific direction at an intersection,' or 'find all speeding cars on the highway.' Some queries for surveillance applications include 'detect intruders' or 'track an object of interest.' In general, video analytics queries require detecting and classifying the objects of interest (e.g., vehicles) in a sequence of video frames. We use object detection as a representative complex and fundamental vision task. E.g., pose estimation will require the machine to locate the human first. Why videos need to be streamed? The accuracy of computer vision tasks has improved significantly with the advent of deep neural networks (DNNs) <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b21">[22]</ref><ref type="bibr" target="#b22">[23]</ref><ref type="bibr" target="#b23">[24]</ref><ref type="bibr" target="#b31">32]</ref>. However, running DNNs on live video feeds incurs a high computational cost (e.g., running a standard DNN object detector on a 30 frame-per-second video requires one dedicated GPU <ref type="bibr" target="#b21">[22]</ref>), and the camera clients capturing the video have limited computational ability. Therefore, the video needs to be streamed to cloud or edge servers (as shown in <ref type="figure">Figure 1</ref>) to offload the computationally intensive DNN-based vision tasks (e.g., <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b4">5]</ref>). Some pipelines rely on special client-side hardware (e.g., <ref type="bibr" target="#b18">[19]</ref>) to extract image features (e.g., <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b14">15]</ref>) or run the first few NN layers (e.g., <ref type="bibr" target="#b32">[33]</ref>), and send these extracted features or intermediate results, instead of videos/frames, to the server. While deploying hardware accelerator or GPU on edge devices is practical, its high cost prohibits a scalable solution, especially if we need to deploy it in smart cities or on low-end mobile devices; even with GPU capability, most mobile devices do not run at a high frame rate (30 frames/sec). Instead, this work targets a more flexible setting where the server provides object detection as a service to which any camera can send video for analytics without a large bandwidth overhead and computational cost. What's an ideal streaming protocol? A video streaming protocol can be seen as a function that applies some compression operation p(·) (e.g., resolution downsizing and frame sampling) on the original video v, and sends the compressed video p(v) to the server. <ref type="bibr" target="#b0">1</ref> In video analytics, the optimal video streaming protocol maximizes the inference accuracy while keeping the size of the compressed video below available bandwidth to keep the inference delay constant. Formally, it can be written as follows: given video content v, and available bandwidth w, the optimal protocol p * is</p><formula xml:id="formula_0">p * = argmax |p(v)|≤w F(p(v))<label>(1)</label></formula><p>where F(p(v)) is the inference accuracy of running the server-side NN model on p(v). A video protocol can be "parameterized" by various control knobs:</p><p>• Frame selection.</p><p>• Area cropping (sending only a cropped area). <ref type="bibr" target="#b0">1</ref> Compressing videos without losing information critical to DNN inference is reminiscent of other signal processing settings, such as LPC compression used for speech recognition <ref type="bibr" target="#b20">[21]</ref>, which tries to retain only the signal elements necessary for correct speech recognition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Client (Camera) Server (DNN) Video Streaming Protocol</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Frames</head><p>Figure 1: Streaming videos for vision analytics.</p><p>• Resolution of a selected frame (or area).</p><p>• Compression level of a selected frame (or area).</p><p>Why not classic video streaming protocols? Conventional video streaming (encoding standards, e.g., H.265 <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b30">31]</ref>, and protocols, e.g., RTMP <ref type="bibr" target="#b19">[20]</ref>, DASH <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b29">30]</ref>) have been designed to maximize the user-perceived quality-of-experience (QoE). The viewing experience suffers if video resolution is low, the video re-buffers, or many frames are dropped. So, to ensure high user-perceived quality, these streaming protocols optimize the video resolution (or bitrate) within available bandwidth, avoid video stalling (rebuffering) events and excessive frame drops, and shorten the startup delay.</p><p>Dropping frames or lowering the frame resolution does not affect video analytics in the same way as it affects user-perceived quality. Instead, the goal of video analytics is to maximize the inference accuracy. Higher frame resolution may have negligible or diminishing effect on accuracy, if the object can be detected at a lower resolution. Further, the DNN inference accuracy does not suffer when the video is "choppy" or the video stalls, as long as the dropped frames do not add new information or the missing information can be retrieved if needed. A straightforward idea is to send only key frames (I frames) of H.264 video from the client to server but it may achieve lower accuracy or higher bandwidth because the current encoding is agnostic to objects in the frame. Further, recent efforts to make video encoding aware of the objects/regions of interest (e.g., <ref type="bibr" target="#b17">[18]</ref>) require that the client specifies the region-of-interest before encoding. In short, whether a video gives a user satisfying viewing experience, i.e., human-perceived QoE, is different from whether a video provides enough information for the inference of a deep neural network (or analytics algorithm in general), i.e., DNN-perceived QoE.</p><p>Why not existing video analytics pipelines? In the existing pipelines, the clients either use simple decision rules or a classifier to select a subset of frames to send to the server, on which the server runs DNNs. For example, Glimpse <ref type="bibr" target="#b2">[3]</ref>, designed for wearable devices, assumes that the server detects the objects, sends the bounding box back to the client, and the client tracks this object. Vigil <ref type="bibr" target="#b35">[36]</ref> assumes the client has sufficient computational capability to run object detection and prioritizes frames with more objects. NoScope <ref type="bibr" target="#b12">[13]</ref> and MCDNN <ref type="bibr" target="#b10">[11]</ref> use multiple specialized DNNs where a filter (a frame difference detector or a simpler inference model) sends only the frames that are likely to have objects to more complex NN models. We take Glimpse as an example to illustrate the limitation of relying on client-side heuristics. Glimpse selects the frames to send based on the pixellevel changes between frames, but it can arguably cause false negatives (e.g., an object of interest does appear but does not change enough pixels to trigger the client to send the frame), as well as false positives (e.g., color changes in background trigger the client to send many frames while the actual objects of interest are static).</p><p>To sum up, both traditional video streaming protocols and previous analytics pipelines are essentially clientdriven; it is the client-side logic that determines how the video is compressed and streamed. This client-driven workflow, however, suffers from the fundamental limitation that, without any input from the server, it is difficult to predict precisely what the server needs, i.e., how much information is needed to encode all objects of interest. In other words, these approaches are oblivious to the server-side inference accuracy (F(·) in Eq. 1), and are thus unable to directly maximize the inference accuracy under given bandwidth constraints.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">A case for a server-driven approach</head><p>In contrast, we make a case for server-driven approach, which maximizes the analytics accuracy by giving the server full (or partial) control over what to send from the client to the server. In this section, we empirically demonstrate the advantages of an optimal server-driven design over alternatives. We end the section with the key challenges toward designing a practical server-driven protocol, and the intuition why it is tractable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Potential improvement</head><p>The distinctive feature of a server-driven streaming protocol is that the analytics server decides the operations (p in Eq. 1) that client uses to compress the video before sending it to the server. Because the server runs the DNN model, in theory it is capable of picking the operations that directly maximize the inference accuracy.</p><p>Here, we quantify the full potential of a server-driven streaming protocol using an oracle version. The oracle protocol (unrealistically) assumes that the server can access the original video and pick the optimal values for each of the control knobs-frame selection, area cropping, resolution, and compression level. That is, it selects the exact frames where the objects move, crops out only the spatial regions that contain objects, selects the minimal resolution at which the server-side logic can detect the object, etc. The oracle protocol vs. streaming all encoded frames (MPEG) and client-side heuristics (Glimpse). <ref type="figure" target="#fig_0">Figure 2</ref> shows the improvement by the oracle protocol using an example video which includes 13 vehicle objects. We compare the oracle protocol with two baselines: (1) streaming all frames pre-encoded by MPEG (with varying resolutions frome 348×128 to 1392×512, and quantization parameter from 18 to 51) to the server, and (2) Glimpse <ref type="bibr" target="#b2">[3]</ref> (with varying degree of sensitivity at the frame different detector). Note that we use Glimpse as an example to illustrate the common limitation of client-driven heuristics shared by other similar pipelines. For fairness, we run the same server-side DNN logic in all experiments (see <ref type="table" target="#tab_0">Table 1</ref> for all setups), and the oracle protocol uses the same functional partition of Glimpse (i.e., client tracks all objects detected by the server). The accuracy metric could be applicationdependent, we use F1 score (harmonic mean of inference precision and recall) as in <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b34">35]</ref>. We can see that when all control knobs are set with the optimal values, the oracle protocol (the square point) saves bandwidth usage by about 250× while achieving almost 100% accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Challenge and opportunities</head><p>Implementing a server-driven protocol in practice, however, faces a fundamental dilemma. For the server to determine what to fetch from the client, it must first profile the NN's accuracy of the video under different configurations. In other words, the server is unable to decide what to fetch from the client, if it has never seen the original video, but sending the original video to the server negates the benefit of saving the bandwidth in the first place.</p><p>Is it possible to send the server a small amount of data that is just enough to allow the server to drive the protocol? The answer is positive. Our key insight is that the inference result on low-quality video (e.g., low resolution, low frame rate, or aggressive compression), while not accurate, is sufficient to reveal what additional information is needed by the NN model to achieve higher accuracy. It manifests itself in two concrete ideas. Idea #1: Inference results on low-resolution frames can indicate where objects are likely to appear. For each detected object, the DNN-based models also returns a confidence value. Although inference results at low resolution often have low confidence values, they can nevertheless indicate the areas where objects are likely to appear, so the protocol can "zoom-in" on these areas with more pixels to improve accuracy. <ref type="figure" target="#fig_1">Figure 3</ref> illustrates it in action: on the low resolution image (left), we detect three objects, based on which we crop out three bounding boxes and run inference with high resolution (right), which reveals one of them is a false positive. Idea #2: Inference results on sparsely sampled frames can indicate which frames are likely to contain objects. The difference between objects detected in two sampled frames can indicate whether the server needs to sample additional frames in between. For instance, if the server detects one object in the 1st frame and 3 objects in the 30th frame, this naturally suggests that there are frames with new objects that we have not sampled, and we need to sample additional frames in between.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Towards a practical design</head><p>We have seen that a server-driven streaming protocol enables new opportunities for bandwidth savings as well as accuracy improvement in vision analytics. This section formalizes the server-driven protocol, and presents SimpleProto, a concrete design that achieves substantial improvement in practice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Formalizing server-driven protocol</head><p>Iterative workflow using superposition coding: The ideas in §3.2 inspire an interactive workflow which optimizes server-side inference accuracy by sending information incrementally: the client first sends a base-quality video (e.g., low resolution or frames sampled sparsely in time) to the server, and if the inference output is not confident, the server decides to get additional information so that it can recover higher-quality video by "adding" the new data to the base-quality video it already has. Fortunately, this can be achieved by superposition coding <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b7">8]</ref> where the sender communicates messages of the same signal at multiple resolutions by encoding them in different layers. The base layer represents the video frames at a low spatial resolution or sampled sparsely temporally or at a higher compression level while an enhancement layer adds information to the previous layers progressively in spatio-temporal dimensions to get better inference quality. Such coding schemes have been used in video encoding for MPEG <ref type="bibr" target="#b16">[17]</ref> to add prediction frames (P/B frames) to the key frames, and in Scalable video coding <ref type="bibr" target="#b26">[27]</ref> to scale video quality while broadcasting to multiple devices. Server-driven protocol as active learning: The workflow of a server-driven protocol closely resembles an active learning process <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7]</ref>. In active learning, given a set of unlabeled data points, one needs to train an accurate classifier by labeling as few data points as possible. Conceptually, the goal of video analytics is to separate the regions of frames that have objects of interest from other regions or other frames; in other words, a "classifier" that separates the spatio-temporal regions that include objects of interest from the rest of the video. Now, we can view a video as a group of bits ("data points"), each being a small area on a single frame, and each frame is preclustered into regions ("clusters") (by, for instance, region proposals commonly used in object detectors <ref type="bibr" target="#b22">[23]</ref>). The label of each bit is which object of interest it belongs to, or that it belongs to no object. Sending a video segment at a high resolution or a higher sampling rate to the server can be seen as labeling more bits in the region. Casting the server-driven iterative workflow as active learning provides a systematic framework for applying the insight of gradually increasing video quality until the inference is accurate enough.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">A concrete design and its early promise</head><p>Next, we present SimpleProto, a simple server-driven protocol that achieves substantial improvement. Extending it with complex active learning strategies is likely to bring more benefits and performance guarantees, and is an interesting next step.</p><p>SimpleProto control logic: The client in SimpleProto only passively sends data (a frame or a cropped area) when requested by the server. As in §3.1, the client runs a tracking logic, so the goal of the server is to detect objects and their locations in the frames where the object set changes. For each new frame, SimpleProto runs the basic iterative workflow ( §4.1) to make decisions on each of the knobs ( §2) one by one, and in the order of cropping, resolution, and frame rate. For brevity, we used a fixed compression level, but it can be optimized in almost the same way as selecting resolution. For each new frame, the logic starts with low sampling rate (or use I or P frames of H.264 to indicate if a frame is worth sampling) and low resolution. In each iteration, if a bounding box is detected with sufficient confidence at a lower resolution, SimpleProto crops out that area, and sends it at a higher resolution to server for inference. The iterations end (1) if the inference confidence is below al pha (default, 30%), then the area is discarded, or (2) if the confidence exceeds beta (default, 80%), then an object is successfully detected. Finally, if the new sampled frame has a different number of objects than the last sampled frame, SimpleProto runs an iterative binary search between these two frames in order to locate the exact frame where new objects first appeared. It should also be noted that SimpleProto will miss an object if it is not "noticeable" at a low resolution (e.g., the object is too small) or at the low frame rate (e.g., the object appears and disappears too quickly).</p><p>Under dynamic bandwidth: In practice, the available bandwidth may be dynamic, so SimpleProto's basic logic may not be able to complete all the server-client iterations needed to achieve sufficient accuracy. Fortunately, SimpleProto's iterative workflow is amenable to bandwidth variation. One can set a deadline for per-frame inference, and let SimpleProto exit at the last iteration before the deadline. Because each iteration progressively increases the inference accuracy (e.g., reducing false positives via increasing resolution, and reducing false negatives via sampling more frames), such early exit should strike the best accuracy-bandwidth tradeoff under a given bandwidth constraint.</p><p>Protocol interfaces: Like other video streaming protocols, a server-driven protocol for vision analytics operates at application layer. It maintains two connections (which could be multiplexed in one transport session) between the client and the server: one for image/video data transmission, and one for control messages. The serverside process exposes three APIs 2 :</p><p>(1) a user-facing API, through which a user specifies the objects of interest and gets their locations and labels in the frames; (2) a DNNfacing API, through which the server gets the bounding boxes of detected objects in an image from DNN logic 3 ; and (3) a client-facing API, through which the server fetches a region of a specific frame in a specific resolution. The client-side process simply receives frames from the camera (video source), compresses and sends frames as specified by the server in the control messages.</p><p>Early promise: <ref type="figure" target="#fig_2">Figure 4</ref> compares the bandwidth- accuracy tradeoffs of SimpleProto with MPEG, Glimpse, and the oracle ( §3.1) using the same video of <ref type="figure" target="#fig_0">Figure 2</ref>, and <ref type="figure" target="#fig_3">Figure 5</ref> shows the bandwidth reduction of SimpleProto on five traffic video clips from <ref type="bibr" target="#b8">[9]</ref> (summarized in <ref type="table" target="#tab_0">Table 1</ref>) when the F1 score is fixed above 0.95. On one hand, SimpleProto outperforms both baselines of MPEG and Glimpse: While performance of SimpleProto does depend on the content of the video, SimpleProto achieves comparable accuracy (F1 score &gt; 0.95) using 4-23×less bandwidth than MPEG or Glimpse. The overhead of running SimpleProto is not substantial; SimpleProto runs 2-3 iterations on most selected frames, and the number of frames that the client needs to store locally is bounded by the minimal frame sampling rate of one per few seconds, which means it will only need to save several second of videos. On the other hand, we see a considerable gap between SimpleProto and the oracle protocol, which shows that SimpleProto only scratches the surface and we can improve the trade-off substantially.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Open questions</head><p>Tighter integration with client/server analytics stack: Although superposition coding ensures no redundant data is sent (i.e., total bandwidth usage is bounded), the total delay of these communications and server-side processing could potentially grow unbounded. For instance, the SimpleProto server logic may fetch data from the client multiple times to analyze one frame, and runs complex server logic before the next data fetching. Therefore, to make distributed video analytics practical, the video streaming protocol must be integrated with the server/client-side analytics stack (e.g., <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b34">35]</ref>) to jointly optimize performance tradeoffs. Leveraging insights from computer vision literature: Like traditional video streaming, streaming video for DNN-based vision analytics faces the challenge that it is extremely complex to understand what the "viewer" (in this case, DNN) cares about. However, we see an opportunity that since vision analytics use artificial models designed by researchers, it is plausible to "open up the black box" of DNN <ref type="bibr" target="#b27">[28]</ref>. To take a simple example, suppose we know that the server-side model detects dog by using the color features, then the client can remove all green parts of the video, since no dog is green, e.g. by using probabilistic predicates <ref type="bibr" target="#b15">[16]</ref>.  <ref type="figure" target="#fig_3">Figure 5</ref>. Video F is used in <ref type="figure" target="#fig_0">Figure 2</ref> and <ref type="figure" target="#fig_2">Figure 4</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Appendix</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The oracle protocol vs. streaming all encoded frames (MPEG) and client-side heuristics (Glimpse).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Inference results on low-resolution image (left) indicate where the protocol should "zoom-in" with high resolution (right) to improve the inference accuracy.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Comparing SimpleProto with the oracle, and baselines of MPEG and Glimpse on an example video.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Bandwidth reduction of SimpleProto over MPEG and Glimpse (F1 score &gt; 0.95) on five videos.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 summarizes</head><label>1</label><figDesc></figDesc><table>the basic statistics of the videos 
from [9]. The object detector used in the experiments 
is Faster-RCNN ResNet101 [1] with confidence thresh-
old of 30%. Here the definition of object change rate is 
the average number of how many objects leave and enter 
a frame within a second. 

Video Frame Camera Resolution Object 
rate 
type 
(pixels) 
change 
(fps) 
rate 
A 
10 
Static 
1242 x 375 
0.44 
B 
2 
Moving 1280 x 720 
0.27 
C 
10 
Moving 1392 x 512 
0.3 
D 
10 
Moving 1242 x 375 
0.23 
E 
10 
Moving 1392 x 512 
0.42 
F 
10 
Moving 1392 x 512 
2.73 

Table 1: Table summarizing statistics of videos used in 
</table></figure>

			<note place="foot" n="2"> Note that a server-driven protocol can be equivalently implemented by the client, as long as the server exposes interfaces to allow client to make the same decisions as if the logic is run on the server. 3 This is the same to how DNN object detectors are run, so no additional work is needed by vision analytics designers</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Tensorflow detection model zoo</title>
		<ptr target="https://github.com/tensorflow/models/blob/master/research/objectdetection/g3doc/detectionmodelzoo.md" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Compact global descriptors for visual search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Chandrasekhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Morre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Veillard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Goh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Compression Conference</title>
		<imprint>
			<biblScope unit="page" from="333" to="342" />
			<date type="published" when="2015-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Glimpse: Continuous, realtime object recognition on mobile devices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ravindranath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bahl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Balakrishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th ACM Conference on Embedded Networked Sensor Systems, SenSys &apos;15</title>
		<meeting>the 13th ACM Conference on Embedded Networked Sensor Systems, SenSys &apos;15<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Comments on broadcast channels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Cover</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on information theory</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2524" to="2530" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">MAUI: Making smartphones last longer with code offload</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Cuervo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Balasubramanian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wolman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Saroiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chandra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bahl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th International Conference on Mobile Systems, Applications, and Services, MobiSys &apos;10</title>
		<meeting>the 8th International Conference on Mobile Systems, Applications, and Services, MobiSys &apos;10<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="49" to="62" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Hierarchical sampling for active learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Dasgupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hsu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th international conference on Machine learning</title>
		<meeting>the 25th international conference on Machine learning</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="208" to="215" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Active learning tutorial. ICML</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Dasgupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Langford</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A proof of marton&apos;s coding theorem for the discrete memoryless broadcast channel</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">El</forename><surname>Gamal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">C</forename><surname>Van Der Meulen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Information Theory</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="120" to="122" />
			<date type="published" when="1981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Vision meets robotics: The kitti dataset. The International</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lenz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Stiller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Robotics Research</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1231" to="1237" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Towards wearable cognitive assistance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Richter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Pillai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Satyanarayanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th Annual International Conference on Mobile Systems, Applications, and Services, MobiSys &apos;14</title>
		<meeting>the 12th Annual International Conference on Mobile Systems, Applications, and Services, MobiSys &apos;14</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="68" to="81" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Mcdnn: An approximation-based execution framework for deep stream processing under resource constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Philipose</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wolman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krishnamurthy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th Annual International Conference on Mobile Systems, Applications, and Services, MobiSys &apos;16</title>
		<meeting>the 14th Annual International Conference on Mobile Systems, Applications, and Services, MobiSys &apos;16</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kalenichenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Weyand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Andreetto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Adam</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.04861</idno>
		<title level="m">Mobilenets: Efficient convolutional neural networks for mobile vision applications</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Noscope: Optimizing neural network queries over video at scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Emmons</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Abuzaid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bailis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zaharia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. VLDB Endow</title>
		<meeting>VLDB Endow</meeting>
		<imprint>
			<date type="published" when="2017-08" />
			<biblScope unit="volume">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Energy characterization and optimization of image sensing toward continuous mobile vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Likamwa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Priyantha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Philipose</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bahl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceeding of the 11th Annual International Conference on Mobile Systems, Applications, and Services, MobiSys &apos;13</title>
		<meeting>eeding of the 11th Annual International Conference on Mobile Systems, Applications, and Services, MobiSys &apos;13</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="69" to="82" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Hnip: Compact deep invariant representations for video matching, localization, and retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">Y</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Chandrasekhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Multimedia</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1968" to="1983" />
			<date type="published" when="2017-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Accelerating machine learning queries with probabilistic predicates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chowdhery</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kandula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chaudhuri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGMOD. ACM</title>
		<imprint>
			<date type="published" when="2018-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The h. 264/mpeg4 advanced video coding standard and its applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Marpe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wiegand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">J</forename><surname>Sullivan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE communications magazine</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="134" to="143" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Region-of-interest-based video coding for video conference applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Meddeb</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
		<respStmt>
			<orgName>Telecom ParisTech</orgName>
		</respStmt>
	</monogr>
<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Glimpse: A programmable early-discard camera architecture for continuous mobile vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Naderiparizi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Philipose</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Priyantha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ganesan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services</title>
		<meeting>the 15th Annual International Conference on Mobile Systems, Applications, and Services</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="292" to="305" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Adobes real time messaging protocol. Copyright Adobe Systems Incorporated</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Thornburgh</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1" to="52" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Introduction to digital speech processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">R</forename><surname>Rabiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">W</forename><surname>Schafer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations and Trends® in Signal Processing</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1" to="194" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">You only look once: Unified, real-time object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Redmon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Divvala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Farhadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="779" to="788" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Faster r-cnn: towards real-time object detection with region proposal networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="1137" to="1149" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Object detection networks on convolutional feature maps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="1476" to="1481" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">The emergence of edge computing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Satyanarayanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="30" to="39" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Edge analytics in the internet of things</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Satyanarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Simoens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Pillai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Amos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Pervasive Computing</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="24" to="31" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Overview of the scalable video coding extension of the h. 264/avc standard</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Schwarz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Marpe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wiegand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on circuits and systems for video technology</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="1103" to="1120" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Not just a black box: Interpretable deep learning by propagating activation differences. ICML</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shrikumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Greenside</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shcherbina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kundaje</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">The mpeg-dash standard for multimedia streaming over the internet</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sodagar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE MultiMedia</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="62" to="67" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Dynamic adaptive streaming over http-: standards and design principles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Stockhammer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM conference on Multimedia systems</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="133" to="144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Overview of the high efficiency video coding (hevc) standard. IEEE Transactions on circuits and systems for video technology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">J</forename><surname>Sullivan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ohm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-J</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wiegand</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="1649" to="1668" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Inception-v4, inception-resnet and the impact of residual connections on learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Alemi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Distributed deep neural networks over the cloud, the edge and end devices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Teerapittayanon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Mcdanel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Distributed Computing Systems (ICDCS), 2017 IEEE 37th International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="328" to="339" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A scalable and privacy-aware iot service for live video analytics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Amos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Pillai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Sadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Satyanarayanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th ACM on Multimedia Systems Conference, MMSys&apos;17</title>
		<meeting>the 8th ACM on Multimedia Systems Conference, MMSys&apos;17</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="38" to="49" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Live video analytics at scale with approximation and delay-tolerance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Ananthanarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bodik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Philipose</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bahl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Freedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NSDI</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">The design and implementation of a wireless video surveillance system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chowdhery</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Bahl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Jamieson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Banerjee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st Annual International Conference on Mobile Computing and Networking</title>
		<meeting>the 21st Annual International Conference on Mobile Computing and Networking</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="426" to="438" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
