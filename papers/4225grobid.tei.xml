<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2020-10-16T20:09+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">SECTOR: A Neural Model for Coherent Topic Segmentation and Classification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Arnold</surname></persName>
							<email>sarnold@beuth-hochschule.de</email>
							<affiliation key="aff0">
								<orgName type="institution">Beuth University of Applied Sciences Berlin</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rudolf</forename><surname>Schneider</surname></persName>
							<email>ruschneider@beuth-hochschule.de</email>
							<affiliation key="aff0">
								<orgName type="institution">Beuth University of Applied Sciences Berlin</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philippe</forename><surname>Cudré-Mauroux</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of Fribourg</orgName>
								<address>
									<settlement>Fribourg</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><forename type="middle">A</forename><surname>Gers</surname></persName>
							<email>gers@beuth-hochschule.de</email>
							<affiliation key="aff2">
								<orgName type="institution">Beuth University of Applied Sciences</orgName>
								<address>
									<settlement>Berlin</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Löser</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Beuth University of Applied Sciences</orgName>
								<address>
									<settlement>Berlin</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">SECTOR: A Neural Model for Coherent Topic Segmentation and Classification</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>When searching for information, a human reader first glances over a document, spots relevant sections, and then focuses on a few sentences for resolving her intention. However , the high variance of document structure complicates the identification of the salient topic of a given section at a glance. To tackle this challenge, we present SECTOR, a model to support machine reading systems by segmenting documents into coherent sections and assigning topic labels to each section. Our deep neural network architecture learns a latent topic embedding over the course of a document. This can be leveraged to classify local topics from plain text and segment a document at topic shifts. In addition, we contribute WikiSection, a publicly available data set with 242k labeled sections in English and German from two distinct domains: diseases and cities. From our extensive evaluation of 20 architectures, we report a highest score of 71.6% F1 for the segmentation and classification of 30 topics from the English city domain, scored by our SECTOR long short-term memory model with Bloom filter embeddings and bidirectional segmentation. This is a significant improvement of 29.5 points F1 over state-of-the-art CNN classifiers with baseline segmentation.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Today's systems for natural language understanding are composed of building blocks that extract semantic information from the text, such as named entities, relations, topics, or discourse structure. In traditional natural language processing (NLP), these extractors are typically applied to bags of words or full sentences ( <ref type="bibr" target="#b27">Hirschberg and Manning, 2015)</ref>. Recent neural architectures build upon pretrained word or sentence embeddings ( <ref type="bibr" target="#b44">Mikolov et al., 2013;</ref><ref type="bibr" target="#b38">Le and Mikolov, 2014)</ref>, which focus on semantic relations that can be learned from large sets of paradigmatic examples, even from long ranges ( <ref type="bibr" target="#b16">Dieng et al., 2017)</ref>.</p><p>From a human perspective, however, it is mostly the authors themselves who help best to understand a text. Especially in long documents, an author thoughtfully designs a readable structure and guides the reader through the text by arranging topics into coherent passages <ref type="bibr" target="#b22">(Glavaš et al., 2016)</ref>. In many cases, this structure is not formally expressed as section headings (e.g., in news articles, reviews, discussion forums) or it is structured according to domain-specific aspects (e.g., health reports, research papers, insurance documents).</p><p>Ideally, systems for text analytics, such as topic detection and tracking (TDT) <ref type="bibr" target="#b3">(Allan, 2002</ref>), text summarization ( <ref type="bibr" target="#b30">Huang et al., 2003)</ref>, information retrieval (IR) ( <ref type="bibr" target="#b15">Dias et al., 2007)</ref>, or question answering (QA) , could access a document representation that is aware of both topical (i.e., latent semantic content) and structural information (i.e., segmentation) in the text ( <ref type="bibr" target="#b43">MacAvaney et al., 2018</ref>). The challenge in building such a representation is to combine these two dimensions that are strongly interwoven in the author's mind. It is therefore important to understand topic segmentation and classification as a mutual task that requires encoding both topic information and document structure coherently.</p><p>In this paper, we present SECTOR, <ref type="bibr">1</ref> an end-to-end model that learns an embedding of latent topics from potentially ambiguous headings and can be applied to entire documents to predict local topics on sentence level. Our model encodes topical information on a vertical dimension and structural information on a horizontal dimension. We show that the resulting embedding can be leveraged in a downstream pipeline to segment a document into coherent sections and classify the sections into one of up to 30 topic categories reaching 71.6% F 1 -or alternatively, attach up to 2.8k topic labels with 71.1% mean average precision (MAP). We further show that segmentation performance of our bidirectional long short-term memory (LSTM) architecture is comparable to specialized state-of-the-art segmentation methods on various real-world data sets.</p><p>To the best of our knowledge, the combined task of segmentation and classification has not been approached on the full document level before. There exist a large number of data sets for text segmentation, but most of them do not reflect real-world topic drifts <ref type="bibr" target="#b11">(Choi, 2000;</ref><ref type="bibr" target="#b53">Sehikh et al., 2017)</ref>, do not include topic labels <ref type="bibr" target="#b18">(Eisenstein and Barzilay, 2008;</ref><ref type="bibr" target="#b31">Jeong and Titov, 2010;</ref><ref type="bibr" target="#b22">Glavaš et al., 2016)</ref>, or are heavily normalized and too small to be used for training neural networks <ref type="bibr" target="#b10">(Chen et al., 2009)</ref>. We can utilize a generic segmentation data set derived from Wikipedia that includes headings ( <ref type="bibr" target="#b36">Koshorek et al., 2018</ref>), but there is also a need in IR and QA for supervised structural topic labels <ref type="bibr" target="#b0">(Agarwal and Yu, 2009;</ref><ref type="bibr" target="#b43">MacAvaney et al., 2018)</ref>, different languages and more specific domains, such as clinical or biomedical research <ref type="bibr" target="#b56">(Tepper et al., 2012;</ref><ref type="bibr" target="#b57">Tsatsaronis et al., 2012)</ref>, and news-based TDT ( <ref type="bibr" target="#b37">Kumaran and Allan, 2004;</ref><ref type="bibr" target="#b40">Leetaru and Schrodt, 2013)</ref>.</p><p>Therefore we introduce WIKISECTION, 2 a large novel data set of 38k articles from the English and German Wikipedia labeled with 242k sections, original headings, and normalized topic labels for up to 30 topics from two domains: diseases and cities. We chose these subsets to cover both clinical/biomedical aspects (e.g., symptoms, treatments, complications) and news-based topics (e.g., history, politics, economy, climate). Both article types are reasonably well-structured according to Wikipedia guidelines ( <ref type="bibr" target="#b49">Piccardi et al., 2018</ref>), but we show that they are also comple- <ref type="bibr">2</ref> The data set is available under the CC BY-SA 3.0 license at https://github.com/sebastianarnold/ WikiSection. mentary: Diseases is a typical scientific domain with low entropy (i.e., very narrow topics, precise language, and low word ambiguity). In contrast, cities resembles a diversified domain, with high entropy (i.e., broader topics, common language, and higher word ambiguity) and will be more applicable to for example, news, risk reports, or travel reviews.</p><p>We compare SECTOR to existing segmentation and classification methods based on latent Dirichlet allocation (LDA), paragraph embeddings, convolutional neural networks (CNNs), and recurrent neural networks (RNNs). We show that SECTOR significantly improves these methods in a combined task by up to 29.5 points F 1 when applied to plain text with no given segmentation.</p><p>The rest of this paper is structured as follows: We introduce related work in Section 2. Next, we describe the task and data set creation process in Section 3. We formalize our model in Section 4. We report results and insights from the evaluation in Section 5. Finally, we conclude in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>The analysis of emerging topics over the course of a document is related to a large number of research areas. In particular, topic modeling ( <ref type="bibr" target="#b9">Blei et al., 2003</ref>) and TDT ( <ref type="bibr" target="#b33">Jin et al., 1999</ref>) focus on representing and extracting the semantic topical content of text. Text segmentation ( <ref type="bibr" target="#b7">Beeferman et al. 1999</ref>) is used to split documents into smaller coherent chunks. Finally, text classification <ref type="bibr" target="#b34">(Joachims 1998</ref>) is often applied to detect topics on text chunks. Our method unifies those strongly interwoven tasks and is the first to evaluate the combined topic segmentation and classification task using a corresponding data set with long structured documents.</p><p>Topic modeling is commonly applied to entire documents using probabilistic models, such as LDA ( <ref type="bibr" target="#b9">Blei et al., 2003)</ref>. <ref type="bibr" target="#b4">AlSumait et al. (2008)</ref> introduced an online topic model that captures emerging topics when new documents appear. <ref type="bibr" target="#b20">Gabrilovich and Markovitch (2007)</ref> proposed the Explicit Semantic Analysis method in which concepts from Wikipedia articles are indexed and assigned to documents. Later, and to overcome the vocabulary mismatch problem, <ref type="bibr" target="#b12">Cimiano et al. (2009)</ref> introduced a method for assigning latent concepts to documents. More recently, <ref type="bibr" target="#b41">Liu et al. (2016)</ref> represented documents with vectors of closely related domain keyphrases. <ref type="bibr" target="#b62">Yeh et al. (2016)</ref> proposed a conceptual dynamic LDA model for tracking topics in conversations. <ref type="bibr" target="#b8">Bhatia et al. (2016)</ref> utilized Wikipedia document titles to learn neural topic embeddings and assign document labels. <ref type="bibr" target="#b16">Dieng et al. (2017)</ref> focused on the issue of long-range dependencies and proposed a latent topic model based on RNNs. However, the authors did not apply the RNN to predict local topics.</p><p>Text segmentation has been approached with a wide variety of methods. Early unsupervised methods utilized lexical overlap statistics <ref type="bibr" target="#b24">(Hearst 1997;</ref><ref type="bibr" target="#b11">Choi 2000)</ref>, dynamic programming ( <ref type="bibr" target="#b59">Utiyama and Isahara, 2001</ref>), Bayesian models ( <ref type="bibr" target="#b18">Eisenstein and Barzilay, 2008)</ref>, or pointwise boundary sampling ( <ref type="bibr" target="#b17">Du et al., 2013</ref>) on raw terms.</p><p>Later, supervised methods included topic models ( <ref type="bibr" target="#b51">Riedl and Biemann, 2012)</ref> by calculating a coherence score using dense topic vectors obtained by LDA. <ref type="bibr" target="#b6">Bayomi et al. (2015)</ref> exploited ontologies to measure semantic similarity between text blocks. <ref type="bibr" target="#b2">Alemi and Ginsparg (2015)</ref> and <ref type="bibr" target="#b45">Naili et al. (2017)</ref> studied how word embeddings can improve classical segmentation approaches. <ref type="bibr" target="#b22">Glavaš et al. (2016)</ref> utilized semantic relatedness of word embeddings by identifying cliques in a graph.</p><p>More recently, <ref type="bibr" target="#b53">Sehikh et al. (2017)</ref> utilized LSTM networks and showed that cohesion between bidirectional layers can be leveraged to predict topic changes. In contrast to our method, the authors focused on segmenting speech recognition transcripts on word level without explicit topic labels. The network was trained with supervised pairs of contrary examples and was mainly evaluated on artificially segmented documents. Our approach extends this idea so it can be applied to dense topic embeddings which are learned from raw section headings.  tackled segmentation by training a CNN to learn coherence scores for text pairs. Similar to <ref type="bibr" target="#b53">Sehikh et al. (2017)</ref>, the network was trained with short contrary examples and no topic objective. The authors showed that their pointwise ranking model performs well on data sets by <ref type="bibr" target="#b31">Jeong and Titov (2010)</ref>. In contrast to our method, the ranking algorithm strictly requires a given ground truth number of segments for each document and no topic labels are predicted. <ref type="bibr" target="#b36">Koshorek et al. (2018)</ref> presented a large new data set for text segmentation based on Wikipedia that includes section headings. The authors introduced a neural architecture for segmentation that is based on sentence embeddings and four layers of bidirectional LSTM. Similar to <ref type="bibr" target="#b53">Sehikh et al. (2017)</ref>, the authors used a binary segmentation objective on the sentence level, but trained on entire documents. Our work takes up this idea of end-to-end training and enriches the neural model with a layer of latent topic embeddings that can be utilized for topic classification.</p><p>Text classification is mostly applied at the paragraph or sentence level using machine learning methods such as support vector machines <ref type="bibr" target="#b34">(Joachims, 1998)</ref> or, more recently, shallow and deep neural networks ( <ref type="bibr" target="#b28">Le et al., 2018;</ref><ref type="bibr" target="#b14">Conneau et al., 2017)</ref>. Notably, paragraph vectors ( <ref type="bibr" target="#b38">Le and Mikolov, 2014</ref>) is an extension of word2vec for learning fixed-length distributed representations from texts of arbitrary length. The resulting model can be utilized for classification by providing paragraph labels during training. Furthermore, <ref type="bibr" target="#b35">Kim (2014)</ref> has shown that CNNs combined with pre-trained task-specific word embeddings achieve the highest scores for various text classification tasks.</p><p>Combined approaches of topic segmentation and classification are rare to find. Agarwal and Yu (2009) classified sections of BioMed Central articles into four structural classes (introduction, methods, results, and discussion). However, their manually labeled data set only contains a sample of sentences from the documents, so they evaluated sentence classification as an isolated task. <ref type="bibr" target="#b10">Chen et al. (2009)</ref> introduced two Wikipedia-based data sets for segmentation, one about large cities, the second about chemical elements. Although these data sets have been used to evaluate word-level and sentence-level segmentation ( <ref type="bibr" target="#b36">Koshorek et al., 2018</ref>), we are not aware of any topic classification approach on this data set.</p><p>Tepper et al. (2012) approached segmentation and classification in a clinical domain as supervised sequence labeling problem. The documents were segmented using a maximum entropy model and then classified into 11 or 33 categories. A similar approach by <ref type="bibr" target="#b1">Ajjour et al. (2017)</ref> used sequence labeling with a small number of 3-6 classes. Their model is extractive, so it does not produce a continuous segmentation over the entire document. Finally, <ref type="bibr" target="#b49">Piccardi et al. (2018)</ref> did not approach segmentation, but recommended an ordered set of section labels based on Wikipedia articles. Eventually, we were inspired by passage retrieval ( <ref type="bibr" target="#b42">Liu and Croft, 2002</ref>) as an important downstream task for topic segmentation and classification. For example, <ref type="bibr" target="#b25">Hewlett et al. (2016)</ref> proposed WikiReading, a QA task to retrieve values from sections of long documents. The objective of TREC Complex Answer Retrieval is to retrieve a ranking of relevant passages for a given outline of hierarchical sections ( <ref type="bibr" target="#b46">Nanni et al., 2017)</ref>. Both tasks highly depend on a building block for local topic embeddings such as our proposed model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Task Overview and Data set</head><p>We start with a definition of the WIKISECTION machine reading task shown in <ref type="figure" target="#fig_0">Figure 1</ref>. We take a document D = S, T consisting of N consecutive sentences S = [s 1 , . . . , s N ] and empty segmentation T = ∅ as input. In our example, this is the plain text of a Wikipedia article (e.g., about Trichomoniasis 3 ) without any section information. For each sentence s k , we assume a distribution of local topics e k that gradually changes over the course of the document.</p><p>The task is to split D into a sequence of distinct topic sections T = [T 1 , . . . , T M ], so that each predicted section T j = S j , y j contains a sequence of coherent sentences S j ⊆ S and a topic label y j that describes the common topic in these sentences. For the document Trichomoniasis, the sequence of topic labels is y 1...M = [ symptom, cause, diagnosis, prevention, treatment, complication, epidemiology ].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">WikiSection Data Set</head><p>For the evaluation of this task, we created WIKI-SECTION, a novel data set containing a gold standard of 38k full-text documents from English and German Wikipedia comprehensively annotated with sections and topic labels (see <ref type="table">Table 1</ref>). The documents originate from recent dumps in English <ref type="bibr">4</ref> and German. <ref type="bibr">5</ref> We filtered the collection using SPARQL queries against <ref type="bibr">Wikidata (Tanon et al., 2016)</ref>. We retrieved instances of Wikidata categories disease (Q12136) and their subcategories (e.g., Trichomoniasis or Pertussis) or city (Q515) (e.g., London or Madrid).</p><p>Our data set contains the article abstracts, plain text of the body, positions of all sections given by the Wikipedia editors with their original headings (e.g., "Causes | Genetic sequence") and a normalized topic label (e.g., disease. cause). We randomized the order of documents and split them into 70% training, 10% validation, 20% test sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Preprocessing</head><p>To obtain plain document text, we used Wikiextractor, <ref type="bibr">6</ref> split the abstract sections and stripped all section headings and other structure tags except newline characters and lists.</p><p>Vocabulary Mismatch in Section Headings. <ref type="table" target="#tab_2">Table 2</ref> shows examples of section headings from disease articles separated into head (most common), torso (frequently used), and tail (rare). Initially, we expected articles to share congruent structure in naming and order. Instead, we observe a high variance with 8.5k distinct headings in the diseases domain and over 23k for English cities. A closer inspection reveals that Wikipedia authors utilize headings at different granularity levels, frequently copy and paste from other articles, but also introduce synonyms or hyponyms, which leads to a vocabulary mismatch problem ( <ref type="bibr" target="#b19">Furnas et al., 1987)</ref>. As a result, the distribution of headings is heavy-tailed across all articles. Roughly 1% of headings appear more than 25 times whereas the vast majority (88%) appear 1 or 2 times only.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Synset Clustering</head><p>In order to use Wikipedia headlines as a source for topic labels, we contribute a normalization method to reduce the high variance of headings to a few representative labels based on the clustering of BabelNet synsets <ref type="bibr" target="#b47">(Navigli and Ponzetto, 2012</ref>  synsets S h ⊂ S. For example, "Cognitive behavioral therapy" is assigned to synset bn:03387773n. Next, we insert all matched synsets into an undirected graph G with nodes s ∈ S and edges e. We create edges between all synsets that match among each other with a lemma h ∈ H. Finally, we apply a community detection algorithm <ref type="bibr" target="#b48">(Newman, 2006</ref>) on G to find dense clusters of synsets. We use these clusters as normalized topics and assign the sense with most outgoing edges as representative label, in our example e.g. therapy.</p><p>From this normalization step we obtain 598 synsets that we prune using the head/tail division rule count(s) &lt; 1 <ref type="bibr">, 2012)</ref>. This method covers over 94.6% of all headings and yields 26 normalized labels and one other class in the English disease data set. <ref type="table">Table 1</ref> shows the corresponding numbers for the other data sets. We verify our normalization process by manual inspection of 400 randomly chosen headinglabel assignments by two independent judges and report an accuracy of 97.2% with an average observed inter-annotator agreement of 96.0%.</p><formula xml:id="formula_0">|S| s i ∈S count(s i ) (Jiang</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">SECTOR Model</head><p>We introduce SECTOR, a neural embedding model that predicts a latent topic distribution for every position in a document. Based on the task During inference (B), we invoke SECTOR with unseen plain text to predict topic embeddings e k on sentence level. The embeddings are used to segment the document and classify headingsˆzheadingsˆheadingsˆz j and normalized topic labelsˆylabelsˆ labelsˆy j .</p><p>described in Section 3, we aim to detect M sections T 1...M in a document D and assign topic labels y j = topic(S j ), where j = 1, . . . , M . Because we do not know the expected number of sections, we formulate the objective of our model on the sentence level and later segment based on the predictions. Therefore, we assign each sentence s k a sentence topic label ¯ y k = topic(s k ), where k = 1, . . . , N . Thus, we aim to predict coherent sections with respect to document context:</p><formula xml:id="formula_1">p(¯ y 1 , ... , ¯ y N | D) = N k=1 p(¯ y k | s 1 , ... , s N )<label>(1)</label></formula><p>We approach two variations of this task: For WIKISECTION-topics, we choose a single topic label y j ∈ Y out of a small number of normalized topic labels. However, from this simplified classification task arises an entailment problem, because topics might be hierarchically structured. For example, a section with heading "Treatment | Gene Therapy" might describe genetics as a subtopic of treatment. Therefore, we also approach an extended task WIKISECTION-headings to capture ambiguity in a heading, We follow the CBOW approach ( <ref type="bibr" target="#b44">Mikolov et al., 2013)</ref> and assign all words in the heading z j ⊂ Z as multi-label bag over the original heading vocabulary. This turns our problem into a ranked retrieval task with a large number of ambiguous labels, similar to <ref type="bibr" target="#b50">Prabhu and Varma (2014)</ref>. It further eliminates the need for normalized topic labels. For both tasks, we aim to maximize the log likelihood of model parameters Θ on section and sentence level:</p><formula xml:id="formula_2">L(Θ) = M j=1 log p(y j | s 1 , ... , s N ; Θ) ¯ L(Θ) = N k=1 log p(¯ y k | s 1 , ... , s N ; Θ)<label>(2)</label></formula><p>Our SECTOR architecture consists of four stages, shown in <ref type="figure" target="#fig_1">Figure 2</ref>: sentence encoding, topic embedding, topic classification and topic segmentation. We now discuss each stage in more detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Sentence Encoding</head><p>The first stage of our SECTOR model transforms each sentence s k from plain text into a fixed-size sentence vector x k that serves as input into the neural network layers. Following <ref type="bibr" target="#b26">Hill et al. (2016)</ref>, word order is not critical for document-centric evaluation settings such as our WIKISECTION task. Therefore, we mainly focus on unsupervised compositional sentence representations.</p><p>Bag-of-Words Encoding. As a baseline, we compose sentence vectors using a weighted bagof-words scheme. Let I(w) ∈ {0, 1} |V| be the indicator vector, such that I(w) (i) = 1 iff w is the i-th word in the fixed vocabulary V, and let tf-idf(w) be the TF-IDF weight of w in the corpus. We define the sparse bag-of-words encoding x bow ∈ R |V| as follows:</p><formula xml:id="formula_3">x bow (s) = w∈s tf-idf(w) · I(w)<label>(3)</label></formula><p>Bloom Filter Embedding. For large V and long documents, input matrices grow too large to fit into GPU memory, especially with larger batch sizes. Therefore we apply a compression technique for sparse sentence vectors based on Bloom filters <ref type="bibr" target="#b54">(Serrà and Karatzoglou, 2017)</ref>. A Bloom filter projects every item of a set onto a bit array A(i) ∈ {0, 1} m using k independent hash functions. We use the sum of bit arrays per word as compressed Bloom embedding x bloom ∈ N m :</p><formula xml:id="formula_4">x bloom (s) = w∈s k i=1 A hash i (w)<label>(4)</label></formula><p>We set parameters to m = 4096 and k = 5 to achieve a compression factor of 0.2, which showed good performance in the original paper.</p><p>Sentence Embeddings. We use the strategy of <ref type="bibr" target="#b5">Arora et al. (2017)</ref> to generate a distributional sentence representation based on pre-trained word2vec embeddings ( <ref type="bibr" target="#b44">Mikolov et al., 2013</ref> </p><formula xml:id="formula_5">v s = 1 |S| w∈s α α + p(w) v w x emb (s) = v s − uu T v s<label>(5)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Topic Embedding</head><p>We model the second stage in our architecture to produce a dense distributional representation of latent topics for each sentence in the document. We use two layers of LSTM (Hochreiter and Schmidhuber, 1997) with forget gates ( <ref type="bibr" target="#b21">Gers et al., 2000</ref>) connected to read the document in the forward and backward direction <ref type="bibr" target="#b23">(Graves, 2012)</ref>. We feed the LSTM outputs to a ''bottleneck'' layer with tanh activation as topic embedding. <ref type="figure" target="#fig_2">Figure 3</ref> shows these layers in context of the complete architecture. We can see that context from left (k − 1) and right (k + 1) affects forward and backward layers independently. It is therefore important to separate these weights in the embedding layer to precisely capture the difference between sentences at section boundaries. We modify our objective given in Equation (2) accordingly with long-range depen- dencies from forward and backward layers of the LSTM:</p><formula xml:id="formula_6">L(Θ) = N k=1 log p(¯ y k | x 1...k−1 ; Θ, Θ ) + log p(¯ y k | x k+1...N ; Θ, Θ )<label>(6)</label></formula><p>Note that we separate network parameters Θ and Θ for forward and backward directions of the LSTM, and tie the remaining parameters Θ for the embedding and output layers. This strategy couples the optimization of both directions into the same vector space without the need for an additional loss function. The embeddings e 1...N are calculated from the context-adjusted hidden states h k of the LSTM cells (here simplified as f LSTM ) through the bottleneck layer:</p><formula xml:id="formula_7">h k = f LSTM (x k , h k−1 , Θ) h k = f LSTM (x k , h k+1 , Θ) e k = tanh(W eh h k + b e ) e k = tanh(W eh h k + b e )<label>(7)</label></formula><p>Now, a simple concatenation of the embeddings e k = e k ⊕ e k can be used as topic vector by downstream applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Topic Classification</head><p>The third stage in our architecture is the output layer that decodes the class labels. To learn model parameters Θ required by the embedding, we need to optimize the full model for a training target. For the WIKISECTION-topics task, we use a simple one-hot encoding ¯ y ∈ {0, 1} |Y| of the topic labels constructed in Section 3.3 with a softmax activation output layer. For the WIKISECTIONheadings task, we encode each heading as lowercase bag-of-words vector ¯ z ∈ {0, 1} |Z| , such that ¯ z (i) = 1 iff the i-th word in Z is contained in the heading, for example, ¯ z k ˆ ={gene, therapy, treatment}. We then use a sigmoid activation function:</p><formula xml:id="formula_8">ˆ ¯ y k = softmax(W ye e k + W ye e k + b y ) ˆ ¯ z k = sigmoid(W ze e k + W ze e k + b z )<label>(8)</label></formula><p>Ranking Loss for Multi-Label Optimization.</p><p>The multi-label objective is to maximize the likelihood of every word that appears in a heading:</p><formula xml:id="formula_9">L(Θ) = N k=1 |Z| i=1 log p(¯ z (i) k | x 1...N ; Θ)<label>(9)</label></formula><p>For training this model, we use a variation of the logistic pairwise ranking loss function proposed by dos <ref type="bibr" target="#b52">Santos et al. (2015)</ref>. It learns to maximize the distance between positive and negative labels:</p><formula xml:id="formula_10">L = log 1 + exp(γ(m + − score + (x))) + log 1 + exp(γ(m − + score − (x)))<label>(10)</label></formula><p>We calculate the positive term of the loss by taking all scores of correct labels y + into account. We average over all correct scores to avoid a toostrong positive push on the energy surface of the loss function ( <ref type="bibr" target="#b39">LeCun et al., 2006</ref>). For the negative term, we only take the most offending example y − among all incorrect class labels.</p><formula xml:id="formula_11">score + (x) = 1 |y + | y∈y + s θ (x) (y) score − (x) = arg max y∈y − s θ (x) (y)<label>(11)</label></formula><p>Here, s θ (x) (y) denotes the score of label y for input x. We follow the authors and set scaling factor γ = 2, margins m + = 2.5, and m − = 0.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Topic Segmentation</head><p>In the final stage, we leverage the information encoded in the topic embedding and output layers to segment the document and classify each section.</p><p>Baseline Segmentation Methods. As a simple baseline method, we use prior information from the text and split sections at newline characters (NL). Additionally, we merge two adjacent sections if they are assigned the same topic label after classification. If there is no newline information available in the text, we use a maximum label (max) approach: We first split sections at every sentence break (i.e., S j = s k ; j = k = 1, . . . , N ) and then merge all sections that share at least one label in the top-2 predictions.</p><p>Using Deviation of Topic Embeddings for Segmentation. All information required to classify each sentence in a document is contained in our dense topic embedding matrix E = [e 1 , . . . , e N ]. We are now interested in the vector space movement of this embedding over the sequence of sentences. Therefore, we apply a number of transformations adapted from Laplacian-of-Gaussian edge detection on images ( <ref type="bibr" target="#b63">Ziou and Tabbone, 1998)</ref>  </p><formula xml:id="formula_12">d k = cos(e k−1 , e k ) = e k−1 · e k e k−1 e k<label>(12)</label></formula><p>Finally we apply the sequence d 1...N with parameters D = 16 and σ = 2.5 to locate the spots of fastest movement (see <ref type="figure" target="#fig_3">Figure 4)</ref>, i.e. all k where d k−1 &lt; d k &gt; d k+1 ; k = 1 . . . N in our discrete case. We use these positions to start a new section.</p><p>Improving Edge Detection with Bidirectional Layers. We adopt the approach of <ref type="bibr" target="#b53">Sehikh et al. (2017)</ref>, who examine the difference between forward and backward layer of an LSTM for segmentation. However, our approach focuses on the difference of left and right topic context over time steps k, which allows for a sharper distinction between sections. Here, we obtain two smoothed embeddings e and e and define the bidirectional embedding deviation (bemd) as geometric mean of the forward and backward difference:</p><formula xml:id="formula_13">d k = cos( e k−1 , e k ) · cos( e k , e k+1 ) (13)</formula><p>After segmentation, we assign each segment the mean class distribution of all contained sentences:</p><formula xml:id="formula_14">ˆ y j = 1 | S j | s i ∈S j ˆ ¯ y i<label>(14)</label></formula><p>Finally, we show in the evaluation that our SECTOR model, which was optimized for sentences ¯ y k , can be applied to the WIKISECTION task to predict coherently labeled sections T j = S j , ˆ y j .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Evaluation</head><p>We conduct three experiments to evaluate the segmentation and classification task introduced in Section 3. The WIKISECTION-topics experiment constitutes segmentation and classification of each section with a single topic label out of a small number of clean labels (25-30 topics). The WIKISECTION-headings experiment extends the classification task to multi-label per section with a larger target vocabulary (1.0k-2.8k words). This is important, because often there are no clean topic labels available for training or evaluation. Finally, we conduct a third experiment to see how SECTOR performs across existing segmentation data sets.</p><p>Evaluation Data Sets. For the first two experiments we use the WIKISECTION data sets introduced in Section 3.1, which contain documents about diseases and cities in both English and German. The subsections are retained with full granularity. For the third experiment, text segmentation results are often reported on artificial data sets <ref type="bibr" target="#b11">(Choi, 2000)</ref>. It was shown that this scenario is hardly applicable to topic-based segmentation ( <ref type="bibr" target="#b36">Koshorek et al., 2018</ref>), so we restrict our evaluation to real-world data sets that are publicly available. The Wiki-727k data set by <ref type="bibr" target="#b36">Koshorek et al. (2018)</ref> contains Wikipedia articles with a broad range of topics and their top-level sections. However, it is too large to compare exhaustively, so we use the smaller Wiki-50 subset.</p><p>We further use the Cities and Elements data sets introduced by <ref type="bibr" target="#b10">Chen et al. (2009)</ref>, which also provide headings. These sets are typically used for word-level segmentation, so they don't contain any punctuation and are lowercased. Finally, we use the Clinical Textbook chapters introduced by <ref type="bibr" target="#b18">Eisenstein and Barzilay (2008)</ref>, which do not supply headings.</p><p>Text Segmentation Models. We compare SEC-TOR to common text segmentation methods as baseline, C99 (Choi, 2000) and TopicTiling ( <ref type="bibr" target="#b51">Riedl and Biemann, 2012</ref>) and the state-of-the-art TextSeg segmenter ( <ref type="bibr" target="#b36">Koshorek et al., 2018)</ref>. In the third experiment we report numbers for BayesSeg (Eisenstein and Barzilay, 2008) (configured to predict with unknown number of segments) and <ref type="bibr">GraphSeg (Glavaš et al., 2016</ref>).</p><p>Classification Models. We compare SECTOR to existing models for single and multi-label sentence classification. Because we are not aware of any existing method for combined segmentation and classification, we first compare all methods using given prior segmentation from newlines in the text (NL) and then additionally apply our own segmentation strategies for plain text input: maximum label (max), embedding deviation (emd) and bidirectional embedding deviation (bemd).</p><p>For the experiments, we train a Paragraph Vectors (PV) model ( <ref type="bibr" target="#b38">Le and Mikolov, 2014</ref>) using all sections of the training sets. We utilize this model for single-label topic classification (depicted as PV&gt;T) by assigning the given topic labels as paragraph IDs. Multi-label classification is not possible with this model. We use the paragraph embedding for our own segmentation strategies. We set the layer size to 256, window size to 7, and trained for 10 epochs using a batch size of 512 sentences and a learning rate of 0.025. We further use an implementation of CNN <ref type="bibr" target="#b35">(Kim, 2014</ref>) with our pre-trained word vectors as input for single-label topics (CNN&gt;T) and multi-label headings (CNN&gt;H). We configured the models using the hyperparameters given in the paper and trained the model using a batch size of 256 sentences for 20 epochs with learning rate 0.01. SECTOR Configurations. We evaluate the various configurations of our model discussed in prior sections. SEC&gt;T depicts the single-label topic classification model which uses a softmax activation output layer, SEC&gt;H is the multilabel variant with a larger output and sigmoid activations. Other options are: bag-of-words sentence encoding (+bow), Bloom filter encoding (+bloom) and sentence embeddings (+emb); multi-class cross-entropy loss (as default) and ranking loss (+rank).</p><p>We have chosen network hyperparameters using grid search on the en disease validation set and keep them fixed over all evaluation runs. For all configurations, we set LSTM layer size to 256, topic embeddings dimension to 128. Models are trained on the complete train splits with a batch size of 16 documents (reduced to 8 for bag-of-words), 0.01 learning rate, 0.5 dropout, and ADAM optimization. We used early stopping after 10 epochs without MAP improvement on the validation data sets. We pretrained word embeddings with 256 dimensions for the specific tasks using word2vec on lowercase English and German Wikipedia documents using a window size of 7. All tests are implemented in Deeplearning4j and run on a Tesla P100 GPU with 16GB memory. Training a SEC+bloom model on en city takes roughly 5 hours, inference on CPU takes on average 0.36 seconds per document. In addition, we trained a SEC&gt;H@fullwiki model with raw headings from a complete English Wikipedia dump, 8 and use this model for cross-data set evaluation.</p><p>Quality Measures. We measure text segmentation at sentence level using the probabilistic P k error score <ref type="bibr" target="#b7">(Beeferman et al., 1999</ref>), which calculates the probability of a false boundary in a window of size k, lower numbers mean better segmentation. As relevant section boundaries we consider all section breaks where the topic label changes. We set k to half of the average segment length. We measure classification performance on section level by comparing the topic labels of all ground truth sections with predicted sections. We <ref type="bibr">8</ref> Excluding all documents contained in the test sets. select the pairs by matching their positions using maximum boundary overlap. We report microaveraged F 1 score for single-label or Precision@1 for multi-label classification. Additionally, we measure Mean Average Precision (MAP), which evaluates the average fraction of true labels ranked above a particular label ( <ref type="bibr">Tsoumakas et al., 2009</ref>). <ref type="table" target="#tab_7">Table 3</ref> shows the evaluation results of the WIKISECTION-topics single-label classification task, <ref type="table">Table 4</ref> contains the corresponding numbers for multi-label classification. <ref type="table" target="#tab_9">Table 5</ref> shows results for topic segmentation across different data sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Results</head><p>SECTOR Outperforms Existing Classifiers. With our given segmentation baseline (NL), the best sentence classification model CNN achieves 52.1% F 1 averaged over all data sets. SECTOR improves this score significantly by 12.4 points. Furthermore, in the setting with plain text input, SECTOR improves the CNN score by 18.8 points using identical baseline segmentation. Our model finally reaches an average of 61.8% F 1 on the classification task using sentence embeddings and bidirectional segmentation. This is a total improvement of 27.8 points over the CNN model. Topic Embeddings Improve Segmentation. SECTOR outperforms C99 and TopicTiling significantly by 16.4 and 18.8 points P k , respectively, on average. Compared to the maximum label baseline, our model gains 3.1 points by using the bidirectional embedding deviation and 1.0 points using sentence embeddings. Overall, SECTOR misses only 4.2 points P k and 2.6 points F 1 compared with the experiments with prior newline segmentation. The third experiments reveals that our segmentation method in isolation almost reaches state-of-the-art on existing data sets and beats the unsupervised baselines, but lacks performance on cross-data set evaluation. Classification and segmentation on plain text C99 37.4 n/a n/a 42.7 n/a n/a 36.8 n/a n/a 38.3 n/a n/a TopicTiling 43.4 n/a n/a 45.4 n/a n/a 30.5 n/a n/a 41.3 n/a n/a TextSeg 24.3 n/a n/a 35.7 n/a n/a 19.3 n/a n/a 27.5 n/a n/a PV&gt;T* max 43.    <ref type="table">Table 4</ref>: Results for segmentation and multi-label classification trained with raw Wikipedia headings. Here, the task is to segment the document and predict multi-word topics from a large ambiguous target vocabulary. model training and inference using pre-trained embeddings is faster by an average factor of 3.2.</p><p>Topic Embeddings Perform Well on Noisy Data. In the multi-label setting with unprocessed Wikipedia headings, classification precision of SECTOR reaches up to 72.3% P@1 for 2.8k labels. This score is in average 9.5 points lower compared to the models trained on the small number of 25-30 normalized labels. Furthermore, segmentation performance only misses 3.8 points P k compared with the topics task. Ranking loss could not improve our models significantly, but achieved better segmentation scores on the headings task. Finally, the cross-domain English fullwiki model performs only on baseline level for segmentation, but still achieves better classification performance than CNN on the English cities data set.    <ref type="figure" target="#fig_5">Figure 5</ref>: Heatmaps of predicted topic labelsˆylabelsˆ labelsˆy k for document Trichomoniasis from PV and SECTOR models with newline and embedding segmentation. Shading denotes probability for 10 out of 27 selected topic classes on Y axis, with sentences from left to right. Segmentation is shown as black lines, X axis shows expected gold labels. Note that segments with same class assignments are merged in both predictions and gold standard ('. . . ').</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Discussion and Model Insights</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SECTOR Captures Latent Topics from Context.</head><p>We clearly see from NL predictions (left side of <ref type="figure" target="#fig_5">Figure 5</ref>) that SECTOR produces coherent results with sentence granularity, with topics emerging and disappearing over the course of a document. In contrast, PV predictions are scattered across the document. Both models successfully classify first (symptoms) and last sections (epidemiology). However, only SECTOR can capture diagnosis, prevention, and treatment. Furthermore, we observe additional screening predictions in the center of the document. This section is actually labeled "Prevention | Screening" in the source document, which explains this overlap. Furthermore, we observe low confidence in the second section labeled cause. Our multi-class model predicts for this section {diagnosis, cause, genetics}. The ground truth heading for this section is "Causes | Genetic sequence," but even for a human reader this assignment is not clear. This shows that the multilabel approach fills an important gap and can even serve as an indicator for low-quality article structure.</p><p>Finally, both models fail to segment the complication section near the end, because it consists of an enumeration. The embedding deviation segmentation strategy (right side of <ref type="figure" target="#fig_5">Figure 5</ref>) completely solves this issue for both models. Our SECTOR model is giving nearly perfect segmentation using the bidirectional strategy, it only misses the discussed part of cause and is off by one sentence for the start of prevention. Furthermore, averaging over sentence-level predictions reveals clearly distinguishable section class labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions and Future Work</head><p>We presented SECTOR, a novel model for coherent text segmentation and classification based on latent topics. We further contributed WIKISECTION, a collection of four large data sets in English and German for this task. Our end-to-end method builds on a neural topic embedding which is trained using Wikipedia headings to optimize a bidirectional LSTM classifier. We showed that our best performing model is based on sparse word features with Bloom filter encoding and significantly improves classification precision for 25-30 topics on comprehensive documents by up to 29.5 points F 1 compared with state-of-the-art sentence classifiers with baseline segmentation. We used the bidirectional deviation in our topic embedding to segment a document into coherent sections without additional training. Finally, our experiments showed that extending the task to multi-label classification of 2.8k ambiguous topic words still produces coherent results with 71.1% average precision.</p><p>We see an exciting future application of SECTOR as a building block to extract and retrieve topical passages from unlabeled corpora, such as medical research articles or technical papers. One possible task is WikiPassageQA ( , a benchmark to retrieve passages as answers to non-factoid questions from long articles.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Overview of the WIKISECTION task: (1) The input is a plain text document D without structure information. (2) We assume the sentences s 1...N contain a coherent sequence of local topics e 1...N . (3) The task is to segment the document into coherent sections S 1...M and (4) to classify each section with a topic label y 1...M .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Training and inference phase of segmentation and topic classification (SECTOR). For training (A), we preprocess Wikipedia documents to supply a ground truth for segmentation T, headings Z and topic labels Y. During inference (B), we invoke SECTOR with unseen plain text to predict topic embeddings e k on sentence level. The embeddings are used to segment the document and classify headingsˆzheadingsˆheadingsˆz j and normalized topic labelsˆylabelsˆ labelsˆy j .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Neural network architecture SECTOR. The recurrent model consists of stacked LSTM, embedding and output layers that are optimized on document level and later accessed during inference in stages 1-4.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Embedding deviations emd k and bemd k of the smoothed SECTOR topic embeddings for example document Trichomoniasis. The plot shows the first derivative of vector movement over sentences k = 1, . . . N from left to right. Predicted segmentation is shown as black lines, the axis labels indicate ground truth segmentation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>9 42.7 (0.0) (0.0) 20.3 59.4 50.4 38.5 (0.0) (0.1)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 shows</head><label>5</label><figDesc>Figure 5 shows classification and segmentation of our SECTOR model compared to the PV baseline.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Frequency and entropy (H) of top-3 head and 
randomly selected torso and tail headings for category 
diseases in the English Wikipedia. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head></head><label></label><figDesc>to obtain the magnitude of embedding deviation (emd) per sentence. First, we reduce the dimensionality of E to D dimensions using PCA, that is, we solve E = U ΣW T using singular value decomposition and then project E on the D principal components E D = EW D . Next, we apply</figDesc><table>Gaussian smoothing 
to obtain a smoothed matrix E 
D by convolution 
with a Gaussian kernel with variance σ 2 . From the 
reduced and smoothed embedding vectors e 

1...N 

we construct a sequence of deviations d 1...N by 
calculating the stepwise difference using cosine 
distance: 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Results for topic segmentation and single-label classification on four WIKISECTION data sets. n = 718 
/ 464 / 3, 907 / 2, 507 documents. Numbers are given as P k on sentence level, micro-averaged F 1 and MAP at 
segment-level. For methods without segmentation, we used newlines as segment boundaries (NL) and merged 
sections of same classes after prediction. Models marked with * are based on pre-trained distributional embeddings. 

WikiSection-headings 
multi-label classification 

en disease 
1.5k topics 

de disease 
1.0k topics 

en city 
2.8k topics 

de city 
1.1k topics 

model configuration 
segm. P k P@1 MAP P k P@1 MAP P k P@1 MAP P k P@1 MAP 

CNN&gt;H* 
max 40.9 36.7 31.5 41.3 14.1 21.1 36.9 43.3 46.7 42.2 40.9 46.5 
SEC&gt;H+bloom 
bemd 35.4 35.8 38.2 36.9 31.7 37.8 20.0 65.2 62.0 23.4 49.8 53.4 
SEC&gt;H+bloom+rank 
bemd 40.2 47.8 49.0 42.8 28.4 33.2 41.9 66.8 59.0 34.9 59.6 54.6 
SEC&gt;H+emb* 
bemd 30.7 50.5 57.3 32.9 26.6 36.7 17.9 72.3 71.1 19.3 68.4 70.2 
SEC&gt;H+emb+rank* 
bemd 30.5 47.6 48.9 42.9 32.0 36.4 16.1 65.8 59.0 18.3 69.2 58.9 
SEC&gt;H+emb@fullwiki* bemd 42.4 9.7 17.</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Results for cross-data set evaluation on existing data sets. Numbers marked with * are generated by 
models trained specifically for this data set. A value of 'n/a' indicates that a model is not applicable to this problem. 

inf 
scr 
man 
epi 
com 
trea 
prev 
diag 
cau 
sym 

sym 
cau ... diag 
prev 
... trea 
com 
epi 
inf 
scr 
man 
epi 
com 
trea 
prev 
diag 
cau 
sym 

sym 
cau ... diag 
prev 
... trea 
com 
epi 

pro 
scr 
pat 
epi 
com 
trea 
prev 
diag 
cau 
sym 

sym 
cau ... diag 
prev 
... trea 
com 
epi 
pro 
scr 
pat 
epi 
com 
trea 
prev 
diag 
cau 
sym 

sym 
cau ... diag 
prev 
... trea 
com 
epi 

PV&gt;T (NL) 

SEC&gt;T+bloom (NL) 

PV&gt;T (emd) 

SEC&gt;T+bloom (bemd) 

</table></figure>

			<note place="foot" n="3"> https://en.wikipedia.org/w/index.php? title=Trichomoniasis&amp;oldid=814235024.</note>

			<note place="foot" n="4"> https://dumps.wikimedia.org/enwiki/ 20180101. 5 https://dumps.wikimedia.org/dewiki/ 20180101.</note>

			<note place="foot" n="6"> http://attardi.github.io/wikiextractor/. 7 We match lemmas of main senses and compounds to synsets of type NOUN CONCEPT.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We would like to thank the editors and anonymous reviewers for their helpful suggestions and comments. Our work is funded by the German Federal Ministry of Economic Affairs and Energy (BMWi) under grant agreement 01MD16011E (Medical Allround-Care Service Solutions) and H2020 ICT-2016-1 grant agreement 732328 (FashionBrain).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Automatically classifying sentences in full-text biomedical articles into introduction, methods, results and discussion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shashank</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">23</biblScope>
			<biblScope unit="page" from="3174" to="3180" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Unit segmentation of argumentative texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yamen</forename><surname>Ajjour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Fan</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Kiesel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henning</forename><surname>Wachsmuth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benno</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th Workshop on Argument Mining</title>
		<meeting>the 4th Workshop on Argument Mining</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="118" to="128" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Text segmentation based on semantic word embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">A</forename><surname>Alemi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Ginsparg</surname></persName>
		</author>
		<idno>cs.CL/1503.05543v1</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Introduction to topic detection and tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Allan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Topic Detection and Tracking</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="1" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">On-line LDA: Adaptive topic models for mining text streams with applications to topic detection and tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Loulwah</forename><surname>Alsumait</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Barbará</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlotta</forename><surname>Domeniconi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eighth IEEE International Conference on Data Mining</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="3" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A simple but tough-to-beat baseline for sentence embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingyu</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tengyu</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR 2017: 5th International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">OntoSeg: A novel approach to text segmentation using ontological similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bayomi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Levacher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">R</forename><surname>Ghorab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lawless</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 International Conference on Data Mining Workshop</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1274" to="1283" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Statistical models for text segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Doug</forename><surname>Beeferman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Berger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Lafferty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="177" to="210" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Automatic labelling of topics with neural embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shraey</forename><surname>Bhatia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jey</forename><forename type="middle">Han</forename><surname>Lau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Baldwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th International Conference on Computational Linguistics</title>
		<meeting>the 26th International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="953" to="963" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Latent dirichlet allocation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="993" to="1022" />
			<date type="published" when="2003-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Global models of document structure using latent permutations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R K</forename><surname>Harr Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Branavan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">R</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Karger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics</title>
		<meeting>Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="371" to="379" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Advances in domain independent linear text segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">Y</forename><surname>Freddy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st North American Chapter of the Association for Computational Linguistics Conference</title>
		<meeting>the 1st North American Chapter of the Association for Computational Linguistics Conference</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2000" />
			<biblScope unit="page" from="26" to="33" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Explicit versus latent concept models for cross-language information retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Cimiano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antje</forename><surname>Schultz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergej</forename><surname>Sizov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Sorg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steffen</forename><surname>Staab</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st International Joint Conference on Artifical Intelligence</title>
		<meeting>the 21st International Joint Conference on Artifical Intelligence</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1513" to="1518" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">WikiPassageQA: A benchmark collection for research on non-factoid answer passage retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liu</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">Bruce</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 41st International ACM SIGIR Conference on Research &amp; Development in Information Retrieval</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1165" to="1168" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Very deep convolutional networks for text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexis</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lo¨ıclo¨ıc</forename><surname>Barrault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the 15th Conference of the European Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1107" to="1116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Topic segmentation algorithms for text summarization and passage retrieval: An exhaustive evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gaël</forename><surname>Dias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elsa</forename><surname>Alves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">José Gabriel Pereira</forename><surname>Lopes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Second AAAI Conference on Artificial Intelligence</title>
		<meeting>the Twenty-Second AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="1334" to="1340" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">TopicRNN: A recurrent neural network with long-range semantic dependency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Adji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chong</forename><surname>Dieng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Paisley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR 2017: 5th International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Topic segmentation with a structured topic model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lan</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wray</forename><surname>Buntine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="190" to="200" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Bayesian unsupervised topic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Eisenstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2008 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="334" to="343" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The vocabulary problem in human-system communication</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><forename type="middle">W</forename><surname>Furnas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">K</forename><surname>Landauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Louis</forename><forename type="middle">M</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Susan</forename><forename type="middle">T</forename><surname>Dumais</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="964" to="971" />
			<date type="published" when="1987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Computing semantic relatedness using Wikipedia-based explicit semantic analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeniy</forename><surname>Gabrilovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaul</forename><surname>Markovitch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twentieth International Joint Conference on Artificial Intelligence</title>
		<meeting>the Twentieth International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1606" to="1611" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Learning to forget: Continual prediction with LSTM</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><forename type="middle">A</forename><surname>Gers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><forename type="middle">A</forename><surname>Schmidhuber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fred</forename><forename type="middle">A</forename><surname>Cummins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Compututation</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2451" to="2471" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Unsupervised text segmentation using semantic relatedness graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Goran</forename><surname>Glavaš</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Federico</forename><surname>Nanni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simone</forename><forename type="middle">Paolo</forename><surname>Ponzetto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifth Joint Conference on Lexical and Computational Semantics</title>
		<meeting>the Fifth Joint Conference on Lexical and Computational Semantics</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="125" to="130" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Supervised Sequence Labelling with Recurrent Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>Springer</publisher>
			<biblScope unit="volume">385</biblScope>
			<pubPlace>Berlin Heidelberg</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">TextTiling: Segmenting text into multi-paragraph subtopic passages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marti</forename><forename type="middle">A</forename><surname>Hearst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="33" to="64" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">WikiReading: A novel large-scale language understanding task over Wikipedia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Hewlett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Lacoste</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Fandrianto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jay</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Kelcey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Berthelot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1535" to="1545" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Learning distributed representations of sentences from unlabelled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Korhonen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1367" to="1377" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julia</forename><surname>Hirschberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in natural language processing</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">349</biblScope>
			<biblScope unit="page" from="261" to="266" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Do convolutional networks need to be deep for text classification?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hoa</forename><forename type="middle">T</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christophe</forename><surname>Cerisara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Denis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for the Advancement of Artificial Intelligence 2018 Workshop on Affective Content Analysis</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="29" to="36" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Applying machine learning to text segmentation for information retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangji</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fuchun</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dale</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nick</forename><surname>Cercone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="333" to="362" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Multidocument topic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minwoo</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Titov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th ACM International Conference on Information and Knowledge Management</title>
		<meeting>the 19th ACM International Conference on Information and Knowledge Management</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1119" to="1128" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Head/tail breaks: A new classification scheme for data with a heavy-tailed distribution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Professional Geographer</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="482" to="494" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Topic tracking for radio, TV broadcast and newswire</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hubert</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rich</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sreenivasa</forename><surname>Sista</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frederick</forename><surname>Walls</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the DARPA Broadcast News Workshop</title>
		<meeting>the DARPA Broadcast News Workshop</meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1999" />
			<biblScope unit="page" from="199" to="204" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Text categorization with support vector machines: Learning with many relevant features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thorsten</forename><forename type="middle">Joachims</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Machine Learning</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1998" />
			<biblScope unit="page" from="137" to="142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Convolutional neural networks for sentence classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoon</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1746" to="1751" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Text segmentation as a supervised learning task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omri</forename><surname>Koshorek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adir</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Mor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Rotman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="469" to="473" />
		</imprint>
	</monogr>
	<note>Short Papers</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Text classification and named entities for new event detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giridhar</forename><surname>Kumaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Allan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 27th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page" from="297" to="304" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Distributed representations of sentences and documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st International Conference on Machine Learning</title>
		<meeting>the 31st International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="1188" to="1196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">A tutorial on energy-based learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raia</forename><surname>Hadsell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Predicting Structured Data</title>
		<imprint>
			<publisher>MIT</publisher>
			<date type="published" when="2006" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">GDELT: Global data on events, location, and tone</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kalev</forename><surname>Leetaru</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><forename type="middle">A</forename><surname>Schrodt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISA Annual Convention</title>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2013" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1" to="49" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Representing documents via latent keyphrase inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jialu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingbo</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taylor</forename><surname>Cassidy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clare</forename><forename type="middle">R</forename><surname>Voss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th International Conference on World Wide Web</title>
		<meeting>the 25th International Conference on World Wide Web</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1057" to="1067" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Passage retrieval based on language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W. Bruce</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh International Conference on Information and Knowledge Management</title>
		<meeting>the Eleventh International Conference on Information and Knowledge Management</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="375" to="382" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Characterizing question facets for complex answer retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sean</forename><surname>Macavaney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Yates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arman</forename><surname>Cohan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Soldaini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Hui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nazli</forename><surname>Goharian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ophir</forename><surname>Frieder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 41st International ACM SIGIR Conference on Research &amp; Development in Information Retrieval</title>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1205" to="1208" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<idno>cs.CL/1301.3781v3</idno>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Comparative study of word embedding methods in topic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marwa</forename><surname>Naili</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anja</forename><forename type="middle">Habacha</forename><surname>Cha¨ıbicha¨ıbi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henda Hajjami Ben</forename><surname>Ghézala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st International Conference Knowledge-Based and Intelligent Information &amp; Engineering Systems</title>
		<meeting>the 21st International Conference Knowledge-Based and Intelligent Information &amp; Engineering Systems</meeting>
		<imprint>
			<publisher>Elsevier</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">112</biblScope>
			<biblScope unit="page" from="340" to="349" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Benchmark for complex answer retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Federico</forename><surname>Nanni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bhaskar</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Magnusson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Dietz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGIR International Conference on Theory of Information Retrieval</title>
		<meeting>the ACM SIGIR International Conference on Theory of Information Retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="293" to="296" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">BabelNet: The automatic construction, evaluation and application of a wide-coverage multilingual semantic network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Navigli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simone</forename><forename type="middle">Paolo</forename><surname>Ponzetto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">193</biblScope>
			<biblScope unit="page" from="217" to="250" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Finding community structure in networks using the eigenvectors of matrices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Mark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Newman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical Review E</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">36104</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Structuring Wikipedia articles with section recommendations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tiziano</forename><surname>Piccardi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michele</forename><surname>Catasta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leila</forename><surname>Zia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>West</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 41th International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 41th International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="665" to="674" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">FastXML: A fast, accurate and stable treeclassifier for extreme multi-label learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yashoteja</forename><surname>Prabhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manik</forename><surname>Varma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="263" to="272" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">TopicTiling: A text segmentation algorithm based on LDA</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Riedl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Biemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL 2012 Student Research Workshop</title>
		<meeting>ACL 2012 Student Research Workshop</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="37" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Classifying relations by ranking with convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cicero</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="626" to="634" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Topic segmentation in ASR transcripts using bidirectional RNNs for change detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Imran</forename><surname>Sehikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dominique</forename><surname>Fohr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irina</forename><surname>Illina</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Automatic Speech Recognition and Understanding Workshop</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="512" to="518" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Getting deep recommenders fit: Bloom embeddings for sparse binary input/output networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joan</forename><surname>Serrà</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandros</forename><surname>Karatzoglou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh ACM Conference on Recommender Systems</title>
		<meeting>the Eleventh ACM Conference on Recommender Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="279" to="287" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">From Freebase to Wikidata: The great migration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Denny</forename><surname>Thomas Pellissier Tanon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Vrandecic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Schaffert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lydia</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pintscher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th International Conference on World Wide Web</title>
		<meeting>the 25th International Conference on World Wide Web</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1419" to="1428" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Statistical section segmentation in freetext clinical records</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Tepper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Capurro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucy</forename><surname>Vanderwende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meliha</forename><surname>Yetisgen-Yildiz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth International Conference on Language Resources and Evaluation</title>
		<meeting>the Eighth International Conference on Language Resources and Evaluation</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="2001" to="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">BioASQ: A challenge on large-scale biomedical semantic indexing and question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Tsatsaronis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Schroeder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios</forename><surname>Paliouras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yannis</forename><surname>Almirantis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ion</forename><surname>Androutsopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Gaussier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Gallinari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thierry</forename><surname>Artieres</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">R</forename><surname>Alvers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Zschunke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Technical Report FS-12-05 Information Retrieval and Knowledge Discovery in Biomedical Text</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="92" to="98" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Mining multi-label data</title>
	</analytic>
	<monogr>
		<title level="m">Grigorios Tsoumakas, Ioannis Katakis, and Ioannis Vlahavas</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="667" to="685" />
		</imprint>
	</monogr>
	<note>Data Mining and Knowledge Discovery Handbook</note>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">A statistical model for domain-independent text segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masao</forename><surname>Utiyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hitoshi</forename><surname>Isahara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 39th</title>
		<meeting>the 39th</meeting>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
				<title level="m">Annual Meeting on Association for Computational Linguistics</title>
		<imprint>
			<publisher>ACL</publisher>
			<biblScope unit="page" from="499" to="506" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Learning to rank semantic coherence for topic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sujian</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yajuan</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Houfeng</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1340" to="1344" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Topic detection and tracking for conversational content by using conceptual dynamic latent Dirichlet allocation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jui-Feng</forename><surname>Yeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Shan</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen-Hsien</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">216</biblScope>
			<biblScope unit="page" from="310" to="318" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Edge detection techniques -An overview</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Djemel</forename><surname>Ziou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salvatore</forename><surname>Tabbone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition and Image Analysis</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="537" to="559" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
