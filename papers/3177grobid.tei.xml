<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2020-10-16T20:10+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Evaluating text coherence based on semantic similarity graph</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date type="published" when="2017-08-03">2017. August 3, 2017. 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Wira</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computing</orgName>
								<orgName type="institution">Tokyo Institute of Technology Tokyo</orgName>
								<address>
									<addrLine>Megurô Ookayama 2-12-1 152-8550</addrLine>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gotama</forename><surname>Putra</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computing</orgName>
								<orgName type="institution">Tokyo Institute of Technology Tokyo</orgName>
								<address>
									<addrLine>Megurô Ookayama 2-12-1 152-8550</addrLine>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takenobu</forename><surname>Tokunaga</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computing</orgName>
								<orgName type="institution">Tokyo Institute of Technology Tokyo</orgName>
								<address>
									<addrLine>Megurô Ookayama 2-12-1 152-8550</addrLine>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Evaluating text coherence based on semantic similarity graph</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of TextGraphs-11: the Workshop on Graph-based Methods for Natural Language Processing</title>
						<meeting>TextGraphs-11: the Workshop on Graph-based Methods for Natural Language Processing <address><addrLine>Vancouver, Canada</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="76" to="85"/>
							<date type="published" when="2017-08-03">2017. August 3, 2017. 2017</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Coherence is a crucial feature of text because it is indispensable for conveying its communication purpose and meaning to its readers. In this paper, we propose an unsupervised text coherence scoring based on graph construction in which edges are established between semantically similar sentences represented by vertices. The sentence similarity is calculated based on the cosine similarity of semantic vectors representing sentences. We provide three graph construction methods establishing an edge from a given vertex to a preceding adjacent vertex, to a single similar vertex, or to multiple similar vertices. We evaluated our methods in the document discrimination task and the insertion task by comparing our proposed methods to the supervised (Entity Grid) and unsu-pervised (Entity Graph) baselines. In the document discrimination task, our method outperformed the unsupervised baseline but could not do the supervised baseline, while in the insertion task, our method out-performed both baselines.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Coherence plays an important role in a text because it enables a text to convey its communication purpose and meaning to its readers <ref type="bibr">(Bam- berg, 1983;</ref><ref type="bibr" target="#b6">Grosz and Sidner, 1986)</ref>. Coherence also decreases reading time as a more coherent text is easier to read with less reader's cognitive load ( <ref type="bibr" target="#b19">Todirascu et al., 2016)</ref>. While there is no single agreed definition of coherence, we can compile several definitions of coherence and note its important aspects.</p><p>First, a text is coherent if it can convey its communication purpose and meaning to its readers ( <ref type="bibr" target="#b21">Wolf and Gibson, 2005;</ref><ref type="bibr" target="#b18">Somasundaran et al., 2014;</ref><ref type="bibr" target="#b4">Feng et al., 2014</ref>). Second, a text needs to be integrated as a whole, rather than a series of independent sentences <ref type="bibr" target="#b0">(Bamberg, 1983;</ref><ref type="bibr">Gar- ing, 2014</ref>). It means that sentences in the text are centralised around a certain theme or topic, and are arranged in a particular order in terms of logical, spatial, and temporal relations. Third, every sentence in a coherent text has relation(s) to each other ( <ref type="bibr" target="#b9">Halliday and Hasan, 1976;</ref><ref type="bibr">Grosz and Sid- ner, 1986;</ref><ref type="bibr" target="#b12">Mann and Thompson, 1988;</ref><ref type="bibr" target="#b21">Wolf and Gibson, 2005)</ref>. It suggests that a text exhibits discourse/rhetorical relation and cohesion. Fourth, text coherence is greatly influenced by the presence of a certain organisation in the text <ref type="bibr">(Pers- ing et al., 2010;</ref><ref type="bibr" target="#b18">Somasundaran et al., 2014</ref>). The organisation helps readers to anticipate the upcoming textual information. Although a wellorganised text is highly probable to be coherent, only the organisation does not constitute coherence. Textual organisation concerns the structural formation and logical development of a text, while lexical and semantic continuity is also indispensable for coherent text <ref type="bibr" target="#b4">(Feng et al., 2014</ref>). Fifth, it is easier to read a coherent text than its less coherent counterpart <ref type="bibr" target="#b5">(Garing, 2014)</ref>. Thus when writing a text, it is not enough to only revise the text with careful editing and proofreading from the lexical, or grammatical aspect. Coherence aspect also should be taken into account in revising the text <ref type="bibr" target="#b0">(Bamberg, 1983;</ref><ref type="bibr" target="#b5">Garing, 2014)</ref>.</p><p>There are studies on computational modelling of text coherence based on the supervised learning approach, such as the Entity Grid model <ref type="bibr">(Barzi- lay and Lapata, 2008)</ref>. The Entity Grid model has been further extended into the Role Matrix model ( <ref type="bibr" target="#b11">Lin et al., 2011;</ref><ref type="bibr" target="#b4">Feng et al., 2014</ref>). However, these models have a few drawbacks. First, department trial Microsoft evidence competitors markets products brands case Netscape software <ref type="table">Table 1</ref>: Entity Grid example Entity Grid using co-reference resolution has a bias towards the original ordering of text when comparing a text with its permutated counterparts. The co-reference resolution module is trained on well-formed texts; thus it does not perform very well for ill-organised texts. The methods utilising a discourse parser for modelling text coherence ( <ref type="bibr" target="#b11">Lin et al., 2011;</ref><ref type="bibr" target="#b4">Feng et al., 2014</ref>) have the same problem. Second, the supervised model often suffers from data sparsity, domain dependence, and computational cost for training. To alleviate these problems in the supervised model, Guinaudeau and <ref type="bibr" target="#b8">Strube (2013)</ref> proposed an unsupervised coherence model known as the Entity Graph model. The Entity Grid, Role Matrix, and Entity Graph model assumed coherence was achieved by local cohesion, i.e. repeated mentions of the same entities constitute cohesion. However, they did not capture the contribution of related-yet-notidentical entities <ref type="bibr" target="#b17">(Petersen et al., 2015)</ref>. To our best knowledge, the closest study addressing this problem was done by <ref type="bibr" target="#b10">Li and Hovy (2014)</ref>. The key idea of <ref type="bibr" target="#b10">Li and Hovy (2014)</ref> is to learn a distributed sentence representation which captures the underlying semantic relations between consecutive sentences. To tackle these limitations of the past research, we present an unsupervised text coherence model that captures the contribution of related-yet-not-identical entities.</p><formula xml:id="formula_0">S1 S O S X O − − − − − − S2 − − O − − X S O − − − S3 − − S O − − − − S O O</formula><p>The rest of this paper is organised as follows. Section 2 describes related work; Section 3 introduces our proposed unsupervised method to measure text coherence from a semantic similarity perspective; Section 4 describes experimental results; then followed by the conclusion in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>This section provides an overview of existing coherence scoring models, both supervised and unsupervised. Entity Grid is considered as a supervised baseline in this paper. On the other hand, Entity Graph is selected as an unsupervised baseline.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Entity Grid</head><p>The Entity Grid model focused on the evaluation of local cohesion developed on top of the Centering theory ( <ref type="bibr" target="#b1">Barzilay and Lapata, 2008)</ref>. The key idea of the Centering theory is that the distribution of entities in coherent texts exhibits certain regularities ( <ref type="bibr" target="#b7">Grosz et al., 1995)</ref>. The text is said to be less coherent if it exhibits many attention shifts, i.e. frequent changes in attention (centre) ( <ref type="bibr" target="#b7">Grosz et al., 1995)</ref>. However, if the centre of attention has smooth transitions, it will be more coherent, e.g. when sentences in a text mentioning the same entity. <ref type="bibr" target="#b1">Barzilay and Lapata (2008)</ref> proposed a computational model by representing text as a matrix called Entity Grid in which the column corresponds to entities, the row corresponds to sentences in the text, and the cell denotes the role of the entity in the sentence. The role of an entity is defined as one of S(subject), O(object), or X(neither). The cell is filled with "−" if the entity is not mentioned in the sentence. If the entity serves multiple roles in the sentence, the priority order would be S, O, and then X. They consider co-referent noun phrases as an entity. As an example, the text in <ref type="figure" target="#fig_1">Figure 1</ref> is transformed into the Entity Grid as in <ref type="table">Table 1</ref>. The bracketed words in <ref type="figure" target="#fig_1">Figure 1</ref> are recognised as the entities in <ref type="table">Table 1</ref>. Also, they differentiate salient entities. An entity is considered salient if it occurs at least t times in the text. The text is further encoded into a feature vector, denoting the probability of local entity transitions ( <ref type="bibr" target="#b1">Barzilay and Lapata, 2008)</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Entity Graph</head><p>To tackle the disadvantages of the supervised coherence model, <ref type="bibr" target="#b8">Guinaudeau and Strube (2013)</ref> proposed a graph model to measure text coherence. Graph data structure allows us to relate nonadjacent sentences, spanning globally in the text to reflect global coherence as opposed to the local coherence of the Entity Grid model. A text is represented as a directed bipartite graph. The first partition is a sentence partition in which each vertex represents a sentence. The second partition is a discourse partition in which each vertex represents an entity. The weighted edge between a sentence vertex and an entity vertex is established if the entity is mentioned in the sentence. A weight is assigned to each edge based on entity's role in the sentence: 3 for a subject entity, 2 for an object entity, and 1 for others. <ref type="figure">Figure 2</ref> shows an example of the bipartite graph transformation from the text in <ref type="figure" target="#fig_1">Figure 1</ref>. This directed bipartite graph is further transformed into a directed projection graph in which a vertex represents a sentence, and a directed weighted edge is established between vertices if they share same entities. The direction of the edge corresponds to the surface sequential order of the sentences within the text. For example, a vertex which represents the second sentence can only have outgoing edges to third, fourth, but not to the first sentence. There are three projection methods, P U , P W , and P Acc depending on the weighting scheme of edges. P U assigns a binary weight to each edge: one for the edge connecting two sentences sharing at least one entity in common and zero for others. P W assigns the number of shared entities between connected sentences to each edge as its weight. P Acc calculates an edge weight by accumulating the products of the weights of edges sharing an entity in the bipartite graph over the shared entities by the connected two sentences. The weight of the edge established between sentence s i and s j is calculated by</p><formula xml:id="formula_1">W ij = e∈E ij bw(e, s i ) · bw(e, s j ),<label>(1)</label></formula><p>where E ij is the set of entities shared by s i and s j and bw(e, s) is a weight of the edge between entity e and sentence s in the bipartite graph. Furthermore, the edge weight in the projection graph can be normalised with dividing by the distance between the sentences, i.e. |j − i|. <ref type="figure" target="#fig_2">Figure 3</ref> shows the projection graph transformed from <ref type="figure">Figure 2</ref> after the normalisation. To measure text coherence by the projection graph, <ref type="bibr" target="#b8">Guinaudeau and Strube (2013)</ref> used the average OutDegree of every vertex in the projection graph. The OutDegree of a vertex is defined as the summation of the weight of outgoing edges leaving the vertex.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>78</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Constructing semantic similarity graphs</head><p>As mentioned in Section 1, a text is coherent if it can convey its communication purpose to readers, integrated as a whole, cohesive, well organised, and easy to read. We would like to approach coherence from the cohesion perspective. We argue that coherence of a text is built by cohesion among its sentences. We call our method as Semantic Similarity Graph.</p><p>Our proposed method employs an unsupervised learning approach. The unsupervised approach suffers less from data sparsity, domain dependence, and computational cost for training which often arise in the supervised approach. We encode a text into a graph G(V, E), where V is a set of vertices and E is a set of edges in the graph. The vertex v i ∈ V represents the i-th sentence s i in the text, and the weighted directed edge e i,j ∈ E represents a semantic relation from the i-th to the j-th sentences. In what follows, the term "edge" refers to the weighted directed edge.</p><p>As stated by <ref type="bibr" target="#b9">Halliday and Hasan (1976)</ref>, cohesion is a matter of lexicosemantics. Our method projects a sentence into a vector representation using pre-trained GloVe word vectors 1 by <ref type="bibr" target="#b15">Pennington et al. (2014)</ref>. A sentence consists of multiple words {w 1 , w 2 , · · · , w M } where each of them is mapped into a vector space, i.e.</p><formula xml:id="formula_2">{ w 1 , w 2 , · · · , w M }.</formula><p>A sentence s can be encoded as a vector s by taking the average of consisting word vectors. Formally, a sentence vector s is described as</p><formula xml:id="formula_3">s = 1 M M k=1 w k ,</formula><p>where M denotes the number of words in the sentence.</p><p>We propose three methods for constructing a graph from a text based on semantic similarity between sentence pairs in the text. Given a certain sentence vertex in the graph, how to decide its counterpart vertices for establishing edges is the crucial point. The following subsections describe each method to decide a counterpart vertex.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Preceding adjacent vertex (PAV)</head><p>People read a text from the beginning to the end and understand a particular part of the text based <ref type="bibr">1</ref> We use word vectors trained on Wikipedia 2014 + Gigaword 5, 6B tokens 400K vocab, uncased, 100d. The resource is available at https://nlp.stanford.edu/projects/glove/ for i ← 2 to N do if sim(si, si−1) &gt; 0 then creates edge ei,i−1 with sim(si, si−1) as the weight else for j ← i − 2 to 1 do if sim(si, sj) &gt; 0 then creates edge ei,j with sim(si, sj) as the weight break <ref type="figure">Figure 4</ref>: Graph construction algorithm with similarity of PAV on information provided in the preceding part. When they do not understand a particular part, people look backwards for what they have missed.</p><p>We mimic this reading process into graph construction that is reflected in the algorithm in <ref type="figure">Fig- ure 4</ref>, where N is the number of sentences in the text to be processed. First we define a similarity measure sim(s i , s j ) of a pair of sentences s i and s j as</p><formula xml:id="formula_4">sim(s i , s j ) = α uot(s i , s j ) + (1 − α) cos( s i , s j ),</formula><p>where uot is the number of unique overlapping terms between the sentences s i and s j divided by the number of unique terms in the two sentences; cos( s i , s j ) is a cosine similarity of the sentence vectors; α is a balancing factor ranging over <ref type="bibr">[0,</ref><ref type="bibr">1]</ref>.</p><p>The algorithm constructs a graph by establishing a weighted directed edge from each sentence vertex to the preceding adjacent sentence vertex (PAV) if the sim value between the current and the preceding adjacent vertices exceeds zero; otherwise, the algorithm tries to establish an edge to the next closest preceding vertex with non-zero sim value. The established edge is assigned the sim value as its weight.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Single similar vertex (SSV)</head><p>Cohesion between two sentences s i and s j means that we need to know s i in order to understand s j or vice versa <ref type="bibr" target="#b9">(Halliday and Hasan, 1976)</ref>. In this sense, we interpret cohesion as a semantic dependency among sentences. We simulate the semantic dependency with the semantic similarity between sentences. Since the dependency could happen in both direction, we allow edges to the following vertices as well as preceding vertices.</p><p>In the previous method, "precedence" and "adjacency" are the important constraints for establishing the edges in graph construction. This Figure 5: Example of semantic similarity graphs method discards these constraints and establishes edges based on only the semantic similarity between sentences. However, the edges are still directed and weighted. Also, only a single outgoing edge is allowed from every vertex in the graph. We cast semantic dependency task into an information retrieval task. When establishing an edge from a certain sentence vertex, we search for the most similar sentence in the text. The similarity measure between two sentences s i and s j is calculated based on the cosine similarity of their semantic vectors. An edge is established from the sentence vertex in question to the most similar sentence vertex with the weight calculated by</p><formula xml:id="formula_5">weight(e i,j ) = cos( s i , s j ) |i − j| .<label>(2)</label></formula><p>This weight calculation takes into account the distance between two sentences, i.e. we prefer a closer counterpart.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Multiple similar vertex (MSV)</head><p>In the previous method, we allowed only a single outgoing edge for every sentence vertex in the graph. Here we discard the singular condition and allow multiple outgoing edges for every vertex. Instead of choosing the most similar sentence in the text, we choose multiple sentences that exceed a certain threshold (θ) in terms of cosine similarity with the sentence in question. Edges are established for all vertex pairs with the edge weight given in Equation (2). <ref type="figure">Figure 5</ref> shows an example of semantic similarity graphs constructed by three proposed methods for the text shown in <ref type="figure">Figure 6</ref>. The parameters for the PAV and MSV-based methods are the optimal value in the evaluation experiment that is described in the next section, and the insertion sentence (I) was placed in the correct position (B).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Text coherence measure</head><p>From a constructed graph by one of the three methods explained in the preceding subsections, text coherence measure tc is calculated by averaging averaged weight of outgoing edges from every vertex in the graph as</p><formula xml:id="formula_6">tc = 1 N N i=1 1 L i L i k=1 weight(e ik ),</formula><p>where N is the number of sentences in the text and L i is the number of outgoing edges from the vertex v i . L i is always one for the PAV and SSV based graph construction, since we allow only a single outgoing edge from every vertex in the graph in these methods. A larger tc value denotes a more coherent text. The proposed models have two significant differences from the Entity Graph model, our direct competitor. First, the Entity Graph model only allows establishing outgoing edges in the following direction, i.e. from the vertex v i to the vertex v j , where i &lt; j. On the other hand, the proposed models except for the PAV based graph construction allow edges in both directions. Second, the Entity Graph model only measures coherence based on shared entities between sentences with respect to their syntactic role. This is also the case for the Entity Grid model. The proposed models measure text coherence based on the similarity between semantic vectors of sentences; hence we can take into account related-yet-not-identical entities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Evaluation and results</head><p>We evaluate the proposed methods on two experimental tasks: the document discrimination task and insertion task. All stop words are removed from the texts in this experiment, while lemmatisation is not employed.</p><p>The performance of the proposed methods is also compared with our reimplementation of Entity Grid ( <ref type="bibr" target="#b1">Barzilay and Lapata, 2008)</ref> and Entity Graph ( <ref type="bibr" target="#b8">Guinaudeau and Strube, 2013</ref>). The experimental settings for each method are described below.</p><p>PAV The balancing factor α ranges over</p><formula xml:id="formula_7">[0.0, 0.1, 0.2, · · · , 1.0].</formula><p>SSV There is no particular parameter to set. Entity Grid The optimal value for transition length three (bigram and trigram) is used.</p><p>In document discrimination task, we implement the Entity Grid model with and without saliency. An entity is judged as salient if it is mentioned in the text at least twice. Saliency is not employed in the insertion task because the texts in the insertion task are relatively short and an entity is not mentioned many times.</p><p>Entity Graph We implemented three projection methods with normalisation: P U , P W , and P Acc .</p><p>Co-reference resolution is not employed to avoid bias as mentioned by <ref type="bibr" target="#b14">Nahnsen (2009)</ref>. However, we follow the suggestion by <ref type="bibr">Eisner and Char- niak (2011)</ref> to consider all nouns (including nonhead nouns) as entities in our experiment. The role of each entity is extracted using the dependency parser in Stanford CoreNLP toolkit <ref type="bibr">(Man- ning et al., 2014</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Document discrimination task</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Data</head><p>In the document discrimination task, sentences in a text are randomly permutated to generate another text; the task is to identify the original text given a pair of the original and the randomised one. The result is considered successful if the original is identified with the strictly higher coherence value. The performance is measured by accuracy, i.e. the ratio of successfully identified pairs to all pairs in the test set.</p><p>Our data came from a part of the English WSJ text in OntoNotes Release 5.0 (LDC2013T19). Half of the data is used for training while another half is used for testing. For each instance in both training and testing data, at most 20 random permutations were created. Detail of the data is shown in <ref type="table" target="#tab_2">Table 2</ref>. <ref type="table">Table 3</ref> shows the result of the document discrimination task of each method with the various experimental settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Result and discussion</head><p>Entity Grid without saliency performed the best (0.845), followed by Entity Grid with saliency (0.837), PAV (0.774, α = 0.4), MSV (0.741,    <ref type="table">Table 3</ref>: Result of the document discrimination task θ = 0.1), Entity Graph (0.725), then SSV (0.676).</p><p>The performances of PAV and MSV are increasing over changes of parameter until at certain point becomes steadily decreasing. We performed the McNemar test in R to find out that the difference in accuracy between every pair of methods is statistically significant at p &lt; 0.05. Contrary to <ref type="bibr" target="#b1">Barzilay and Lapata (2008)</ref>, the saliency factor did not work effectively for Entity Grid in our data. The PAV and MSV based-method performed better than Entity Graph. This result suggests that coherence is not only the matter of surface overlapping of entities and their syntactic roles, but semantic similarity between sentences also should be taken into account. This also confirms that  <ref type="table">Table 4</ref>: Number of the same judgements between two methods in the document discrimination task the semantic relation between adjacent sentences (local coherence) is more important for coherence than semantic relation between long-distance sentences in the document discrimination task. We also calculated the number of the same judgement between all pairs of methods (questions that are answered correctly and incorrectly by both methods in the pair). <ref type="table">Table 4</ref> shows the number of the same judgement between every pair of the methods. We found out the PAV-MSV pair shares the largest number of the same judgement (11,998, 88.3%). The MSV-based method establishes an edge between sentences whenever their similarity exceeds the threshold. However, it has relatively many same judgements with PAV. This implies the local coherence is sufficient enough to solve the document discrimination task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Insertion task</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Data</head><p>In the insertion task described in <ref type="bibr">Barzilay and La- pata (2008)</ref>, the coherence measure is evaluated based on to what extent the measure can estimate the original sentence position in a text from which one sentence is taken out randomly. The coherence measure of the text with a taken-out sentence inserted at the original position, i.e. the original text, is expected to be the highest value among other values of text with the sentence inserted at a wrong position.</p><p>We argue, however, adopting the TOEFL R iBT insertion type question is more suitable for this kind of task than using the artificially generated texts by sentence deletion. The TOEFL R insertion type question aims at measuring test takers' ability to understand the text coherence. Test takers are given a coherent text with an insert-sentence. The task is to find the best place to insert the insert-sentence. To the best of our observation, the texts in the TOEFL R iBT insertion type question are coherent even before the insert-sentence is inserted. An example of the TOEFL R iBT insertion type question is shown in <ref type="figure">Figure 6</ref>.</p><p>In the following evaluation, a method is judged as a success if it assigns the highest coherence value to the text formed by inserting the insertsentence at the correct insertion position. We do not allow tie values and judge it as fail even though the correct position has the highest tie value.</p><p>We collected 104 insertion type questions from various TOEFL R iBT preparation books. The average number of sentences in a text is 7.05 (SD: standard deviation=1.85); the average number of tokens in a text is 139.8 (SD=43.7). As the data size is relatively small, we adopted the one-heldout cross validation for the Entity Grid model. The same rank is assigned to incorrect insertion positions when training the Entity Grid model. We did not adopt the Entity Grid model considering saliency since each text is relatively short in this data thus term frequency (saliency) tends to be low for all terms. <ref type="table">Table 5</ref> shows the result of the insertion task of each method with the various experimental settings. Our proposed methods showed good performance, particularly the PAV-based graph construction method outperformed both baselines: Entity Grid and Entity Graph. The PAV method obtained the best performance at α = 0.0, while MSV method performed best at θ = 0.8. However, the McNemar test revealed that the difference in accuracy between every pair of methods was not statistically significant at p &lt; 0.05. This is probably due to the limited size of the insertion data compared with the document discrimination task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Result and discussion</head><p>There are two questions correctly answered and 31 questions incorrectly answered by all methods. These two correctly answered questions have  <ref type="table">Table 5</ref>: Result of the insertion task similar characteristics, having word overlaps and synonyms across adjacent sentences. These questions also tend to contain more common words. On the other hand, the failed questions tend to contain more uncommon words, technical terms and named entities. Although the successful questions also contain named entities, they were mentioned more frequently in the texts as opposed to the failed questions. Therefore we suspected the limited coverage of our GloVe dictionary and investigated the proportion of the out of vocabulary (OOV) ratio of the texts. Among all of the questions, there are 32 out of 104 questions including the OOV words; each question contains one to three OOV words in type/in token. All methods failed in 15 out of these 32 questions but succeeded in the rest 17. This fact suggests that OOV words are not necessarily the main reason for failures in the insertion task.</p><p>Comparing the parameters (α of PAV and θ of MSV) in <ref type="table">Table 3 and Table 5</ref>, they are different to achieve the best performance in two different datasets. In the PAV-based method, there is no significant difference in the average uot value of every pair of adjacent two sentences between the datasets. We also calculated the cosine similarity of every pair of adjacent two sentences to find more similar adjacent sentences in the insertion task data than in the document discrimination task data; 90% of the adjacent sentence similarities lies in 0.3 ∼ 0.6 in the document discrimination task, while it ranges 0.5 ∼ 0.9 in the insertion task data. This difference suggests that the uot factor helps relatively more in the document discrimination task for the PAV-based method, while it has less impact in the insertion task. This explains the difference α values of PAV across the two tasks.</p><p>To investigate the difference of the parameter θ in the MSV-based model, we calculated the cosine similarity of every sentence pair in the text. In both datasets, more than 90% of the sentence similarities lies in 0.5 ∼ 1.0. When the similarity is transformed into the edge weight by dividing by the sentence distance, the difference becomes apparent; while 86.6% of the edge weights in the document discrimination task lies less than 0.2, the edge weights scatter over 0 ∼ 1.0 in the insertion task. This happens because the average length of the texts in the document discrimination task is longer than that of the insertion task. Unless setting a low threshold (θ), the MSV-based model hardly establishes edges between sentence vertices. In other words, establishing edges between distant sentences would contribute to the performance of these tasks.  <ref type="table">Table 6</ref>: Number of the same answers between two methods in the insertion task <ref type="table">Table 6</ref> shows the number of the same answers between every pair of the methods. The SSV-MSV pair shares the most same answers in the insertion task among all pairs (84, 80.8%), followed by the PAV-MSV pair (79, 76.0%), then PAV-SSV pair (75, 72.1%). The PAV-based method performs best without considering the overlapping terms between the adjacent sentences (uot) by setting α = 0. In this case, the PAV-based method is almost similar to the SSV-based method except for allowing only backwards edges. However, <ref type="table">Table 6</ref> shows the PAV-based method answered differently from the SSV-based method in almost 30% questions. To further investigate the difference, we focused on the questions that were answered incorrectly by the PAV-based method but answered correctly by the SSV-based method. There are 14 of such questions, in which the SSV-based method tends to establish edges between distant sentences; the average distance between sentence vertices is 2.8 (SD = 0.7). This suggests that the SSVbased method could capture distant sentence relations contributing to text coherence more appropriately than the PAV-based method.</p><p>We also investigated 11 questions that were answered incorrectly by the PAV-based method but answered correctly by the MSV-based method. In these questions, the MSV-based method tends to establish more edges than the PAV-based method. The average number of outgoing edges from a sentence vertex in the graph constructed by the MSVbased method is 2.5 (SD = 1.8). In addition, the MSV-based method tends to establish edges between distant sentences as well as the SSV-based method; the average distance between sentence vertices is 2.6 (SD = 0.9). This suggests that the MSV-based method also could capture many distant sentence relations contributing to text coherence more appropriately than the PAV-based method.</p><p>Although the PAV-based method performs best with the present data, which considers only local cohesion between adjacent sentences, we need to introduce a more refined mechanism for incorporating distant sentence relations than the current SSV and MSV-based methods, as we showed that long-distance relations could contribute in determining text coherence. The representation of sentences and calculation of similarity between sentences would be direct targets of the refinement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>This paper presented three novel unsupervised text coherence scoring methods, in which text coherence is regarded to be realised by cohesion of sentences in the text and the cohesion is represented in a graph structure corresponding to the text. In the graph structure, a vertex corresponds to a sentence in the text, and an edge represents a semantic relationship between corresponding sentences. As cohesion is a matter of lexicosemantics, sentences are transformed into semantic vector representations, and their similarity is calculated based on the cosine similarity between the vectors. Edges between sentence vertices are established based on the similarity and distance between the sentences. We presented three methods to construct a graph: the PAV, SSV, and MSV-based methods.</p><p>We evaluated the proposed methods in the document discrimination task and the insertion task. Our best performing method (PAV) outperformed the unsupervised baseline (Entity Graph) but not the supervised baseline (Entity Grid) in the document discrimination task. The difference was statistically significant at p &lt; 0.05. In the insertion task, our best performing method (PAV) outperformed both supervised and unsupervised baselines, but the difference is not statistically significant at p &lt; 0.05. We argue that further experiment is necessary with a larger size of data in the insertion task.</p><p>Our experimental result showed that our best proposed method (PAV) performed 0.774 in accuracy in the document discrimination task, but only performed 0.356 in the insertion task. There is a big gap in their performance between two tasks. The error analysis revealed a possibility to improve the performance by introducing a more refined representation of sentence vectors and calculation in semantic the similarity between sentences for capturing distant relations between sentences.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>S1[(The Justice Department)S is conducting an (anti- trust trial)O against (Microsoft Corp.)X with (evidence)X that (the company)S is increasingly attempting to crush (competitors)O.] S2[(Microsoft)O is accused of try- ing to forcefully buy into (markets)X where (its own products)S are not competitive enough to unseat (es- tablished brands)O.] S3[(The case)S revolves around (evidence)O of (Microsoft)S aggressively pressuring (Netscape)O into merging (browser software)O.]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Part of an example text from (Barzilay and Lapata, 2008)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Example of projection graphs</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>(</head><label></label><figDesc>The columns "# sent." and "# token" denote the average number of sentences and tokens in a text respectively.)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>(</head><label></label><figDesc>Figure 6: Example of the TOEFL R iBT insertion type question (Education Testing Service, 2007)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head># text # sent. # token # perm.</head><label>text</label><figDesc></figDesc><table>training 686 
23.7 
510.9 
13,660 
testing 
683 
24.4 
521.4 
13,586 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 : Data for the document discrimination task</head><label>2</label><figDesc></figDesc><table></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">What makes a text coherent</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Betty</forename><surname>Bamberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">College Composition and Communication</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="417" to="429" />
			<date type="published" when="1983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Modeling local coherence: Entity based approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirela</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="34" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">The Official Guide to the New TOEFL R iBT International Edition</title>
		<imprint>
			<date type="published" when="2007" />
			<publisher>McGraw Hill</publisher>
			<pubPlace>Singapore</pubPlace>
		</imprint>
	</monogr>
	<note>Education Testing Service</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Extending the entity grid with entity-specific features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Micha</forename><surname>Eisner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Charniak</surname></persName>
		</author>
		<ptr target="http://dl.acm.org/citation.cfm?id=2002736" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: Short Papers</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: Short Papers<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="125" to="129" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The impact of deep hierarchical discourse structures in the evaluation of text coherence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vanessa</forename><surname>Wei Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziheng</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graeme</forename><surname>Hirst</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/C14-1089" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers. Dublin City University and Association for Computational Linguistics</title>
		<meeting>COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers. Dublin City University and Association for Computational Linguistics<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="940" to="949" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Coherence in argumentative essays of first year college of liberal arts students at de la salle university</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Alphie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Garing</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>DLSU Research Congress</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Attention, intentions, and the structure of discourse</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Barbara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Candace</forename><forename type="middle">L</forename><surname>Grosz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sidner</surname></persName>
		</author>
		<ptr target="http://dl.acm.org/citation.cfm?id=12457.12458" />
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="175" to="204" />
			<date type="published" when="1986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Centering: A framework for modeling the local coherence of discourse</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><forename type="middle">J</forename><surname>Grosz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Weinstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aravind</forename><forename type="middle">K</forename><surname>Joshi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="203" to="225" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Graph-based local coherence modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Camille</forename><surname>Guinaudeau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Strube</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/P13-1010" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="93" to="103" />
		</imprint>
	</monogr>
	<note>Long Papers). Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Halliday</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruqaiya</forename><surname>Hasan</surname></persName>
		</author>
		<title level="m">Cohesion in English. Longman</title>
		<meeting><address><addrLine>Singapore</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1976" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A model of coherence based on distributed sentence representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/D14-1218" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP). Association for Computational Linguistics</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP). Association for Computational Linguistics<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2039" to="2048" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Automatically evaluating text coherence using discourse relations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziheng</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hwee</forename><forename type="middle">Tou</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min-Yen</forename><surname>Kan</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/P11-1100" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies. Association for Computational Linguistics</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies. Association for Computational Linguistics<address><addrLine>Portland, Oregon, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="997" to="1006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Rhetorical structure theory: Toward a functional theory of text organization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>William</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandra</forename><forename type="middle">A</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Thompson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Text</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="243" to="281" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The stanford corenlp natural language processing toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenny</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mcclosky</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/P14-5010" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations</title>
		<meeting>52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations<address><addrLine>Baltimore, Maryland</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="55" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Domain-independent shallow sentence ordering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thade</forename><surname>Nahnsen</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/N/N09/N09-3014" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics</title>
		<meeting>Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics<address><addrLine>Boulder, Colorado</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="78" to="83" />
		</imprint>
	</monogr>
	<note>Student Research Workshop and Doctoral Consortium. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/D14-1162" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP). Association for Computational Linguistics</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP). Association for Computational Linguistics<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Modeling organization in student essays</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isaac</forename><surname>Persing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Ng</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/D10-1023" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2010 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="229" to="239" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Entropy and graph based modelling of document coherence using discourse entities: An application to ir</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Casper</forename><surname>Petersen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christina</forename><surname>Lioma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><forename type="middle">Grue</forename><surname>Simonsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Birger</forename><surname>Larsen</surname></persName>
		</author>
		<idno type="doi">10.1145/2808194.2809458</idno>
		<ptr target="https://doi.org/10.1145/2808194.2809458" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 International Conference on The Theory of Information Retrieval</title>
		<meeting>the 2015 International Conference on The Theory of Information Retrieval<address><addrLine>New York, NY, USA, ICTIR &apos;15</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="191" to="200" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Lexical chaining for measuring discourse coherence quality in test-taker essays</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Swapna</forename><surname>Somasundaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jill</forename><surname>Burstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Chodorow</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/C14-1090" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers. Dublin City University and Association for Computational Linguistics</title>
		<meeting>COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers. Dublin City University and Association for Computational Linguistics<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="950" to="961" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Are cohesive features relevant for text readability evaluation?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amalia</forename><surname>Todirascu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Francois</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Delphine</forename><surname>Bernhard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nuria</forename><surname>Gala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anne-Laure</forename><surname>Ligozat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers. The COLING</title>
		<meeting>COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers. The COLING</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title/>
		<ptr target="http://aclweb.org/anthology/C16-1094" />
	</analytic>
	<monogr>
		<title level="j">Organizing Committee</title>
		<imprint>
			<biblScope unit="page" from="987" to="997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Representing discourse coherence: A corpus-based study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Gibson</surname></persName>
		</author>
		<idno type="doi">10.1162/0891201054223977</idno>
		<ptr target="https://doi.org/10.1162/0891201054223977" />
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="249" to="288" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
