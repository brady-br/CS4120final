<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2020-09-29T02:54+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Software Engagement with Sleeping CPUs</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Zhu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">North Carolina State University</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">National University of Defense Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">‡</forename><surname>Meng</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of Rochester</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhu</forename></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Wu</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Colorado School of Mines</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xipeng</forename><surname>Shen</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">North Carolina State University</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Shen</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of Rochester</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiying</forename><surname>Wang</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">National University of Defense Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Software Engagement with Sleeping CPUs</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Idle CPUs may enter power-saving hardware sleeps by, for instance, lowering the operating voltage and flushing the caches. However, wakeup delays that reach one hundred µSecs or more are disrupting the operations of fast devices like solid-state disks and tightly integrated accelerators. On the other hand, maximal power savings on modern multicores are only realized through continuous , simultaneous CPU sleeps. We argue that strong software engagement (at the OS and applications) is needed to maximize the power saving while maintaining the desired performance. Specifically, we present anticipatory CPU wakeups for latency-sensitive operations on fast devices. We also explore power-saving sleep shaping opportunities through non-work-conserving scheduling on smartphones and staged bursts on servers. 1 Motivation and Approach An idle CPU can enter hardware sleep states that power down various resources to conserve energy. The wakeup of a sleeping CPU incurs a delay due to the restoration of the hardware operating condition and state. For instance, an Intel E5-2620 v3 Haswell socket can save a few dozen Watts of power by sleeping at the ACPI C6 state (cycles halted; clocks shut off; L1 / L2 cache flushed; core voltage removed). On the other hand, its wakeup causes 106 µSecs of extra delay for a simple network ping-pong service. Emerging hardware and workload trends have highlighted the challenges of the CPU sleep management. From the performance perspective, wakeup delays of dozens or hundreds of µSecs could cause excessive disruptions. Commodity solid-state disks are already operating at 100 µSec-level latencies (particularly for reads). Emerging integrated accelerators like GPUs (exemplified by Intel IvyBridge and Haswell, AMD Fusion APUs, and NVIDIA Denver) allow fast CPU / accelerator interactions and facilitate efficient acceleration of fine-grained tasks. A slow CPU wakeup produces significant slowdown for these device operations. In a further example , latency-sensitive network services (e.g., a memory-cached hash table) inside a data center may suffer multi-fold slowdown if a wakeup from a CPU deep sleep is involved. From the power perspective, the benefit of CPU sleeping is highly influenced by the sleep pattern. First, it is desirable for a CPU to sleep continuously to minimize the energy costs during active / sleeping state transitions. Second, due to aggressive resource sharing, modern mul-ticores realize maximal power saving only when all CPU cores/threads sleep simultaneously. Unfortunately, continuous , simultaneous CPU sleeps are rare under the conventional work-conserving CPU scheduling when fine-grained units of work may activate one or a few CPUs in intermittent fashions. This paper argues for strong software engagement (at both OS and application levels) of CPU sleep management to maintain high performance when needed and maximize the energy saving when possible. Specifically in low-latency operating conditions, the CPU should start waking up early (before the work-triggering interrupt) such that the CPU is immediately ready for work when needed. Such anticipatory wakeups are best requested by the software layers with knowledge of or ability to model the time of future work resumption. The OS should aggregate anticipatory wakeup requests and maintain a CPU sleep plan with high efficiency and (if desirable) proper energy accounting. On the other hand, many system and application contexts manifest a high degree of slacks in their quality-of-service requirements. For example, due to the long operation time of the wide area network and other peripheral devices in smartphones, some tasks can be slowed substantially without compromising the user experience. Also, requests in a web server application may be delayed as long as they are all completed within a specified latency threshold. Such quality-of-service flexibility presents opportunities for shaping the CPU idleness patterns (through delaying, staging, and consolidating work) toward continuous, simultaneous CPU sleeps with high power saving. Much of prior attention on energy-efficient CPU management has targeted the processor frequency control [13, 22, 23]. Among the most seminal, Weiser et 1</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Motivation and Approach</head><p>An idle CPU can enter hardware sleep states that power down various resources to conserve energy. The wakeup of a sleeping CPU incurs a delay due to the restoration of the hardware operating condition and state. For instance, an Intel E5-2620 v3 Haswell socket can save a few dozen Watts of power by sleeping at the ACPI C6 state (cycles halted; clocks shut off; L1 / L2 cache flushed; core voltage removed). On the other hand, its wakeup causes 106 µSecs of extra delay for a simple network ping-pong service.</p><p>Emerging hardware and workload trends have highlighted the challenges of the CPU sleep management. From the performance perspective, wakeup delays of dozens or hundreds of µSecs could cause excessive disruptions. Commodity solid-state disks are already operating at 100 µSec-level latencies (particularly for reads). Emerging integrated accelerators like GPUs (exemplified by Intel IvyBridge and Haswell, AMD Fusion APUs, and NVIDIA Denver) allow fast CPU / accelerator interactions and facilitate efficient acceleration of fine-grained tasks. A slow CPU wakeup produces significant slowdown for these device operations. In a further example, latency-sensitive network services (e.g., a memorycached hash table) inside a data center may suffer multifold slowdown if a wakeup from a CPU deep sleep is involved.</p><p>From the power perspective, the benefit of CPU sleeping is highly influenced by the sleep pattern. First, it is desirable for a CPU to sleep continuously to minimize the energy costs during active / sleeping state transitions. Second, due to aggressive resource sharing, modern multicores realize maximal power saving only when all CPU cores/threads sleep simultaneously. Unfortunately, continuous, simultaneous CPU sleeps are rare under the conventional work-conserving CPU scheduling when finegrained units of work may activate one or a few CPUs in intermittent fashions.</p><p>This paper argues for strong software engagement (at both OS and application levels) of CPU sleep management to maintain high performance when needed and maximize the energy saving when possible. Specifically in low-latency operating conditions, the CPU should start waking up early (before the work-triggering interrupt) such that the CPU is immediately ready for work when needed. Such anticipatory wakeups are best requested by the software layers with knowledge of or ability to model the time of future work resumption. The OS should aggregate anticipatory wakeup requests and maintain a CPU sleep plan with high efficiency and (if desirable) proper energy accounting.</p><p>On the other hand, many system and application contexts manifest a high degree of slacks in their quality-ofservice requirements. For example, due to the long operation time of the wide area network and other peripheral devices in smartphones, some tasks can be slowed substantially without compromising the user experience. Also, requests in a web server application may be delayed as long as they are all completed within a specified latency threshold. Such quality-of-service flexibility presents opportunities for shaping the CPU idleness patterns (through delaying, staging, and consolidating work) toward continuous, simultaneous CPU sleeps with high power saving.</p><p>Much of prior attention on energy-efficient CPU management has targeted the processor frequency control <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b22">23]</ref>. Among the most seminal, Weiser et al. <ref type="bibr" target="#b22">[23]</ref> proposed fine-grained frequency adjustment and workload scheduling to conserve energy. Recent work by Le Sueur and Heiser <ref type="bibr" target="#b19">[20]</ref> experimentally demonstrated the large energy effects of CPU hardware sleeps, but without proposing an approach for systematic management. The network community has explored the use of "sleep" proxies to keep machines continuously shutdown <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b16">17]</ref>. These works target the ACPI S state management where a "sleeping" machine may take seconds to wakeup, which is very different from the much finergrained CPU hardware sleeps that we study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Latency-Sensitive Anticipatory Wakeup</head><p>In a latency-sensitive environment, the wakeup delay of a sleeping CPU can be a substantial performance concern. If the future work triggering event can be anticipated with a predictable elapsed time, the CPU should start waking up in advance so that it is immediately ready for work when needed. Errors of such prediction can be tolerated by earlier CPU wakeups at the cost of additional power consumption.</p><p>Anticipatory CPU wakeups are particularly beneficial for operations on fast devices. For example, the I/O completion time on a Flash-based solid state disk can be modeled on the operation type (read / write) and I/O size. The operating system device layer can maintain such a model and initiate an anticipatory CPU wakeup for each synchronous I/O operation so that the waiting application receives a prompt response. This support can be realized with full application transparency.</p><p>On the other hand, it is generally impossible to predict the run time of computational kernels on Turingcomplete accelerators like GPUs. Fortunately, many GPU applications iterate over similar computational kernels in their execution (e.g., in an iterative linear system solver or an iterative machine learning refinement like K-means clustering). Such an iterative pattern enables an application to make history-based runtime prediction and request for anticipatory CPU wakeups accordingly.</p><p>On a network server, the CPU wakeup delay also prolongs the response time to client requests. However, it is difficult for the server to anticipate future client requests, especially if the request arrival follows a memoryless Poisson process (when requests come from a large number of independent clients). In such cases, anticipatory wakeups may only be possible if they are requested in advance by remote clients before they issues requests for real work.</p><p>On a multicore machine with a large number of CPUs, the anticipatory wakeup should only activate the CPU(s) necessary for latency-sensitive operation to conserve the power consumption. On the other hand, it must ensure the readiness for all tasks on the notification path of the wakeup event. This includes the blocking user process (e.g., the one blocked on the read system call to the SSD) as well as the device interrupt handler. Waking up the interrupt handling CPU is straightforward if the interrupts are handled by a fixed CPU. It requires more coordination if the interrupt handling is load-balanced across a number of CPUs.</p><p>It is easy to foresee a system environment where multiple fast devices and network services are serving latencysensitive tasks. Therefore multiple simultaneous anticipatory wakeups may be requested in the system. The operating system should aggregate such requests and maintain a CPU sleep plan with high efficiency. Such multiuse environments also raise the question on fine-grained energy resource accounting and attribution between concurrent tasks <ref type="bibr" target="#b18">[19]</ref>. In particular, the energy use of a resource principal should include that of its anticipatory CPU wakeups even if the system idles for much of the wakeup durations.</p><p>In terms of resolving the power / latency conflict, our anticipatory CPU wakeup is related to the Linux Wakelocks mechanism (developed primarily for Android). However, the Wakelocks mechanism is not anticipatory and it currently manages the system suspension but not CPU sleep states. Our idea is also reminiscent of the anticipatory I/O work <ref type="bibr" target="#b10">[11]</ref> that targets a very different problem context-anticipating future high-locality I/O accesses to reduce the seek time on mechanical disks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SSD Case Study</head><p>We made a preliminary implementation of the proposed anticipatory CPU wakeup mechanism in the Linux 3.12.13 kernel. A wakeup request on a CPU is made with two parameters-the starting time and duration of the wakeup. The initial wakeup is implemented using a kernel high-resolution timer. In the wakeup duration, the CPU idle management is prevented from entering any of the hardware sleep states. The CPU may return to the normal sleep if the anticipated event does not occur by the end of the wakeup duration. To enable fast responses of SSD I/O accesses, we augment the device layer to initiate an anticipatory CPU wakeup for each synchronous I/O operation.</p><p>We perform an experimental study on a dual-socket (6-core, 12-hyperthread per socket) Intel E5-2620 v3 Haswell machine with a Samsung 850 PRO SSD. A device-level 4 KB read to the SSD takes about 100 µSecs. When a 4 KB read is dispatched to the device, the OS lets the CPU to enter the C1-HSW sleep state. Given approximately 20 µSecs of sleep exit latency, we make an anticipatory request to wake up the CPU in 80 µSecs for the duration of 20 µSecs. system doubles when there is 1 mSec or more inter-I/O idle time due to the CPU wakeup delay. While disabling all CPU sleeps can achieve the optimal I/O latency, it would increase the CPU+DRAM power by 2-5×. In comparison, our anticipatory CPU wakeup mechanism incurs no visible power cost while it significantly brings down the I/O latency slowdown (from 101% to 37% at 1 mSec inter-I/O idle time).</p><p>The predictability of the SSD I/O time is enabled by its strong linear correlation with the I/O size. On our Samsung 850 PRO SSD, the Pearson's correlation coefficient 1 between read latency and I/O size is very close to 1.00. The correlation coefficient between write latency and I/O size is also quite high at 0.91. However, if the OS dispatches multiple I/O operations to the SSD (which is beneficial to exploit SSD I/O parallelism <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b17">18]</ref>), the I/O time prediction would be more difficult.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>GPU Case Study</head><p>We also test the idea of anticipatory CPU wakeup on GPU program executions. A GPU kernel is usually launched by a CPU control thread. CPU sleeping can delay the control thread from finding out the completion of a GPU kernel computation.</p><p>The problem is particularly pronounced on CPU-GPU integrated processors, where the tight integration of CPU and GPU allows the use of GPU to accelerate short requests-the lengths of which may be comparable to a sleeping CPU's wakeup delay. For instance, the GPU kernel lengths in most benchmarks in AMD SDK v2.9 <ref type="bibr" target="#b0">[1]</ref> range from 100 µSecs to 1000 µSecs on an AMD A10-6800K processor. A 100 µSecs wakeup delay of CPU can degrade the responsiveness of the request processing substantially. Meanwhile, because such requests are often repeatedly issued in the programs, they can together weigh substantially in the overall execution time of the program. Wakeup delays hence can also significantly slow down an entire program. <ref type="bibr" target="#b0">1</ref> The covariance of two variables divided by the product of their standard deviations. Nearing 1.0 indicates a strong linear correlation. A main concern for utilizing the anticipatory CPU wakeup in GPU applications is the challenge of predicting a GPU kernel's runtime. Fortunately, many GPU applications iterate over similar computational kernels in their execution, which makes history-based runtime prediction promising. We experiment with two data clustering programs, K-means and StreamCluster <ref type="bibr" target="#b2">[3]</ref>. In both, clustering happens through an iterative process. In each iteration, a GPU kernel is invoked to compute the distances between all data points and all potential cluster centers; after that, the potential cluster centers are updated based on the distances, the kernel is invoked again, and the process continues until centers stop changing. <ref type="figure" target="#fig_1">Figure 2</ref> reports the processing time for the sequence of GPU kernel requests invoked in the two benchmarks. On K-means, the kernel lengths are around 540 µSecs with less than ±25 µSecs fluctuations (except for the first invocation). On StreamCluster, the lengths of most kernel invocations are around 500 µSecs with about ±50 µSecs except for a few outliers. The stability suggests good predictability of the kernel running time. Our experiments show that for the two benchmarks, the kernel length can be predicted with about 87% accuracy. Anticipatory wakeup helps K-means and StreamCluster speed up about 10% over the default interrupt-based method. Meanwhile, it helps them save about 56% power, compared to busy-waiting, in which the CPU control thread keeps polling for the status of GPU.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Energy-Conserving Sleep Shaping</head><p>Other than causing latency concerns, CPU sleeps on modern multicores produce disproportionate power usage (due to hardware resource sharing on a multicore socket) and thus present new opportunities for saving energy. <ref type="figure" target="#fig_2">Figure 3(A)</ref> shows that on a dual-socket (6-core, , we removed its battery, connected it with an external power source, and intercepted the power line to measure the phone power using an Agilent U1272A digital multimeter. The phone display was dimmed to the minimum brightness during our power measurement. shows the power of an Exynos 5422-based Samsung Galaxy S5 smartphone. The Exynos system-onchip adopts the ARM big.LITTLE architecture <ref type="bibr" target="#b8">[9]</ref> with two heterogenous clusters of four cores each-the small cluster contains four Cortex-A7 cores that run up to 1.3 GHz, and the big cluster contains four Cortex-A15 cores that run up to 1.9 GHz. We observe a disproportionate power jump when activating the big cluster (starting at the fifth core).</p><p>Through two case examinations, we argue that flexible quality-of-service requirements in a broad range of system / application scenarios allow for the shaping of CPU sleep patterns toward energy conservation. Our work is related to earlier efforts of shaping a device's sleep / idle pattern for energy saving (e.g., page allocation that consolidates the memory uses on specific DRAM chips <ref type="bibr" target="#b11">[12]</ref> and prefetching / caching to enable bursty disk accesses <ref type="bibr" target="#b13">[14]</ref>), but we face new challenges due to different problem contexts.</p><p>Slack Enabled Quiescence Today's smartphones are equipped with powerful multicore processors. However, our experiments found that typical mobile applications do not exhibit sufficient parallelism to fully utilize them. This provides opportunities to apply aggressive energy saving techniques. On the other hand, high-quality user interactions discourage any resource-saving mechanisms that would negatively affect the user experience. We argue that strong software management of CPU sleep states can achieve energy savings on smartphones without compromising the quality-of-service.</p><p>Putting CPUs to sleep with no performance penalty is possible if all CPU tasks over a time period are not on the critical path leading to the user response. Such slack of non-critical CPU tasks are most common during synchronous network or I/O operations that block the user response. The slack allows a period of quiescencesimultaneous sleeps of all CPUs or CPUs on the highpower cluster of a heterogeneous platform. We note that not every I/O operation presents opportunities for CPU sleeps without performance penalty. In particular, during a background I/O operation (e.g., GPS beacon processing), concurrent CPU tasks may still be on the user response critical path and therefore present no slack for CPU quiescence. Delaying or slowing them may lead to longer user responses. We discuss how to identify I/O operations on the critical user response path. A user interaction is generally triggered by a touch event and ends with a screen update. The OS may track events that signify causal dependencies <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b24">25]</ref> between execution segments in a user interaction. They include kernel events such as process / thread forking and inter-process signals, pipes, and sockets, and application activities like Android Binder messages and looper thread work queue operations. The online dependency information can tell whether a synchronous I/O operation is causally dependent on the user input event. However, analysis of the entire critical path generally requires the offline construction of the full causal dependency graph leading to the final user response. We can leverage the unified UI framework of the modern mobile operating systems, in which interaction with a UI component generally triggers a deterministic series of operations that follow the same causal dependencies. Thus we can memorize the offline behavior characterization for each UI component to help identify the performance-critical execution path online.</p><p>We assess the feasibility of this idea on the Exynos 5422 based Samsung Galaxy S5 smartphone. Its CPU power characteristics were presented in <ref type="figure" target="#fig_2">Figure 3</ref>. We use Bbench <ref type="bibr" target="#b9">[10]</ref>, an automatic browser test script that repeatedly loads locally cached websites. We emulate the wide area network delay by injecting a 100 mSecs wait when the browser loads a web page. During this period, our system delays all the tasks on the four CPUs of the big cluster and lets them enter deep sleeps. Our experiments show that such CPU quiescence produces no observable performance impact while it reduces the total energy consumption by 6%.</p><p>Such slack enabled quiescence can be more effective in energy saving if there are substantial co-run background tasks. For example, the user may browse the web while the phone is performing software updates. The system can delay non-critical background tasks (software updates) while synchronous I/O operations (e.g., fetching web pages) are blocking the user response. Their executions are piggybacked while the high-power CPU cluster is activated for critical operations leading to the user response. Such co-execution does not impact performance as long as the critical tasks do not fully utilize the multicore CPUs.</p><p>Staged Bursts The response time to client requests is an important quality-of-service metric for web applications. In many situations, rather than completing every request as soon as possible, a request may be delayed as long as it is responded within a certain time threshold (e.g., the latency of pleasant human perception). At the same time, we recognize the potential of high parallelism in server applications-many independent requests, while running simultaneously, produce high energy efficiency on multicores. These motivate a nonwork-conserving workload management approach, we call staged bursts, where the server operation alternates between two phases-a staging phase that buffers requests without running them, and a burst phase that runs the buffered requests at a high degree of parallelism.</p><p>We use a simple experiment to demonstrate the potential effectiveness of server staged bursts. We set the response time threshold at 0.5 second. On our 24-CPU Haswell machine running Linux 3.12.13, we set up the Apache Lucene / Solr <ref type="bibr" target="#b1">[2]</ref> search engine as an Apache Tomcat Servlet container. We constructed a search workload of 1,414,444 indexed documents from the Wikipedia data dumps <ref type="bibr" target="#b3">[4]</ref>. Queries in our test workload are generated by randomly selecting and sequencing article titles in the Wikipedia data dump.</p><p>When serving the workload at 100 requests/sec, the machine's processor package and DRAM consumes about 68 Watts of power under the conventional system setup while the 999th permille response time is 284 mSecs. We then add a staging proxy (running on another machine) which buffers requests and releases all buffered requests once every 250 mSecs. Under such staged bursts, the processor package and DRAM consumes only 53 Watts of power (22% reduction) while the 999th permille response time is still below 500 mSecs.</p><p>A robust support of staged burst processing faces important challenges that require strong engagement from all system layers. Specifically, the maintenance of tail latency service objectives <ref type="bibr" target="#b7">[8]</ref> requires application-level performance feedbacks <ref type="bibr" target="#b12">[13]</ref> as well as kernel-level resource control. For instance, resource containers <ref type="bibr" target="#b5">[6]</ref>style mechanisms can encapsulate activities belonging to individual client requests, and dynamically trigger burst processing when some staged requests are in danger of missing their latency deadlines.</p><p>During the burst phase, energy efficiency favors simultaneous utilization of all CPUs. However, a conventional OS sometimes hesitates in migrating tasks for CPU load balancing, due to the concern of losing the cache locality (and DRAM locality in the case of NUMA). In the above experiment, to achieve more simultaneous burst processing, we removed Linux's restriction that tasks are not migrated to idle CPUs with short idle periods in the recent past. Balancing the energy efficiency and cache locality goals may require the modeling of power <ref type="bibr" target="#b18">[19]</ref> and locality effects <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b20">21]</ref> from collectible processor hardware event counters and statistics.</p><p>To enforce simultaneous CPU sleeps, it is important to idle all CPUs on the main socket during the staging phase. Therefore the request receipt and buffering must be done elsewhere which still incurs an energy cost. To minimize such costs, one idea is to run the staging proxies for a large pool of servers on a single staging machine. Another is to use a companion low-power processor (such as the KnightShift architecture <ref type="bibr" target="#b23">[24]</ref>) to stage and buffer requests. Our experience suggests that the latter idea can be accomplished by today's smartphone processors (using only one Watt of power while adding a few mSecs of additional latency).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>This paper recognizes the significant power and performance implications of hardware sleeps on modern multicores. We thus argue for strong software engagement to realize the performance and energy saving potentials. Specifically, in latency-sensitive environments, anticipatory wakeups can maintain high performance despite the significant sleep wakeup delays. On the other hand, if the system quality-of-service requirements allow certain flexibility of delayed work, workload staging and parallel burst processing can enable high energy efficiency on multicores.</p><p>We conclude with a series of open questions. Anticipatory CPU wakeups require predicting the time of future work triggering events that can be challenging, particularly for network servers responding to external client requests. Identifying quality-of-service slacks and opportunities for simultaneous CPU sleeps requires online tracking of execution dependencies and identification of performance-critical task segments. Finally, work consolidation for energy-efficient parallel multicores execution must balance the need for cache affinity and reconcile with the limitation of application / system scalability.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 illustratesFigure 1 :</head><label>11</label><figDesc>Figure 1: Performance (99th percentile I/O latency) and power of an SSD-based workload that repeatedly reads 4 KB of data at a random file location with varying inter-I/O idle time.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The processing time for the sequence of GPU kernel requests invoked by K-means and StreamCluster.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Disproportionate multicore power on the number of active CPUs. The CPU package and DRAM power on the Haswell server (A) was reported by the Intel processor's power MSRs. For the Exynos-based smartphone (B), we removed its battery, connected it with an external power source, and intercepted the power line to measure the phone power using an Agilent U1272A digital multimeter. The phone display was dimmed to the minimum brightness during our power measurement.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>12-hyperthread per socket) Intel E5-2620 v3 Haswell machine, activating the first CPU consumes 37 Watts of power beyond idling while activating each additional CPU consumes 8 Watts or less. In another example, Fig- ure 3(B)</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amd</forename><surname>App Sdk</surname></persName>
		</author>
		<ptr target="9.developer.amd.com/tools-and-sdks/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Apache Solr search server. lucene.apache. org/solr</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Rodinia benchmark suite</title>
		<ptr target="www.cs.virginia.edu/˜skadron/wiki/rodinia/index.php/Main_Page" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Wikipedia data dumps. dumps.wikimedia. org/enwiki</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">SleepServer: A software-only approach for reducing the energy consumption of PCs within enterprise environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savage</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Gupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">USENIX Annual Technical Conf</title>
		<meeting><address><addrLine>San Deigo, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Resource containers: A new facility for resource management in server systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Banga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Druschel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mogul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Third USENIX Symp. on Operating Systems Design and Implementation (OSDI)</title>
		<meeting><address><addrLine>New Orleans, LA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999-02" />
			<biblScope unit="page" from="45" to="58" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A case for NUMA-aware contention management on multicore systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Blagodurov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhuravlev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dashti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fedorova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">USENIX Annual Technical Conf</title>
		<meeting><address><addrLine>Portland, OR</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">The tail at scale. Communications of the ACM</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Barroso</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013-02" />
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page" from="74" to="80" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Big. little processing with arm cortex-a15 &amp; cortex-a7</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Greenhalgh</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
	<note>ARM White paper</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Full-System Analysis and Characterization of Interactive Smartphone Applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gutierrez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Dreslinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wenisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mudge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Saidi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Emmons</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Paver</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2011 IEEE Int&apos;l Symp. on Workload Characterization (IISWC)</title>
		<meeting><address><addrLine>Austin, TX, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="81" to="90" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Anticipatory scheduling: A disk scheduling framework to overcome deceptive idleness in synchronous I/O</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Iyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Druschel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">18th ACM Symp. on Operating Systems Principles (SOSP)</title>
		<meeting><address><addrLine>Banff, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001-10" />
			<biblScope unit="page" from="117" to="130" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Power aware page allocation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">R</forename><surname>Lebeck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ellis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">9th Int&apos;l Conf. on Architectural Support for Programming Languages and Operating Systems (ASPLOS)</title>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000-11" />
			<biblScope unit="page" from="105" to="116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Towards energy proportionality for large-scale latency-critical workloads</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Govindaraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Barroso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kozyrakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">41st Int&apos;l Symp. on Computer Architecture (ISCA)</title>
		<meeting><address><addrLine>Minneapolis, MN</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-06" />
			<biblScope unit="page" from="301" to="312" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Energy efficient prefetching and caching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">E</forename><surname>Papathanasiou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">L</forename><surname>Scott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">USENIX Annual Technical Conf</title>
		<meeting><address><addrLine>Boston, MA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">FIOS: A fair, efficient Flash I/O scheduler</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">10th USENIX Conf. on File and Storage Technologies (FAST)</title>
		<meeting><address><addrLine>San Jose, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">AppInsight: Mobile app performance monitoring in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ravindranath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Padhye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mahajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Obermiller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shayandeh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">10th USENIX Symp. on Operating Systems Design and Implementation (OSDI)</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="107" to="120" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Sleepless in Seattle no longer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Reich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Goraczko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Padhye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">USENIX Annual Technical Conf</title>
		<meeting><address><addrLine>Boston, MA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">FlashFQ: A fair queueing I/O scheduler for Flash-based SSDs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Park</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">USENIX Annual Technical Conf</title>
		<meeting><address><addrLine>San Jose, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Power containers: An OS facility for fine-grained power and energy management on multicore servers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shriraman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Dwarkadas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">18th Int&apos;l Conf. on Architectural Support for Programming Languages and Operating Systems (ASPLOS)</title>
		<meeting><address><addrLine>Houston, TX</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Slow down or sleep, that is the question</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">L</forename><surname>Sueur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Heiser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">USENIX Annual Technical Conf</title>
		<meeting><address><addrLine>Portland, OR</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Thread clustering: Sharing-aware scheduling on SMP-CMP-SMT multiprocessors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Azimi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stumm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Second EuroSys Conf</title>
		<meeting><address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007-03" />
			<biblScope unit="page" from="47" to="58" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">The TURBO diaries: Application-controlled frequency scaling explained</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-T</forename><surname>Wamhoff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Diestelhorst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fetzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Marlier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Felber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dice</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">USENIX Annual Technical Conf</title>
		<meeting><address><addrLine>Philadelphia, PA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Scheduling for reduced CPU energy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Weiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Welch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Demers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shenker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">First USENIX Symp. on Operating Systems Design and Implementation (OSDI)</title>
		<meeting><address><addrLine>Monterey, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994-11" />
			<biblScope unit="page" from="13" to="23" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">KnightShift: Scaling the energy proportionality wall through serverlevel heterogeneity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Annavaram</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">45th Int&apos;l Symp. on Microarchitecture (MICRO)</title>
		<imprint>
			<publisher>Vancouver</publisher>
			<date type="published" when="2012-12" />
			<biblScope unit="page" from="119" to="130" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Panappticon: event-based tracing to measure mobile application and platform performance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>Bild</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">P</forename><surname>Dick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><forename type="middle">M</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dinda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Hardware/Software Codesign and System Synthesis</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1" to="10" />
		</imprint>
		<respStmt>
			<orgName>CODES+ ISSS</orgName>
		</respStmt>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
