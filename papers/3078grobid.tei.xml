<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2020-09-29T03:00+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Active Control of Memory for Java Virtual Machines and Applications Active Control of Memory for Java Virtual Machines and Applications</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>June 18-20. 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Norman</forename><surname>Bobroff</surname></persName>
							<email>bobroff@us.ibm.com</email>
							<affiliation key="aff0">
								<orgName type="laboratory">IBM T.J. Watson Research Center Yorktown Heights</orgName>
								<orgName type="institution">IBM T. J. Watson Research Center</orgName>
								<address>
									<postCode>10598</postCode>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Westerink</surname></persName>
							<email>peterw@us.ibm.com</email>
							<affiliation key="aff0">
								<orgName type="laboratory">IBM T.J. Watson Research Center Yorktown Heights</orgName>
								<orgName type="institution">IBM T. J. Watson Research Center</orgName>
								<address>
									<postCode>10598</postCode>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liana</forename><surname>Fong</surname></persName>
							<email>llfong@us.ibm.com</email>
							<affiliation key="aff0">
								<orgName type="laboratory">IBM T.J. Watson Research Center Yorktown Heights</orgName>
								<orgName type="institution">IBM T. J. Watson Research Center</orgName>
								<address>
									<postCode>10598</postCode>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Norman</forename><surname>Bobroff</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">IBM T.J. Watson Research Center Yorktown Heights</orgName>
								<orgName type="institution">IBM T. J. Watson Research Center</orgName>
								<address>
									<postCode>10598</postCode>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Westerink</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">IBM T.J. Watson Research Center Yorktown Heights</orgName>
								<orgName type="institution">IBM T. J. Watson Research Center</orgName>
								<address>
									<postCode>10598</postCode>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liana</forename><surname>Fong</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">IBM T.J. Watson Research Center Yorktown Heights</orgName>
								<orgName type="institution">IBM T. J. Watson Research Center</orgName>
								<address>
									<postCode>10598</postCode>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Active Control of Memory for Java Virtual Machines and Applications Active Control of Memory for Java Virtual Machines and Applications</title>
					</analytic>
					<monogr>
						<title level="m">• Philadelphia, PA USENIX Association 11th International Conference on Autonomic Computing 97</title>
						<imprint>
							<date type="published">June 18-20. 2014</date>
						</imprint>
					</monogr>
					<note>This paper is included in the Open access to the Proceedings of the 11th International Conference on Autonomic Computing (ICAC &apos;14) is sponsored by USENIX.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>A controller is implemented to manage memory as an elastic resource similar to computing cycles for Java applications. The controller actively arbitrates constrained memory between collocated JVMs in response to demand. A key aspect of the work is that JVM metrics are used as proxies for application KPIs so that application performance instrumentation and modeling are not required. A metric corresponding to the allocation rate of memory is derived from the JVM metrics and established as the measure of application performance and is used as the effective feedback mechanism to the controller. The controller is based on a fair share policy in which memory is distributed to equalize the marginal performance value to all JVMs. The design is tested for effectiveness and stability using the suite of SPECjvm2008 and SPECjbb2005 benchmarks.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Matching real memory and CPU resources to the time varying memory-processor demand footprint of applications is an important element in systems performance management. Active sharing of processors between applications within and across virtual machines (VMs) in response to demand is a mature feature of the operating systems and hypervisors. Active sharing of memory (ASM) is the analogous capability where physical memory pages move seamlessly between applications and across virtual machines to satisfy demand. This improves system wide memory utilization, or alternatively increases the application density or workload intensity hosted on a compute system. ASM is sometimes referred to as logical memory overcommit as it reduces the total amount of memory necessary in a system with time varying workloads from the sum of the maximum demand of each workload to the maximum of the sum of the workloads. ASM is distinguished from paging which requires saving and restoring state in order to reuse pages from processes or VMs. Exploiting ASM requires the ability to identify unused memory in applications and operating systems and (re)map those pages to collocated applications, or move them to another VM on a common hypervisor. This function is widely available at the VMhypervisor layer in the commercial space. But support at the application layer has been lagging as traditional application design and coding practice has not emphasized the need to dynamically return memory from the process space to the OS.</p><p>Widespread use of the Java Virtual Machine (JVM) as a server application platform creates an opportunity to extend the scope of ASM into the application layer. Emerging JVM technologies such as heap ballooning <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3]</ref> and dynamic heap sizing <ref type="bibr" target="#b3">[4]</ref> provide mechanisms to release committed memory from the virtual heap space. Given these advances it is an appropriate time to visit the architecture and control functions required for an automatic ASM solution that focuses on Java applications. This paper describes two novel aspects of JVM memory management: JVM metrics are shown to be suitable proxies for application based key performance indicators (KPI); and JVM heap memory is actively sized in response to resource changes and workload variability by equalizing the value of memory as indicated by the JVM metrics. Memory intensive benchmarks from the SPECjvm2008 <ref type="bibr" target="#b6">[7]</ref> suite and SPECjbb2005 <ref type="bibr" target="#b5">[6]</ref> are used to correlatefJVM metrics and application KPIs, and to evaluate the control system. <ref type="figure" target="#fig_0">Figure 1</ref> shows the platform used to investigate active memory sharing (AMS) in a virtual environment. From a logical perspective, the figure is a tree with application JVMs at the top, and the hypervisor memory pool of a physical machine (PM) at the root. One or more collocated JVMs is hosted by an operating system (OS). Each OS apportions its memory pool to processes (JVMs and other applications), free pools, and system cache. In turn, the operating systems share the common physical platform memory in the hypervisor pool. Memory flows slowly down the tree to the OS and hypervisor pools on the non-critical path, while the flow of memory up the tree is on the critical path. This paper focuses on the upper layer, fairly apportioning memory between collocated JVM based applications in response to workload changes, memory demand, and changes in OS memory.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background and Related Work</head><p>Commercial methods are becoming available to release unused pages backing the JVM heap memory: VMWare's EM4J <ref type="bibr" target="#b7">[8]</ref> applies a balloon mechanism that plugs into the JVM and is leveraged in the memory control work of Ginko <ref type="bibr" target="#b1">[2]</ref>. Direct heap resizing is available in the IBM J9 JVM since version 7.0 <ref type="bibr" target="#b3">[4]</ref>. Section 3.2 describes in detail how we leverage this JVM control knob, MaxHeapSize to actively control heap memory.</p><p>Recent work has studied active JVM memory sizing. Ginkgo <ref type="bibr" target="#b1">[2]</ref> implements an application driven memory overcommitment system. Salomie <ref type="bibr" target="#b2">[3]</ref> designs an application level ballooning controller in Xen-based environment. CRAMM <ref type="bibr" target="#b8">[9]</ref> enables dynamically choosing of JVM heap sizes to meet workload demand, while avoiding latency in paging. QoE-JVM <ref type="bibr" target="#b4">[5]</ref> uses an economic model for active heap sizing in the Jikes research JVM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Approach</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">JVM metrics as proxies for application performance</head><p>There are several reasons to use JVM metrics as proxies for application performance as developed in Section 4. Most Java processes and applications do not maintain internal measures of their rate of progress. When available the interpretation of the KPI's often requires domain spe- End-to-end application performance depends components other than the JVM. For example, the database tier may be slowed because of insufficient OS system buffers. Note that the effect of a slow database on a Java application tier is manifest in JVM metrics such as rate of object allocation since the application can't make progress. Here, the local controller gives the JVM less memory than if the JVM tier is running at full load. This released memory makes its way to the database server via the flow of <ref type="figure" target="#fig_0">Figure 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">JVM direct page releasing mechanism</head><p>The JVM memory control knob leveraged in this work is the MaxHeapSize parameter of IBM's J9 JVM. At startup J9 reserves a contiguous region of virtual process space for its heap sized by the command line argument -Xmx which is exposed through JMX as the immutable MaxHeapSizeLimit . The J9 JVM maintains a second, soft, heap maximum setting called the MaxHeapSize whose operation is described in Sciampacone <ref type="bibr" target="#b3">[4]</ref>). Basically, MaxHeapSize can be set via JMX at any time during JVM execution to a value less than MaxHeapSizeLimit. When actual heap used drops below MaxHeapSize the JVM attempts to resize the heap using MaxHeapSize as the new limit.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">JVM Metrics and Application Performance</head><p>This section analyzes the correlation between JVM metrics and workload intrinsic performance (e.g., business operations per second-bops) for memory intensive benchmarks culled from SPECjvm2008 and SPECjbb2005. The goal is to utilize the JVM metrics as proxies for application KPI's to correctly size or arbitrate JVM memory.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Metrics collected from the JVM</head><p>Several JVM metrics are exposed through the JMX API, providing a measure of how the application benefits from memory.</p><p>• Mem-freed -Cumulative number of bytes collected by the GC since a JVM startup.</p><p>• Heap-inuse -Current amount of the heap memory containing objects with live references.  <ref type="table">Table 1</ref>: Max memory and allocation rate in benchmarks</p><p>• Heap-committed (hpCom) -Physical memory mapped to the virtual heap.</p><p>• GC CPU -The fraction of the system CPU cycles spent in GC. A decrease in GC CPU often provides an indication of whether adding memory is benefiting the application.</p><p>• Collection rate (coll-rate) -The number of GCs reported by the JVM over the sampling interval. The algorithm that determines when GC occurs is internal to the JVM.</p><p>• Allocation rate (alloc-rate) -This measure is is derived from the inuse-heap and mem-freed metrics. It is the rate of memory allocated during an interval and is computed in the sample interval [t 1 ,t 2 ] using the allocated bytes; alloc-rate = [ heap-inuse(t 2 ) -heap-inuse(t 1 ) + memfreed(t 2 ) -mem-freed(t 1 ) ] / [( t 2 − t 1 ]</p><p>Allocation rate depends jointly on application demand, and the ability to satisfy the demand. Furthermore, it is a complementary measure to the GC CPU and GC collection rate metrics. If the JVM heap allocator is slowed down because of low memory, that latency translates at the application code to time spent in the Java 'new' memory allocation operator.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Memory intensive workloads</head><p>Two benchmark groups are used to establish the correlation of the JMX metrics and workload performance. SPECjvm2008 contains over 20 individual benchmarks that cover a wide range of applications. Of these, the 10 which use more than 128MB of committed heap are considered memory intensive. The excluded set in this group use less than 50MB opt committed heap. SPECjbb2005 is representative of a traditional transactional workload.</p><p>The benchmarks selected are summarized in <ref type="table">Table 1</ref>. They cover a range of committed heap size from 128MB to 5GB, and allocation rates from 10MB/s to over 1GB/s. All benchmarks are CPU intensive and multithreaded.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Results</head><p>The correlation between the SPECjvm2008 benchmark KPIs and the JVM metrics is explored as a function of the MaxHeapSize (MB) parameter as the JVM control knob. <ref type="figure">Figures 2, 3</ref>, 4, and 5, are representative data sets the workloads. In each figure, the SPECjvm2008 performance number (bops) recorded during the runs is shown in (a). The corresponding JVM metric averages are displayed in subplots: (b) -GC CPU (%); (c) -collectionrate (ct/s); (d) -allocation rate (MB/s); and (e) -committed physical memory (MB). These data also indicate the open loop response the MaxHeapSize input control.</p><p>The derby database benchmark of <ref type="figure">Figure 2</ref>(a) typifies workloads exhibiting the threshold memory pattern. Here, most of the gain in application performance occurs within a critical heap size, after which the value of adding memory is low.</p><p>Derby also illustrates an interesting behavior with respect to committed memory within the threshold pattern. The region at the right hand side of <ref type="figure">Figure 2</ref>(e) shows that as the heap maximum is increased beyond the critical region, the JVM continues to commit real memory and grow the heap well into the low benefit region. Doubling the memory by incrementing the MaxHeapSize control value 1GB provides less than 2% performance improvement. This memory greedy pattern is also observed in the scientific benchmarks grouped together in <ref type="table">Table 1</ref>. For example, in the large FFT benchmark of <ref type="figure">Figure 3</ref>, the JVM commits about 1GB of memory beyond the point of improving performance. Systems executing this workload pattern benefit from limiting MaxHeapSize to avoid consuming physical memory.</p><p>The xml.validation benchmark <ref type="figure" target="#fig_2">(Figure 4(a)</ref>) also typifies the threshold pattern, but is not memory greedy. <ref type="figure" target="#fig_2">Fig- ure 4</ref> shows that the JVM only committed 150MB.</p><p>In contrast, the compiler benchmark of <ref type="figure">Figure 5</ref> benefits proportionally to the maximum heap memory control parameter. The behavior is monotonic, but there is  <ref type="figure">Figure 3</ref>. The lower correlation does not imply that the JVM metrics are not suited as input data to the active memory control system. In the case of the scimark.fft.large benchmark, the data of <ref type="figure">Figure 3</ref> are flat and so the jitter contributes significantly to the correlation calculation.</p><p>These experiments suggest that decisions about the benefit to the application of additional memory be made on the basis of the observed change in JVM metrics as memory is added to the JVM, rather than on the metric values themselves. Consider the threshold pattern of <ref type="figure">Figure 2</ref>. Adding memory clearly benefits the application, as indicated by the concurrent improvement in allocation rate.  <ref type="figure">Figure 6</ref> suggests the allocation rate is the single most consistent indicator of workload performance. The only benchmark where its correlation is significantly depressed relative to the other metrics is for the sci.lu.lg benchmark. Closed loop studies in Section 5 further validate the choice of allocation rate as the best single proxy for application performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Active JVM Memory Control</head><p>The objective of the memory controller is to leverage the JVM performance metrics of the prior section (esp. allocation-rate) to fair share the available memory between collocated JVMs. The fair sharing condition defines the distribution of memory between JVMs at a given workload so that: equal changes in the MaxHeapSize of each JVM result in equal changes in the relative performance of each JVM. The relative performance slope (S) for each JVM (j) is defined as the slope of the curve of the application performance (P j ) against MaxHeapSize, normalized by the performance value:</p><formula xml:id="formula_0">S j = ΔP j ΔMaxHeapSize j × 1 P j .</formula><p>The controller attempts to actively set MaxHeapSize j such that S j is the same for all j.</p><p>JVM metrics are used to measure the application performance P j . Section 4 identified allocation rate as a strong candidate for an application performance proxy. The open loop and offline data are now used to evaluate the JVM metrics in our slope equalizing algorithm. target value of the MaxHeapSize control parameter computed by the algorithm for each application JVM. Each data point represents the MaxHeapSizes that equalize the S j for a given total memory. The total memory varies from 200MB on the left to 800MB on the right. The solid line labeled SPEC KPI is the reference curve showing the ideal apportionment using the application (i.e.SPECjvm2008) KPIs. The three other lines correspond to the GC-CPU, collection rate, and allocation rate metrics. The data show that the allocation-rate metric produces the closest agreement with the SPEC KPIs. This result supports the correlation analysis of <ref type="figure">Figure 6</ref>. Similar results are achieved using other workloads of Table 1. The JVM metrics are fed into the control module on the left which has three logical components: the slope evaluator; the Compute Next MaxheapSize module that estimates the next MaxHeapSize value based on the current state; and the dither function. The data collector and controllers for collocated JVMs run in a single lightweight JVM process use less than 0.1% CPU and 20MB of memory.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Controller architecture</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Evaluating relative performance</head><p>A key function of the controller is to measure the slope of the allocation rate against the MaxHeapSize parameter at the current workload. To accomplish this, the controller modulates the MaxHeapSize parameter about its current target value. In this Dithering <ref type="bibr" target="#b9">[10]</ref> technique, the MaxHeapSize is varied faster than the system response through a range about the target MaxHeapSize. The JVM metrics are sampled at limit points of this dithering range. Expanding the dither range too far results in oscillations in JVM performance, while reducing it yields a slower control speed. Empirically, a reasonable tradeoff is achieved with the lower point at 80% of the current target MaxHeapSize, and the upper point at 120%. <ref type="figure" target="#fig_6">Figure 9</ref> illustrates operation of the collection of data using dithering when running the derby benchmark as memory is removed from the system. Each subfigure is a snapshot showing the allocation rates measured at the ends of the dither range, and at the current MAxHeapSizeTarget. The three dither points are acquired on sequential measurement cycles about 5 seconds apart. This means that in a snapshot the three points are not necessarily at 80%, 100% , and 120% of the target MaxHeapSize as the target may have changed at each measurement cycle. Consequently, the three measured dither-points in the curve window may not lie on a locally convex curve. This situation is improved by relying more on the latest measurements than on older ones. <ref type="figure" target="#fig_6">Figure 9</ref> shows there are critical and noncritical regions of control. In the critical region, at the bottom of the figure, the slope is steep indicating the high value of additional memory to the application. In the noncritical region at the top of the figure, memory is not as valuable. Fortunately, the main difficulties caused by noise and jitter in measuring slope occur in the noncritical region of controller operation where the slope is low.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Memory balancing methodology</head><p>The 'Compute next MaxHeapSize' module of <ref type="figure" target="#fig_4">Figure 8</ref> determines the next set of target MaxHeapSize values to input into the JVMs based on the current system state based on the following procedure:</p><p>1. Check the available OS memory -If it has been modified, that memory is apportioned to the JVMs according the principle of equalizing the slopes. 2. Adjust the target MaxHeapSize -The current algorithm uses an iterative, greedy procedure to estimate the new set of HeapSizeMax values that equalize the slopes. At each step, memory is moved from the JVM with the lowest slope to the JVM with the steepest slope. The iterative computation is ended under either of two conditions: i) for any JVM, memory is only changed when within the upper and lower dither points; ii) the deviation from the equal slope condition no longer improves. 3. Select the dither points for each JVM-The direction and value of the dither is chosen for each JVM so that at any time the sum does not exceed the total available memory. <ref type="figure" target="#fig_0">Figure 11</ref> shows the phase offset between the dithering pattern two located JVMs. 4. Execute the new MaxHeapSize target for each JVM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Experimental results</head><p>The controller is evaluated using collocated JVMs running the SPECjvm2008 derby and the SPECjbb2005 transactional benchmarks. <ref type="figure" target="#fig_0">Figure 10</ref> shows the allocation rate of each benchmark. The total memory constraint for the two JVMs is 1.5 GB.</p><p>The system state is held constant for 580 seconds with SPECjbb2005 using 10 warehouses. The variability in allocation rate during this period is due to different phases in the underlying workload. At 580s, the number   of SPECjbb2005 warehouses doubles to 20, introducing a step like change in the demand for memory. An 80s period of exponentially decaying oscillatory behavior in the control system occurs during the transition to the new operating point. The process CPU followed a similar pattern (not shown in the <ref type="figure">figure)</ref>, with about a 13% shift from Derby to SPECjbb2005. <ref type="figure" target="#fig_0">Figure 11</ref> shows the corresponding control signal of MaxHeapSize sent to JVMs during runs. The dither signal is clearly seen imposed on the average MaxHeapSize control signal. Comparing the strength of the dither to the allocation rate data, <ref type="figure" target="#fig_0">Figure 10</ref> indicates the dither does not affect the application performance, as desired. Experiments using the SPECjvm2008 compiler.compiler and SPECjbb2005 yielded comparable results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>JVM metrics are shown to work well as proxies for application KPIs so that application performance instrumentation and modeling are not required. This expands the applicability and ease of resource arbitration between collocated Java applications.</p><p>The control system of Section 5 is successfully applied in actively apportioning memory between collocated Java applications whose internal functions are largely unknown. Results show the response time to a step in workload intensity is of order of 80 seconds.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: System view of elastic memory</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :Figure 3 :</head><label>23</label><figDesc>Figure 2: The SPECjvm derby workload typifies the threshold pattern and is memory greedy</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: The SPECjvm2008 xml.validation benchmark exhibits a threshold pattern, but is not memory greedy</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :񮽙 񮽙 񮽙 񮽙 񮽙񮽙 񮽙񮽙 񮽙񮽙 񮽙 񮽙 񮽙 񮽙񮽙 񮽙 񮽙 񮽙񮽙 񮽙 񮽙 񮽙 񮽙񮽙 񮽙񮽙 񮽙񮽙 񮽙񮽙 񮽙 񮽙 񮽙񮽙 񮽙 񮽙 񮽙񮽙 񮽙񮽙 񮽙 񮽙 񮽙 񮽙 񮽙 񮽙񮽙 񮽙 񮽙 񮽙Figure 7 :</head><label>57</label><figDesc>Figure 5: SPECjvm2008 compiler.compiler benefits up to about 5GB of memory</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 8 is</head><label>8</label><figDesc>Figure 8 is a component diagram of the measure-analyzecontrol cycle that tracks workload memory demand and actively sets the MaxHeapSize parameter of each JVM. On the right of the figure is the data collector which uses JMX to poll the data from the JVM. The typical polling interval is 5 seconds. The JVM metrics are fed into the control module on the left which has three logical components: the slope evaluator; the Compute Next MaxheapSize module that estimates the next MaxHeapSize value based on the current state; and the dither function. The data collector and controllers for collocated JVMs run in a single lightweight JVM process use less than 0.1% CPU and 20MB of memory.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Main components of the memory controller.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Snapshots of the dithering points.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 10 :</head><label>10</label><figDesc>Figure 10: The allocation rate metric for collocated Derby and SPECjbb workloads.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 11 :</head><label>11</label><figDesc>Figure 11: The MaxHeapSize control parameter including dithering for the Derby and SPECjbb workloads.</figDesc></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cordero</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Correia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">T</forename><surname>El</surname></persName>
		</author>
		<title level="m">IBM PowerVM Virtualization Introduction and Configuration</title>
		<imprint>
			<date type="published" when="2013-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Applications know best: Performance-driven memory overcommit with ginkgo</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hines</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">R</forename><surname>Gordon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Da</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silva</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ryu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">D</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben-Yehuda</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Cloud Computing Technology and Science (CloudCom)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="130" to="137" />
		</imprint>
	</monogr>
	<note>IEEE Third International Conference on</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Application level ballooning for efficient server consolidation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salomie</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-I</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alonso</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Roscoe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elphin-Stone</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th ACM European Conference on Computer Systems</title>
		<meeting>the 8th ACM European Conference on Computer Systems</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="337" to="350" />
		</imprint>
	</monogr>
	<note>EuroSys &apos;13, ACM</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Garbage collection in WebSphere Application Server V8, Part 2: Balanced garbage collection as a new option</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sciampacone</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Burka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Micic</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IBM WebSphere Developer Technical Journal</title>
		<imprint>
			<date type="published" when="2011-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Qoe-jvm: An adaptive and resourceaware java runtime for cloud computing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simao</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Viega</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">LNCS</title>
		<imprint>
			<biblScope unit="page" from="566" to="583" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Standard</forename><surname>Performance</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Corporation</surname></persName>
		</author>
		<ptr target="http://www.spec.org/jbb2005" />
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Standard</forename><surname>Performance</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Corporation</surname></persName>
		</author>
		<ptr target="http://www.spec.org/jvm2008" />
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vmware Vfabric5 Doc</forename><surname>Center</surname></persName>
		</author>
		<ptr target="http://pubs.vmware.com/vfabric5/index.jsp#em4j/about.html" />
		<title level="m">Elastic Memory for Java</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Virtual memory support for garbage-collected applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Berger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">D</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">F</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moss</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E B</forename><surname>Cramm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th Symposium on Operating Systems Design and Implementation</title>
		<meeting>the 7th Symposium on Operating Systems Design and Implementation</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="103" to="116" />
		</imprint>
	</monogr>
	<note>OSDI &apos;06, USENIX Association</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Dither in nonlinear systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zames</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shneydor</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TRANSACTIONS ON AUTONATIC CONTROL AC</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="660" to="667" />
			<date type="published" when="1976" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
