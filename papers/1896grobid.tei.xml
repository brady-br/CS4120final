<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2020-09-29T02:16+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">TRIAD: Creating Synergies Between Memory, Disk and Log in Log Structured Key-Value Stores TRIAD: Creating Synergies Between Memory, Disk and Log in Log Structured Key-Value Stores</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>July 12-14, 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oana</forename><surname>Balmau</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">EPFL</orgName>
								<orgName type="institution" key="instit2">EPFL</orgName>
								<orgName type="institution" key="instit3">EPFL</orgName>
								<orgName type="institution" key="instit4">EPFL</orgName>
								<address>
									<settlement>Nutanix, Nutanix</settlement>
									<country>Pavan Konka Nutanix</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diego</forename><surname>Didona</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">EPFL</orgName>
								<orgName type="institution" key="instit2">EPFL</orgName>
								<orgName type="institution" key="instit3">EPFL</orgName>
								<orgName type="institution" key="instit4">EPFL</orgName>
								<address>
									<settlement>Nutanix, Nutanix</settlement>
									<country>Pavan Konka Nutanix</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rachid</forename><surname>Guerraoui</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">EPFL</orgName>
								<orgName type="institution" key="instit2">EPFL</orgName>
								<orgName type="institution" key="instit3">EPFL</orgName>
								<orgName type="institution" key="instit4">EPFL</orgName>
								<address>
									<settlement>Nutanix, Nutanix</settlement>
									<country>Pavan Konka Nutanix</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>EPFL</roleName><forename type="first">Willy</forename><surname>Zwaenepoel</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">EPFL</orgName>
								<orgName type="institution" key="instit2">EPFL</orgName>
								<orgName type="institution" key="instit3">EPFL</orgName>
								<orgName type="institution" key="instit4">EPFL</orgName>
								<address>
									<settlement>Nutanix, Nutanix</settlement>
									<country>Pavan Konka Nutanix</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huapeng</forename><surname>Yuan</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">EPFL</orgName>
								<orgName type="institution" key="instit2">EPFL</orgName>
								<orgName type="institution" key="instit3">EPFL</orgName>
								<orgName type="institution" key="instit4">EPFL</orgName>
								<address>
									<settlement>Nutanix, Nutanix</settlement>
									<country>Pavan Konka Nutanix</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aashray</forename><surname>Arora</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">EPFL</orgName>
								<orgName type="institution" key="instit2">EPFL</orgName>
								<orgName type="institution" key="instit3">EPFL</orgName>
								<orgName type="institution" key="instit4">EPFL</orgName>
								<address>
									<settlement>Nutanix, Nutanix</settlement>
									<country>Pavan Konka Nutanix</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karan</forename><surname>Gupta</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">EPFL</orgName>
								<orgName type="institution" key="instit2">EPFL</orgName>
								<orgName type="institution" key="instit3">EPFL</orgName>
								<orgName type="institution" key="instit4">EPFL</orgName>
								<address>
									<settlement>Nutanix, Nutanix</settlement>
									<country>Pavan Konka Nutanix</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Nutanix</roleName><forename type="first">Pavan</forename><surname>Konka</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">EPFL</orgName>
								<orgName type="institution" key="instit2">EPFL</orgName>
								<orgName type="institution" key="instit3">EPFL</orgName>
								<orgName type="institution" key="instit4">EPFL</orgName>
								<address>
									<settlement>Nutanix, Nutanix</settlement>
									<country>Pavan Konka Nutanix</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oana</forename><surname>Balmau</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">EPFL</orgName>
								<orgName type="institution" key="instit2">EPFL</orgName>
								<orgName type="institution" key="instit3">EPFL</orgName>
								<orgName type="institution" key="instit4">EPFL</orgName>
								<address>
									<settlement>Nutanix, Nutanix</settlement>
									<country>Pavan Konka Nutanix</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diego</forename><surname>Didona</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">EPFL</orgName>
								<orgName type="institution" key="instit2">EPFL</orgName>
								<orgName type="institution" key="instit3">EPFL</orgName>
								<orgName type="institution" key="instit4">EPFL</orgName>
								<address>
									<settlement>Nutanix, Nutanix</settlement>
									<country>Pavan Konka Nutanix</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rachid</forename><surname>Guerraoui</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">EPFL</orgName>
								<orgName type="institution" key="instit2">EPFL</orgName>
								<orgName type="institution" key="instit3">EPFL</orgName>
								<orgName type="institution" key="instit4">EPFL</orgName>
								<address>
									<settlement>Nutanix, Nutanix</settlement>
									<country>Pavan Konka Nutanix</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Willy</forename><surname>Zwaenepoel</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">EPFL</orgName>
								<orgName type="institution" key="instit2">EPFL</orgName>
								<orgName type="institution" key="instit3">EPFL</orgName>
								<orgName type="institution" key="instit4">EPFL</orgName>
								<address>
									<settlement>Nutanix, Nutanix</settlement>
									<country>Pavan Konka Nutanix</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huapeng</forename><surname>Yuan</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">EPFL</orgName>
								<orgName type="institution" key="instit2">EPFL</orgName>
								<orgName type="institution" key="instit3">EPFL</orgName>
								<orgName type="institution" key="instit4">EPFL</orgName>
								<address>
									<settlement>Nutanix, Nutanix</settlement>
									<country>Pavan Konka Nutanix</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aashray</forename><surname>Arora</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">EPFL</orgName>
								<orgName type="institution" key="instit2">EPFL</orgName>
								<orgName type="institution" key="instit3">EPFL</orgName>
								<orgName type="institution" key="instit4">EPFL</orgName>
								<address>
									<settlement>Nutanix, Nutanix</settlement>
									<country>Pavan Konka Nutanix</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karan</forename><forename type="middle">Gupta</forename><surname>Nutanix</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">EPFL</orgName>
								<orgName type="institution" key="instit2">EPFL</orgName>
								<orgName type="institution" key="instit3">EPFL</orgName>
								<orgName type="institution" key="instit4">EPFL</orgName>
								<address>
									<settlement>Nutanix, Nutanix</settlement>
									<country>Pavan Konka Nutanix</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">TRIAD: Creating Synergies Between Memory, Disk and Log in Log Structured Key-Value Stores TRIAD: Creating Synergies Between Memory, Disk and Log in Log Structured Key-Value Stores</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2017 USENIX Annual Technical Conference (USENIX ATC &apos;17)</title>
						<meeting>the 2017 USENIX Annual Technical Conference (USENIX ATC &apos;17) <address><addrLine>Santa Clara, CA, USA</addrLine></address>
						</meeting>
						<imprint>
							<date type="published">July 12-14, 2017</date>
						</imprint>
					</monogr>
					<note>This paper is included in the Open access to the Proceedings of the 2017 USENIX Annual Technical Conference is sponsored by USENIX. https://www.usenix.org/conference/atc17/technical-sessions/presentation/blamau</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We present TRIAD, a new persistent key-value (KV) store based on Log-Structured Merge (LSM) trees. TRIAD improves LSM KV throughput by reducing the write amplification arising in the maintenance of the LSM tree structure. Although occurring in the background , write amplification consumes significant CPU and I/O resources. By reducing write amplification, TRIAD allows these resources to be used instead to improve user-facing throughput. TRIAD uses a holistic combination of three techniques. At the LSM memory component level, TRIAD leverages skew in data popularity to avoid frequent I/O operations on the most popular keys. At the storage level, TRIAD amortizes management costs by deferring and batching multiple I/O operations. At the commit log level, TRIAD avoids duplicate writes to storage. We implement TRIAD as an extension of Facebook&apos;s RocksDB and evaluate it with production and synthetic workloads. With these workloads, TRIAD yields up to 193% improvement in throughput. It reduces write amplification by a factor of up to 4x, and decreases the amount of I/O by an order of magnitude.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Key-value (KV) stores <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b27">29,</ref><ref type="bibr" target="#b33">35,</ref><ref type="bibr" target="#b36">38,</ref><ref type="bibr" target="#b37">39,</ref><ref type="bibr" target="#b45">47]</ref> are nowadays a widespread solution for handling large-scale data in cloud-based applications. They have several advantages over traditional DBMSs, including simplicity, scalability, and high throughput. KV store applications include, among others, messaging <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b16">18]</ref>, online shopping <ref type="bibr" target="#b23">[25]</ref>, search indexing <ref type="bibr" target="#b20">[22]</ref> and advertising <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b20">22]</ref>. At Nutanix, we use KV stores for storing the metadata for our core enterprise platform, which serves thousands of customers with petabytes of storage capacity <ref type="bibr" target="#b19">[21]</ref>.</p><p>KV store systems are available for workloads that fit entirely in memory (e.g., <ref type="bibr">Mica [36]</ref>, Redis <ref type="bibr" target="#b2">[3]</ref>, and Memcached <ref type="bibr" target="#b1">[2]</ref>), as well as for workloads that require persistent storage (e.g., <ref type="bibr">LevelDB [4]</ref>, RocksDB <ref type="bibr" target="#b11">[12]</ref>). LogStructured Merge trees (LSMs) <ref type="bibr" target="#b39">[41,</ref><ref type="bibr" target="#b38">40]</ref> are a popular design choice for the latter category. LSMs achieve high write throughput at the expense of a small decrease in read throughput. They are today employed in a wide range of KV stores such as LevelDB <ref type="bibr" target="#b3">[4]</ref>, RocksDB <ref type="bibr" target="#b11">[12]</ref>, Cassandra <ref type="bibr" target="#b0">[1]</ref>, cLSM <ref type="bibr" target="#b27">[29]</ref>, and bLSM <ref type="bibr" target="#b42">[44]</ref>.</p><p>Broadly speaking, LSMs are organized in two components: a memory component and a disk component. The memory component seeks to absorb updates. For applications that do not tolerate data loss in the case of failure, the updates may be temporarily backed up in a commit log stored on disk. When the memory component becomes full, it is flushed to persistent storage, and a new one is installed. The disk component is organized into levels, each level containing a number of sorted files, called SSTables. The levels closer to the memory component hold the fresher information. When level L i is full, one or more selected files from level L i are compacted into files at level L i+1 , discarding stale values. This compaction operation occurs in the background.</p><p>Compaction and flushing are key operations, responsible for maintaining the LSM structure and its properties. Unfortunately, they take up a significant amount of the available resources. For instance, for our production workloads at Nutanix, our measurements indicate that, at peak times, compaction can consume up to 45% of the CPU. Moreover, per cluster, an average of 2.5 hours per day is spent on compaction operations for the maps storing the metadata. Clearly, compaction and flushing pose an important performance challenge, even though they occur outside the critical path of user-facing operations.</p><p>We propose three new complementary techniques to close this gap. Our techniques reduce both the time and space taken by the compaction and flushing operations, leading to increased throughput. The first technique decreases compaction overhead for skewed workloads. We keep KV pairs that are updated frequently (i.e., hot en-tries) in the memory component, and we only flush the cold entries. This separation eliminates frequent compactions triggered by different versions of the same hot entry. The main idea of the second technique is to defer file compaction until the overlap between files becomes large enough, so as to merge a high number of duplicate keys. Finally, our third technique avoids flushing the memory component altogether, by changing the role the commit logs play in LSMs and using them in a manner similar to SSTables.</p><p>Combined, our three techniques form TRIAD, a new LSM KV store we build on top of RocksDB. We extensively compare TRIAD against the original version of RocksDB on various synthetic workloads, with a focus on skewed workloads, as well as on Nutanix production workloads. TRIAD achieves up to 193% higher throughput than RocksDB. This improvement is the result of an order of magnitude decrease in I/O due to compaction and flushing, up to 4x lower write amplification and 77% less time spent compacting and flushing, on average.</p><p>To summarize, this paper makes the following key contributions: (1) the design of TRIAD, a system combining three complementary techniques for reducing compaction work in LSMs, each interesting in its own right, (2) a publicly available implementation of TRIAD as an extension of RocksDB, one of the most popular state-of-the-art LSM KV stores, and (3) an evaluation of its benefits in comparison to RocksDB.</p><p>Roadmap. The rest of the paper is structured as follows. Section 2 gives an overview of the LSM tree. Section 3 presents the background I/O overheads in LSM KV stores. Section 4 presents our three techniques for reducing the impact of the compaction and flushing operations on performance. Section 5 describes our evaluation results. Section 6 discusses related work. Section 7 concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background on LSM</head><p>We provide an overview of the LSM structure, its userfacing operations and the flushing and compaction processes that take place in the background.</p><p>LSM Structure. The high-level view of a typical LSM-based KV store is shown in <ref type="figure" target="#fig_0">Figure 1</ref>. The system has three main components, which we briefly describe.</p><p>▷Memory Component. The memory component C m is a sorted data structure residing in main memory. Its purpose is to temporarily absorb the updates performed on the KV store. The size of the memory component is typically small, ranging from a few MBs to tens of MBs. ▷Disk Component. The disk component C disk is structured into multiple levels (L 0 , L 1 , . . . ), with increasing sizes. Each level contains multiple sorted files, called SSTables. The memory component C m is flushed to the first level, L 0 . Because of this, the SSTables in L 0 have overlapping key ranges. SSTables on levels L i (i ̸ = 0) have disjoint key ranges. The choice of the number of levels in C disk is an interesting aspect of the LSM structure. From a correctness perspective, it would suffice to have only two levels on disk: one to flush memory components and one in which we compact. However, there is an I/O disadvantage to this approach. When we merge L 0 SSTables into L 1 , we identify all the L 1 SSTables that have overlapping key ranges with the L 0 SSTable that is being compacted (the SSTables from L 0 cover the entire key range, because they are directly flushed from memory). If L 1 files are large, then fewer files would have overlapping key ranges, but we would have to re-write large files, leading to overhead in the compaction work and a penalty in terms of of memory use. If L 1 files are small, then a large number of files would have overlapping key ranges with the L 0 file. These files would need to be opened and rewritten, creating large overhead in the compaction work. The leveled structure allows LSMs to amortize the compaction work, as the updates trickle down the levels.</p><p>▷Commit Log. The commit log is a file residing on disk. Its purpose is to temporarily log the updates that are made to C m (in small batches), if the application requires that the data is not lost in case of a failure. All updates performed on C m are also appended to the commit log. Typically, the size of the commit log is kept small in order to provide fast recovery in case the operations need to be replayed to recover from a failure. A typical value for the size of the commit log is on the order of hundreds of MB.</p><p>User-facing operations. The main user-facing operations in LSM-based KV stores are reads (Get(k)) and updates <ref type="bibr">(Update(k, v)</ref>). Update(k, v) associates value v to key k. Updates are absorbed in C m and possibly appended to the commit log. Hence, LSM KV stores achieve high write throughput. Get(k) returns the most recent value of k. As illustrated in <ref type="figure" target="#fig_0">Figure 1</ref>, the read first goes to C m ; if k is not found in C m , the read continues to L 0 , checking all the files. If k is not found in L 0 , the read goes to L 1 ,. . . L n , until k is found. Apart from L 0 , only one file is checked for the rest of C disk 's levels, because of the non-overlapping key ranges property.</p><p>Flushing. LSM KV stores have two main background operations: flushing and compaction. Flushing is the operation that writes C m to L 0 , once C m becomes full. In case a commit log is used, the flush can also be triggered by the commit log getting full, even if there is still room in the memory component.</p><p>Compaction. Compaction is the background operation that merges files in disk component L i into files with overlapping key ranges in disk component L i+1 , discarding older values in the process. Leveled compaction is a popular strategy for compaction in LSM KV stores <ref type="bibr" target="#b4">[5,</ref><ref type="bibr">14]</ref>. When the size of L i exceeds its target size, a file F in L i is picked and merged into the files from L i+1 that have overlapping key ranges with F, in a way similar to a merge sort. Therefore, in the case of leveled LSM trees, each KV pair might be eventually propagated down to the component on the last level. Hence, some KV pairs could be rewritten once for every level during compaction. RocksDB and TRIAD employ leveled compaction. The techniques proposed by TRIAD could, however, easily be adapted to size-tiered <ref type="bibr" target="#b20">[22]</ref> approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Motivation</head><p>Despite I/O operations not being in the critical path of user-facing operations, flushing, logging and compaction still consume computational resources. The amount of CPU cycles spent to coordinate these operations translates into a commensurate amount of processing power that cannot be used to serve the user-generated workload. Hence, the frequency and the length of the I/O operations have a significant impact on the final performance perceived by the user.</p><p>We provide experimental evidence of this claim by measuring the extent of the performance reduction due to I/O operations. We consider two workloads that exhibit different levels of skew in the data popularity (skewed/uniform) and two read/write mixes (write dominated and balanced).</p><p>We run these workloads on RocksDB and on a version of RocksDB in which we disable background I/O operations (i.e., flushing and compaction; logging was enabled for both experiments). We pin all of the system activity (i.e., 8 worker threads and all threads created by the KV store) to 8 cores. The LSM structures of the two systems are pre-populated with an identical value for every key accessed during the experiment. This ensures that every read operation can be served, possibly by traversing the on-disk LSM tree. In the RocksdDB version with no background I/O, when a memory component is full, we discard it instead of persisting it, serving requests only from the pre-populated data store. We compare the throughput achieved by the two systems and report it in <ref type="figure" target="#fig_1">Figure 2</ref>. The plot shows that, for all workloads, background I/O represents a major performance bottleneck, yielding up to a 3x in throughput loss with respect to the ideal case. Driven by these results, we investigate the causes that trigger frequent and intensive I/O operations. We identify three main sources of expensive I/O operations, one for each of the three main components of the LSM tree architecture, namely (1) data-skew unawareness, at the memory component level; (2) premature and iterative compaction, at the LSM tree level; (3) duplicated writes at the logging level.</p><p>1. Data skew unawareness. Many KV store workloads exhibit skewed data popularity, in which a few hot keys have a much higher probability of being updated than cold keys <ref type="bibr" target="#b14">[16]</ref>. As we show in Section 5, some Nutanix production workloads also exhibit similar skew.</p><p>Data skew causes the commit log to grow more rapidly than C m , because updates to the same keys are appended to the log but absorbed in-place by C m . This triggers frequent flushes of C m before it reaches its maximum size. Not only does this increase the frequency of flushing, but because the size of the flushed C m is often smaller than the maximum, the fixed cost of opening and storing a file in L 0 is not amortized by the actual writing of data in it.</p><p>Data skew also has a negative impact on the extent of the compaction process. In fact, it is highly likely that a copy of a hot key is present in many levels of the LSM tree structure. This results in frequent compaction operations that easily trickle down the LSM tree structure, causing long cascading compaction phases at L i that likely result into spilling new data to L i+1 . 2. Premature and iterative compaction. Existing LSM KV systems exhibit a two-fold limitation in the compaction process. Some LSM KV stores keep only one file in L 0 to avoid looking up several SSTables in L 0 when reading <ref type="bibr" target="#b4">[5]</ref>. As a result, every time the memory component is flushed, a compaction from L 0 to the underlying levels is triggered. This choice leads to frequent compactions of the LSM tree.</p><p>Other LSM schemes <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr">14]</ref> keep several files in L 0 . This approach leads to the second limitation of existing LSM KV stores. The issue lies in how LSMs compact L 0 to L 1 when several SSTables are present in L 0 . In fact, files in L 0 are compacted to higher levels one at a time, resulting in several consecutive compaction operations. If two files in L 0 share a common key, this key is compacted twice in the underlying LSM tree. Data skew exacerbates this problem, because it increases the probability that multiple L 0 files contain the same set of hot keys. Clearly, the higher the load on the system, the higher is the probability of this event happening.</p><p>This phenomenon can also arise in systems that keep a single file in L 0 . Indeed, during the compaction, the system continues serving user operations, thus potentially triggering multiple flushes of the memory component to L 0 . As a result, when a compaction finishes, it is possible that multiple files reside in L 0 .</p><p>3. Duplicate writes. When C m is flushed to L 0 , the corresponding commit log is discarded because flushing already ensures the durability of the data. Each KV pair in the new file in L 0 , however, corresponds to the last version of a key written in the memory component and, hence, appended to the commit log. Therefore, when flushing the memory component to disk in L 0 , the system is actually replaying I/O that it has already performed when populating the commit log.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">TRIAD</head><p>We now provide a detailed description of TRIAD's techniques. The pseudocode for the main parts of TRIAD's bypassing new file creation during flushes, at the commit log level. The three techniques complement each other and target the main components of LSM KV stores. Even if they work best together, they are stand-alone techniques and generally applicable to LSM-based KV stores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">TRIAD-MEM</head><p>The goal of TRIAD-MEM is to leverage the skew exhibited by many workloads <ref type="bibr" target="#b14">[16]</ref> to reduce flushing and, hence, reduce the frequency of compactions. To this end, TRIAD-MEM only flushes cold keys to disk, while keeping hot keys in memory. This avoids the numerous compactions triggered to ensure non-overlapping key ranges in the LSM disk structure.</p><p>TRIAD-MEM separates entries that are updated often (i.e., hot entries) from entries which are rarely updated (i.e., cold entries) upon flushing C m to L 0 . The hot entries are kept in the new C m and only the cold entries are written to disk. This way, the hot entries are updated just in-memory and do not trigger a high number of compactions on disk. The hot-cold key separation during a flush to L 0 is shown in <ref type="figure" target="#fig_2">Figure 3</ref> and <ref type="figure" target="#fig_3">Figure 4</ref>.</p><p>The separation between hot and cold keys is shown in the separateKeys function in Algorithm 2. The top-K entries of the old C m are selected, where K is a parameter of the system. Ideally, K should be high enough to accommodate all the hot keys, but low enough to avoid a high memory overhead for C m . Thus, properly setting K requires some a priori knowledge about the workload. TRIAD, however, is designed to deliver high per- formance with no information about the workload. In our current implementation, K is a constant. We will show in Section 5 that thanks to its holistic multi-level approach, TRIAD is robust against settings of K that correspond to not storing all the hot keys in memory. We are also currently investigating techniques to automatically set K depending on the runtime workload, for example by means of hill climbing <ref type="bibr" target="#b41">[43]</ref>. The entries that are preserved in the new memory component and not sent to disk are written to the commit log associated to the new memory component, as shown in <ref type="figure" target="#fig_2">Figure 3</ref>. This write-back is necessary in order to not lose information. A final optimization when separating the hot and cold keys is not flushing at all if C m 's size is not larger than a certain threshold (denoted FLUSH_T H in Algorithm 1). Indeed, in the case of very skewed workloads, a flush might be triggered not because C m is full, but because the commit log becomes full. To avoid having a large number of small files, we keep all entries in memory, discard the old commit log, and create a new commit log, with only the freshest values of C m entries.</p><p>We experiment with several methods for hot-cold key detection, including looking at mean and standard deviation of the update frequencies, and selection according to quantiles. Simply selecting as hot keys those keys that are updated with higher frequency than the average one is effective in all workloads.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">TRIAD-DISK</head><p>TRIAD-DISK acts at L 0 of the LSM disk component. In a nutshell, TRIAD-DISK delays compaction until there is enough key overlap in the files that are being compacted. To approximate the key overlap between files, we use the HyperLogLog (HLL) probabilistic cardinality estimator <ref type="bibr" target="#b26">[28,</ref><ref type="bibr" target="#b28">30]</ref>. HLL is an algorithm that approximates the number of distinct elements in a multiset. To compute the overlap between a set of files, we define a metric we call the overlap ratio. Assuming we have n files on L 0 , the overlap ratio is defined as 1 -</p><formula xml:id="formula_0">(UniqueKeys( f ile 1 , f ile 2 , . . . f ile n )) / sum(Keys( f ile i )),</formula><p>where Keys( f ile i ) is the number of keys of the i-th SSTable and UniqueKeys is the number of unique keys after merging the n files. UniqueKeys and Key( f ile i ) are approximated using HLL. <ref type="figure" target="#fig_4">Figure 5</ref> shows an example of how the overlap ratio is used to defer compaction. In the upper part of the figure, there is only one file on L 0 ; the L 0 file overlaps with two files on L 1 . Since the overlap ratio is smaller than the cutoff threshold in this case, compaction is deferred. The lower part of the figure shows the system at a time when L 0 contains two files. The overlap ratio is computed between all the files in L 0 and their respective overlapping files on L 1 . The overlap ratio is higher than the threshold,  so compaction can proceed, by doing a multi-way merge between all files in L 0 and the overlapping files in L 1 .</p><p>The function deferCompaction in Algorithm 2 shows the TRIAD-DISK pseudo-code. We associate an HLL structure to each L 0 file in the LSM disk component. Before each compaction in L 0 , we calculate the overlap ratio of all files in L 0 . If the overlap ratio is below a threshold, we defer the compaction, unless the number of files in L 0 exceeds the maximum allowed number. If the maximum number of files in L 0 is reached, we proceed with the L 0 to L 1 compaction, regardless of the key overlap.</p><p>The use of HLL is not new in the context of LSM compaction. So far, however, the way HLL is used is to detect which files have the most key overlap to be compacted (for instance in systems such as Cassandra <ref type="bibr" target="#b0">[1]</ref>). This way, the highest number of duplicate keys is discarded during compaction. RocksDB employs a similar idea, where the estimation of the key overlap in files at L i and L i+1 is based on the files' key ranges and sizes. Our use of HLL is different. Instead of employing HLL to decide which files to compact, we are using HLL to decide whether to compact L 0 into L 1 at the current moment, or defer it to a later point in time. If the L 0 and L 1 SSTables do not have enough key overlap, compaction is delayed until more L 0 SSTables are generated.</p><p>Current LSMs trigger the compaction of L 0 into L 1 as soon as the number of files on L 0 reaches a certain threshold. The larger the threshold, the more files need to be accessed in L 0 by read operations, which increases read latency. However, since the chance of a key being present multiple files on L 0 is low (otherwise, the large overlap ratio would trigger compaction), TRIAD-DISK can tolerate more files in L 0 without hurting read performance, as we show in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">TRIAD-LOG</head><p>The main insight of TRIAD-LOG is that the data that is written to memory and then persisted into L 0 SSTables is already written to disk, in the commit log. The general idea of TRIAD-LOG is to transform CL into a special type of L 0 SSTable, a CL-SSTable. This way, flushing from memory to L 0 is avoided altogether.</p><p>TRIAD-LOG enhances the role played by the commit log. As C m is being written to, the commit log plays its classic role. When flushing is triggered, instead of copying C m to disk, we convert the commit log into a CLSSTable. As shown in <ref type="figure" target="#fig_5">Figure 6</ref>, instead of storing copies of the memory components in L 0 , we store CL-SSTables. For readability, we only depict the TRIAD-LOG technique, and not the integration with our two other techniques.</p><p>The advantage of treating the commit logs as L 0 SSTables is that the I/O due to flushing from memory is avoided. However, unlike SSTables, the commit log is not sorted. The sorted structure of the classic SSTables makes it easy to merge SSTables during compaction and to retrieve information from the files. To avoid scanning the entire CL-SSTable in order to find an entry in L 0 files, we keep the commit log file offset of the most recent update in C m , for each KV pair. Once the flush operation is triggered, only the small index associated to the offsets in the commit log is written to disk. The index is then grouped with its corresponding commit log file, thus creating the new L 0 CL-SSTable format.</p><p>For instance, consider a commit log with entries of size 8B, in the format (Key; Value): (1;10), (2;20), (3;30), (4;40), (3;300). Then, in C m , TRIAD-LOG keeps the following entries, in the format (Key; Value; CL offset; CL name): (1; 10; 0; CL-name), (2; 20; 8; CLname), (3; 300; 32; CL-name), and (4; 40; 24; CLname). The CL offset is equal to 32 for Key 3, because we keep the offset of the most recent update.</p><p>TRIAD-LOG offers the greatest benefits when the workload is more uniform. For such workloads it is relatively rare that the same key appears several times in the log. The corresponding CL-SSTable therefore contains the most recent values of many distinct keys, and relatively few older values. For skewed workloads, in contrast, the log typically contains multiple updates of the same keys, and the corresponding CL-SSTable therefore stores a high number of old values that are no longer relevant.</p><p>The flow of the write operation remains unchanged by TRIAD-LOG. The writes are performed in C m and persisted in the commit log. The only difference is that apart from the value associated to the key, the commit log name and offset entries are updated as well. Similarly, the read path is largely unchanged, except for accessing the files in L 0 . As before, the reads first look in C m , then in all of the L 0 files, and then in one file for each of the lower levels of the disk component. Unlike before, when a file from L 0 is read, the index is searched for the key, and, if found, the CL-SSTable is accessed at the corresponding offset. Compaction from L 1 to L n is unchanged, because no modifications are done to the SSTable format on these levels. Only the compaction between L 0 and L 1 is affected by our technique. A new compaction operation is needed for merging a CL-SSTable with a regular SSTable. Since the index kept on the CL-SSTable is sorted, it is still possible to proceed in a merge-sort style manner. For clarity and brevity of the presentation, we omit the pseudocode for merging SSTables.</p><p>It is straightforward to integrate TRIAD-LOG with TRIAD-DISK, since TRIAD-DISK affects only the decision to call compaction. The integration with TRIAD-MEM is done by flushing only the part of the index corresponding to the cold keys, ignoring the offsets of the hot keys. Then, during compaction, the hot keys are skipped, similarly to the duplicate updates.</p><p>TRIAD Memory Overhead Analysis. TRIAD reduces I/O by using additional metadata in memory. TRIAD-MEM needs an update frequency (4B) field for each memory component entry. For each (CL-)SSTable on L 0 , TRIAD-DISK tracks the HLL structure (4KB per file). TRIAD-LOG adds two new fields for each memory component entry: the commit log file ID (4B) and the offset in the commit log (4B). Finally, TRIAD-LOG keeps track of the offsets index (8B per entry) for each CL-SSTable on L 0 . While the HLLs and offset indexes could be stored on disk, this would incur a performance penalty. Since the number of files on L 0 is not large, the memory overhead is not significant. Generally, less than 10 files are kept on L 0 . Hence, an upper bound on TRIAD's memory overhead is: 12B * EntriesC m + 10 * (4KB + EntriesC m * 8B). In our tests, the memory overhead is on the order of tens of MB, which is negligible with respect to the tens of GB of I/O saved.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Evaluation</head><p>We implement TRIAD as an extension of Facebook's popular RocksDB LSM-based KV store. The source code of our implementation is available at https://github .com/epfl-labos/TRIAD. We evaluate TRIAD with production and synthetic workloads, and we compare it against RocksDB. We show that: (1) TRIAD achieves up to 193% higher throughput in production workloads. (2) TRIAD effectively reduces I/O by an order of magnitude and spends, on average, 77% less time performing flushing and compaction. (3) TRIAD's three techniques work in synergy and enable the system to achieve high throughput without a priori information about the workload (e.g., skew on data popularity or write intensity).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experimental Setup</head><p>We compare TRIAD against RocksDB. Unless stated otherwise, RocksDB is configured to run with its default parameters, and we do not change the corresponding values in the TRIAD implementation. TRIAD uses an overlap threshold of 0.4 and a maximum number of 6 L 0 files for TRIAD-DISK. In addition, we configure TRIAD-MEM such that its definition of hot keys corresponds to the top 1 percent of keys in terms of access frequency.</p><p>To evaluate TRIAD, we use four production workloads from Nutanix (see Section 5.2). We complement our evaluation with synthetic benchmarks that allow us to control key parameters of the workload, such as skew and write intensity (see Section 5.3). The evaluation is performed on a 20 core Intel Xeon, with two 10-core 2.8 GHz processors, 256 GB of RAM, 960GB SSD Samsung 843T, running Ubuntu 14.04.</p><p>Each synthetic benchmark experiment consists of a number of threads concurrently performing operations on the KV store -searching, inserting or deleting keys. Each operation is chosen at random, according to the given workload probability distribution, and performed on a key chosen according to the given workload skew distribution. Before each experiment, the LSM tree is initialized with roughly half of the keys in the key range.</p><p>We use as evaluation metrics throughput measured in KOperations/second (KOPS), bytes written to disk, time spent in background operations (i.e., compaction and flushing), write amplification (WA), and read amplification (RA). WA and RA are established metrics for measuring I/O LSM KV store efficiency <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b30">32,</ref><ref type="bibr" target="#b32">34,</ref><ref type="bibr" target="#b33">35,</ref><ref type="bibr" target="#b36">38,</ref><ref type="bibr" target="#b46">48]</ref>. WA is the amount of data written to storage compared to the amount of data that the application writes. Intuitively, the lower the WA, the less work is done during compaction. We compute system-wide WA as:  </p><formula xml:id="formula_1">WA = (</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Production Workloads</head><p>The production workloads used for the evaluation of TRIAD are internal Nutanix metadata workloads. The key probability distributions of the workloads are shown in <ref type="figure">Figure 7</ref>. The data sizes and number of updates are shown in <ref type="figure" target="#fig_6">Figure 8</ref>. The production workloads have two different skew profiles: W2 and W4 have more skew in their access patterns, W1 and W3 have less skew. The left-hand side of <ref type="figure">Figure 9A</ref> presents the throughput comparison between RocksDB and TRIAD, for the four production workloads. TRIAD outperforms RocksDB in the four workloads, with a throughput increase of up to 193%. The right-hand side of <ref type="figure">Figure 9A</ref> shows the corresponding WA for each of the workloads. TRIAD reduces WA by up to 4x.</p><p>As expected <ref type="bibr" target="#b32">[34]</ref>, in RocksDB the WA is higher for the less skewed workloads (W1 and W3) and lower for the more skewed workloads (W2 and W4). There is also a clear correlation between the throughput and the WA: throughput is lower in the workloads with higher WA.</p><p>For TRIAD WA is uniform across the four workloads, because TRIAD-MEM converts the skew of the application workload into a disk workload that is closer to uniform. Hence, the workload skew perceived by the disk component is more or less the same across the four workloads, leading, in turn, to more predictable throughput. In contrast with RocksDB, TRIAD's throughput does not exhibit high fluctuation across workloads. We explore this connection between throughput and WA further in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Synthetic Workloads</head><p>We define three workload skew profiles: (WS1) A highly skewed workload where 1% of the data is accessed and updated 99% of the time. This workload reflects the characteristics of Facebook workloads analyzed in <ref type="bibr" target="#b14">[16]</ref>. (WS2) A medium skew workload, where 20% of the data is accessed and updated 80% of the time. (WS3) A uniform workload where all keys have the same popularity.</p><p>We use two different read-write ratios: one with 10% reads and 90% writes, and one with 50% reads and 50% writes. In all experiments, each key is 8B and each value is 255B. To shorten our experiments with the synthetic workloads, we use a small memory component of 4MB and a dataset of 1M keys, so that compactions happen at shorter time intervals. <ref type="figure">Figure 9B</ref> shows the throughput comparison between TRIAD and RocksDB for the three workload skews and two read-write ratios. <ref type="figure">Figure 9C</ref> shows the corresponding WA. TRIAD performs up to 2.5x better than RocksDB for the skewed workloads and up to 2.2x better for the uniform workloads.</p><p>For WS1 all the hot data fits in memory, allowing TRIAD to achieve a throughput increase of 50% for both the write-intensive and the balanced workloads. For WS2, TRIAD-MEM cannot accommodate all the hot keys. Nevertheless, TRIAD still achieves a throughput gain of 51% in the write-intensive workload and 25% in the balanced workload, because TRIAD-DISK and TRIAD-LOG act as a safety net against possible undersizing of the data structure tracking hot keys (Section 4.1), due to lack of detailed knowledge of the workload characteristics. This result showcases the robustness of TRIAD: It consistently delivers high performance, despite not having any prior knowledge of the incoming workload.</p><p>WA is decreased by up to 4x in the moderately skewed and uniform workloads. For the highly skewed workload, however, the WA does not change, despite the gain in throughput. This happens because the 1% of the data that is updated 99% of the time fits entirely in memory. As a consequence, C m is only rarely flushed (as we explain in Section 4), because it takes longer for enough cold entries to be present in C m to trigger a flush. Therefore, even if the total number of bytes is decreased by an order of magnitude, as <ref type="figure">Figure 9D</ref> shows on the lefthand side, the proportion between the compacted bytes and flushed bytes is similar to RocksDB.</p><p>Finally, the right-hand side of <ref type="figure">Figure 9D</ref> shows the time spent in compaction. For the highly skewed workload, the time spent in compaction in TRIAD is an order of magnitude lower than RocksDB, for the same reason as explained above. For the moderately skewed and Throughput Skew 1%-99% Throughput Skew 1%-99%</p><p>LoWA LSM uniform workloads, the time spent in compaction is decreased by 48% and 72%, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RocksDB</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Breakdown of TRIAD's Benefits</head><p>We discuss the contribution of each of TRIAD's techniques, for different types of workloads, reporting the throughput achieved by versions of TRIAD where we only implement one out of the three techniques. <ref type="figure" target="#fig_0">Figure 10</ref> shows the throughput breakdown for each of the techniques, for synthetic workloads WS3 (lefthand side) and WS1 (right-hand side), with a 10%-90% read-write ratio. While all three techniques outperform RocksDB individually, TRIAD-MEM brings more benefits than TRIAD-DISK and TRIAD-LOG for the highly skewed workload, and vice-versa for the uniform workload. Indeed, TRIAD-MEM alone obtains 97% of the throughput that TRIAD achieves for the skewed workload. For the uniform workload, TRIAD-DISK and TRIAD-LOG obtain 85% and 97%, respectively.</p><p>A similar trend can be noticed in the WA breakdown in <ref type="figure" target="#fig_0">Figure 11</ref>. TRIAD-MEM performs best for WS1, but does not decrease WA as the workload is closer to uniform, having close to no effect compared to RocksDB for the workload with no skew (right-most column). TRIAD-DISK and TRIAD-LOG are complementary to TRIAD-MEM, decreasing WA by up to 60% and 40%, respectively, for the uniform workload.</p><p>The lower-right plot in <ref type="figure" target="#fig_0">Figure 11</ref> shows the RA breakdown for a uniform workload, with 10% reads. As expected, TRIAD-MEM lowers RA, because more requests can be served from memory. TRIAD-DISK, however, increases RA compared to the baseline, as it keeps more files in L 0 , and all these files may have to be accessed on a read. TRIAD-LOG does not have an impact on read amplification. Overall, TRIAD has a low overhead over the baseline, increasing RA by at most 5%.</p><p>The breakdown shows tat the three techniques are complementary: no one alone gives 100% of the benefits across all workload types. Their combination allows TRIAD to achieve high performance for any workload, automatically adapting to its characteristics without a priori knowledge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related Work</head><p>Our work is related to previous designs of LSM-based KV stores and to various systems that employ optimization techniques similar to the ones integrated in TRIAD. Related LSM-based KV stores. LevelDB <ref type="bibr" target="#b3">[4]</ref> is one of the earliest LSM-based KV stores and employs levelstyle compaction. Its single-threaded compaction, along with the use of a global lock for synchronization at the memory component level are two of its main bottlenecks. RocksDB <ref type="bibr" target="#b11">[12]</ref> introduces multi-threaded compaction and tackles other concurrency issues. LevelDB and RocksDB expose several tuning knobs, such as the number and the sizing of levels, and policies for compaction <ref type="bibr" target="#b12">[13,</ref><ref type="bibr">14,</ref><ref type="bibr" target="#b25">27]</ref>. Recent studies, simulations and analytical models show that the efficiency of LSM-based KV stores is highly dependent on their proper setting, as well as workload parameters <ref type="bibr" target="#b32">[34,</ref><ref type="bibr" target="#b24">26]</ref> and requirements like memory budget <ref type="bibr" target="#b22">[24]</ref>. In contrast, TRIAD presents techniques that cover a large spectrum of workloads. Thanks to its holistic approach, TRIAD is able to deliver high performance without relying on a priori information about the workload.</p><p>bLSM <ref type="bibr" target="#b42">[44]</ref> proposes carefully scheduling compaction to bound write latency. VT-tree <ref type="bibr" target="#b43">[45]</ref> uses an extra layer of indirection to avoid sorting any previously sorted KV pairs during compaction. HyperlevelDB <ref type="bibr" target="#b8">[9]</ref> also addresses the write and compaction issues in LevelDB, through improved parallelism and an alternative compaction algorithm <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8]</ref>. HyperLevelDB's compaction chooses a set of SSTables which result in the lowest WA between two levels. TRIAD takes a different approach to prevent the occurrence of high WA, by using HLL to decide whether to compact or not at the first level of the disk component.</p><p>LSM-trie <ref type="bibr" target="#b45">[47]</ref> proposes a compaction scheme based on the use of cryptographic functions. This scheme gives up the sorted order of the entries in the LSM tree to favor compaction efficiency over performance in range queries. TRIAD instead preserves the sorted order of the keys, facilitating support for efficient range queries.</p><p>WiscKey <ref type="bibr" target="#b35">[37]</ref> separates keys from values and only stores keys in a sorted LSM tree, allowing it to reduce data movement, and consequently reduce write amplification. The techniques proposed in TRIAD are orthogonal to this approach, and can be leveraged in synergy to it to further enhance I/O efficiency. Cassandra <ref type="bibr" target="#b0">[1]</ref>, HBase <ref type="bibr" target="#b10">[11]</ref> and BigTable <ref type="bibr" target="#b20">[22]</ref> are distributed LSM KV stores, employing size-tiered compaction. In addition, Cassandra also supports the leveled compaction strategy, based on LevelDB's compaction scheme <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6]</ref>. For both compaction strategies, Cassandra introduced HyperLogLog (HLL) to estimate the overlap between SSTables, before starting the merge <ref type="bibr" target="#b9">[10]</ref>. TRIAD also makes use of HLL in its deferred compaction scheme. However, instead of using HLL to determine which files to compact, the overlap between files computed with HLL is used only at L 0 , to determine whether we should compact or wait.</p><p>Ahmad and Kemme <ref type="bibr" target="#b13">[15]</ref> also target a distributed KV store and propose to offload the compaction phase to dedicated servers. In contrast, the techniques proposed in TRIAD are applied within each single KV store instance and do not need dedicated resources to be implemented.</p><p>Tucana <ref type="bibr" target="#b40">[42]</ref>, LOCS <ref type="bibr" target="#b44">[46]</ref> and FloDB <ref type="bibr" target="#b15">[17]</ref> act on other aspects of the KV store design to improve performance. Tucana uses an internal structure similar to a B − ε tree <ref type="bibr" target="#b18">[20]</ref> and uses copy-on-write instead of write-ahead logging. LOCS exploits the knowledge of the underlying SSD multi-channel architecture to improve performance, e.g., by load balancing I/O. FloDB inserts an additional fast in-memory buffer on top of the existing in-memory component of the LSM tree to achieve better scalability. TRIAD can integrate some of these features to further improve its performance. Systems with similar optimization techniques. The hot-cold separation technique is employed in SSDs to improve the efficiency of the garbage collection needed by the Flash Translation Layer <ref type="bibr" target="#b21">[23,</ref><ref type="bibr" target="#b31">33]</ref>. In TRIAD, instead, it is used at the KV store level to reduce the amount of data written to disk.</p><p>Delaying and batching the execution of updates is used in B − ε trees and in systems, e.g., file-systems <ref type="bibr" target="#b29">[31]</ref>, which use B − ε trees as main building block. This technique is employed to amortize the cost of updates <ref type="bibr" target="#b17">[19]</ref> and to reduce the cases in which the effect of an update is immediately undone by a following update <ref type="bibr" target="#b47">[49]</ref>. By contrast, TRIAD defers the compaction of the L 0 level of the LSM tree and batches the compaction of multiple keys to increase the efficiency of the compaction process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>TRIAD is a new LSM KV store aiming to reduce background I/O operations to disk. TRIAD embraces a holistic approach that operates at different levels of the LSM KV store architecture. TRIAD increases I/O efficiency by incorporating data skew awareness, by improving the compaction process of the LSM tree data structure and by performing more efficient logging.</p><p>We compared TRIAD with Facebook's RocksDB and we showed, using production and synthetic workloads, that TRIAD achieves up to an order of magnitude lower I/O overhead and up to 193% higher throughput.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: High-level view of a typical LSM KV store.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Background I/O impact on throughput.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>hot KV pairs in new memtable and Write them in new commitFigure 3 :</head><label>3</label><figDesc>Figure 3: TRIAD-MEM: Before hot-cold key separation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: TRIAD-MEM: After hot-cold key separation and flush.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Overlap ratio example.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: TRIAD-LOG operation flow.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Production workloads: number of updates and number of keys.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 10 :</head><label>10</label><figDesc>Figure 10: Throughput breakdown for uniform and skewed workloads. 16 threads.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 11 :</head><label>11</label><figDesc>Figure 11: Write Amplification and Read Amplification Breakdown. 8 threads.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>then ▷ Do not flush if mem too small 15:</head><label></label><figDesc></figDesc><table>Algorithm 1 Update and Flush. 

1: function UPDATE(Key k, Val v) 
2: Entry e =mem.getEntry(k) 
3: CommitLog log =getCommitLog() 
4: if (e̸ = NULL) then 
5: 

e.val = v; e.updates++ 

6: 

CLUpdateOffset(log,&amp;e) 
▷ Update CL name and offset in entry e 

7: else 
8: 

e = new Entry(k, v); e.updates = 1 

9: 

CLUpdateOffset(log,&amp;e) 
▷ Update CL name and offset in entry e 

10: 

mem.add(e) 

11: end if 
12: end function 

13: function FLUSH(Memtable mem) 
14: if (mem.getSize() &lt; FLUSH_T H) CommitLog newLog = new CommitLog() 

16: 

populateLog(nwLog, mem) 

17: 

CommitLog log = getCommitLog() 

18: 

setCurrentCommitLog(newLog) 

19: 

discardCommigLog(log) 

20: 

CLUpdateOffset(newLog, mem) 

21: else 
22: 

Memtable hotMem = new Memtable() 

23: 

Memtable coldMem = new Memtable() 

24: 

separateKeys(mem, hotMem, coldMem) 

25: 

setCurrentMemtable(hotMem) 

26: 

CommitLog log = getCommitLog() 

27: 

CommitLog newLog = new CommitLog() 
▷ Write back hotMem entries to the new log 

28: 

populateLog(newLog, hotMem) 

29: 

setCurrentCommitLog(newLog) 
▷ Update hotMem with offsets from new CL 

30: 

CLUpdateOffset(newLog, hotMem) 
▷ Extract index corresponding to cold keys 

31: 

CLIndex index = getKeysAndOffsets(coldMem) 
▷ Flush only index and link it to old CL 

32: 

flushToDisk(index, log) 

33: end if 
34: end function 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Algorithm 2 Key Separation and Deferred Compaction. 1: function SEPARATEKEYS(Memtables mem, hotMem, coldMem) 2: int hotKeyCount = sizeof(Memtable) * PERC_HOT / sizeof(Entry) 3: Entry[] hotKeys = getTopKHot(mem, hotKeyCount) 4: hotMem.add(hotKeys) 5: for k in hotMem do ▷ Reset hotness 6:</head><label>2</label><figDesc></figDesc><table>k.hotness = 0; k.updates = 0 

7: end for 
8: coldMem = mem 
9: coldMem.remove(hotKeys) 
10: end function 

11: function DEFERCOMPACTION(()) 
12: assert(level == 0) 
13: int totalKeys = 0 
14: HyperLogLog hllVect[] 
15: FileMetaData levelFiles[] 
16: levelFiles = getLevelFiles(0) 
17: for f in levelFiles do 
18: 

totalKeys+= f.hllKeysCount() 

19: 

hllVect.pushBack(f.hllGet()) 

20: end for 
21: int estimated = hhllMergedEstimate(hllVect) 
22: double overlapRatio = 1 -(estimated / totalKeys) 
23: boolean notEnoughOverlap = overlapRatio &lt; OV ERLAP_RAT IO_T H 
24: boolean notEnoughFiles = getLevelFiles(0).size()≤ MAX_FILES_L0 
25: if notEnoughOverlap ∧ notEnoughFiles then 
26: 

return true 
▷ Defer compaction 

27: end if 
28: return false 
29: end function 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Bytes f lushed + Bytes compacted )/Bytes f lushed . RA is the average number of disk accesses per read.</head><label></label><figDesc></figDesc><table>1e 

-8 

1e 

-7 

1e 

-6 

1e -5 

0 
1M 
2M 
3M 
4M 

Access probability (log) 

Key id by decreasing popularity 

Workload 3 
Workload 4 

Workload 1 
Workload 2 

Figure 7: Production workloads key probability distribu-
tions (Logarithmic scale on y axis). 

Wkld. 1 Wkld. 2 Wkld. 3 Wkld. 4 

Updates 250M 
75M 
200M 
75M 

Keys 
40M 
9M 
30M 
8M 

</table></figure>
		</body>
		<back>

			<div type="acknowledgement">
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Apache</forename><surname>Cassandra</surname></persName>
		</author>
		<ptr target="http://cassandra.apache.org" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Memcached, an open source, high-performance, distributed memory object caching system</title>
		<ptr target="https://memcached.org/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Redis, an open source, in-memory data structure store</title>
		<ptr target="https://redis.io/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Leveldb</surname></persName>
		</author>
		<ptr target="https://github.com/google/leveldb" />
		<editor>Google</editor>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Leveled Compaction in Apache Cassandra</title>
		<ptr target="http://www.datastax.com/dev/blog/leveled-compaction-in-apache-cassandra" />
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">When to Use Leveled Compaction</title>
		<ptr target="http://www.datastax.com/dev/blog/when-to-use-leveled-compaction" />
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Hyperleveldb performance benchmarks</title>
		<ptr target="http://hyperdex.org/performance/leveldb/" />
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Inside</surname></persName>
		</author>
		<ptr target="http://hackingdistributed.com/2013/06/17/hyperleveldb/" />
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">LevelDB intended to meet the needs of HyperDex while remaining compatible with LevelDB</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hyperleveldb</surname></persName>
		</author>
		<ptr target="https://github.com/rescrv/HyperLevelDB" />
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Improving compaction in Cassandra with cardinality estimation</title>
		<ptr target="http://www.datastax.com/dev/blog/improving-compaction-in-cassandra-with-cardinality-estimation" />
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Apache HBase, a distributed, scalable, big data store</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">RocksDB, a persistent key-value store for fast storage environments</title>
		<ptr target="http://rocksdb.org/" />
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">RocksDB options of compaction priority</title>
		<ptr target="http://rocksdb.org/blog/2016/01/29/compaction_pri.html" />
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Compaction management in distributed key-value datastores</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmad</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">Y</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kemme</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. VLDB Endow</title>
		<meeting>VLDB Endow</meeting>
		<imprint>
			<date type="published" when="2015-04" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="850" to="861" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Workload analysis of a large-scale key-value store</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Atikoglu</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Frachtenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paleczny</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ACM SIGMETRICS Performance Evaluation Review</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Unlocking memory in persistent keyvalue stores</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Balmau</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Guerraoui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Trigonakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zablotchi</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Flodb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twelfth European Conference on Computer Systems</title>
		<meeting>the Twelfth European Conference on Computer Systems<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="80" to="94" />
		</imprint>
	</monogr>
	<note>EuroSys &apos;17, ACM</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Robust data sharing with key-value stores</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B ˘ Asescu</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Cachin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Eyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Haas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sorniotti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vukoli´cvukoli´ Vukoli´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachevsky</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">An introduction to bε-trees and write-optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Bender</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Farach-Colton</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jannen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>John-Son</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kuszmaul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Porter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">E</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhan</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2015-10" />
			<biblScope unit="volume">40</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Lower bounds for external memory dictionaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brodal</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">S</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fagerberg</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourteenth Annual ACM-SIAM Symposium on Discrete Algorithms (Philadelphia</title>
		<meeting>the Fourteenth Annual ACM-SIAM Symposium on Discrete Algorithms (Philadelphia<address><addrLine>PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="546" to="554" />
		</imprint>
	</monogr>
	<note>SODA &apos;03</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Characterizing private clouds: A large-scale empirical analysis of enterprise clusters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cano</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Aiyar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Krishnamurthy</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Bigtable: A distributed storage system for structured data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">C</forename><surname>Wal-Lach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Burrows</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chandra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Fikes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gruber</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">E</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Computer Systems</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">On efficient wear leveling for large-scale flashmemory storage systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-P</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2007 ACM Symposium on Applied Computing</title>
		<meeting>the 2007 ACM Symposium on Applied Computing<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1126" to="1130" />
		</imprint>
	</monogr>
	<note>SAC &apos;07, ACM</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Monkey: Optimal navigable key-value store</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dayan</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Athanassoulis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>And Idreos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 ACM International Conference on Management of Data</title>
		<meeting>the 2017 ACM International Conference on Management of Data<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="79" to="94" />
		</imprint>
	</monogr>
	<note>SIGMOD &apos;17, ACM</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Dynamo: amazon&apos;s highly available key-value store</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Decandia</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hastorun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jampani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kakulapati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lakshman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Pilchin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sivasubramanian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vosshall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vogels</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Optimizing space amplification in rocksdb</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Callaghan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Galanis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Borthakur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Savor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Strum</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIDR 2017, 8th Biennial Conference on Innovative Data Systems Research</title>
		<meeting><address><addrLine>Chaminade, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Optimizing space amplification in rocksdb</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Callaghan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Galanis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Borthakur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Savor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stumm</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">The analysis of a near-optimal cardinality estimation algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fusy</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">É</forename><surname>Olivier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meunier</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hyperloglog</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Scaling concurrent log-structured data stores</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Golan-Gueta</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Bortnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hillel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kei-Dar</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Eurosys</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Hyperloglog in practice: algorithmic engineering of a state of the art cardinality estimation algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heule</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Nunkesser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hall</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Betrfs: Write-optimization in a kernel file system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jannen</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Akshintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Esmet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Mittal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Pandey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Walsh</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bender</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Farach-Colton</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kusz-Maul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">C</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Porter</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">E</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trans. Storage</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">29</biblScope>
			<date type="published" when="2015-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">A comparison of fractal trees to log-structured merge (lsm) trees. White Paper</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuszmaul</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Application-managed flash</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lee</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arvind</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th Usenix Conference on File and Storage Technologies</title>
		<meeting>the 14th Usenix Conference on File and Storage Technologies<address><addrLine>Berkeley, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="339" to="353" />
		</imprint>
	</monogr>
	<note>FAST&apos;16, USENIX Association</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Towards accurate and fast evaluation of multi-stage log-structured designs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lim</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Andersen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaminsky</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Silt: A memory-efficient, high-performance key-value store</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lim</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Andersen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaminsky</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">MICA: A holistic approach to fast in-memory key-value storage</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lim</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Andersen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaminsky</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">management</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page">32</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">U</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Pillai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Arpaci-Dusseau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arpaci-Dusseau</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">H</forename><surname>Wisckey</surname></persName>
		</author>
		<title level="m">Separating keys from values in ssd-conscious storage. FAST</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Nvmkv: A scalable, lightweight, ftl-aware key-value store</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marmol</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Sundararaman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Talagala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rangaswami</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>USENIX ATC</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Nvmkv: A scalable and lightweight flash aware key-value store</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marmol</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Sundararaman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Talagala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ran-Gaswami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Devendrappa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ramsundar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ganesan</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<pubPlace>HotStorage</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">The log-structured merge-tree (LSM-tree)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O&amp;apos;neil</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Gawlick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>And O&amp;apos;neil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acta Informatica</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Beating the I/O bottleneck: A case for log-structured file systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ousterhout</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douglis</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGOPS Operating Systems Review</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Design and implementation of a fast and efficient scale-up key-value store</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Papagiannis</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Saloustros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>González-Férez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bilas</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tucana</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 USENIX Conference on Usenix Annual Technical Conference</title>
		<meeting>the 2016 USENIX Conference on Usenix Annual Technical Conference<address><addrLine>Berkeley, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="537" to="550" />
		</imprint>
	</monogr>
	<note>USENIX ATC &apos;16, USENIX Association</note>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Artificial intelligence: a modern approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Russell</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Norvig</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename></persName>
		</author>
		<imprint/>
	</monogr>
	<note>2nd edition</note>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">bLSM: a general purpose log structured merge tree</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sears</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramakrishnan</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>ACM</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Building workload-independent storage with vt-trees</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shetty</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Spillane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Malpani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Andrews</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Seyster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zadok</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
		<respStmt>
			<orgName>FAST</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">An efficient design and implementation of lsm-tree based key-value store on open-channel ssd</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cong</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth European Conference on Computer Systems</title>
		<meeting>the Ninth European Conference on Computer Systems<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
	<note>EuroSys &apos;14, ACM</note>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">LSM-trie: An LSM-tree-based ultra-large key-value store for small data items</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">U</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>USENIX ATC</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Plasson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Gillis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Talagala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sundararaman</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Optimizing every operation in a write-optimized file system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jannen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Pandey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Akshintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chandnani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Deo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kasheff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Walsh</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bender</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Farach-Colton</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kusz-Maul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">C</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Porter</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">E</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th Usenix Conference on File and Storage Technologies</title>
		<meeting>the 14th Usenix Conference on File and Storage Technologies<address><addrLine>Berkeley, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1" to="14" />
		</imprint>
	</monogr>
	<note>FAST&apos;16, USENIX Association</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
