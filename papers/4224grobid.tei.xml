<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2020-10-16T20:09+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">EmoTag -Towards an Emotion-Based Analysis of Emojis</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>Sep 2-4, 2019</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abu</forename><surname>Awal</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Rutgers University</orgName>
								<address>
									<settlement>New Brunswick</settlement>
									<region>NJ</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Md</forename><surname>Shoeb</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Rutgers University</orgName>
								<address>
									<settlement>New Brunswick</settlement>
									<region>NJ</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shahab</forename><surname>Raji</surname></persName>
							<email>shahab.raji@rutgers.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Rutgers University</orgName>
								<address>
									<settlement>New Brunswick</settlement>
									<region>NJ</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerard</forename><surname>De Melo</surname></persName>
							<email>gerard.demelo@rutgers.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Rutgers University</orgName>
								<address>
									<settlement>New Brunswick</settlement>
									<region>NJ</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">EmoTag -Towards an Emotion-Based Analysis of Emojis</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of Recent Advances in Natural Language Processing</title>
						<meeting>Recent Advances in Natural Language Processing <address><addrLine>Varna, Bulgaria</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="1094" to="1103"/>
							<date type="published">Sep 2-4, 2019</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.26615/978-954-452-056-4_126</idno>
					<note>1094</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Despite being a fairly recent phenomenon, emojis have quickly become ubiquitous. Besides their extensive use in social media , they are now also invoked in customer surveys and feedback forms. Hence, there is a need for techniques to understand their sentiment and emotion. In this work, we provide a method to quantify the emotional association of basic emotions such as anger, fear, joy, and sadness for a set of emojis. We collect and process a unique corpus of 20 million emoji-centric tweets, such that we can capture rich emoji semantics using a comparably small dataset. We evaluate the induced emotion profiles of emojis with regard to their ability to predict word affect intensities as well as sentiment scores.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In recent years, information technology has profoundly altered the way humans communicate. A substantial proportion of the global population has adopted the use of social media platforms (such as Twitter, Facebook, and Instagram) and messaging technology (such as Facebook Messenger, WeChat, and WhatsApp) to interact and voice their opinion. The unique properties and expressive capabilities afforded by computer and mobile device-mediated communication has led to quite distinct forms of expression in comparison with classic email etiquette, let alone traditional written correspondence.</p><p>Meanwhile, for any meaningful analysis of social interactions or expression of opinions, it is critical to extract and understand the sentiment and the affect of the source. There are numerous studies investigating the connection between words or sentences and the affects they convey. However, emojis are a particularly prominent feature of modern online interaction. Thus, this paper introduces a new basis for studying this new modality with regard to conveyed affective associations. Emojis have become widespread in social media, and are variously used to carry emotional and contextual information pertaining to the content of social media posts. There have been studies exploring the relationship between hashtags and tweets <ref type="bibr" target="#b10">(Ferragina et al., 2015)</ref>, and between emojis and tweets <ref type="bibr" target="#b2">(Campero et al., 2017)</ref>. Additional research has aimed at conducting sentiment analysis based on emojis and hashtags <ref type="bibr" target="#b26">(Novak et al., 2015)</ref>. A number of other works study the connection between words and emotions, resulting in datasets such as <ref type="bibr">EmoLex (Mohammad and Turney, 2013)</ref>. Most of these studies relied upon a crowdsourcing approach to compile the data and lexicons and to capture relationships among linguistic and paralinguistic elements ( <ref type="bibr" target="#b19">Kulahcioglu and de Melo, 2019)</ref>.</p><p>However, previous work has neglected to focus on the emotional aspects of emojis. For instance, we may ultimately be interested in devising a system that jointly assesses the affect conveyed by a tweet based not only on the words, but also in part on the emojis occurring within it. In some cases, an emoji may reinforce the emotion conveyed by the text. In other cases, it may reveal an additional dimension of affect. In some cases, it may also point in the opposite direction, e.g., by helping to discern sarcasm, which otherwise might be hard to ascertain in certain contexts. Currently, there are no readily available resources to understand the direct relationship between emojis and emotions.</p><p>We address this gap by harvesting an emojicentric collection of tweets. From this, we create the EmoTag resource. The name alludes to its usefulness in exploiting emoji for emotional tag-ging. The resource is based on a series of cooccurrence statistics that allow us to quantify the emotional associations of individual emojis. We subsequently assess these connections in a series of experiments and case studies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head><p>Emotion and Communication. Facial expression has been an important aspect of communication that predates the emergence of mankind. Chevalier-Skolnikoff, in ascending order of phylogenetic complexity, draws connections between the degree of evolution of the brain and the spectrum of facial expression observed for a species <ref type="bibr" target="#b3">(Chevalier-Skolnikoff, 1973)</ref>. Charles Darwin's well-known volume on the expression of emotions <ref type="bibr">(Darwin, 1872)</ref> analysed the connection between emotions and their expression. He remarked for instance, that for both animals and humans, anger coincides with eye muscle contractions and teeth exposure, and commented on the fact that humans lift their eyebrows in moments of surprise. His work then goes on to study the role of such forms of facial expression in conveying to others how an animal feels, studying primates as well as human infants and adults.</p><p>In light of this, humans continue to rely extensively on such nonverbal cues even in oral forms of linguistic communication. Although a person's emotion and mood can to some extent be conveyed by means of suitable content words (e.g., "I am happy to hear that!") or interjections ("Wow!"), face-to-face communication has important properties that written communication tends to lack <ref type="bibr" target="#b1">(Bordia, 1997)</ref>. These include facial expressions of the aforementioned sort, but also gesture and intonation. In certain circumstances, e.g. certain problem-solving settings, face-to-face communication may hence prove more efficient and effective <ref type="bibr" target="#b1">(Bordia, 1997)</ref>.</p><p>Accordingly, since the beginning of writing, humans have resorted to surrogate mechanisms to convey emotive signals, attempting to push the boundaries and overcome some of the inherent restrictions of plain written language as a medium. Examples include illustrative embellishments and ornaments, calligraphy, a judicious use of color, and various typographic instruments. For instance, it has been shown that the choice of font may radically alter the affective perception of a text <ref type="bibr" target="#b14">(Juni and Gross, 2008;</ref><ref type="bibr" target="#b18">Kulahcioglu and de Melo, 2018</ref>).</p><p>Emoticons and Emoji. While emoticons such as ":-)" and Japanese (kaomoji) such as "(ˆ ˆ)", both based on regular characters, have been in use for several decades, emojis originated in Japan in the 1990s and have only recently spread globally. Despite the lexicographic similarity between the two words emoji and emotion, etymologically, the former stems from the Japanese words (e, picture) and (moji, character). Emoji characters, similar to earlier dingbat characters, are pictorial and colorful.</p><p>Their principal use has indeed been to convey emotion, particularly via facial expression emojis. In 2015, Oxford Dictionaries declared the Face with Tears of Joy emoji its Word of the Year 2015. <ref type="bibr" target="#b15">Kaye et al. (2017)</ref> explained how emojis may aid the interlocutor in disambiguating utterances that would otherwise remain ambiguous. Emojis may also be useful as a more instantaneously and widely recognized form of communicating degrees of satisfaction. Kay et al. go as far as suggesting them for consideration as possible alternatives to regular Likert scales ( <ref type="bibr" target="#b15">Kaye et al., 2017)</ref>.</p><p>Historically, the spread of emojis has been driven in large part by their adoption in popular messaging and social media platforms, which led, among things, to their inclusion in Shift JIS, and, subsequently, the Unicode standard. Nowadays, they are ubiquitous in social media and chat applications, but increasingly also in emails and other digital correspondence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Related Work</head><p>Emoticons. Early studies focused on the use of emoticons in social media. <ref type="bibr" target="#b11">Go et al. (2009)</ref> proposed a form of distant supervision by using emoticons as noisy labels for Twitter sentiment classification. <ref type="bibr" target="#b5">Davidov et al. (2010)</ref> adopted a fairly similar approach by handpicking smileys and hashtags as tweet labels and relying on a supervised method for sentiment analysis of tweets.</p><p>Emoji Semantics. A prominent work on emojis is the DeepMoji project ( <ref type="bibr" target="#b2">Campero et al., 2017</ref>) from MIT. It provided a model that recommends emojis given a natural language sentence as input. The deep learning model was trained on a collection of 1.2B tweets to learn the sentiment, emotions, and the use of sarcasm in short text. <ref type="bibr" target="#b0">Barbieri et al. (2016)</ref> proposed a method to learn vector space embeddings of emojis using the standard word2vec skip-gram approach, applied to a large collection of tweets. In contrast, <ref type="bibr" target="#b9">Eisner et al. (2016)</ref> attempted to learn vector embeddings of emojis based on their short descriptions in the Unicode standard.</p><p>Emoji Associations. The first paper that thoroughly investigated the sentiment of emojis <ref type="bibr">(No- vak et al., 2015)</ref> proposed a sentiment ranking of 715 emojis on a corpus of 70,000 tweets. This work provides a basis for future research on the logographic usage of emojis in social media.</p><p>Zhou and Wang (2017) trained a natural language conversation model that accounts for the underlying emotion of utterances by exploiting the existence of emojis as a signal. <ref type="bibr" target="#b28">Rakhmetullina et al. (2018)</ref> proposed a method to classify emojis with regard to their sentiment and emotion. Their corpus consists of 500 labeled tweets, and they categorize emojis by assigning them labels for 8 emotions. For this, they applied a distant supervision technique for a reliable mapping based on manually annotated data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EmoTag</head><p>Given the prominence of emojis in human communication, our work seeks to study relevant associations of emojis. We begin by assembling a dataset for this purpose (Section 4.1), and subsequently induce a series of lexicons that reveal potential connections (Section 4.2), including between words and emojis, as well as between emojis and emotions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data Collection</head><p>In assembling a collection of social media postings containing both emojis and hashtags with tweets, one strategy would be to rely on available datasets and filter them so as to retain only those entries that contain both emojis and hashtags. However, this approach results in a comparably small number of postings. Despite the overall surge in popularity of emojis, only a fraction of all postings includes emojis.</p><p>Instead, we proceeded to compile a new dataset of about 20.8 million tweets by specifically searching for postings that contain emojis. For the set of target emojis, our goal was to focus on emojis associated with emotions, as opposed to generic symbols from domains such as transportation or household appliances. To this end, we relied on a set of most frequently used 620 emojis from <ref type="bibr">No- vak et al. (2015)</ref> and from Emoji Tracker 1 , a website that monitors the use of emojis on Twitter in realtime.</p><p>Using our set of frequent emojis as search terms, we retrieved tweets that specifically contain one or more of these target emojis. The number of tweets is evenly distributed across different emojis. While tweets can be in any language, we only collected tweets labeled as being in English. In total, we obtained a set of 20.8 million tweets over a span of one year. In addition to the volume that such a large time span provides, collecting the data for every day of the year aids in mitigating the effect of potential biases in the data. All collected tweets contain at least one emoji.</p><p>Note that only a fraction of all tweets have hashtags. Specifically, within our collected data, we found that only 10-15% of our tweets with emojis also include hashtags. To clean up the data, we removed usernames (marked with @-symbol), tweets consisting only of hashtags and emojis but no text, tweets that only contain a short time stamp such as "6AM" or simply a URL (with or without the "http://" prefix), as well as all duplicate tweets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Lexicon Induction</head><p>Based on the corpus, EmoTag is constructed as a series of lexicons.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Co-occurring Emojis</head><p>We first collect a series of co-occurrence based lexicons. Each entry in such a lexicon is the representation of pairwise count of desired unigram tokens. These resources can be useful for the community, but also allow us to conduct analyses of the data.</p><p>In our tweet collection, there are roughly 36K tweets per emoji, and these have a uniform distribution across the collection time period.</p><p>Inspecting the results, we observe that the overall top-ranked pair of co-occurring emojis in our dataset is U+1F61D and U+1F61C . These showed up together 42K times, which is fairly frequent in comparison with other pairs. Note that U+1F61D is the "face with stuck-out tongue and tightly-closed eyes" emoji, while U+1F61C is the "face with stuck-out tongue and winking eye" emoji.</p><p>Another emoji, U+1F602 , the "face with tears of joy" one, appears to be the most common emojis to co-occur saliently with others. It appears with a broad range of other emojis with a relatively high frequency. Three other popular emojis that co-occurred with U+1F602 include U+1F62D ("loudly crying face"), U+1F648 ("see-no-evil monkey"), and U+1F629 ("weary face"). Somewhat different from the previous cases, the fourth pair in <ref type="table" target="#tab_2">Table 1 involves the emoji U+1F62D</ref> , i.e., a crying face, and U+1F602 , i.e., a face with tears of joy. This is unusual in the sense that these two emojis possess opposite sentiment polarities. According to <ref type="bibr" target="#b26">Novak et al. (2015)</ref>, the sentiment value of U+1F62D is -0.093, whereas the sentiment value of U+1F602 is 0.221, i.e., a positive sentiment. This suggests that people tend to conflate the two due to their similar appearance, as both involve tears. Another possibility is that people may be using one of the two sarcastically. As shown in the table, similar observations can also be made for certain other pairs of emojis.</p><p>Our results also show a correlation between U+1F60D and U+1F629 . The two are paired up around 2,500 times, illustrating another connection between a positive and a negative sentiment emoji. U+1F629</p><p>is the "weary face" emoji, whereas U+1F60D is the "smiling face with heart-shaped eyes" one. This appears to stem from tweets that express positive sentiment about a target entity, but also negative sentiment about the current situation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Emoji-Words Lexicon</head><p>Another lexicon that we produce aims to provide co-occurring words for a given emoji, or, vice versa, emojis for a given word. <ref type="table" target="#tab_2">Table 2</ref> shows an excerpt of the emoji-word lexicon, grouped by words. For example, the word "miss" co-  occurs with a wide range of emojis, but the top co-occurring emojis are U+1F62D , U+2764 , and U+1F622 . These emojis are likely to be used when someone misses someone or something. Similarly, the words "happy" and "love" appear with numerous emojis that carry happy and positive sentiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3">Emoji-Hashtags Lexicon</head><p>This lexicon provides a collection of hashtags along with the emojis that they co-occur with. The resource also includes the corresponding cooccurrence frequencies between emojis and hashtags. According to our findings, the emoji U+1F637 ("face with medical mask") co-occurs with the hashtags #sick, #flu, #yuck, #cold, #in-somnia, and #dying, which all are clearly semantically relevant for this emoji.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Interpretable Emoji-Based Word Vectors</head><p>Interpretability and explainability are widely regarded as highly desirable attributes of AI-driven decision making ( <ref type="bibr" target="#b29">Xian et al., 2019)</ref>. Dense word vectors such as those produced by word2vec ( <ref type="bibr" target="#b21">Mikolov et al., 2013</ref>) are ubiquitous in NLP ( <ref type="bibr" target="#b6">de Melo, 2017)</ref>. However, it is often remarked that they lack interpretability, in the sense that individual values in such vectors do not carry any easily interpretable inherent significance. Previous work has proposed interpretable word vectors consisting of one or more sentiment polarity scores for a word (Dong and de Melo, 2018; Dong and de . Given that emojis represent a wide spectrum of aspects considered relevant in human communication, we study to what extent emojis can serve as a means of inducing word vectors endowed with interpretability. This can be achieved by assigning every word a 620-dimensional word vector, in which each dimension reflects the association of that word with one out of 620 emojis. Since we use a list of the 620 most frequent emojis, the dimensionality of a vector becomes 620. An obvious method would be to adopt just simple frequency counts as the values in these vectors, i.e., for a given word, the entries in its word vector would simply reflect the number of times that word co-occurred with a given emoji.</p><p>However, we can improve over this by relying on the word2vec Skip-Gram with Negative Sampling algorithm ( <ref type="bibr" target="#b21">Mikolov et al., 2013</ref>) as an intermediate representation, as illustrated in <ref type="figure" target="#fig_0">Fig. 1</ref>. We first train such a word2vec model on the EmoTag corpus. Then a cosine similarity score is calculated between all words and emojis. This yields a semantic relatedness score in <ref type="bibr">[0,</ref><ref type="bibr">1]</ref> for any wordemoji pair. Thus, we can view the score as reflecting to what extent a word correlates with an emoji. We use these correlation coefficients to form a word vector v w ∈ [0, 1] d for every word w, such that each of the d = 620 dimensions reflects the correlation with a particular emoji. This is the final EmoTag word vector representation that we use in all experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Evaluation</head><p>In the following, we evaluate EmoTag for machine learning-driven emotion analysis of tweets and show how it can be used to reveal the sentiment and emotion of individual emojis.</p><p>The first study aims at evaluating the usefulness of our interpretable EmoTag word vectors in a downstream task, exploiting them in a machine learning-driven system that seeks to identify the emotion intensity of tweets.</p><p>Subsequently, we use our data to compute sentiment polarity scores for emojis, comparing these against existing human annotations of emoji sentiment.</p><p>Finally, we develop the first resource providing emotion scores for emojis. We evaluate these by showing how they can be used to automatically induce emotion scores for words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Emotion Intensity Prediction with Interpretable Emoji-Based Word Vectors</head><p>We begin by evaluating the interpretable emojibased word vectors, assessing to what extent they are able to keep up with regular word vectors in a downstream task relating to emotions.</p><p>Benchmark. In particular, we consider the EmoInt Shared Task from WASSA (Workshop on Computational Approaches to Subjectivity, Sentiment &amp; Social Media Analysis) 2017 (Mohammad and Bravo-Marquez, 2017a), which involves determining the intensity or degree of emotion felt by a speaker when a tweet and a target emotion are given. Tweets were provided for four different emotion categories (anger, fear, joy, and sadness), and the ground truth intensity values range between 0 and 1. The Affective Tweets (AT) package was provided to all participants as a baseline for the competition <ref type="bibr" target="#b24">(Mohammad and Bravo-Marquez, 2017b</ref>), providing a rich set of features constructed based on several emotion and sentiment lexicons such as NRC-EmoLex, <ref type="bibr">NRC10E, etc. (Mohammad and Bravo-Marquez, 2017a</ref>).</p><p>Model. We rely on a deep neural network to predict the emotion intensity for each tweet, adopting a similar CNN-LSTM architecture as that of IMS ( <ref type="bibr">Köper et al., 2017)</ref>, the 2nd-ranked system among all participants in the competition, with the CNN architecture based on that proposed by <ref type="bibr" target="#b16">Kim (2014)</ref>. In training, each tweet is represented by a matrix of size m x d, where d is the dimensionality of the pre-trained word vectors and m = 50 is the maximal token sequence length considered for  <ref type="table" target="#tab_3">Table 3</ref>: Comparing with other methods, with regard to anger (A), fear (F), joy (J), sadness (S), average (Avg), dimensionality (d).</p><p>a tweet. We can thus feed in either regular word vectors or our interpretable emoji-based EmoTag vectors for the series of words in the tweet. We applied a dropout rate of 0.25. The obtained matrix then serves as input to a convolutional layer with a window size of 3, followed by a max-pooling layer (size 2) and an LSTM (Hochreiter and Schmidhuber, 1997) to predict a numerical output for each tweet. This numerical value was then added as a feature along with other auxiliary features, and passed to a Random Forest regressor to obtain the final intensity score for a particular emotion. The IMS team used a total of 142 features, including the 45 baselines features from Affective Tweets.</p><p>Since we are comparing our results with both the baseline features and the features used by the IMS team, our classifier is also fed with the 142 features. All features were passed to a random forest regressor with 800 trees for identifying the intensity of a given emotion. A separate model is trained for each of the four target emotions.</p><p>Results.  tion, EmoTag actually outperforms the IMS team's baseline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Evaluating the Sentiment of Emojis</head><p>Next, we evaluate to what extent our interpretable word-emoji vectors can aid in revealing the sentiment of emojis.</p><p>Method. For obtaining sentiment scores, we rely on the NRC Emotion Lexicon EmoLex <ref type="bibr">(Moham- mad and Turney, 2013)</ref>, a list of English words and their associations with eight basic emotions (anger, fear, anticipation, trust, surprise, sadness, joy, and disgust) and two sentiments (negative and positive). The associations are merely given as Boolean labels (0 or 1). To obtain a sentiment score for an individual emoji, we first consider all words with a sentiment score of 1 in EmoLex. Then, we rank all words associated with the given emoji based on their similarity score according to our interpretable word vectors, where a higher similarity score results in a higher rank. According to the ranking, the top K = 3 words are picked and their similarity scores are aggregated using a simple addition, which becomes the ultimate sentiment score for the given target emoji.</p><p>Results. To evaluate the sentiment score of emojis, we measure the Pearson correlations for several groups of emojis treating the scores by <ref type="bibr" target="#b26">Novak et al. (2015)</ref> as gold scores. <ref type="table">Table 5</ref> summarizes the Pearson correlations for several groups of emojis. The first row of the table represents Novak's top 100 positive sentiment emojis. We also consider additional groups based on the Unicode standard emoji descriptions, particularly those with a face and those with monkey faces. Note that we observed a high positive sentiment score for all emojis with kiss symbol or kissing face in our data, compared to Novak's scores. For some emojis, our model obtains a high sentiment score such as 0.991 for "Kissing Cat Face</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Emoji Group</head><p>Correlations Top 100 positive emojis 0.71 Emojis with face 0.45 Monkey face emojis 0.53 Emojis with kissing 0.14 <ref type="table">Table 5</ref>: Pearson Correlations for Sentiment Score with Closed Eyes" U+1F63D, whereas the score by <ref type="bibr" target="#b26">Novak et al. (2015)</ref> is 0.571. This can happen for several reasons. In some cases, the sentiment scores they propose may be misleading for certain emojis, especially if they are less frequent in their dataset. An example is U+1F63D, which has an occurrence frequency of 88 only, compared to emojis such as "Face with Tears of Joy" U+1F602, which occurred 14,622 times. Thus, in some cases, their results may not be reliable.</p><p>Still, the results often show a strong agreement, although our method produces sentiment scores for emojis only indirectly via their associations with words. <ref type="table" target="#tab_4">Table 4</ref> provides examples of such sentiment scores generated by <ref type="bibr">EmoTag and Novak et al. (2015)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Evaluating Emotion Profiles of Emojis</head><p>Finally, we use our data to evaluate to what extent emojis are associated with certain emotions. For this, we again rely on our emoji-based word vectors in conjunction with EmoLex, the NRC Emotion Lexicon <ref type="bibr" target="#b25">(Mohammad and Turney, 2013)</ref>. EmoLex provides a set of words along with a set of binary labels, where 1 signifies that the word carries a particular association, while 0 represents the negative case.</p><p>Method. First, for each emoji, we identify the top K in EmoLex according to their cosine similarity with the emoji, as obtained in our interpretable word vectors, where a higher similarity score entails a higher rank. For the top K words, we compute a weighted average of emotion labels. The emotion labels are taken from EmoLex, while the similarity scores are used as weights. This weighted average then serves as the final emotion score of the emoji. The same process is followed for all emojis. Results. We evaluate our induced emoji emotion scores indirectly by using them to reproduce emotion intensity scores for words, for which we have ground truth intensity scores in the Affect Intensity lexicon by <ref type="bibr" target="#b22">(Mohammad, 2018)</ref>. This lexicon comes with 6K tokens, where tokes are grouped by the four emotions anger, fear, joy, and sadness. It provides crowdsourced emotion intensity scores, which range between 0 and 1, with 1 meaning that the word exhibits the highest degree of association with a particular emotion and 0 referring to the lowest degree. Note that this ground truth resource is distinct from the NRC Emotion Lexicon used in inducing our scores. The latter merely provides Boolean labels for word-emotion pairs, and thus it is non-trivial to derive affect intensity scores from it, particularly via emojis.</p><p>To reproduce word emotion intensities based on our emoji emotion scores, we proceed as follows. For a given word w, we rank the top K emojis based on their similarity score in the EmoTag word vectors, where higher scores entail a higher rank. Once the top K emojis have been identified, we then compute the arithmetic mean of the emotion scores of those related emojis, which yields the final emotion score for the target word w. We chose K = 10, which led to better results than alternative values. <ref type="table">Table 8</ref> depicts the Pearson correlations for different subsets of the Affect Intensity lexicon. These correlations reveal how close we are in predicting the emotion score for a given word based on our emoji emotion scores. The first row shows the scores for words that are common to all four emotion groups, whereas the last row includes all words. <ref type="table">Table 7</ref> provides examples of emotion scores for a few select emojis.</p><p>Analysis. For further analysis, we compare our scores with the classification obtained by <ref type="bibr">Rakhme- tullina et al. (2018)</ref>. <ref type="table" target="#tab_6">Table 6</ref> compares the emotional label that their classification provides against our emotion scores for anger, joy, sadness. Note that this is the complete set of emoji results provided in their paper, apart from one additional emoji for the emotion surprise, which our method currently does not support, due to its omission in EmoLex. Their labeling did not include the emotion fear, so we omit it in our comparison. The bold scores in the last three columns indicate what emotion labeling we would obtain if we had to select a single label for an emoji based on our obtained emotion intensity scores. For example, in our case, emoji "Folded Hands" U+1F64F obtains the highest score 0.485 for the emotion joy, which is labeled as being in the joy category in their study as well. There are three cases (high-   <ref type="table">Table 7</ref>: Emotion scores of emojis for anger (A), fear (F), joy (J), sadness (S).  <ref type="table">Table 8</ref>: Pearson Correlations of gold scores and our predicted scores for Affect Intensity lexicon lighted in red) at which our scoring would fail. According to their labeling system and results, emoji "Weary Face" U+1F629 should have obtained its highest score for sadness (0.234) instead of anger (0.236), though both scores are very close in our case.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Tokens</head><p>The emoji "Face With Tears of Joy" U+1F602 scored 0.381 on anger, which is the highest among all scores for it, although the authors of Emoji2Emotion marked it as belonging to the joy category. This may stem from the phenomenon of people frequently confusing this emoji with the "Loudly Crying Face" U+1F62D emoji. In <ref type="table">Table  1</ref>, we observe that both appear together very often, which results in a strong association with a negative emotion (anger) for an emoji that intrinsically ought to be more associated with joy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>The characteristics of a medium profoundly affect the way that people express themselves using said medium. While written communication lacks the non-verbal cues that make face-to-face communication particularly effective for problem-solving <ref type="bibr" target="#b1">(Bordia, 1997)</ref>, modern social media, and messaging platforms have unique properties that are interesting in their own right. Among these, the use of emojis stands out as meriting very special consideration, not least due to their ability to compensate for some of the shortcomings of written language as a medium in conveying emotion and affect.</p><p>While research in social science and social media analytics has extensively studied the use of emojis in everyday communication, previous work has not fully explored the connection between emojis and emotion. This paper presents a detailed analysis of how emojis and words co-occur in social media, including their connection to emotions. It also shows how an interpretable word embedding can be formed with the help of emojis, which shows promise as an additional ingredient in emotion detection-related tasks.</p><p>Another key contribution of this work is the creation of a large resource, consisting of several different sub-lexicons that describe connections among emoji, words, and other items, as well as emotion scores for emojis, which are released to the public 2 . We hence believe that this work will substantially benefit other researchers in several different fields.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Inducing Interpretable Word Vectors via Emojis</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 : Co-occurring Emojis and Words</head><label>2</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 summarizes</head><label>3</label><figDesc></figDesc><table>the results for the 
EmoInt task, providing Pearson correlations for 
each emotion as well the average Pearson corre-
lation for all four emotions, along with the di-
mensionality of the respective word vectors used 
in the experiments. The results show that the in-
terpretable word vectors in EmoTag are able to 
yield results that are comparable with those of 
other dense word representations that are not in-
terpretable. It should be kept in mind that EmoTag 
was built based on a very small corpus, i.e., only 
20M tweets, comparing to the massive size of the 
corpora used for pretrained word vectors such as 
the two GloVe models. For further comparison, 
we also report results on just the AffectiveTweets 
(AT) features, as well as the original IMS system. 
In some cases, for example for the sadness emo-

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Comparison of emoji sentiment scores 
from EmoTag and Novak et al. (2015). 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="true"><head>Table 6 : A comparison between Emoji2Emotion (E2E) and EmoTag</head><label>6</label><figDesc></figDesc><table>Emoji 
Name 
A 
F 
J 
S 
U+1F620 
Angry face 
0.49 0.36 0.07 0.44 

U+1F46E Police officer 0.34 0.49 0.16 0.27 

U+1F492 
Wedding 
0.09 0.14 0.63 0.25 

U+1F4A9 
Pile of poo 
0.35 0.34 0.15 0.47 

</table></figure>

			<note place="foot" n="1"> http://emojitracker.com/</note>

			<note place="foot" n="2"> http://emoji.nlproc.org</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">What does this emoji mean? a vector space skip-gram model for twitter emojis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francesco</forename><surname>Barbieri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francesco</forename><surname>Ronzano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Horacio</forename><surname>Saggion</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Language Resources and Evaluation conference</title>
		<meeting><address><addrLine>LREC. Portoroz, Slovenia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Face-to-face versus computermediated communication: A synthesis of the experimental literature</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prashant</forename><surname>Bordia</surname></persName>
		</author>
		<idno type="doi">10.1177/002194369703400106</idno>
		<ptr target="https://doi.org/10.1177/002194369703400106" />
	</analytic>
	<monogr>
		<title level="j">The Journal of Business Communication</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="99" to="118" />
			<date type="published" when="1973" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Using millions of emoji occurrences to learn any-domain representations for detecting sentiment, emotion and sarcasm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andres</forename><surname>Campero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bjarke</forename><surname>Felbo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><surname>Saxe</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1708.00524" />
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Facial expression of emotion in nonhuman primates. In Darwin and Facial Expression: A Century of Research in Review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suzanne</forename><surname>Chevalier-Skolnikoff</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1973" />
			<publisher>Academic Press</publisher>
			<biblScope unit="page" from="11" to="89" />
			<pubPlace>New York, NY</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">1872. The Expression of the Emotions in Man and Animals. Appleton. The original was published 1898 by Appleton</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Darwin</surname></persName>
		</author>
		<imprint>
			<publisher>University of Chicago Press</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Chicago and London</orgName>
		</respStmt>
	</monogr>
	<note>Reprinted 1965 by the</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Enhanced sentiment learning using twitter hashtags and smileys</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitry</forename><surname>Davidov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Tsur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ari</forename><surname>Rappoport</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd International Conference on Computational Linguistics: Posters. Association for Computational Linguistics</title>
		<meeting>the 23rd International Conference on Computational Linguistics: Posters. Association for Computational Linguistics<address><addrLine>Stroudsburg, PA, USA, COLING &apos;10</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="241" to="249" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Multilingual vector representations of words, sentences, and documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Melo</forename><surname>Gerard De</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IJCNLP 2017</title>
		<meeting>IJCNLP 2017</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Cross-lingual propagation for deep sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerard</forename><surname>De Melo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AAAI 2018</title>
		<meeting>AAAI 2018</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A helping hand: Transfer learning for deep sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerard</forename><surname>De Melo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">emoji2vec: Learning emoji representations from their description</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Eisner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Rocktäschel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isabelle</forename><surname>Augenstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matko</forename><surname>Bosnjak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/W16-6208" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of The Fourth International Workshop on Natural Language Processing for Social Media. Association for Computational Linguistics</title>
		<meeting>The Fourth International Workshop on Natural Language Processing for Social Media. Association for Computational Linguistics<address><addrLine>Austin, TX, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="48" to="54" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">On analyzing hashtags in twitter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Ferragina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francesco</forename><surname>Piccinno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Santoro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International AAAI Conference on Web and Social Media</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Twitter sentiment classification using distant supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Go</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richa</forename><surname>Bhayani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Huang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title/>
		<idno type="doi">10.1162/neco.1997.9.8.1735</idno>
		<ptr target="https://doi.org/10.1162/neco.1997.9.8.1735" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Emotional and persuasive perception of fonts. Perceptual and motor skills</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Juni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julie</forename><forename type="middle">S</forename><surname>Gross</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="page" from="35" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Emojis: Insights, affordances, and possibilities for psychological science</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linda</forename><forename type="middle">K</forename><surname>Kaye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephanie</forename><forename type="middle">A</forename><surname>Malone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helen</forename><forename type="middle">J</forename><surname>Wall</surname></persName>
		</author>
		<idno type="doi">10.1016/j.tics.2016.10.007</idno>
		<ptr target="https://doi.org/https://doi.org/10.1016/j.tics.2016.10.007" />
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="66" to="68" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Convolutional neural networks for sentence classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoon</forename><surname>Kim</surname></persName>
		</author>
		<idno type="doi">10.3115/v1/D14-1181</idno>
		<ptr target="https://doi.org/10.3115/v1/D14-1181" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP). Association for Computational Linguistics</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP). Association for Computational Linguistics<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1746" to="1751" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">IMS at EmoInt-2017: Emotion intensity prediction with affective norms, automatically extended resources and deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maximilian</forename><surname>Köper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeny</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roman</forename><surname>Klinger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis. Workshop at Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics</title>
		<meeting>the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis. Workshop at Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Fontlex: A typographical lexicon based on affective associations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tugba</forename><surname>Kulahcioglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerard</forename><surname>De Melo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">;</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Khalid</forename><surname>Choukri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Cieri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thierry</forename><surname>Declerck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sara</forename><surname>Goggi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koiti</forename><surname>Hasida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hitoshi</forename><surname>Isahara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bente</forename><surname>Maegaard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th Language Resources and Evaluation Conference (LREC 2018). European Language Resources Association (ELRA)</title>
		<meeting>the 11th Language Resources and Evaluation Conference (LREC 2018). European Language Resources Association (ELRA)<address><addrLine>Joseph Mariani,Héì ene Mazo, Asuncion Moreno, Jan Odijk; Paris, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>Stelios Piperidis, and Takenobu Tokunaga</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Paralinguistic recommendations for affective word clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tugba</forename><surname>Kulahcioglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gerard De Melo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACM IUI</title>
		<meeting>ACM IUI</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title/>
		<idno type="doi">10.1145/3301275.3302327</idno>
		<ptr target="https://doi.org/10.1145/3301275.3302327" />
		<imprint>
			<publisher>ACM</publisher>
			<biblScope unit="page" from="132" to="143" />
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
		<ptr target="http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>C. J. C. Burges, L. Bottou, M. Welling, Z. Ghahramani, and K. Q. Weinberger</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2013" />
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Word affect intensities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saif</forename><surname>Mohammad</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/L18-1027" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th Language Resources and Evaluation Conference. European Language Resource Association</title>
		<meeting>the 11th Language Resources and Evaluation Conference. European Language Resource Association<address><addrLine>Miyazaki, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">WASSA-2017 shared task on emotion intensity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saif</forename><surname>Mohammad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felipe</forename><surname>Bravo-Marquez</surname></persName>
		</author>
		<idno type="doi">10.18653/v1/W17-5205</idno>
		<ptr target="https://doi.org/10.18653/v1/W17-5205" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis</title>
		<meeting>the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="34" to="49" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Emotion intensities in tweets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Saif</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felipe</forename><surname>Mohammad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bravo-Marquez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th Joint Conference on Lexical and Computational Semantics (*SEM)</title>
		<meeting>the 6th Joint Conference on Lexical and Computational Semantics (*SEM)<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Crowdsourcing a word-emotion association lexicon</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Saif</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><forename type="middle">D</forename><surname>Mohammad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Turney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Intelligence</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="436" to="465" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Borut Sluban, and Igor Mozetič</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petra</forename><forename type="middle">Kralj</forename><surname>Novak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jasmina</forename><surname>Smailovi´csmailovi´c</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Plos One</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">12</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>Sentiment of emojis</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title/>
		<idno type="doi">10.1371/journal.pone.0144296</idno>
		<ptr target="https://doi.org/10.1371/journal.pone.0144296" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Distant supervision for emotion classification task using emoji 2 emotion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aisulu</forename><surname>Rakhmetullina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dietrich</forename><surname>Trautmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georg</forename><surname>Groh</surname></persName>
		</author>
		<ptr target="http://ceur-ws.org" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st International Workshop on Emoji Understanding and Applications in Social Media</title>
		<meeting>the 1st International Workshop on Emoji Understanding and Applications in Social Media<address><addrLine>Stanford, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2130</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Reinforcement knowledge graph reasoning for explainable recommendation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yikun</forename><surname>Xian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zuohui</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Muthukrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerard</forename><surname>De Melo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongfeng</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="doi">10.1145/3331184.3331203</idno>
		<ptr target="https://doi.org/10.1145/3331184.3331203" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGIR 2019</title>
		<meeting>SIGIR 2019<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="285" to="294" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Mojitalk: Generating emotional responses at scale. arXiv 1711</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xianda</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William Yang</forename><surname>Wang</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1711.04090v1" />
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
