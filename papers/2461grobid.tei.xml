<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2020-09-29T02:42+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Open access to the Proceedings of the 17th USENIX Conference on File and Storage Technologies (FAST &apos;19) is sponsored by OpenEC: Toward Unified and Configurable Erasure Coding Management in Distributed Storage Systems This paper is included in the Proceedings of the 17th USENIX Conference on File and Storage Technologies (FAST &apos;19). OpenEC: Toward Unified and Configurable Erasure Coding Management in Distributed Storage Systems</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>February 25-28, 2019</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolu</forename><surname>Li</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Runhui</forename><surname>Li</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><forename type="middle">P C</forename><surname>Lee</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuchong</forename><surname>Hu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolu</forename><surname>Li</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">The Chinese University of Hong Kong ‡ Huazhong University of Science and Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">†</forename></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Runhui</forename><surname>Li</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">The Chinese University of Hong Kong ‡ Huazhong University of Science and Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">†</forename></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><forename type="middle">P C</forename><surname>Lee</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">The Chinese University of Hong Kong ‡ Huazhong University of Science and Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuchong</forename><surname>Hu</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">The Chinese University of Hong Kong</orgName>
								<orgName type="institution" key="instit2">Huazhong University of Science and Technology</orgName>
								<address>
									<settlement>Boston</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Open access to the Proceedings of the 17th USENIX Conference on File and Storage Technologies (FAST &apos;19) is sponsored by OpenEC: Toward Unified and Configurable Erasure Coding Management in Distributed Storage Systems This paper is included in the Proceedings of the 17th USENIX Conference on File and Storage Technologies (FAST &apos;19). OpenEC: Toward Unified and Configurable Erasure Coding Management in Distributed Storage Systems</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published">February 25-28, 2019</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Erasure coding becomes a practical redundancy technique for distributed storage systems to achieve fault tolerance with low storage overhead. Given its popularity, research studies have proposed theoretically proven erasure codes or efficient repair algorithms to make erasure coding more viable. However, integrating new erasure coding solutions into existing distributed storage systems is a challenging task and requires non-trivial re-engineering of the underlying storage workflows. We present OpenEC, a unified and configurable framework for readily deploying a variety of erasure coding solutions into existing distributed storage systems. OpenEC decouples erasure coding management from the storage work-flows of distributed storage systems, and provides erasure coding designers with configurable controls of erasure coding operations through a directed-acyclic-graph-based programming abstraction. We prototype OpenEC on two versions of HDFS with limited code modifications. Experiments on a local cluster and Amazon EC2 show that OpenEC preserves both the operational performance and the properties of erasure coding solutions; OpenEC can also automatically optimize erasure coding operations to improve repair performance.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Erasure coding provides a low-cost redundancy mechanism for fault-tolerant storage, and is now widely deployed in today's distributed storage systems (DSSs). Examples include enterprise-level DSSs <ref type="bibr" target="#b12">[15,</ref><ref type="bibr" target="#b18">21,</ref><ref type="bibr" target="#b27">30]</ref> and many open-source DSSs <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b5">7,</ref><ref type="bibr" target="#b28">31,</ref><ref type="bibr" target="#b51">54,</ref><ref type="bibr" target="#b52">55]</ref>. Unlike replication that simply creates identical data copies for redundancy protection, erasure coding introduces much less storage overhead through the coding operations of data copies, while preserving the same degree of fault tolerance <ref type="bibr" target="#b50">[53]</ref>. Modern DSSs mostly realize erasure coding based on the classical Reed-Solomon (RS) codes <ref type="bibr" target="#b40">[43]</ref>, yet RS codes have high performance penalty, especially in repairing lost data when failures happen. Thus, research studies have proposed new erasure coding solutions with improved performance, such as erasure codes with theoretical guarantees and efficient repair algorithms that are applicable to general erasure-coding-based storage ( §6).</p><p>However, deploying new erasure coding solutions in DSSs is a daunting task. Existing studies often integrate new erasure coding solutions into specific DSSs by re-engineering the DSS workflows (e.g., the read/write paths). The tight coupling between erasure coding management and the DSS workflows makes new erasure coding solutions hard to be generalized for other DSSs and further enhanced. Some DSSs with built-in erasure coding features (e.g., HDFS with erasure coding <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b4">5]</ref>, Ceph <ref type="bibr" target="#b51">[54]</ref>, and Swift <ref type="bibr" target="#b5">[7]</ref>) provide certain configuration capabilities, such as interfaces for implementing various erasure codes and controlling erasure-coded data placement, yet the interfaces are rather limited and it is nontrivial to extend the DSSs with more advanced erasure codes and repair algorithms ( §2.2). How to fully realize the power of erasure coding in DSSs remains a challenging issue.</p><p>We present OpenEC, a unified and configurable framework for erasure coding management in DSSs, with the primary goal of bridging the gap between designing new erasure coding solutions and enabling the feasible deployment of such new solutions in DSSs. Inspired by software-defined storage <ref type="bibr" target="#b13">[16,</ref><ref type="bibr" target="#b45">48,</ref><ref type="bibr" target="#b48">51]</ref>, which aims for configurable storage management without being constrained by the underlying storage architecture, we apply this concept into erasure coding management. Our main idea is to decouple erasure coding management from the DSS workflows. Specifically, OpenEC runs as a middleware system between upper-layer applications and the underlying DSS, and is responsible for performing all erasure coding operations on behalf of the DSS. Such a design relaxes the stringent dependence on the erasure coding support of DSSs. More importantly, OpenEC takes the full responsibility of erasure coding management, and hence provides flexibility for erasure coding designers to (i) incorporate a variety of erasure coding solutions, (ii) configure the workflows of erasure coding operations, and (iii) decide the placement of both erasure-coded data and erasure coding operations across storage nodes. Our contributions are summarized as follows:</p><p>• We propose a new programming model for erasure coding implementation and deployment. Our model builds on an abstraction called an ECDAG, a directed acyclic graph that defines the workflows of erasure coding operations. We show how we feasibly realize a general erasure coding solution through the ECDAG abstraction.</p><p>• We design OpenEC, which translates an ECDAG into erasure coding operations atop a DSS. OpenEC supports encoding operations on or off the write path as well as various state-of-the-art repair operations. In particular, it can automatically optimize an ECDAG for hierarchical topologies to improve repair performance.</p><p>• We implement a prototype of OpenEC on HDFS-RAID <ref type="bibr" target="#b4">[5]</ref> and Hadoop 3.0 HDFS (HDFS-3) <ref type="bibr" target="#b0">[1]</ref>. Its integrations into HDFS-RAID and HDFS-3 only require limited code changes (with no more than 450 LoC).</p><p>• We evaluate OpenEC on a local cluster and Amazon EC2.</p><p>OpenEC incurs negligible performance overhead in DSS operations, supports various state-of-the-art erasure codes and repair algorithms, and increases the repair throughput by at least 82% through automatically customizing an ECDAG for a hierarchical topology.</p><p>The source code of our OpenEC prototype is available at: http://adslab.cse.cuhk.edu.hk/software/openec.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background and Motivation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Erasure Coding Basics</head><p>Consider a DSS that comprises multiple storage nodes and organizes data in units of blocks. We construct erasure coding as an (n, k) code with two configurable parameters n and k, where k &lt; n. For every k fixed-size original blocks (called data blocks), an (n, k) code encodes them into n − k redundant blocks of the same size (called parity blocks), such that any k out of the n erasure-coded blocks (including both data and parity blocks) can decode the k data blocks; that is, any n − k block failures can be tolerated. We call the collection of n erasure-coded blocks a coding group. A DSS encodes different sets of k data blocks independently, and distributes the n erasure-coded blocks of each coding group across n storage nodes to protect against any n − k storage node failures. In this paper, our discussion focuses on the coding operations (i.e., encoding or decoding) of a single coding group.</p><p>For performance reasons, a DSS implements coding operations in small-size units called packets, while the read/write units are in blocks; for example, our experiments set the default packet and block sizes as 128 KiB and 64 MiB, respectively). It divides a block into multiple packets, and encodes the packets at the same block offsets in a coding group together. Thus, instead of first reading the whole blocks to start coding operations, a DSS can perform packet-level coding operations, while reading the whole blocks, in a pipelined manner. To simplify our discussion, we use blocks as the units of coding operations, and only differentiate packets and blocks in our implementation ( §4.5).</p><p>Given the prevalence of failures, repairs are frequent operations in DSSs <ref type="bibr" target="#b37">[40]</ref>. We consider two types of repairs: (i) degraded reads, which decode the unavailable data blocks that are being requested, and (ii) full-node recovery, which decodes all lost blocks of a failed storage node. Since repairs trigger substantial traffic <ref type="bibr" target="#b37">[40]</ref>, achieving high repair performance is important in erasure coding deployment. RS codes <ref type="bibr" target="#b40">[43]</ref> are the most popular erasure codes that are widely used in production <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">7,</ref><ref type="bibr" target="#b12">15,</ref><ref type="bibr" target="#b28">31,</ref><ref type="bibr" target="#b51">54,</ref><ref type="bibr" target="#b52">55]</ref>, but they incur high repair costs. Thus, many repair-friendly erasure codes have been proposed. Since single-failure repairs (i.e., repairing a single lost block of a coding group in degraded reads or a single failed node in full-node recovery) are the most common repair scenarios <ref type="bibr" target="#b18">[21,</ref><ref type="bibr" target="#b37">40]</ref>, existing repair-friendly erasure codes aim to minimize the repair bandwidth or I/O in singlefailure repairs. Examples are regenerating codes <ref type="bibr" target="#b11">[14]</ref>, including minimum-storage regenerating (MSR) and minimumbandwidth regenerating (MBR) codes, as well as locally repairable codes (LRCs) <ref type="bibr" target="#b18">[21,</ref><ref type="bibr" target="#b20">23,</ref><ref type="bibr" target="#b41">44,</ref><ref type="bibr" target="#b46">49]</ref>.</p><p>Our work focuses on practical erasure codes. In particular, we target linear codes, which include RS codes, MSR and MBR codes, as well as LRCs. Linear codes perform linear coding operations based on the Galois field arithmetic <ref type="bibr" target="#b14">[17]</ref>. Mathematically, for an (n, k) code, let d 0 , · · · , d k−1 be the k data blocks, and p 0 , · · · , p n−k−1 be the n − k parity blocks. Each parity block p j (0 ≤ j ≤ n − k − 1) can be expressed as p j = ∑ k−1 i=0 γ ji d i , where γ ji is some coding coefficient for computing p j . Note that the linear operations are additive associative (i.e., independent of how additions are grouped).</p><p>Also, our work addresses sub-packetization, which is used in various designs of MSR and MBR codes <ref type="bibr" target="#b11">[14,</ref><ref type="bibr" target="#b15">18,</ref><ref type="bibr" target="#b29">32,</ref><ref type="bibr" target="#b36">39,</ref><ref type="bibr" target="#b39">42,</ref><ref type="bibr" target="#b42">45,</ref><ref type="bibr" target="#b47">50,</ref><ref type="bibr" target="#b49">52]</ref>. Sub-packetization divides each block into smallersize sub-blocks, so that repairs can be done by retrieving sub-blocks rather than whole blocks.</p><p>Most DSSs assume that all erasure-coded blocks are immutable and do not support in-place updates. Thus, we focus on four basic operations: writes, normal reads, degraded reads, and full-node recovery ( §4.2), while we address inplace updates in future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Limitations of Erasure Coding Management</head><p>Modern DSSs now support erasure coding, yet existing erasure coding management in such DSSs remains stringent and still faces practical limitations. To motivate our study, we review six state-of-the-art DSSs that currently realize erasurecoded storage: HDFS-RAID <ref type="bibr" target="#b4">[5]</ref>, HDFS-3 <ref type="bibr" target="#b0">[1]</ref>, QFS <ref type="bibr" target="#b28">[31]</ref>, Tahoe-LAFS <ref type="bibr" target="#b52">[55]</ref>, Ceph <ref type="bibr" target="#b51">[54]</ref>, and Swift <ref type="bibr" target="#b5">[7]</ref>. HDFS-RAID is the erasure coding extension of HDFS <ref type="bibr" target="#b43">[46]</ref> in the earlier version of Hadoop. Here, we focus on Facebook's HDFS-RAID implementation <ref type="bibr" target="#b2">[3]</ref>, which builds on Hadoop version 0.20. HDFS-3 builds on the newer Hadoop version 3.0, which includes erasure coding by design. QFS resembles HDFS and includes erasure coding by design. All HDFS-RAID, HDFS-3, and QFS organize data in fixed-size blocks. In contrast, Tahoe-LAFS, Ceph, and Swift organize data in variable-size objects and partition each object into equal-size data blocks for erasure coding.</p><p>(L1) Limited support for adding advanced erasure codes: Existing DSSs provide encoding/decoding interfaces for implementing new erasure codes. However, most DSSs do not provide interfaces for adding erasure codes with subpacketization (e.g., MSR and MBR codes <ref type="bibr" target="#b11">[14,</ref><ref type="bibr" target="#b15">18,</ref><ref type="bibr" target="#b29">32,</ref><ref type="bibr" target="#b36">39,</ref><ref type="bibr" target="#b39">42,</ref><ref type="bibr" target="#b42">45,</ref><ref type="bibr" target="#b47">50,</ref><ref type="bibr" target="#b49">52]</ref>) and handling erasure-coded blocks at the granularity of sub-blocks, while only recently Ceph includes the sub-packetization feature in its master codebase <ref type="bibr" target="#b49">[52]</ref>. Also, recent erasure codes <ref type="bibr" target="#b16">[19,</ref><ref type="bibr" target="#b35">38]</ref> address the hierarchical nature of DSSs to reduce cross-rack <ref type="bibr" target="#b16">[19]</ref> (or cross-cluster <ref type="bibr" target="#b35">[38]</ref>) repair traffic, yet realizing such hierarchy-aware erasure codes needs modifications to the DSS workflows. (L2) Limited configurability for workflows of coding operations: Enabling configurable workflows of coding operations allows better resource usage within a DSS. Take repairs (degraded reads or full-node recovery) as an example. DSSs execute repairs at different entities upon the detection of failures. For a degraded read, it is executed at the client (in HDFS-RAID, HDFS-3, QFS, and Tahoe-LAFS), the proxy (in Swift), or a storage node (in Ceph); for full-node recovery, it is executed at either storage nodes (in HDFS-RAID, HDFS-3, QFS, Ceph, and Swift) or the client (in <ref type="table">Tahoe-LAFS)</ref>. Both degraded reads and full-node recovery operate in a fetch-andcompute manner, in which the entity that executes the repair will retrieve available blocks from other non-failed storage nodes and reconstruct the lost blocks. On the other hand, besides the fetch-and-compute approach, we cannot configure a DSS to adopt different repair workflows or distribute the repair loads across storage nodes. For example, recent repair algorithms <ref type="bibr" target="#b22">[25,</ref><ref type="bibr" target="#b26">29]</ref> decompose a single-block repair operation into partial sub-block repair operations that are parallelized across storage nodes for better bandwidth usage, but existing DSSs do not support this feature by design. (L3) Limited configurability for placement of coding operations: All DSSs we consider ensure that the n erasurecoded blocks of each coding group are stored in n distinct storage nodes, and most of them additionally allow configurable block placement. For example, both HDFS-RAID and HDFS-3 provide a base class for configuring block placement policies; QFS provides an in-rack placement option to store multiple blocks in a rack; Ceph uses placement groups, while Swift uses object rings, to control how erasure-coded blocks are placed in different storage nodes.</p><p>However, existing DSSs focus on how erasure-coded blocks are placed after encoding, but do not specify where to perform the coding operations. For example, in encoding operations, we may want to co-locate the computations of parity blocks at one storage node (rather than distribute the computations across different storage nodes) to limit the I/Os of retrieving data blocks. Also, the repair algorithms in <ref type="bibr" target="#b22">[25,</ref><ref type="bibr" target="#b26">29]</ref> require some storage nodes that store available data blocks to first compute partially decoded blocks and send the results to other storage nodes for further decoding. In this case, we need to place the partial decoding operations at specific storage nodes. Such fine-grained placement of coding operations is currently not supported in existing DSSs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Lessons Learned and Goals</head><p>The root cause of the limitations in §2.2 is that the current erasure coding management is tightly coupled with the DSS workflows. Realizing erasure coding in DSSs needs to address how coding operations are performed (i.e., the control flow) and how erasure-coded blocks are stored and accessed (i.e., the data flow). The current practice is that erasure coding designers only define an erasure code and its coding operations (e.g., the coding coefficients used in coding operations), while DSS developers require dedicated engineering efforts to integrate the coding operations into the read/write paths of DSSs without compromising the correctness of upper-layer applications. Such tight coupling makes the extensions of erasure coding features inflexible.</p><p>OpenEC decouples erasure coding management from the underlying DSS by providing a unified and configurable framework for erasure coding management, such that erasure coding designers can leverage OpenEC to realize new erasure coding solutions and configure the workflows of coding operations, without worrying how they are integrated into the DSS workflows. Specifically, OpenEC addresses the limitations in §2.2 with the following goals: (i) extensibility of new erasure codes; (ii) configurable workflows of coding operations; and (iii) configurable placement of both erasurecoded blocks and coding operations. To achieve these goals, OpenEC builds on a programming model for erasure coding management, as elaborated in the following sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Programming Model</head><p>We propose a programming model that allows erasure coding designers to not only define an erasure code structure and its coding operations, but also configure how coding operations are performed in a DSS. We present a new erasure coding abstraction called an ECDAG ( §3.1), followed by three primitives for constructing an ECDAG ( §3.2). We then propose a programming interface for realizing an erasure code based on the ECDAG abstraction ( §3.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">ECDAG Overview</head><p>At a high level, an ECDAG is a directed acyclic graph that describes the workflows of coding operations of a coding group of an erasure code. Each vertex represents a block in the coding group, and the connections among vertices describe how vertices are related by linear combinations. To address the limitations in §2.2, we design ECDAGs to work for general linear codes (L1 addressed). Also, we can construct different ECDAGs to configure how and where coding operations are performed (L2 and L3 addressed, respectively).</p><p>Consider a coding group of an (n, k) code with n erasurecoded blocks; to simplify our discussion, we do not consider sub-packetization first. We index the blocks from 0 to n − 1, and let b i denote the block with index i. Without loss of generality, we refer to b 0 , · · · , b k−1 as k data blocks, and b k , · · · , b n−1 as n − k parity blocks. In some cases (see below), the coding operations may generate some intermediately computed blocks that will not be finally stored (as opposed to blocks b 0 , b 1 , · · · , b n−1 ). We call such blocks virtual blocks, and denote a virtual block by b i for some i ≥ n.</p><p>In an ECDAG, let v i (i ≥ 0) be a vertex that maps to block </p><formula xml:id="formula_0">b i ; we call a vertex v i (i ≥ n) that maps to a virtual block b i a virtual vertex. Let e i, j (i, j ≥ 0) be a directed edge from v i</formula><p>to v j indicating that b i is an input to the linear combination for computing b j . Each edge is associated with a coding coefficient for the linear combination. If there exists an edge e i, j , we say that v j is the parent of v i , while v i is a child of v j .</p><p>A vertex can have any number of parents and children. Both encoding and decoding operations are each associated with an ECDAG. The ECDAG for encoding is constructed at the beginning of the encoding operation to describe how data blocks are linearly combined to form each parity block. In contrast, the ECDAG for decoding is constructed on demand depending on what blocks are currently available.</p><p>For example, consider a (5, 4) code (i.e., (4+1)-RAID-5). We can parallelize partial decoding operations as in PPR <ref type="bibr" target="#b26">[29]</ref> by constructing another ECDAG for decoding b 0 (see <ref type="figure" target="#fig_1">Figure 1</ref>(c)), in which we first compute in parallel the partially decoded blocks b 5 and b 6 (both of which are virtual blocks) from b 1 and b 2 and from b 3 and b 4 , respectively, followed by computing b 0 from b 5 and b 6 . This shows that we can flexibly configure coding operations by constructing different ECDAGs. Note that PPR needs to compute b 5 and b 6 at the storage nodes where data blocks (e.g., b 2 and b 4 , respectively) are stored (see <ref type="bibr" target="#b26">[29]</ref> for details). We address this issue in §3.2.</p><p>We can also construct an ECDAG for erasure codes with sub-packetization. Let w be the number of sub-blocks per block (w = 1 means no sub-packetization). We index the sub-blocks of block b 0 from 0 to w − 1, those of b 1 from w to 2w − 1, and so on. Each vertex v i (i ≥ 0) now corresponds to the sub-block with index i, while any vertex v i for i ≥ nw is a virtual vertex. For example, consider the (4, 2) MISER code <ref type="bibr" target="#b42">[45]</ref> (an MSR code based on interference alignment), where w = 2.  <ref type="bibr" target="#b42">[45]</ref>, in which we first compute an encoded sub-block from each of other available blocks b 1 , b 2 , and b 3 (represented by the virtual vertices v 8 , v 9 , and v 10 , respectively), followed by using the encoded sub-blocks to decode the lost sub-blocks of b 0 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">ECDAG Primitives</head><p>An ECDAG can be constructed from three primitives: Join, BindX, and BindY. Join is used for constructing an ECDAG, while BindX and BindY control the placement of coding operations. Listing 1 shows their definitions in C++ format.</p><p>Join: It specifies how a parent vertex (with index pidx) is formed by the linear combinations of a list of child vertices (with indices in cidxs) and the corresponding coding coefficients (in coefs). For example, we deploy the (6, 4) RS code and encode four data blocks b 0 , b 1 , b 2 , and b 3 into two new parity blocks b 4 and b 5 . We can construct an ECDAG with Join as follows (see <ref type="figure" target="#fig_3">Figure 3</ref>(a)):</p><p>ECDAG* ecdag = new ECDAG(); ecdag-&gt;Join(4, {0,1,2,3}, {1,1,1,1}); ecdag-&gt;Join(5, {0,1,2,3}, {1,2,4,8});</p><p>BindX: It co-locates the coding operations of multiple vertices (with indices in idxs) that reside at the same level of an ECDAG (i.e., in the x-direction), so as to reduce I/O in coding operations. For example, in <ref type="figure" target="#fig_3">Figure 3</ref>(a), suppose that the data blocks being encoded are stored in different storage nodes. Without BindX, we need to compute b 4 and b 5 separately and retrieve each data block twice. Instead, we can call BindX on vertices v 4 and v 5 to create a new virtual vertex v 6 as follows (see <ref type="figure" target="#fig_3">Figure 3</ref>(b)):</p><formula xml:id="formula_1">int vidx = ecdag-&gt;BindX({4,5});</formula><p>This indicates that blocks b 4 and b 5 are first computed together at the same storage node before being distributed to different storage nodes. Now we only need to retrieve each data block once. Note that the index of v 6 (i.e., 6) is generated randomly and returned as vidx by BindX.  Listing 2: Erasure coding programming interface.</p><p>Thus, we compute parity blocks b 4 and b 5 at the same storage node that stores b 0 , thereby saving the I/Os of retrieving b 0 .</p><p>Note that BindY enables us to implement the repair algorithms (e.g., PPR <ref type="bibr" target="#b26">[29]</ref> and repair pipelining <ref type="bibr" target="#b22">[25]</ref>) that need to compute partially decoded blocks at the storage nodes that store the data blocks. For example, referring to Figure 1(c) for PPR, we can call BindY on v 2 and v 5 , and on v 4 and v 6 , to co-locate the computations of the partially decoded blocks b 4 and b 5 at the storage nodes that store b 2 and b 4 , respectively.</p><p>Remarks: We provide flexibility for erasure coding designers to construct any ECDAG using the above three primitives, yet this also puts burdens on erasure coding designers to configure coding operations. Nevertheless, OpenEC can also automatically call BindX and BindY on some specific subgraph structures of an ECDAG ( §4.4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Erasure Coding Interfaces</head><p>We provide a programming interface for realizing an erasure code. Unlike the traditional approach that takes data blocks as input and generates parity blocks, we program an erasure code through the construction of ECDAGs. OpenEC then parses the ECDAGs to perform the actual coding operations and store the erasure-coded blocks.</p><p>Listing 2 shows the erasure coding programming interface as a base class ECBase. To realize an erasure code, we (as erasure coding designers) inherit ECBase and first define all necessary member variables (e.g., n, k, w, and encoding coefficients) in the constructor method as in traditional erasure code programming. Note that we can store encoding coefficients in a generator matrix <ref type="bibr" target="#b32">[35]</ref> and compute decoding coefficients later based on the available blocks. We then implement three functions, namely Encode, Decode, and Place.</p><p>Encode: It constructs an ECDAG that describes the encoding operation. For example, to encode the (6, 4) RS code based on <ref type="figure" target="#fig_3">Figure 3(</ref> blocks (with indices in to). For example, we can implement Decode for a single lost block as in Listing 4, in which the decoding coefficients are computed based on the available blocks in from. In general, Decode constructs an ECDAG for one of the two scenarios: (i) decoding one lost block, in which we can choose an efficient single-failure repair approach (e.g., see <ref type="figure" target="#fig_0">Figure 2</ref>(c) for the (4, 2) MISER code); or (ii) decoding multiple lost blocks, in which we can choose any k available blocks (e.g., the first k blocks in from) to compute the decoding coefficients and decode all lost blocks.</p><p>Place: It configures how erasure-coded blocks are placed with hierarchy awareness. In addition to storing erasurecoded blocks in different storage nodes, we can configure how the blocks are grouped (e.g., in the same rack in rack-based DSSs). This supports fine-grained block placement configurations as in existing DSSs ( §2.2), and allows the realization of hierarchy-aware erasure codes <ref type="bibr" target="#b16">[19,</ref><ref type="bibr" target="#b35">38]</ref>. For example, we can divide n erasure-coded blocks into two groups via Place as in Listing 5. Note that BindX and BindY in ECDAG construction ( §3.2) address the placement of coding operations, while Place addresses the placement of erasure-coded blocks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">OpenEC Design</head><p>We design OpenEC to provide erasure coding management for a DSS. We show its architecture ( §4.1) and supported basic operations ( §4.2). We then describe how it parses ECDAGs to realize coding operations ( §4.3). We further show how it automatically optimizes coding operations ( §4.4). We conclude this section with the implementation details ( §4.5).  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Architectural Overview</head><p>OpenEC runs as a middleware system atop a DSS. We assume that the controller is reliable (i.e., no singlepoint-of-failure). Our measurements show that the controller can serve a request of parsing an ECDAG for coding operations in less than 0.3 ms in our local cluster ( §5), and hence it incurs limited overhead to basic operations.</p><p>Agent: Each agent performs coding operations as instructed by the controller. It accesses the erasure-coded blocks in HDFS through the HDFS client interface. Note that agents can communicate among themselves to perform coding operations and exchange erasure-coded blocks. We currently deploy each agent at a DataNode, so that the agent can access the local storage of the DataNode without network transfers.</p><p>OECClient: Each OECClient is associated with an agent, and serves as an interface between an upper-layer application and the agent. It connects to the agent via Redis-based communication ( §4.5). An application now accesses HDFS through an OECClient instead of an HDFS client. <ref type="bibr" target="#b0">1</ref> We also implement OpenEC atop QFS <ref type="bibr" target="#b28">[31]</ref>. See <ref type="bibr" target="#b24">[27]</ref> for details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Basic Operations</head><p>OpenEC supports four basic operations: (i) writes; (ii) normal reads; (iii) degraded reads; and (iv) full-node recovery. Writes: Note that HDFS-3 supports online encoding (i.e., clients perform encoding on the write path), while HDFS-RAID supports offline encoding (i.e., clients first write the data blocks in uncoded form, and the data blocks are later encoded in the background). OpenEC is currently designed to support both online and offline encoding. An OECClient specifies which encoding mode to use in a write request. For online encoding, OpenEC encodes data on a per-file basis. When an OECClient writes a file, its agent encodes every k data blocks into n − k parity blocks and writes the n erasurecoded blocks to n DataNodes through the HDFS client. For offline encoding, an OECClient first writes file data via its agent to HDFS. When OpenEC receives an encoding request, the controller parses the specified ECDAG ( §4.3) and instructs all agents to perform encoding, such that every k blocks are encoded into n erasure-coded blocks as a coding group. Normal reads: An OECClient issues normal reads (under no failures) via its agent, which connects to the DataNodes that store the uncoded data blocks and retrieves the data blocks from the DataNodes. Degraded reads: An OECClient issues degraded reads (under failures) via its agent, which connects to non-failed DataNodes and retrieves the available blocks for decoding the lost blocks based on the ECDAG specification. Full-node recovery: The controller coordinates the full-node recovery operation. When it receives a report of lost blocks from the NameNode, it informs the agents to repair the lost blocks based on the ECDAG specification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Parsing an ECDAG</head><p>OpenEC parses ECDAGs to perform coding operations in writes (online or offline encoding), degraded reads, and fullnode recovery. Given an ECDAG, OpenEC decomposes a coding operation into multiple tasks, each of which is executed by an agent. Each task operates in blocks (or sub-blocks in sub-packetization). There are four types of tasks:</p><p>• Load: It loads a block into memory from the agent's input stream, which could be either the OECClient if the block is from upper-layer applications, or the HDFS client if the block is from HDFS.</p><p>• Fetch: It retrieves blocks from other agents.</p><p>• Compute: It computes a block based on the linear combination of blocks and coding coefficients.</p><p>• Persist: It either writes a block to HDFS via the HDFS client, or returns the block to an OECClient.</p><p>Parsing procedure: OpenEC performs topological sorting of an ECDAG (based on depth-first search) to identify the vertex sequence of coding operations. It then assigns tasks to each vertex based on the ECDAG structure. Depending on the Vertices Nodes types of basic operations, OpenEC may perform coding operations on the client side (for online encoding and degraded reads) or distribute the coding operations across storage nodes (for offline encoding and full-node recovery).</p><formula xml:id="formula_2">Tasks v 0 C Load b 0 v 1 C Load b 1 v 2 C Load b 2 v 3 C Load b 3 v 6 C Compute b 4 from {b 0 , b 1 , b 2 , b 3 } with coding coefficients {1,1,1,1}; Compute b 5 from {b 0 , b 1 , b 2 , b 3 } with coding coefficients {1,2,4,8} v 4 C - v 5 C - - C Persist b 0 ; Persist b 1 ; Persist b 2 ; Persist b 3 ; Persist b 4 ; Persist b 5 (a) Online encoding Vertices Nodes Tasks v 0 N 0 Load b 0 v 1 N 1 Load b 1 v 2 N 2 Load b 2 v 3 N 3 Load b 3 v 6 N 0 Fetch b 1 from N 1 ; Fetch</formula><p>OpenEC associates tasks with different types of vertices. At a high level, the Load task is associated with a vertex without any child; the Fetch task is associated with a parent vertex that has a child vertex; the Compute task is associated with a vertex with more than one child for the linear combination; the Persist task is associated with a vertex without any parent, while it is also associated with a vertex without any child in the case of online encoding (see the example below). Example: We show the parsing procedure via an example. Suppose that we encode four data blocks (i.e., b 0 , b 1 , b 2 , and b 3 ) to generate two parity blocks (i.e., b 4 and b 5 ) using the (6, 4) RS code, based on the ECDAG in <ref type="figure" target="#fig_3">Figure 3(c)</ref> and the Encode function in Listing 3. <ref type="table" target="#tab_2">Table 1</ref> shows the vertex sequence of tasks for both online and offline encoding.</p><p>For online encoding (see <ref type="table" target="#tab_2">Table 1</ref>(a)), the client-side agent (denoted by C) performs all coding operations. It finally persists all data blocks and parity blocks into HDFS.</p><p>For offline encoding (see <ref type="table" target="#tab_2">Table 1</ref> Since v 4 and v 5 have no parent and are the last vertices in the topological order, they persist the blocks to HDFS. Note that OpenEC can parallelize the coding operations on the vertices that have no dependencies on others. For example, OpenEC can simultaneously execute the tasks for v 0 , v 1 , v 2 , and v 3 , and similarly the tasks for v 4 and v 5 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Automated Optimizations</head><p>In addition to letting erasure coding designers construct ECDAGs, OpenEC can automatically customize ECDAGs for performance optimizations to save manual configuration efforts. We address this in two aspects. Automated BindX and BindY: OpenEC can automatically call BindX and BindY for some specific subgraph structures of an ECDAG. For BindX, OpenEC examines all parent vertices that have more than one child vertex in an ECDAG. If multiple parent vertices have the same set of child vertices, OpenEC calls BindX on those parent vertices (e.g., v 4 and v 5 in <ref type="figure" target="#fig_3">Figure 3(b)</ref>). For BindY, for any parent vertex (with one or more child vertices), OpenEC calls BindY on the parent vertex and any one of the child vertices (e.g., the parent vertex v 6 and the child vertex v 0 in <ref type="figure" target="#fig_3">Figure 3(c)</ref>). Hierarchy awareness: OpenEC can further enhance the repair performance based on the physical DSS topology. One scenario is that a DSS hierarchically organizes storage nodes in racks <ref type="bibr" target="#b16">[19]</ref> (or clusters <ref type="bibr" target="#b35">[38]</ref>), such that the cross-rack bandwidth is much more constrained than the inner-rack bandwidth. OpenEC can transform an ECDAG into a pipelined ECDAG, so as to mitigate the cross-rack traffic. Our idea is based on repair pipelining <ref type="bibr" target="#b22">[25]</ref>, which pipelines partial coding operations across multiple storage nodes. We additionally perform all partial coding operations within a rack before sending the partial coding results to another rack. To illustrate, suppose that we deploy an (n, k) RS code with k = 6. We want to repair a lost block b 0 from six other available blocks b 1 , b 2 , b 3 , b 4 , b 5 , and b 6 , such that blocks b 1 , b 3 , and b 5 are in one rack, while blocks b 2 , b 4 , and b 6 are in another rack. We also want to store the reconstructed block b 0 at the same rack as b 2 , b 4 , and b 6 . The conventional repair approach is to retrieve all six available blocks and construct an ECDAG as in <ref type="figure" target="#fig_7">Figure 5</ref>(a). Then we need to transfer three blocks (i.e., b 1 , b 3 , and b 5 ) across racks. Instead, OpenEC can automatically construct another ECDAG as in <ref type="figure" target="#fig_7">Figure 5(b)</ref>, in which it first </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Implementation</head><p>We implement an OpenEC prototype in C++ with around 7K LoC. We use Intel's Intelligent Storage Acceleration Library (ISA-L) <ref type="bibr">[6]</ref> to implement erasure coding functionalities. Here, we highlight several implementation details of OpenEC.</p><p>From blocks to packets: OpenEC performs coding operations in units of packets to improve performance, while the read/write operations are still in units of blocks ( §2.1). By default, the packet size is 128 KiB. For encoding (both online and offline), OpenEC writes n erasure-coded packets to n DataNodes; in the case of sub-packetization, each packet is divided into sub-packets. If a DataNode receives an amount of packet data equal to the HDFS block size (64 MiB by default), it seals the block and stores additional packets in a different block. The n sealed erasure-coded blocks then form a coding group. Note that while OpenEC is sending packets to DataNodes, it can start encoding for the next group of packets. Thus, both the sending and encoding operations can be done in parallel. Similarly, OpenEC performs decoding (for degraded reads and full-node recovery) at the packet level. As OpenEC performs packet-level coding operations, the block layouts differ in online and offline encoding. For online encoding, OpenEC adopts a striped layout as in HDFS-3 <ref type="bibr" target="#b3">[4]</ref>, as it stripes file data across blocks at the granularities of packets. For offline encoding, OpenEC adopts a contiguous layout, as the file data is first stored in a block before encoding. <ref type="figure">Figure 6</ref> depicts both block layouts. Internal communication: OpenEC uses Redis <ref type="bibr" target="#b6">[8]</ref> for internal communications among the controller, agents, and OECClient. Each agent maintains a local in-memory key-value Redis store. The controller sends the task instructions of coding operations to an agent via the Redis client, and the task instructions are buffered at the agent for subsequent processing. Agent-to-agent communications are pull-based via the Fetch tasks ( §4.3), such that the sender agent buffers the blocks to be sent in its local Redis store, and the receiver fetches the buffer via the Redis client. Each OECClient also communicates with its associated agent via Redis. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Evaluation</head><p>We conduct testbed experiments on OpenEC. We summarize our major findings on OpenEC: (i) it preserves the performance of HDFS-RAID and HDFS-3 in erasure coding deployment ( §5.2); (ii) it supports various state-of-the-art erasure coding solutions and preserves their properties, especially in network-bound environments ( §5.3); (iii) it can automatically optimize the repair performance for a hierarchical topology ( §5.4); and (iv) it achieves scalable performance in real cloud environments ( §5.5).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Setup</head><p>Testbeds: We evaluate OpenEC on both a local cluster ( §5.2- §5.4) and Amazon EC2 ( §5.5). Our local cluster testbed comprises 16 machines, each of which has a quad-core 3.  as the default DSS for OpenEC, except when we compare OpenEC with HDFS-RAID. Regarding the automated optimization features ( §4.4), our experiments enable automated BindX and BindY, except when we evaluate the original performance of erasure codes without OpenEC optimization in §5.3 and when we evaluate BindX and BindY in §5.4. We also disable hierarchy-aware repairs until we evaluate this feature in §5.4. We assign a dedicated machine to serve both the OpenEC controller and the HDFS NameNode, while each remaining machine serves an OECClient, an OpenEC agent, an HDFS client, and an HDFS DataNode. We plot the average results over 10 runs, including the error bars showing the maximum and minimum of the 10 runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>HDFS-RAID OpenEC</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Performance of Basic Operations</head><p>We compare OpenEC with HDFS-RAID and HDFS-3 in terms of basic operations using our local cluster. As OpenEC adds another software layer between upper-layer applications and the underlying DSS, it may incur extra overhead. We show that such overhead (if any) is limited; in some cases, OpenEC even significantly improves performance. We also compare OpenEC with native coding performance and evaluate its performance for different block and packet sizes.</p><p>Single-client performance in online encoding: We first compare the single-client performance between HDFS-3 and OpenEC, both of which are configured with online encoding to generate erasure-coded data. Here, we use the (9, 6) RS code (as in QFS <ref type="bibr" target="#b28">[31]</ref>). We first write a file of size 384 MiB (i.e., six times the block size), and issue a normal read to the file without failures. We also issue a degraded read to the file with one data block deleted. <ref type="figure" target="#fig_8">Figure 7(a)</ref> shows the throughput results of writes, normal reads, and degraded reads. Both OpenEC and HDFS-3 have similar performance: OpenEC's throughput is slightly less than HDFS-3's by 2.36% in writes, and is slightly higher than HDFS-3's by 2.83% and 4.41% in normal reads and degraded reads, respectively.</p><p>Multi-client performance in online encoding: We compare the multi-client performance between HDFS-3 and OpenEC.</p><p>We run a total of five clients, each of which writes a file of size 384 MiB under the (9, 6) RS code. <ref type="figure" target="#fig_8">Figure 7(b)</ref> shows the aggregate throughput of all five clients in writes, normal reads, and degraded reads. OpenEC has lower aggregate throughput than HDFS-3 in writes by 1.95%, but higher aggregate throughput in normal reads and degraded reads by 12.9% and 8.97%, respectively. Nevertheless, considering the error bars in the figure, we do not see significant performance differences between OpenEC and HDFS-3.</p><p>Offline encoding: We compare the performance between HDFS-RAID and OpenEC in offline encoding. We now deploy OpenEC on HDFS-RAID for fair comparisons. We write 180 blocks, and use offline encoding to generate erasurecoded blocks using the (9, 6) RS code (i.e., a total of 30 coding groups). We then delete the blocks of one storage node and trigger full-node recovery. Here, we measure the offline encoding throughput (i.e., the amount of input data being encoded per unit time) and the full-node recovery throughput (i.e., the amount of lost data being recovered per unit time). Note that HDFS-RAID performs offline encoding and full-node recovery via MapReduce. To exclude the MapReduce startup overhead in our evaluation, we start an empty MapReduce job to measure its latency, and subtract this latency (which is around 20 s) in our evaluation of HDFS-RAID.</p><p>Note that OpenEC does not use MapReduce in offline encoding and full-node recovery. <ref type="figure" target="#fig_8">Figure 7</ref>(c) shows the results. Interestingly, OpenEC increases the offline encoding throughput of HDFS-RAID by 137%. We study the HDFS-RAID source code and find that the performance difference is mainly due to the extra step of HDFS-RAID in reading and re-writing all parity blocks into a single HDFS file after parity regeneration. For fullnode recovery, OpenEC has slightly higher throughput than HDFS-RAID by 7.9%, yet the two systems have limited differences considering the error bars.</p><p>Online vs. offline encoding: We further compare online and offline encoding in OpenEC versus the file size, and study the performance difference between the striped layout (in online encoding) and the contiguous layout (in offline encoding). We deploy OpenEC atop HDFS-3, and show that it allows both online and offline encoding atop HDFS-3 (which currently supports online encoding only).</p><p>We consider the single-client performance, in which a client uses the (12, 8) RS code and writes a file of size ranging from 1 MiB to 64 MiB (assuming that the file size is divisible by eight). For online encoding, OpenEC stripes the file  in packets across eight blocks and seals the blocks after the file write is completed (note that each block is less than the default block size 64 MiB); for offline encoding, OpenEC stores the file in a block and later encodes it with seven other blocks ( §4.2). We compare their performance in a normal read (without failures) and a degraded read (with one data block deleted) to the file; in offline encoding, we delete the data block that stores the file in our degraded read evaluation. <ref type="figure" target="#fig_8">Figure 7(d)</ref> shows the results. The throughput increases with the file size, since the data transfer performance becomes more dominant as the blocks become larger. We also see the performance differences in online and offline encoding. In online encoding, both normal reads and degraded reads show similar performance, in which the client issues reads to eight blocks in parallel. In offline encoding, its normal read throughput is much higher than that in online encoding (by 44-718%), as any slowdown in one of the parallel reads to online-encoded data can degrade the overall performance. However, the degraded read throughput in offline encoding is much less than that in online encoding especially for larger file sizes, as it needs to retrieve eight blocks (i.e., seven additional blocks over the original file) to recover the file. To validate our results, we conduct similar experiments using the original erasure coding implementations in HDFS-3 and HDFS-RAID (which realize online and offline encoding, respectively) and they show similar performance differences as in OpenEC (we omit the results here in the interest of space).</p><p>Comparisons with native coding operations: We compare the computational performance of the ECDAG-based coding operations with that of the native coding operations using ISA-L in HDFS-3. <ref type="figure" target="#fig_9">Figure 8(a)</ref> shows the encoding throughput for k 64-MiB blocks under (n, k) RS codes. ECDAG-based encoding has 29-38% lower throughput than native encoding, mainly because there is additional overhead for creating multiple compute tasks for computing the n − k parity blocks. <ref type="figure" target="#fig_9">Figure 8(b)</ref> shows the decoding throughput for decoding one block, in which ECDAG-based decoding has only slightly less throughput (by 0.6-3.2%) than native decoding, as there is only one compute task for decoding a single block. Nevertheless, compared to the overall read/write operations <ref type="figure" target="#fig_8">(Figure 7)</ref>, the computations of ECDAG-based coding are much faster and incur limited overhead. The performance degrades if the packet size is too small since there are many function calls for retrieving individual packets, or if the packet size is too large since there is less parallelism. To achieve high performance, our default setup chooses the block size as 64 MiB and the packet size as 128 KiB.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Support of Erasure Coding Designs</head><p>We realize several state-of-the-art repair-friendly erasure coding solutions based on the ECDAG abstraction. Recall from §2.1 that existing repair-friendly codes are designed to minimize the repair bandwidth or I/O in single-failure repairs. Thus, we focus on evaluating their performance of repairing one lost block in a coding group under OpenEC. We configure two bandwidth settings in our local cluster: 1 Gb/s and 10 Gb/s. For the 1 Gb/s case, network transfer becomes the bottleneck (compared to coding computations and disk I/O), and we expect that the empirical performance conforms to the theoretical gains. We use the conventional repair approach of RS codes as our baseline, in which it retrieves k blocks from k non-failed DataNodes to decode the lost block in a fetch-and-compute manner ( §2.2). We compare the conventional repair approach with the following solutions:</p><p>• LRC <ref type="figure" target="#fig_1">(Figure 10(a)</ref>): We compare RS codes with Azure's LRC <ref type="bibr" target="#b18">[21]</ref>. For RS codes, we set (n, k) = (9, 6); for LRC, we set (n, k) = (10, 6), in which there are two local parity blocks, each of which is encoded from a local group of three data blocks, and two global parity blocks that are encoded from all six data blocks.</p><p>• MSR codes <ref type="figure" target="#fig_1">(Figure 10(b)</ref>  MSR codes: MISER codes <ref type="bibr" target="#b42">[45]</ref> (which require n ≥ 2k) and Butterfly codes <ref type="bibr" target="#b29">[32]</ref> (which require n = k + 2). We consider the (6, 4) RS code, the (6, 4) Butterfly code, and the (8, 4) MISER code.</p><p>• Repair algorithms <ref type="figure" target="#fig_1">(Figure 10</ref>(c)): We study how the repair algorithms, namely PPR <ref type="bibr" target="#b26">[29]</ref> and repair pipelining <ref type="bibr" target="#b22">[25]</ref>, improve the repair performance of RS codes by parallelizing partial repair operations. We compare them with the conventional repair under the (9, 6) RS code.</p><p>• Double Regenerating Codes (DRC) <ref type="figure" target="#fig_1">(Figure 10(d)</ref>): We compare RS codes with DRC <ref type="bibr" target="#b16">[19]</ref> in a hierarchical network setting. We divide our local cluster into three logical racks. We use the Linux tc command to limit the bandwidth between any two storage nodes at different logical racks as 1 Gb/s <ref type="bibr" target="#b41">[44]</ref>, while the bandwidth between any two storage nodes within the same logical rack remains 10 Gb/s. We compare RS codes and DRC under (n, k) = (6, 4) and (n, k) = (9, 6). In both cases, we distribute the erasurecoded blocks of each coding group evenly across different nodes in three racks (with n/3 erasure-coded blocks each). <ref type="figure" target="#fig_1">Figure 10</ref> shows the results; for our comparisons, Table 2 also shows the theoretical throughput gains of the erasure coding solutions over the conventional repair approach for RS codes. For the 1 Gb/s network, we observe that the empirical throughput gains of the erasure coding solutions are consistent (with only slight degradations) with the theoretical throughput gains. For the 10 Gb/s network, the empirical gains decrease since the coding computation and disk I/O overheads become more significant. For example, MISER codes have less throughput than Butterfly codes in the 10 Gb/s network; the throughput gain of MISER codes drops to 1.25×, while that of Butterfly codes drops to 1.35× <ref type="figure" target="#fig_1">(Figure 10(b)</ref>). The reason is that both MSR codes retrieve data from n − 1 non-failed storage nodes for repairs, and MISER codes connect to more storage nodes than Butterfly codes (seven versus five) and incur higher disk I/O overhead. Overall, OpenEC preserves the properties of the erasure coding solutions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Improvements with Automated Optimizations</head><p>We now evaluate how OpenEC achieves performance gains via automated optimizations ( §4.4) for a hierarchical topology. We again configure a three-rack logical topology in our local cluster as in our DRC experiments in §5.3.</p><p>We first compare the offline encoding performance for three configurations: (i) automated optimization is disabled, (ii) only automated BindX is enabled, and (iii) both automated BindX and BindY are enabled (our default setting). We consider the <ref type="bibr" target="#b6">(8,</ref><ref type="bibr">6)</ref>, <ref type="bibr">(10,</ref><ref type="bibr" target="#b6">8)</ref>, and (12, 10) RS codes. We measure the throughput of offline encoding by writing 30 coding groups of blocks into HDFS-3 via OpenEC, which evenly distributes the blocks across three racks. <ref type="figure" target="#fig_1">Figure 11(a)</ref> shows that enabling only BindX increases the throughput by 37-42%, while enabling both BindX and BindY increases the throughput by 38-44%.</p><p>We also evaluate how OpenEC automatically improves the repair performance via the construction of a pipelined ECDAG. We delete all blocks of one storage node and trigger full-node recovery on the same node. <ref type="figure" target="#fig_1">Figure 11(b)</ref> shows that the repair optimization increases the repair throughput of OpenEC by 82-128%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Performance in Amazon EC2</head><p>We finally evaluate OpenEC in Amazon EC2. We configure three settings with N instances, where N = 10, 20, and 30 (see §5.1 for the instance type). One instance hosts the OpenEC controller and the HDFS NameNode, and each of the remaining N − 1 instances hosts an OECClient, an OpenEC agent, an HDFS client, and an HDFS DataNode. We consider the (9, 6) RS code, and all N − 1 clients issue different basic operations as in §5.2. <ref type="figure" target="#fig_0">Figure 12</ref> shows the results when OpenEC realizes online and offline encoding atop HDFS-3. We observe consistent throughput patterns as in our local cluster experiments in §5.2 (e.g., both normal reads and degraded reads have similar throughput). Also, the performance of OpenEC scales well with the number of instances. (a) Online encoding (b) Offline encoding <ref type="figure" target="#fig_0">Figure 12</ref>: Performance in Amazon EC2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related work</head><p>New erasure coding solutions: RS codes <ref type="bibr" target="#b40">[43]</ref> are widely deployed today (e.g., <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">7,</ref><ref type="bibr" target="#b12">15,</ref><ref type="bibr" target="#b28">31,</ref><ref type="bibr" target="#b51">54,</ref><ref type="bibr" target="#b52">55]</ref>), mainly for two reasons. First, RS codes are maximum distance separable (MDS), meaning that under the coding parameters (n, k), the fault tolerance against n − k block failures is achieved with the minimum storage redundancy (i.e., n/k times the original data). Second, RS codes support general coding parameters n and k (provided that k &lt; n). However, RS codes have high repair costs, and hence many new erasure coding solutions have been proposed to reduce the repair bandwidth or I/O. One direction of research is to design new erasure codes. Minimum-storage regenerating (MSR) codes <ref type="bibr" target="#b11">[14]</ref> minimize the repair bandwidth and preserve the MDS property. Followup studies design new MSR codes <ref type="bibr" target="#b15">[18,</ref><ref type="bibr" target="#b29">32,</ref><ref type="bibr" target="#b36">39,</ref><ref type="bibr" target="#b39">42,</ref><ref type="bibr" target="#b42">45,</ref><ref type="bibr" target="#b47">50,</ref><ref type="bibr" target="#b49">52]</ref>, some of which are evaluated in open-source DSSs (e.g., PM-RBT codes <ref type="bibr" target="#b36">[39]</ref> are evaluated in HDFS, while Butterfly <ref type="bibr" target="#b29">[32]</ref> and Clay <ref type="bibr" target="#b49">[52]</ref> codes are evaluated in Ceph). Aside MSR codes, some MDS codes incur slightly more repair bandwidth than the minimum point but can be easily constructed with any (n, k) (e.g., <ref type="bibr" target="#b21">[24,</ref><ref type="bibr" target="#b38">41]</ref>), while some non-MDS erasure codes trade more storage redundancy than MDS codes for less repair I/O (e.g., <ref type="bibr">[21-23, 33, 44, 49]</ref>). DRC <ref type="bibr" target="#b16">[19]</ref> minimizes the crossrack repair bandwidth in hierarchical topologies.</p><p>Another direction of research is to design efficient repair algorithms that apply to general erasure codes. Lazy repair <ref type="bibr" target="#b8">[11,</ref><ref type="bibr" target="#b44">47]</ref> reduces repair executions by deferring a repair until a threshold number of failures occurs. PPR <ref type="bibr" target="#b26">[29]</ref> and repair pipelining <ref type="bibr" target="#b22">[25]</ref> parallelize a single-failure repair across storage nodes. Proactive degraded reads <ref type="bibr" target="#b17">[20]</ref> mitigate tail latencies via the load balancing of read requests.</p><p>Unlike the above studies, OpenEC targets a different perspective and focuses on unified and configurable erasure coding management. It supports different new erasure codes and repair algorithms in a unified framework. Erasure coding programming: Several open-source libraries are available for erasure coding programming. Zfec <ref type="bibr">[10]</ref> implements RS codes and is used by Tahoe-LAFS <ref type="bibr" target="#b52">[55]</ref>. Jerasure <ref type="bibr" target="#b33">[36]</ref> is a C library that supports various erasure codes. It is later extended with GF-Complete <ref type="bibr" target="#b31">[34]</ref> to enable fast Galois Field arithmetic. ISA-L <ref type="bibr">[6]</ref> is another C library that supports various erasure codes, and it optimizes Galois Field arithmetic for Intel hardware. Both Jerasure and ISA-L libraries are widely used in production (e.g., Ceph and Hadoop 3.0). PyEClib <ref type="bibr" target="#b7">[9]</ref> is a Python library used by OpenStack Swift. It builds on liberasurecode <ref type="bibr" target="#b1">[2]</ref>, which unifies different erasure coding libraries including both Jerasure and ISA-L. OpenEC emphasizes the deployment of erasure codes in DSSs, and it can leverage the above libraries to implement erasure codes via the ECDAG abstraction. Configurable storage: There is an increasing demand of providing flexibility for storage system management and configuring different storage policies based on application requirements. Existing approaches rely on either client-side customization <ref type="bibr" target="#b9">[12,</ref><ref type="bibr" target="#b10">13,</ref><ref type="bibr" target="#b25">28,</ref><ref type="bibr" target="#b34">37]</ref> or the coordination by a centralized controller under the software-defined storage (SDS) framework <ref type="bibr" target="#b13">[16,</ref><ref type="bibr" target="#b45">48,</ref><ref type="bibr" target="#b48">51]</ref>. OpenEC borrows the same principle from SDS, but specifically focuses on configurable erasure coding management in distributed environments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions and Future Work</head><p>This paper presents OpenEC, a new framework that provides unified and configurable erasure coding management for distributed storage. It leverages the ECDAG abstraction to define erasure codes and configure the workflows of coding operations. Our OpenEC prototype achieves effective performance atop HDFS in both local cluster and Amazon EC2 environments, while supporting a variety of state-of-the-art erasure codes and repair algorithms. Our work sheds light on how to facilitate erasure coding designers to deploy erasure coding solutions in a simple and flexible manner. This paper currently focuses on HDFS, which organizes data in fixed-size blocks. Our technical report <ref type="bibr" target="#b24">[27]</ref> also describes how we integrate OpenEC into QFS <ref type="bibr" target="#b28">[31]</ref>. In future work, we study how OpenEC can be deployed in other DSSs, especially object-storage-based DSSs (e.g., Ceph and Swift) that organize data in variable-size objects.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Example for an ECDAG for a (4,2) code with w = 2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 (</head><label>1</label><figDesc>a) shows the ECDAG for the encoding operation, which states that the parity block b 4 is a linear combination of the four data blocks b 0 , b 1 , b 2 , and b 3 . Suppose now that block b 0 is lost. Figure 1(b) shows the ECDAG for the decoding operation for b 0 , which can be computed from other available blocks b 1 , b 2 , b 3 , and b 4 .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 (</head><label>2</label><figDesc>a) shows how the sub-blocks are void Join(int pidx, vector&lt;int&gt; cidxs, vector&lt;int&gt; coefs); int BindX(vector&lt;int&gt; idxs); void BindY(int pidx, int cidx); Listing 1: Primitives for ECDAG construction. indexed. Figure 2(b) shows the ECDAG for the encoding operation, in which the sub-blocks of parity blocks b 2 and b 3 are computed from the sub-blocks of data blocks b 0 and b 1 . Suppose that block b 0 is lost. Figure 2(c) shows the ECDAG for decoding b 0 based on MISER codes</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Construction of ECDAGs for the (6, 4) RS code.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: OpenEC architecture based on HDFS.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>As a proof of concept, we design OpenEC atop two implemen- tations of HDFS [46]: HDFS-RAID [5] and HDFS-3 [1] 1 . HDFS (including both HDFS-RAID and HDFS-3) comprises a NameNode that coordinates the storage in units of blocks across multiple DataNodes (storage nodes). Figure 4 shows how OpenEC is integrated into HDFS. OpenEC comprises a centralized controller, which coordinates multiple agents. An application interacts with OpenEC via an OECClient. Controller: The controller parses ECDAGs and instructs all agents how to perform coding operations and store erasure- coded blocks. It keeps erasure coding metadata and all ECDAGs in local disk for persistence. There are three types of metadata: (i) the information of blocks associated with each file; (ii) the information of blocks associated with each coding group; and (iii) the block locations. The controller interacts with the NameNode in two aspects. First, it accesses or updates the block locations of the NameNode to configure the placement of blocks. Second, it receives the reports of lost blocks from the NameNode and coordinates the repair operations among the agents.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Example of constructing a pipelined ECDAG; vertices of the same color mean that their blocks are in the same rack.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Performance of basic operations in online and offline encoding.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Comparisons with native coding operations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Impact of block and packet sizes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head></head><label></label><figDesc>c), we can construct an ECDAG as in Listing 3.</figDesc><table>Decode: It constructs an ECDAG that takes the available 
blocks (with indices in from) as input and decodes any lost 

ECDAG* Encode() { 
ECDAG* ecdag = new ECDAG(); 
ecdag-&gt;Join(4, {0,1,2,3}, {1,1,1,1}); 
ecdag-&gt;Join(5, {0,1,2,3}, {1,2,4,8}); 
int vidx = ecdag-&gt;BindX({4,5}); 
ecdag-&gt;BindY(vidx, 0); 
return ecdag; 
} 

Listing 3: Encode function. 

ECDAG* Decode(vector&lt;int&gt; from, vector&lt;int&gt; to) { 
ECDAG* ecdag = new ECDAG(); 
vector&lt;int&gt; dcoefs; // decoding coefficients 
// compute dcoefs based on the available blocks 
ecdag-&gt;Join(to[0], from, dcoefs); 
return ecdag; 
} 

Listing 4: Decode function. 

vector&lt;vector&lt;int&gt;&gt; Place() { 
vector&lt;vector&lt;int&gt;&gt; groups; 
for (int i=0; i&lt;n/2; ++i) groups[0].push_back(i); 
for (int i=n/2; i&lt;n; ++i) groups[1].push_back(i); 
return groups; 
} 

Listing 5: Place function. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true"><head>Table 1 :</head><label>1</label><figDesc>Vertex sequence of coding operations, including the nodes that are responsible for processing the vertices as well as the tasks that are performed.</figDesc><table>b 2 from N 2 ; 
Fetch b 3 from N 3 ; 
Compute b 4 from {b 0 , b 1 , b 2 , b 3 } with 
coding coefficients {1,1,1,1}; 
Compute b 5 from {b 0 , b 1 , b 2 , b 3 } with 
coding coefficients {1,2,4,8} 
v 4 
N 4 
Fetch b 4 from N 0 ; Persist b 4 
v 5 
N 5 
Fetch b 5 from N 0 ; Persist b 5 
(b) Offline encoding 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Theoretical gains of state-of-the-art erasure codes or repair algorithms over the conventional repair of RS codes. 

</table></figure>

			<note place="foot">ecdag-&gt;BindY(vidx, 0); 334 17th USENIX Conference on File and Storage Technologies USENIX Association</note>

			<note place="foot" n="2"> We compare the amounts of code changes in OpenEC with those in our previously built prototypes CORE [26] and DoubleR [19], both of which modify HDFS-RAID to realize new erasure codes. Excluding the implementation of erasure codes (e.g., coding operations), CORE and DoubleR make around 2,300 LoC and 4,100 LoC of changes to the HDFS-RAID codebase for the integration of erasure codes, respectively.</note>
		</body>
		<back>

			<div type="acknowledgement">
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title/>
		<idno>Hadoop 3.0.0</idno>
		<ptr target="https://hadoop.apache.org/docs/r3.0.0/" />
	</analytic>
	<monogr>
		<title level="j">Apache</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Erasure code API library written in c with pluggable erasure code backends</title>
		<ptr target="https://github.com/openstack/liberasurecode" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Facebook&apos;s realtime distributed FS based on Apache Hadoop 0.20-append</title>
		<ptr target="https://github.com/facebookarchive/hadoop-20" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hdfs Erasure Coding</surname></persName>
		</author>
		<ptr target="https://hadoop.apache.org/docs/r3.0.0/hadoop-project-dist/hadoop-hdfs/HDFSErasureCoding.html" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hdfs-Raid</forename></persName>
		</author>
		<ptr target="https://wiki.apache.org/hadoop/HDFS-RAID" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Openstack</forename><surname>Swift</surname></persName>
		</author>
		<ptr target="https://wiki.openstack.org/wiki/Swift" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Redis</surname></persName>
		</author>
		<ptr target="http://redis.io/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">A simple Python interface for implementing erasure codes</title>
		<ptr target="https://github.com/openstack/pyeclib" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Total recall: System support for automated availability management</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bhagwan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Tati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savage</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">M</forename><surname>Voelker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of USENIX NSDI</title>
		<meeting>of USENIX NSDI</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Client-aware cloud storage</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">P</forename><surname>Mesnier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hahn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE MSST</title>
		<meeting>of IEEE MSST</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">CYRUS: Towards client-defined cloud storage</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Y</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Joe-Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W.-K</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACM EuroSys</title>
		<meeting>of ACM EuroSys</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Network coding for distributed storage systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Dimakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">B</forename><surname>Godfrey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Wainwright</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ramchandran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Information Theory</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="4539" to="4551" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Availability in globally distributed storage systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Labelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">I</forename><surname>Popovici</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stokely</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V.-A</forename><surname>Truong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Barroso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Grimes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Quinlan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of USENIX OSDI</title>
		<meeting>of USENIX OSDI</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Crystal: Software-defined storage for multi-tenant object stores</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Gracia-Tinedo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sampé</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Zamora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sánchez-Artigas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>García-López</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Moatti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Rom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of USENIX FAST</title>
		<meeting>of USENIX FAST</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Optimizing Galois field arithmetic for diverse processor architectures and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Greenan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">L</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">J E</forename><surname>Schwarz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE MAS-COTS</title>
		<meeting>of IEEE MAS-COTS</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">NCCloud: Applying network coding for the storage repair in a cloud-of-clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">P</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of USENIX FAST</title>
		<meeting>of USENIX FAST</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Optimal repair layering for erasure-coded data centers: From theory to practice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">P C</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. on Storage</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">33</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Latency reduction and load balancing in coded storage systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACM SoCC</title>
		<meeting>of ACM SoCC</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Erasure coding in Windows Azure storage</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Simitci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ogus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Calder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Gopalan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yekhanin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of USENIX ATC</title>
		<meeting>of USENIX ATC</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Rethinking erasure codes for cloud file systems: Minimizing I/O for recovery and degraded reads</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">C</forename><surname>Burns</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Plank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Pierce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of USENIX FAST</title>
		<meeting>of USENIX FAST</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">On fault tolerance, locality, and optimality in locally repairable codes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Kolosov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Yadgar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Liram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Tamo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Barg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of USENIX ATC</title>
		<meeting>of USENIX ATC</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Hashtag erasure codes: From theory to practice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kralevska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gligoroski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">E</forename><surname>Jensen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Øverby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Big Data</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Repair pipelining for erasure-coded storage</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">P C</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of USENIX ATC</title>
		<meeting>of USENIX ATC</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Enabling concurrent failure recovery for regenerating-coding-based storage systems: From theory to practice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">P C</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Computers</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1898" to="1911" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">OpenEC: Toward unified and configurable erasure coding management in distributed storage systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">P C</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<ptr target="http://www.cse.cuhk.edu.hk/~pclee/www/pubs/tech_openec.pdf" />
		<imprint>
			<date type="published" when="2019" />
		</imprint>
		<respStmt>
			<orgName>CUHK</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Differentiated storage services</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mesnier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Akers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACM SOSP</title>
		<meeting>of ACM SOSP</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Partialparallel-repair (PPR): A distributed technique for repairing erasure coded storage</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Panta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-R</forename><surname>Ra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bagchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACM EuroSys</title>
		<meeting>of ACM EuroSys</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Facebook&apos;s warm blob storage system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Muralidhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Lloyd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shankar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Sivakumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of USENIX OSDI</title>
		<meeting>of USENIX OSDI</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">The Quantcast file system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ovsiannikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Rus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Reeves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sutter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kelly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of VLDB Endowment</title>
		<meeting>of VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Opening the chrysalis: On the real repair performance of MSR codes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Pamies-Juarez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Blagojevic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mateescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Guyot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">E</forename><surname>Gad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Bandic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of USENIX FAST</title>
		<meeting>of USENIX FAST</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Simple regenerating codes: Network coding for cloud storage</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename><surname>Papailiopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Dimakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE INFOCOM</title>
		<meeting>of IEEE INFOCOM</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">GF-Complete: A comprehensive open source library for galois field arithmetic</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Plank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Greenan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Houston</surname></persName>
		</author>
		<idno>UT-CS-13-703</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
		<respStmt>
			<orgName>University of Tennessee</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Tutorial: Erasure coding for storage applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Plank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Slides presented at USENIX FAST 2013</title>
		<imprint>
			<date type="published" when="2013-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Jerasure: A library in C/C++ facilitating erasure coding for storage applications -version 1.2</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Plank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Simmerman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Schuman</surname></persName>
		</author>
		<idno>CS-08-627</idno>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
		<respStmt>
			<orgName>University of Tennessee</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">SafeFS: A modular architecture for secure user-space file systems (one FUSE to rule them all)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pontes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Burihabwa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Maia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Paulo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Schiavoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Felber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Mercier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Oliveira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACM SYSTOR</title>
		<meeting>of ACM SYSTOR</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">The storage versus repair-bandwidth trade-off for clustered storage systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Prakash</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Abdrashitov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Médard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans.on Information Theory</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="5783" to="5805" />
			<date type="published" when="2018-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Having your cake and eating it too: Jointly optimal erasure codes for I/O, storage, and network-bandwidth</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Rashmi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Nakkiran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">B</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ramchandran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of USENIX FAST</title>
		<meeting>of USENIX FAST</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A solution to the network challenges of data recovery in erasure-coded distributed storage systems: A study on the Facebook warehouse cluster</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Rashmi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">B</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Borthakur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ramchandran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of USENIX HotStorage</title>
		<meeting>of USENIX HotStorage</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">A &quot;hitchhiker&apos;s&quot; guide to fast and efficient data reconstruction in erasurecoded data centers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">V</forename><surname>Rashmi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">B</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Borthakur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ramchandran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACM SIGCOMM</title>
		<meeting>of ACM SIGCOMM</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Optimal exact-regenerating codes for distributed storage at the MSR and MBR points via a product-matrix construction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">V</forename><surname>Rashmi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">B</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">V</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Information Theory</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="5227" to="5239" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Polynomial codes over certain finite fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">S</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Solomon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Society for Industrial and Applied Mathematics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="300" to="304" />
			<date type="published" when="1960" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Xoring elephants: Novel erasure codes for big data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sathiamoorthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Asteris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Papailiopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Dimakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vadali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Borthakur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of VLDB Endowment</title>
		<meeting>of VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Interference alignment in regenerating codes for distributed storage: Necessity and code constructions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">B</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Rashmi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">V</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ramchandran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Information Theory</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="2134" to="2158" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">The Hadoop distributed file system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Shvachko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Radia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chansler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE MSST</title>
		<meeting>of IEEE MSST</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Lazy means smart: Reducing repair bandwidth costs in erasure-coded distributed storage</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Silberstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ganesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Alvisi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dahlin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACM SYSTOR</title>
		<meeting>of ACM SYSTOR</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">sRoute: Treating the storage stack like a network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">A</forename><surname>Stefanovici</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schroeder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>O&amp;apos;shea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Thereska</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of USENIX FAST</title>
		<meeting>of USENIX FAST</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">A family of optimal locally recoverable codes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Tamo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Barg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Information Theory</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="4661" to="4676" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Zigzag codes: MDS array codes with optimal rebuilding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Tamo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bruck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Information Theory</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1597" to="1616" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">IOFlow: A software-defined storage architecture</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Thereska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ballani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>O&amp;apos;shea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Karagiannis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rowstron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Talpey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACM SOSP</title>
		<meeting>of ACM SOSP</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Clay codes: Moulding MDS codes to yield an MSR code</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Vajha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Ramkumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Puranik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Lobo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sasidharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">V</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Barg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Narayanamurthy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of USENIX FAST</title>
		<meeting>of USENIX FAST</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Erasure coding vs. replication: A quantitative comparison</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Weatherspoon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Kubiatowicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IPTPS</title>
		<meeting>of IPTPS</meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Ceph: A scalable, high-performance distributed file system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Weil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Brandt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">L</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">D</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Maltzahn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of USENIX OSDI</title>
		<meeting>of USENIX OSDI</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Tahoe: the leastauthority filesystem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wilcox-O&amp;apos;hearn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Warner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACM StorageSS</title>
		<meeting>of ACM StorageSS</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
