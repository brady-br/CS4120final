<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2020-09-29T04:11+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Open access to the Proceedings of the 29th USENIX Security Symposium is sponsored by USENIX. Delphi: A Cryptographic Inference Service for Neural Networks DELPHI: A Cryptographic Inference Service for Neural Networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>August 12-14, 2020</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pratyush</forename><surname>Mishra</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">UC Berkeley</orgName>
								<address>
									<settlement>Berkeley</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Lehmkuhl</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">UC Berkeley</orgName>
								<address>
									<settlement>Berkeley</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akshayaram</forename><surname>Srinivasan</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">UC Berkeley</orgName>
								<address>
									<settlement>Berkeley</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenting</forename><surname>Zheng</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">UC Berkeley</orgName>
								<address>
									<settlement>Berkeley</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raluca</forename><forename type="middle">Ada</forename><surname>Popa</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">UC Berkeley</orgName>
								<address>
									<settlement>Berkeley</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pratyush</forename><surname>Mishra</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">UC Berkeley</orgName>
								<address>
									<settlement>Berkeley</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Lehmkuhl</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">UC Berkeley</orgName>
								<address>
									<settlement>Berkeley</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akshayaram</forename><surname>Srinivasan</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">UC Berkeley</orgName>
								<address>
									<settlement>Berkeley</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenting</forename><forename type="middle">Zheng</forename><surname>Raluca</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">UC Berkeley</orgName>
								<address>
									<settlement>Berkeley</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ada</forename><surname>Popa</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">UC Berkeley</orgName>
								<address>
									<settlement>Berkeley</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Open access to the Proceedings of the 29th USENIX Security Symposium is sponsored by USENIX. Delphi: A Cryptographic Inference Service for Neural Networks DELPHI: A Cryptographic Inference Service for Neural Networks</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 29th USENIX Security Symposium</title>
						<meeting>the 29th USENIX Security Symposium						</meeting>
						<imprint>
							<date type="published">August 12-14, 2020</date>
						</imprint>
					</monogr>
					<note>This paper is included in the 978-1-939133-17-5</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Many companies provide neural network prediction services to users for a wide range of applications. However, current prediction systems compromise one party&apos;s privacy: either the user has to send sensitive inputs to the service provider for classification, or the service provider must store its proprietary neural networks on the user&apos;s device. The former harms the personal privacy of the user, while the latter reveals the service provider&apos;s proprietary model. We design, implement, and evaluate DELPHI, a secure prediction system that allows two parties to execute neural network inference without revealing either party&apos;s data. DELPHI approaches the problem by simultaneously co-designing cryptography and machine learning. We first design a hybrid cryptographic protocol that improves upon the communication and computation costs over prior work. Second, we develop a planner that automatically generates neural network architecture configurations that navigate the performance-accuracy trade-offs of our hybrid protocol. Together, these techniques allow us to achieve a 22× improvement in online prediction latency compared to the state-of-the-art prior work.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Recent advances in machine learning have driven increasing deployment of neural network inference in popular applications like voice assistants <ref type="bibr">[Bar18]</ref> and image classification <ref type="bibr">[Liu+17b]</ref>. However, the use of inference in many such applications raises privacy concerns. For example, home monitoring systems (HMS) such as Kuna <ref type="bibr">[Kun]</ref> and Wyze <ref type="bibr">[Wyz]</ref> use proprietary neural networks to classify objects in video streams of users' homes such as cars parked near the user's house, or faces of visitors to the house. These models are core to these companies' business and are expensive to train.</p><p>To make use of these models, either the user has to upload their streams to the servers of the HMS (which then evaluate the model over the stream), or the HMS has to store its model on the user's monitoring device (which then performs the classification). Both of these approaches are unsatisfactory: the first requires users to upload video streams containing sensitive information about their daily activities to another party, while the second requires the HMS to store its model on every device, thus allowing users and competitors to steal the proprietary model.</p><p>To alleviate these privacy concerns, a number of recent works have proposed protocols for cryptographic predic- tion over (convolutional) neural networks [Gil+16; Moh+17; Liu+17a; Juv+18] by utilizing specialized secure multi-party computation (MPC) <ref type="bibr">[Yao86; Gol+87]</ref>. At a high level, these protocols proceed by encrypting the user's input and the service provider's neural network, and then tailor techniques for computing over encrypted data (like homomorphic encryption or secret sharing) to run inference over the user's input. At the end of the protocol execution, the intended party(-ies) learn the inference result; neither party learns anything else about the other's input. <ref type="figure" target="#fig_0">Fig. 1</ref> illustrates this protocol flow. Unfortunately, these cryptographic prediction protocols are still unsuitable for deployment in real world applications as they require the use of heavy cryptographic tools during the online execution. These tools are computationally intensive and often require a large amount of communication between the user and the service provider. Furthermore, this cost grows with the complexity of the model, making these protocols unsuitable for use with state-of-the-art neural network architectures used in practice today. For example, using a state-of-the-art protocol like GAZELLE <ref type="bibr">[Juv+18]</ref> to perform inference for state-of-the-art deep neural networks like ResNet-32 <ref type="bibr">[He+16]</ref> requires ∼ 82 seconds and results in over 560 MB communication. Our contribution. In this paper, we present DELPHI, a cryptographic prediction system for realistic neural network architectures. DELPHI achieves its performance via a careful co-design of cryptography and machine learning. DELPHI contributes a novel hybrid cryptographic prediction protocol, as well as a planner that can adjust the machine learning algorithm to take advantage of the performance-accuracy tradeoffs of our protocol. Our techniques enable us to perform cryptographic prediction on more realistic network architectures than those considered in prior work. For example, using DEL-PHI for cryptographic prediction on ResNet-32 requires just 3.8 seconds and 60 MB communication in the online phase, improving upon GAZELLE by 22× and 9× respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Techniques</head><p>We now describe at a high level the techniques underlying DELPHI's excellent performance.</p><p>Performance goals. Modern convolutional neural networks consist of a number of layers, each of which contains one sublayer for linear operations, and one sub-layer for non-linear operations. Common linear operations include convolutions, matrix multiplication, and average pooling. Non-linear operations include activation functions such as the popular ReLU (Rectified Linear Unit) function.</p><p>Achieving cryptographic prediction for realistic neural networks thus entails (a) constructing efficient subprotocols for evaluating linear and non-linear layers, and (b) linking the results of these subprotocols with each other.</p><p>Prior work. Almost all prior protocols for cryptographic prediction utilize heavyweight cryptographic tools to implement these subprotocols, which results in computation and communication costs that are much higher than the equivalent plaintext costs. Even worse, many protocols utilize these tools during the latency-sensitive online phase of the protocol, i.e., when the user acquires their input and wishes to obtain a classification for it. (This is opposed to the less latencysensitive preprocessing phase that occurs before the user's input becomes available).</p><p>For example, the online phase of the state-of-the-art GAZELLE protocol uses heavy cryptography like linearly homomorphic encryption and garbled circuits. As we show in Section 7.4, this results in heavy preprocessing and online costs: for the popular network architecture ResNet-32 trained over CIFAR-100, GAZELLE requires ∼ 158 seconds and 8 GB of communication during the preprocessing phase, and ∼ 50 seconds and 5 GB of communication during the preprocessing phase, and ∼ 82 seconds and 600 MB of communication during the online phase.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1.1">DELPHI's protocol</head><p>To achieve good performance on realistic neural networks, DELPHI builds upon techniques from GAZELLE to develop new protocols for evaluating linear and non-linear layers that minimize the use of heavy cryptographic tools, and thus minimizes communication and computation costs in the preprocessing and online phases. We begin with a short overview of GAZELLE's protocol as it is the basis for DELPHI's protocols.</p><p>Starting point: GAZELLE. GAZELLE <ref type="bibr">[Juv+18]</ref> is a stateof-the-art cryptographic prediction system for convolutional neural networks. GAZELLE computes linear layers using an optimized linearly-homomorphic encryption (LHE) scheme [Elg85; <ref type="bibr">Pai99; Reg09; Fan+12]</ref> that enables one to perform linear operations directly on ciphertexts. To compute nonlinear layers, GAZELLE uses garbled circuits <ref type="bibr">[Yao86]</ref> to compute the bitwise operations required by ReLU. Finally, because each layer in a neural network consists of alternating linear and non-linear layers, GAZELLE also describes how to efficiently switch back-and-forth between the two aforementioned primitives via a technique based on additive secret sharing.</p><p>As noted above, GAZELLE's use of heavy cryptography in the online phase leads to efficiency and communication overheads. To reduce these overheads, we proceed as follows.</p><p>Reducing the cost of linear operations. To reduce the online cost of computing the linear operations, we adapt GAZELLE to move the heavy cryptographic operations over LHE ciphertexts to the preprocessing phase. Our key insight is that the service provider's input M to the linear layer (i.e. the model weights for that layer) is known before user's input is available, and so we can use LHE to create secret shares of M during preprocessing. Later, when the user's input becomes available in the online phase, all linear operations can be performed directly over secret-shared data without invoking heavy cryptographic tools like LHE, and without requiring interactions to perform matrix-vector multiplications.</p><p>The benefits of this technique are two-fold. First, the online phase only requires transmitting secret shares instead of ciphertexts, which immediately results in an 8× reduction in online communication for linear layers. Second, since the online phase only performs computations over elements of prime fields, and since our system uses concretely small 32-bit primes for this purpose, our system can take advantage of state-of-the-art CPU and GPU libraries for computing linear layers; see Section 7.2 and Remark 4.2 for details. Reducing the cost of non-linear operations. While the above technique already significantly reduces computation time and communication cost, the primary bottleneck for both remains the cost of evaluating garbled circuits for the ReLU activation function. To minimize this cost, we use an alternate approach [Gil+16; <ref type="bibr">Liu+17a; Moh+17; Cho+18]</ref> that is better suited to our setting of computing over finite field elements: computing polynomials. In more detail, DELPHI replaces ReLU activations with polynomial (specifically, quadratic) approximations. These can be computed securely and efficiently via standard protocols <ref type="bibr">[Bea95]</ref>.</p><p>Because these protocols only require communicating a small constant number of field elements per multiplication, using quadratic approximations significantly reduces the communication overhead per activation, without introducing additional rounds of communication. Similarly, since the underlying multiplication protocol only requires a few cheap finite field operations, the computation cost is also reduced by several orders of magnitude. Concretely, the online communication and computation costs of securely computing quadratic approximations are 192× and 10000× smaller (respectively) than the corresponding costs for garbled circuits.</p><p>However, this performance improvement comes at the cost of accuracy and trainability of the underlying neural network. Prior work has already established that quadratic approximations provide good accuracy in some settings [Moh+17; <ref type="bibr">Liu+17a; Gho+17; Cho+18]</ref>. At the same time, both prior work <ref type="bibr">[Moh+17]</ref> and our own experiments indicate that in many settings simply replacing ReLU activations with quadratic approximations results in severely degraded accuracy, and can increase training time by orders of magnitude (if training converges at all). To overcome this, we develop a hybrid cryptographic protocol that uses ReLUs and quadratic approximations to achieve good accuracy and good efficiency.</p><p>Planning an efficient usage of the hybrid cryptographic protocol. It turns out that it is not straightforward to determine which ReLU activations should be replaced with quadratic approximations. Indeed, as we explain in Section 5, simply replacing arbitrary ReLU activations with quadratic approximations can degrade the accuracy of the resulting network, and can even cause the network to fail to train.</p><p>So, to find an appropriate placement or network configuration, we design a planner that automatically discovers which ReLUs to replace with quadratic approximations so as to maximize the number of approximations used while still ensuring that accuracy remains above a specified threshold.</p><p>The insight behind our planner is to adapt techniques for neural architecture search (NAS) and hyperparameter optimization (see <ref type="bibr">[Els+19; Wis+19]</ref> for in-depth surveys of these areas) to our setting. Namely, we adapt these techniques to discover which layers to approximate within a given neural network architecture, and to optimize the hyperparameters for the discovered network. See Section 5 for details.</p><p>The overall system. DELPHI combines the above insights into a cohesive system that service providers can use to automatically generate cryptographic prediction protocols meeting performance and accuracy criteria specified by the provider. In more detail, the service provider invokes DELPHI's planner with acceptable accuracy and performance thresholds. The planner outputs an optimized architecture that meets this goal, which DELPHI then uses to instantiate a concrete cryptographic prediction protocol that utilizes our cryptographic techniques from above.</p><p>This co-design of cryptography and machine learning enables DELPHI to efficiently provide cryptographic prediction for networks deeper than any considered in prior work. For example, in Section 7 we show that using DELPHI to provide inference for the popular ResNet-32 architecture requires only 60 MB communication and 3.8 seconds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">System overview</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">System setup</head><p>There are two parties in the system setup: the client and the service provider (or server). In the plaintext version of our system, the service provider provides prediction as a service using its internal models via an API. The client uses this API to run prediction on its own data by transferring its data to the service provider. The service provider runs prediction using the appropriate neural network, then sends the prediction result back to the client. In DELPHI, the two parties execute a secure prediction together by providing their own inputs. The service provider's input is the neural network, while the client's input is its private input used for prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Threat model</head><p>DELPHI's threat model is similar to that of prior secure prediction works such as GAZELLE <ref type="bibr">[Juv+18]</ref> and MiniONN <ref type="bibr">[Liu+17a]</ref>. More specifically, DELPHI is designed for the two-party semi-honest setting, where only one of the parties is corrupted by an adversary. Furthermore, this adversary never deviates from the protocol, but it will try to learn information about the other parties' private inputs from the messages it receives.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Privacy goals</head><p>DELPHI's goal is to enable the client to learn only two pieces of information: the architecture of the neural network, and the result of the inference; all other information about the client's private inputs and the parameters of the server's neural network model should be hidden. Concretely, we aim to achieve a strong simulation-based definition of security; see Definition 4.1. Like all prior work, DELPHI does not hide information about the architecture of the network, such as the dimensions and type of each layer in the network. For prior work, this is usually not an issue because the architecture is independent of the training data. However, because DELPHI's planner uses training data to optimally place quadratic approximations, revealing the network architecture reveals some information about the data. Concretely, in optimizing an -layer network, the planner makes binary choices, thus reveals at most bits of information about the training data. Because is concretely small for actual networks (for example, = 32 for ResNet32), this leakage is negligible. This leakage can be further mitigated by using differentially private training algorithms <ref type="bibr">[Sho+15; Aba+16]</ref> DELPHI, like most prior systems for cryptographic prediction, does not hide information that is revealed by the result of the prediction. In our opinion, protecting against attacks that exploit this leakage is a complementary problem to that solved by DELPHI. Indeed, such attacks have been successfully carried out even against systems that "perfectly" hide the model parameters by requiring the client to upload its input to the server [Fre+14; <ref type="bibr">Ate+15; Fre+15; Wu+16b; Tra+16]</ref>. Furthermore, popular mitigations for these attacks, such as differential privacy, can be combined with DELPHI's protocol. We discuss these attacks and possible mitigations in more detail in Section 8.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">System architecture and workflow</head><p>DELPHI's architecture consists of two components: a hybrid cryptographic protocol for evaluating neural networks, and a neural network configuration planner that optimizes a given neural network for use with our protocol. Below we provide an overview of these components, and then demonstrate how one would use these in practice by describing an end-to-end workflow for cryptographic prediction in home monitoring systems (HMS).</p><p>Hybrid cryptographic protocol. DELPHI's protocol for cryptographic prediction consists of two phases: an offline preprocessing phase, and an online inference phase. The offline preprocessing phase is independent of the client's input (which regularly changes), but assumes that the server's model is static; if this model changes, then both parties would have to re-run the preprocessing phase. After preprocesing, during the online inference phase, the client provides its input to our specialized secure two-party computation protocol, and eventually learns the inference result. We note that our protocol provides two different methods of evaluating non-linear layers: the first offers better accuracy at the cost of worse offline and online efficiency, while the other degrades accuracy, but offers much improved offline and online efficiency.</p><p>Planner. To help service providers navigate the trade off between performance and accuracy offered by these two complementary methods to evaluate non-linear layers, DELPHI adopts a principled approach by designing a planner that generates neural networks that mix these two methods to maximize efficiency while still achieving the accuracy desired by the service provider. Our planner applies neural architecture search (NAS) to the cryptographic setting in a novel way in order to automatically discover the right architectures.</p><p>Example 2.1 (HMS workflow). As explained in Section 1, a home monitoring system (HMS) enables users to surveil activity inside and outside their houses. Recent HMSes <ref type="bibr">[Kun; Wyz]</ref> use neural networks to decide whether a given activity is malicious or not. If it is, they alert the user. In this setting privacy is important for both the user and the HMS provider, which makes DELPHI an ideal fit. To use DELPHI to provide strong privacy, the HMS provider proceeds as follows.</p><p>The HMS provider first invokes DELPHI's planner to optimize its baseline all-ReLU neural network model. Then, during the HMS device's idle periods, the device and the HMS server run the preprocessing phase for this model. If the device detects suspicious activity locally, it can run the online inference phase to obtain a classification. On the basis of this result, it can decide whether to alert the user or not.</p><p>Remark 2.2 (applications suitable for use with DELPHI). Example 2.1 indicates that DELPHI is best suited for applications where there is ample computational power available for preprocessing, and where inference is latency-sensitive, but is not performed frequently enough to deplete the reserve of preprocessed material. Other examples of such applications include image classification in systems like Google Lens <ref type="bibr">[Goo]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Cryptographic primitives</head><p>In this section, we provide a high-level description of the cryptographic building blocks used in DELPHI; this high-level description suffices to understand our protocols. We provide formal definitions of security properties in Appendix A, and only provide high level intuitions here.</p><p>Garbled circuits. Garbled circuits (GC), introduced in the seminal work of Yao <ref type="bibr">[Yao86]</ref>, are a method of encoding a boolean circuit C and its input x such that, given the encoded circuit and the encoded input, an evaluator can use a special evaluation procedure to obtain the output C(x) while ensuring that the evaluator learns nothing else about C or x. We now describe this notion in more detail.</p><p>A garbling scheme [Yao86; Bel+12] is a tuple of algorithms GS = (Garble, Eval) with the following syntax:</p><formula xml:id="formula_0">• GS.Garble(C) → ( ˜ C, {label i,0 , label i,1 } i∈[n]</formula><p>). On input a boolean circuit C, Garble outputs a garbled circuit˜Ccircuit˜ circuit˜C and a set of labels {label i,0 , label i,1 } i∈ <ref type="bibr">[n]</ref> . Here label i,b represents assigning the value b ∈ {0, 1} to the i-th input label.</p><p>• GS.Eval( ˜ C, {label i,x i }) → y. On input a garbled circuit˜Ccircuit˜ circuit˜C and labels {label i,x i } corresponding to an input x ∈ {0, 1} n , Eval outputs a string y = C(x). We provide a formal definition in Appendix A, and briefly describe here the key properties satisfied by garbling schemes. First, GS must be complete: the output of Eval must equal C(x). Second, it must be private: giveñ C and {label i,x i }, the evaluator should not learn anything about C or x except the size of |C| (denoted by 1 |C| ) and the output C(x).</p><p>Linearly homomorphic public-key encryption. A linearly homomorphic encryption scheme [Elg85; Pai99] is a public key encryption scheme that additionally supports (only) linearly homomorphic operations on the ciphertexts. To give more details, a linearly homomorphic encryption consists of a tuple of algorithms HE = (KeyGen, Enc, Dec, Eval) with the following syntax:</p><p>• HE.KeyGen → (pk, sk). HE.KeyGen is a randomized algorithm that outputs a public key pk and a secret key sk.</p><p>• HE.Enc(pk, m) → c. On input the public key pk and a message m, the encryption algorithm HE.Enc outputs a ciphertext c. The message space is a finite ring R .</p><p>• HE.Dec(sk, c) → m. On input the secret key sk and a ciphertext c, the decryption algorithm HE.Dec outputs the message m contained in c.</p><p>• HE.Eval(pk, c 1 , c 2 , L) → c . On input the public key pk, two ciphertexts c 1 , c 2 encrypting messages m 1 and m 2 , and a linear function L, 1 HE.Eval outputs a new ciphertext c encrypting L(m 1 , m 2 ). Informally, we require HE to satisfy the following properties:</p><p>• Correctness. HE.Dec, on input sk and a ciphertext c := HE.Enc(pk, m), outputs m.</p><p>• Homomorphism. HE.Dec, on input sk and a ciphertext c := HE.Eval(pk, HE.Enc(pk,</p><formula xml:id="formula_1">m 1 ), HE.Enc(pk, m 2 ), L), outputs L(m 1 , m 2 ).</formula><p>• Semantic security. Given a ciphertext c and two messages of the same length, no attacker should be able to tell which message was encrypted in c.</p><p>• Function privacy. Given a ciphertext c, no attacker can tell what homomorphic operations led to c. Oblivious transfer. An oblivious transfer protocol [Rab81; <ref type="bibr">Eve+82; Ish+03]</ref> is a protocol between two parties, a sender who has as input two messages m 0 , m 1 , and a receiver who has as input a bit b. At the end of the protocol, the receiver learns m b . The security requirement states that the sender does not learn anything about bit b and the receiver does not learn anything about the string m 1−b .</p><p>Additive secret sharing. Given a finite ring R and an element x ∈ R , a 2-of-2 additive secret sharing of x is a pair</p><formula xml:id="formula_2">([x] 1 , [x] 2 ) = (x − r, r) ∈ R 2 (so that x = [x] 1 + [x] 2 )</formula><p>where r is a random element from the ring. Additive secret sharing is perfectly hiding, i.e., given a share [x] 1 or [x] 2 , the value x is perfectly hidden. Beaver's multiplicative triples. Beaver's multiplication triples <ref type="bibr">[Bea95]</ref> generation procedure is a two-party protocol that securely computes the following function. Sample</p><formula xml:id="formula_3">a, b ← R and return [a] 1 , [b] 1 , [ab] 1 to the first party and [a] 2 , [b] 2 , [ab] 2</formula><p>to the second party. In this work, we will generate Beaver's triples using a linearly homomorphic encryption scheme; we provide further details in Appendix A. Beaver's multiplication procedure. Let P 1 and P 2 be two parties who hold <ref type="bibr">[x]</ref> </p><formula xml:id="formula_4">1 , [y] 1 and [x] 2 , [y] 2</formula><p>respectively where x, y are some ring elements. Additionally, let us assume that P 1 and P 2 also hold a Beaver's multiplication triple, namely,</p><formula xml:id="formula_5">([a] 1 , [b] 1 , [ab] 1 ) and ([a] 2 , [b] 2 , [ab] 2 )</formula><p>respectively. Beaver's multiplication procedure is a secure protocol such that at the end of the protocol, parties P 1 and P 2 hold an additive secret sharing of xy. We provide details of this protocol in Appendix A but note here that this protocol can be used to securely evaluate any polynomial.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Cryptographic protocols</head><p>In DELPHI, we introduce a hybrid cryptographic protocol for cryptographic prediction (see <ref type="figure" target="#fig_2">Fig. 4</ref>). Our protocol makes two 1 L maps (m 1 , m 2 ) to am 1 + m 2 for some a ∈ R . key improvements to protocols proposed in prior work like <ref type="bibr">MiniONN [Liu+17a]</ref> and GAZELLE <ref type="bibr">[Juv+18]</ref>. First, DELPHI splits the protocol into a preprocessing phase and an online phase such that most of the heavy cryptographic computation is performed in the preprocessing phase. Second, DELPHI introduces two different methods of evaluating non-linear functions that provide the users with trade offs between accuracy and performance. The first method uses garbled circuits to evaluate the ReLU activation function, while the second method uses securely evaluates polynomial approximations of the ReLU. The former provides maximum accuracy but is inefficient, while the latter is computationally cheap but lowers accuracy. (We note that below we describe a protocol for evaluating any polynomial approximation, but in the rest of the paper, we restrict ourselves only to quadratic approximations because these are maximally efficient.)</p><p>Notation. Let R be a finite ring. Let HE = (KeyGen, Enc, Dec, Eval) be a linearly homomorphic encryption over the plaintext space R . The server holds a model M consisting of layers M 1 , . . . , M . The client holds an input vector</p><formula xml:id="formula_6">x ∈ R n .</formula><p>We now give the formal definition of a cryptographic prediction protocol. Intuitively, the definition guarantees that after the protocol execution, a semi-honest client (i.e., one that follows the specification of the protocol) only learns the architecture of the neural network and the result of the inference; all other information about the parameters of the server's neural network model are hidden. Similarly, a semihonest server does not learn any information about the client's input, not even the output of the inference. Definition 4.1. A protocol Π between a server having as input model parameters M = (M 1 , . . . , M ) and a client having as input a feature vector x is a cryptographic prediction protocol if it satisfies the following guarantees.</p><p>• Correctness. On every set of model parameters M that the server holds and every input vector x of the client, the output of the client at the end of the protocol is the correct prediction M(x).</p><p>• Security:</p><p>-Corrupted client. We require that a corrupted, semihonest client does not learn anything about the server's network parameters M. Formally, we require the existence of an efficient simulator Sim C such that View Π C ≈ c Sim C (x, out), where View Π C denotes the view of the client in the execution of Π (the view includes the client's input, randomness, and the transcript of the protocol), and out denotes the output of the inference. -Corrupted server. We require that a corrupted, semihonest server does not learn anything about the private input x of the client. Formally, we require the existence of an efficient simulator Sim S such that View Π S ≈ c Sim S (M), where View Π S denotes the view of the server in the execution of Π. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>USENIX</head><formula xml:id="formula_7">[a i ] 1 , [b i ] 1 , [a i b i ] 1 [a i ] 2 , [b i ] 2 , [a i b i ] 2 M i OT for i ∈[1,…, ℓ] for i ∈[1,…, ℓ]</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Linear</head><p>Figure 3: DELPHI's preprocessing phase. The DELPHI protocol proceeds in two phases: the preprocessing phase and the online phase, and we give the details of both these phases in the subsequent sections.</p><formula xml:id="formula_8">M i r i − s i M i , s i x, r i x i − r i M i (x i − r i ) + s i ˜ C i Labels for M i (x i − r i ) + s i x i+ 1 − r i+ 1 r i+ 1 F o n lin e Beaver [x i+ 1 ] 1 [x i+ 1 ] 2 [x i+ 1 ] 1 − r i+ 1 [x i+ 1 ] 1 − r i+ 1 + [x i+ 1 ] 2 x i+ 1 − r i+ 1 r i+ 1</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Preprocessing phase</head><p>During preprocessing, the client and the server pre-compute data that can be used during the online execution. This phase can be executed independent of the input values, i.e., DELPHI can run this phase before either party's input is known.</p><p>1. The client runs HE.KeyGen to obtain a public key pk and a secret key sk. 2. For every i ∈ [], the client and the server choose random masking vectors r i , s i ← R n respectively.</p><p>3. The client sends HE.Enc(pk, r i ) to the server. The server computes HE.Enc(pk, M i · r i − s i ) using the HE.Eval procedure and sends this ciphertext to the client. 4. The client decrypts the above ciphertexts and to obtain (M i · r i − s i ) for each layer. The server holds s i for each layer and thus, the client and the server hold an additive secret sharing of M i r i . 5. This step depends on the activation type:</p><p>(a) ReLU: The server constructs C by garbling the circuit C described in <ref type="figure" target="#fig_3">Fig. 5</ref>. It sends C to the client and simultaneously, the server and the client exchange labels for the input wires corresponding to r i+1 and M i · r i − s i via an Oblivious Transfer (OT). (b) Polynomial approximaitons: The client and the server run the Beaver's triples generation protocol to generate a number of Beaver's multiplication triples. 2 <ref type="bibr">2</ref> The exact number of triples generated depends on the number of layers that have to be approximated using a polynomial.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Online</head><p>The online phase is divided into a two stages: the setup and the layer evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Setup</head><p>The client on input x, sends x − r 1 to the server. The server and the client now hold an additive secret sharing of x.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Layer evaluation</head><p>At the beginning of the i-th layer, the client holds r i and the server holds x i − r i where x i is the vector obtained by evaluating the first (i − 1) layers of the neural network on input x (with x 1 set to x). This invariant will be maintained for each layer. We now describe the protocol for evaluating the i-th layer, which consists of linear functions and activation functions.</p><p>Linear layer. The server computes M i (x i − r i ) + s i , which ensures that the client and the server an additive secret sharing of M i x i .</p><p>Non-linear layer. After the linear functions, the server holds M i (x i − r i ) + s i and the client holds M i · r i − s i . There are two ways of evaluating non-linear layers: garbled circuits for ReLU, or Beaver's multiplication for polynomial approximation:</p><p>• Garbled circuits</p><p>1. The server sends the garbled labels corresponding to M i (x i − r i ) + s i to the client. 2. The client evaluates the garbled circuit C using the above labels as well as the labels obtained via OT (in the offline phase) to obtain a one-time pad ciphertext OTP(x i+1 − r i+1 ). It then sends this output to the server.</p><p>3. The server uses the one time pad key to obtain x i+1 − r i+1 .</p><p>• Polynomial approximation Output layer. The server sends x − r to the client who adds this with r to learn x .</p><p>Hardwired: A random one time pad key.</p><formula xml:id="formula_9">Input: M i (x i − r i ) + s i , r i+1 , M i · r i − s i . 1. Compute M i · x i = M i (x i − r i ) + s i + (M i · r i − s i ). 2. Compute ReLU(M i · x i ) to obtain x i+1 .</formula><p>3. Compute x i+1 − r i+1 and output OTP(x i+1 − r i+1 ).  Concretely, our implementation works over the 32-bit prime finite field defined by the prime 2138816513, and uses a 15-bit fixed-point representation. This choice of parameters enables a single multiplication of two fixed-point numbers before the result overflows capacity of the prime field. To prevent values from growing exponentially with the number of multiplications (and thus overflowing), we use a trick from <ref type="bibr">[Moh+17]</ref> that allows us to simply truncate the extra LSBs of fixed-point values. This trick works even when the result is secret-shared, albeit at the cost of a 1-bit error.</p><p>Similarly to Slalom <ref type="bibr">[Tra+19]</ref>, our choice of prime field also enables us to losslessly embed our field arithmetic in 64-bit floating point arithmetic. In more detail, 64-bit floating point numbers can represent all integers in the range 2 −53 , . . . , 2 53 . Because the online phase of our protocol for linear layers requires multiplication of a fixed-point matrix by a secret shared vector, the result is a ∼ 45-bit integer, and hence can be represented with full precision in a 64-bit floating point number. This enables our implementation to use state-of-theart CPU and GPU libraries for linear algebra.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Security</head><p>Theorem 4.3. Assuming the existence of garbled circuits, linearly homomorphic encryption and secure protocols for Beaver's triples generation and multiplication procedure, the protocol described above is a cryptographic prediction protocol (see Definition 4.1).</p><p>Proof. Below we describe simulators first for the case where the client is corrupted, and then for the case where the server is corrupted. We provide a hybrid argument that relies on these simulators in Appendix B.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Client is corrupted</head><p>The simulator Sim, when provided with the client's input x, proceeds as follows:</p><p>1. Sim chooses an uniform random tape for the client. 2. In the offline phase:</p><p>(a) Sim receives the public key and the ciphertext HE.Enc(pk, r i ) from the client. In return, it sends HE.Enc(pk, −s i ) for a randomly chosen s i from R n .</p><p>(b) Sim uses the simulator for garbled circuits Sim GS and runs it on 1 λ , 1 |C| and sets the output of the circuit to be a random value. Sim GS outputs C, {label i }. For the i-th OT execution, Sim gives the label i in both slots as input. It sends C to the client. (c) For the secure protocol to generate the Beaver's triples, Sim runs the corresponding simulator for this procedure.</p><p>3. Online phase. In the preamble phase, Sim receives x − r 1 .</p><p>It sends x to the ideal functionality (a semi-honest client uses the same x as its input) and receives the output y. Sim performs the layer evaluation as follows:</p><p>(a) Garbled circuits layer. Sim sends the simulated labels. (b) Polynomial approximation layer. Sim uses the simulator for the Beaver's multiplication procedure to evaluate the polynomial.</p><p>4. Output layer. Sim sends y − r to the client.</p><p>In Appendix B, we show that the simulated distribution is computationally indistinguishable to the real world distribution using the security of the underlying cryptographic building blocks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">Server is corrupted</head><p>The simulator Sim, when provided with the server's input M 1 , . . . , M −1 , proceeds as follows.</p><p>1. Sim chooses an uniform random tape for the server.</p><p>2. In the offline phase:</p><p>(a) Sim chooses a public key pk for a linearly homomorphic encryption scheme. It then sends HE.Enc(pk, 0) to the server. In return, it receives the homomorphically evaluated ciphertext from the server. (b) For every oblivious transfer execution where Sim acts as the receiver, it uses junk input, say 0 as the receiver's choice bit. It receives C from the server.</p><p>(c) For the secure protocol for generating the Beaver's triples, Sim runs the corresponding simulator for this procedure.</p><p>3. Online phase. In the preamble phase, Sim sends r 1 for an uniformly chosen r 1 . Sim performs the layer evaluation step as follows:</p><p>(a) Garbled circuits layer. Sim sends a random value back to the server. (b) Polynomial approximation layer. Sim uses the simulator for the Beaver's multiplication procedure to evaluate the polynomial. At the last round of this step, it sends a random value back to the server.</p><p>In Appendix B, we show that the simulated distribution is indistinguishable from the real world distribution using the security of the underlying cryptographic primitives. . The goal of NAS is to automatically discover neural network architectures that best satisfy a set of user-specified constraints.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Planner</head><p>Most NAS algorithms do so by (partially) training a number of different neural networks, evaluating their accuracy, and picking the best-performing ones. Overview of our planner. DELPHI's planner, when given as input the baseline all-ReLU neural network, operates in two modes. When retraining is either not possible or undesirable (for example if the training data is unavailable or if the provider cannot afford the extra computation required for NAS), the planner operates in the first mode and simply outputs the baseline network. If retraining (and hence NAS) is feasible, then the planner takes as additional inputs the training data, and a constraint on the minimum acceptable prediction accuracy t, and then uses NAS to discover a network configuration that maximizes the number of quadratic approximations while still achieving accuracy greater than t. Our planner then further optimizes the hyperparameters of this configuration. In more detail, in this second mode, our planner uses NAS to optimize the following properties of a candidate network configuration given t: (a) the number of quadratic approximations, (b) the placement of these approximations (that is, the layers where ReLUs are replaced with approximations), and (c) training hyperparameters like learning rate and momentum.</p><p>The foregoing is a brief description that omits many details. Below, we describe how we solved the challenges that required solving to adapt NAS to this setting (Section 5.1), our concrete choice of NAS algorithm (Section 5.2), and detailed pseudocode for the final algorithm <ref type="figure" target="#fig_7">(Fig. 6</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Adapting NAS for DELPHI's planner</head><p>Challenge 1: Training candidate networks. Prior work [Moh+17; Gil+16; Gho+17; Cho+18] and our own experiments indicate that networks that use quadratic approximations are challenging to train and deploy: the quadratic activations cause the underlying gradient descent algorithm to diverge, resulting in poor accuracy. Intuitively, we believe that this behavior is caused by these functions' large and alternating gradients.</p><p>To solve this issue, we used the following techniques: • Gradient and activation clipping: During training, we modify our optimizer to use gradient value clipping, which helps prevent gradients from exploding <ref type="bibr">[Ben+94]</ref>. In particular, we clip the values of all gradients to be less than 2. We furthermore modify our networks to use the ReLU6 activation function <ref type="bibr">[Kri10]</ref> that ensures that post-activation values have magnitude at most 6. This keeps errors from compounding during both inference and training.</p><p>• Gradual activation exchange: Our experiments determined that despite clipping, the gradients were still exploding quickly, especially in deeper networks that contained a higher fraction of approximations. To overcome this, we made use of the following insight: intuitively, ReLU6 and (clipped) quadratic approximations to ReLU should share relatively similar gradients, and so it should be possible to use ReLU6 to initially guide the descent towards a stable region where gradients are smaller, and then to use the approximation's gradients to make fine-grained adjustments within this region. We take advantage of this insight by modifying the training process to gradually transform an already-trained allReLU6 network into a network with the required number and placement of quadratic approximations. In more detail, our training process expresses each activation as a weighted average of quadratic and ReLU6 activations, i.e., act(x) := w q · quad(x) + w r ReLU(x) such that w q + w r = 1. In the beginning, w q = 0 and w r = 1. Our training algorithm then gradually increases w q and reduces w r , so that eventually w q = 1 and w r = 0. This technique also improves running times for the NAS as it no longer has to train each candidate network configuration from scratch. Challenge 2: Efficiently optimizing configurations. Recall from above that our planner aims to optimize the number of quadratic approximations, their placement in the network, and the training hyperparameters. Attempting to optimize all of these variables within a single NAS execution results in a large search space, and finding efficient networks in this search space takes a correspondingly long time.</p><p>To solve this problem, we divided up the monolithic NAS execution into independent runs that are responsible for optimizing different variables. For instance, for an architecture with n non-linear layers, for relevant choices of m &lt; n, we first perform NAS to find high-scoring architectures that have m approximation layers, and then perform NAS again to optimize training hyperparameters for these architectures. At the end of this process, our planner outputs a variety of networks with different performance-accuracy trade-offs. Challenge 3: Prioritizing efficient configurations. Our planner's goal is to choose configurations containing the largest number of approximations in order to maximize efficiency. However, network configurations with large numbers of approximations take longer to train and may be slightly less accurate than networks with fewer approximations. Since the traditional NAS literature focuses on simply maximizing efficiency, using NAS in this default setting results in selecting slower networks over more efficient networks that are just slightly less accurate than the slower ones. To overcome this, we changed the way the NAS assigns "scores" to candidate networks by designing a new scoring function score(·) which balances prioritizing accuracy and performance. Our experiments from Section 7 indicate that this function enables us to select networks that are both efficient and accurate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>score(N) := acc(N)</head><p>1 + #quad. activations #total activations .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Choosing a NAS algorithm</head><p>The discussion so far has been agnostic to the choice of NAS algorithm. In our implementation, we decided to use the popular population-based training algorithm [Jad+17] because it was straightforward to customize it for our use case, and because it enjoys a number of optimized implementations (like the one in <ref type="bibr">[Lia+18]</ref>). Population-based training (PBT) [Jad+17] maintains a population of candidate neural networks that it trains over a series of time steps. At the end of each time step, it measures the performance of each candidate network via a user-specified scoring function, and replaces the worst-performing candidates with mutated versions of the best-performing ones (the mutation function is specified by the user). At the end of the optimization process, PBT outputs the best-performing candidate network architectures it has found (along with the hyperparameters for training them).  Remark 6.1 (reimplementing GAZELLE's algorithms). <ref type="bibr">Riazi et al. [Ria+19]</ref> note that GAZELLE's implementation does not provide circuit privacy for HE, which can result in leakage of information about linear layers. To remedy this, they recommend using larger parameters that ensure circuit privacy. (The caveat is that these parameters result in worse performance than using GAZELLE's highly optimized parameters.) Because DELPHI uses GAZELLE's algorithms in our preprocessing phase, we attempted to modify GAZELLE's implementation <ref type="bibr">4</ref> to use the circuit-private parameters. However, this proved to be difficult, and so we decided to reimplement these algorithms in SEAL, which does support these parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">System implementation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Evaluation</head><p>We divide our evaluation into three sections that answer the following questions.</p><p>• Section 7.2: How efficient are DELPHI's building blocks?</p><p>• Section 7.3: Does DELPHI's planner provide a good balance between efficiency and accuracy for realistic neural networks, such as ResNet-32? • Section 7.4: What is the latency and communication cost of using DELPHI for serving predictions with such neural networks?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Evaluation setup</head><p>All cryptographic experiments were carried out on AWS c5.2xlarge instances possessing an Intel Xeon 8000 series machine CPU at 3.0 GHz with 16 GB of RAM. The client and server were executed on two such instances located in the us-west-1 (Northern California) and us-west-2 (Oregon) regions respectively. The client and server executions used 4 threads each. Machine learning experiments were carried out on various machines with NVIDIA Tesla V100 GPUs. Our machine learning and cryptographic protocol experiments rely on the following datasets and architectures: 1. CIFAR-10 is a standardized dataset consisting of (32 × 32) RGB images separated into 10 classes. The training set contains 50, 000 images, while the test set has 10, 000 images. Our experiments use the 7-layer CNN architecture specified in <ref type="bibr">MiniONN [Liu+17a]</ref>. Doing so allows us to compare our protocol with prior work. 2. CIFAR-100 contains the same number of training and test images as CIFAR-10, but divides them up into 100 classes instead of 10. This increased complexity requires a deeper network with more parameters, and so our experiments use the popular ResNet-32 architecture introduced in <ref type="bibr">[He+16]</ref>. We note that no prior work on secure inference attempts to evaluate their protocols on difficult datasets like CIFAR-100 or on deep network architectures like ResNet-32. Whenever we compare DELPHI with GAZELLE, we estimate the cost of GAZELLE's protocols by summing the costs of our re-implementation of the relevant subprotocols for linear and non-linear layers. We do this as there is no end-to-end implementation of GAZELLE's protocol; only the individual subprotocols are implemented.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Microbenchmarks</head><p>We provide microbenchmarks of DELPHI's performance on linear and non-linear layers, comparing both with GAZELLE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.1">Linear operations</head><p>Below we focus on the performance of convolution operations because these comprise the majority of the cost of neural networks' linear operations. The complexity of a convolution is determined by the dimensions of the input and the size and number of convolution kernels, as well as the padding and stride (the latter parameter decides how often the kernel is applied to the input). In <ref type="table" target="#tab_1">Table 1</ref>, we evaluate the cost of convolutions used in ResNet-32. The key takeaway is that our online time is over 80× smaller than GAZELLE's, and our online communication is over 150× lower. On the other hand, our preprocessing time and communication are higher than GAZELLE's, but are at most equal to GAZELLE's online time and communication. Optimized GPU operations. As explained in Remark 4.2, DELPHI's choice of prime field enables DELPHI to use standard GPU libraries for evaluating convolutional layers in the online phase. However, doing so requires copying the layer weights and input into GPU memory, and copying the output back into CPU memory for every linear layer. This copying can have substantial overhead. To amortize it, one can batch convolutions over different inputs together. In <ref type="table" target="#tab_4">Table 2</ref>, we report the cost of doing so for a batch sizes of 1, 5, and 10. The key takeaway is that, for single convolutions these costs are over 50-100× lower than the equivalent ones in <ref type="table" target="#tab_1">Table 1</ref>, and for batched convolutions, the cost seems to scale sub-linearly with the batch size.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.2">ReLU and quadratic activations</head><p>Recall that our protocol for evaluating ReLU activations uses garbled circuits. Our circuit for ReLU follows the design laid out in <ref type="bibr">[Juv+18]</ref> with minor additional optimizations. To evaluate quadratic activations, our protocol uses Beaver's multiplication procedure <ref type="bibr">[Bea95]</ref>, which requires sending one field element from the server to the client and vice versa, and then requires some cheap local field operations from each party. The communication and computation costs for both activations are presented in <ref type="table" target="#tab_5">Table 3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3">DELPHI's planner</head><p>To demonstrate the effectiveness of our planner we need to show that (a) quadratic activations are an effective replacement for ReLU activations, and that (b) the networks found by the planner offer better performance than all-ReLU networks.</p><p>In our experiments below, we use 80% of the training data to train networks in the planner, and the remaining 20% as a validation set. The planner scores candidate networks based on their validation accuracy, but the final reported accuracy is the test set accuracy. Quadratic activations are effective. We need to show that not only do networks output by our planner achieve good accuracy, but also that the quadratic activations are not redundant. That is, we need to show that the network is not learning to "ignore" quadratic activations. This is a concern because prior work [Mol+17; Liu+18] has shown that modern neural network architectures can be "pruned" to remove extraneous parameters and activations while still maintaining almost the same accuracy.</p><p>We show this point by running our planner in two modes. In the first mode, our planner was configured to find performant networks that used quadratic activations, while in the second mode it was configured to find networks that used the identity function instead of quadratic activations, with the intuition that if the quadratic activations were ineffective, then networks that used the identity function instead would perform just as well. The results of these runs for varying number of non-ReLU layers are displayed in <ref type="figure" target="#fig_8">Fig. 7</ref> (for CIFAR-10) and in <ref type="figure" target="#fig_0">Fig. 8 (for CIFAR-100)</ref>. Together, these results indicate that the networks output by our planner achieve performance that is comparable to that of the all-ReLU baselines. Furthermore, as the number of non-ReLU layers increase, the best-performing networks that use the identity activation function have much worse accuracy than the equivalent networks that use quadratic activations. Planned networks perform better. To evaluate the ability of our planner to find networks that offer good performance, we run the planner to produce networks with a varying number (say k) of quadratic layers. We then compare the number of ReLU activations in these networks to that in all-ReLU networks (like those supported by GAZELLE). <ref type="figure" target="#fig_11">Fig. 9</ref>          this comparison for ResNet32 on CIFAR-100. We observe that the networks found by our planner consistently have fewer activations than the all-ReLU baseline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.4">DELPHI's cryptographic protocols</head><p>We demonstrate the effectiveness of DELPHI's cryptographic protocol by showing that DELPHI's preprocessing phase and online phase offer significant savings in latency and communication cost over prior work (GAZELLE). Figs. 10 and 11 summarizes this improvement for networks found by our planner; we provide a detailed evaluation next. Preprocessing phase. <ref type="figure" target="#fig_0">Figs. 12a and 13a</ref> compare the time required to execute the preprocessing phases of DELPHI and GAZELLE on ResNet32 on CIFAR-100 and the MiniONN architecture on CIFAR-10, respectively. In both cases, we observe that, on networks that have a large number of ReLU activations, DELPHI's preprocessing time is larger than GAZELLE's. This is because DELPHI needs to additionally perform preprocessing for each linear layer. However, as the number of approximate activations increases, DELPHI's preprocessing time quickly decreases below that of GAZELLE, because garbling circuits for ReLUs is far more expensive than the preprocessing phase for the approximate activations. A similar trend can be observed for communication costs in <ref type="figure" target="#fig_0">Figs. 12c and 13c</ref>. Overall, for the most efficient networks output by our planner, DELPHI requires 1.5-2 × less preprocessing time, and 6-40 × less communication. Online phase. <ref type="figure" target="#fig_0">Figs. 12b and 13b</ref> compare the time required to execute the online phases of DELPHI and GAZELLE on ResNet32 on CIFAR-100 and the MiniONN architecture on CIFAR-10, respectively. In both cases, we observe that GAZELLE's use of HE for processing linear layers imposes a significant computational cost. Furthermore, as the number of approximate activations increases, the gap between DELPHI and GAZELLE grows larger. A similar trend can be observed for communication costs in <ref type="figure" target="#fig_0">Figs. 12d and 13d</ref>. Overall, for the most efficient networks output by our planner, DELPHI requires 22-100 × less time to execute its online phase, and 9-40 × less communication.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Related work</head><p>We first discuss cryptographic techniques for for secure execution of machine learning algorithms in Section 8.1. Then, in Section 8.2, we discuss model inference attacks that recover information about the model from predictions, as well as countermeasures for these attacks. Finally, in Section 8.3, we discuss prior work on neural architecture search.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.1">Secure machine learning</head><p>The problem of secure inference can be solved via generic secure computation techniques like secure two-party (2PC) computation <ref type="bibr">[Yao86; Gol+87]</ref>, fully homomorphic encryption (FHE) <ref type="bibr">[Gen09]</ref>, or homomorphic secret sharing (HSS) <ref type="bibr">[Boy+16]</ref>. However, the resulting protocols would suffer from terrible communication and computation complexity. For instance, the cost of using 2PC to compute a function grows with the size of the (arithmetic or boolean) circuit for that function. In our setting, the function being computed is the neural network itself. Evaluating the network requires matrix-vector multiplication, and circuits for this operation grow quadratically with the size of the input. Thus using a generic 2PC protocol for secure inference would result in an immediate quadratic blow up in both computation and communication.</p><p>Similarly, despite a series of efforts to improve the efficiency of FHE [Bra+11; <ref type="bibr">Gen+11; Fan+12; Hal+18; Hal+19]</ref> and HSS <ref type="bibr">[Boy+17]</ref>, their computational overhead is still large, making them unsuitable for use in our scenario.</p><p>Hence, it seems that it is necessary to design specialized protocols for secure machine learning, and indeed there is a long line of prior work [Du+04; Lau+06; Bar+09; Nik+13a; Nik+13b; Sam+15; Bos+15; Wu+16a; Aon+16; Sch+19] that does exactly this. These works generally fall into two categories: those that focus on secure training, and those that focus on secure inference. Since secure training is not our focus in this paper, we omit discussing it, and instead focus on prior work on secure inference. Most of these early works focus on simpler machine learning algorithms such as SVMs and linear regression. Designing cryptographic protocols for these simpler algorithms is often more tractable than our setting of inference for neural networks.</p><p>Hence, in the rest of this section we discuss prior work that focus on secure inference over neural networks. This work generally falls into the following categories: (a) 2PC-based protocols; (b) FHE-based protocols; (c) TEE-based protocols; and (d) protocols working in a multi-party model.</p><p>2PC-based protocols. SecureML <ref type="bibr">[Moh+17]</ref> is one of the first systems to focus on the problem of learning and predicting with neural networks securely. However, it relies entirely on generic 2PC protocols to do this, resulting in poor performance on realistic networks. <ref type="bibr">MiniONN [Liu+17a]</ref> uses the SPDZ protocol to compute linear layers and polynomial approximation activations. Unlike DELPHI, MiniONN generates multiplicative triples for each multiplication in a linear layer; for a layer with input size n, MiniONN requires n 2 offline and online communication, compared to n for DELPHI. GAZELLE [Juv+18] is the system most similar to ours: it uses an efficient HE-based protocol for linear layers, while using garbled circuits to compute non-linear activations. However, its reliance on heavy cryptographic operations in the online phase results in a protocol that is more expensive than DELPHI's protocol with respect to both computation and communication (see Section 7 for a thorough comparison).</p><p>DeepSecure <ref type="bibr">[Rou+18]</ref> and XONN <ref type="bibr">[Ria+19]</ref> use garbled circuits to provide secure inference for the restricted class of binarized neural networks [Cou+15] whose weights are all boolean. This restriction enables these protocols to construct a protocol that uses only a constant number of round trips. DeepSecure additionally prunes the input neural network to reduce the number of activations. <ref type="bibr">Ball et al. [Bal+19]</ref> have also recently constructed a protocol for secure inference that FHE-based protocols. CryptoNets <ref type="bibr">[Gil+16]</ref> is the first work that attempts to optimize and tailor FHE schemes for secure inference. Despite optimizations, the limitations of FHE mean that CryptoNets is limited to networks only a few layers deep, and even for these networks it only becomes efficient when processing a batch of inputs. Recent papers [Hes+17; Bru+18; Bou+18; Cho+18; San+18] develop different approaches to optimize the CryptoNets paradigm, but the resulting protocols still require tens of minutes to provide predictions over networks much smaller than the ones we consider here.</p><p>CHET <ref type="bibr">[Dat+19]</ref> compiles high-level specifications of neural network to FHE-based inference protocols. To efficiently use FHE, CHET must replace all ReLUs with polynomial approximations, which harms accuracy for large networks.</p><p>TEE-based protocols. There are two approaches for inference using trusted execution enclaves (TEEs): (a) inference via server-side enclaves, where the client uploads their input to the server's enclave, and (b) inference in client-side enclaves, where the client submits queries to a model stored in the client-side enclave.</p><p>Slalom and Privado are examples of protocols that rely on server-side enclaves. Slalom <ref type="bibr">[Tra+19]</ref>, like DELPHI, splits inference into an offline and online phase, and uses additive secret sharing for the online phase. Unlike DELPHI, Slalom uses the Intel SGX hardware enclave <ref type="bibr">[McK+13]</ref> to securely compute both the offline and online phases. Privado <ref type="bibr">[Top+18]</ref> compiles neural networks into oblivious neural networks, meaning that computing the transformed network does not require branching on secret data. They use the oblivious network to perform inference inside Intel SGX enclaves. Slalom's implementation indicates that it does not implement linear or non-linear layers obliviously.</p><p>MLCapsule [Han+18] describes a system for performing inference via client-side enclaves. Apple uses a client-side secure enclave to perform fingerprint and face matching to authorize users <ref type="bibr">[App19]</ref>.</p><p>In general, most TEE-based cryptographic inference protocols offer better efficiency than protocols that rely on cryptographic (like DELPHI). This improved efficiency comes at the cost of a weaker threat model that requires trust in hardware vendors and the implementation of the enclave. Furthermore, because the protocol execution occurs in an adversarial environment, any side-channel leakage is more dangerous (since the adversary can carefully manipulate the execution to force this leakage). Indeed, the past few years have seen a number of powerful side-channel attacks [Bra+17; Häh+17; Göt+17; Mog+17; Sch+17; Wan+17; Van+18] against popular enclaves like Intel SGX and ARM TrustZone.</p><p>Protocols with more parties. The discussion above focuses</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>USENIX Association 29th USENIX Security Symposium 2517</head><p>on two-party protocols, because in our opinion secure inference maps naturally to this setting. Nevertheless, a number of works [Ria+18; Wag+18; Tfe; Bar+19] have instead targeted the three-party setting where shares of the model are divided amongst two non-colluding servers, and a client must interact with these servers to obtain their prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2">Model leakage from predictions</head><p>Prediction API attacks [Ate+15; Fre+15; Wu+16b; Tra+16; Sho+17; Jag+19] aim to learn private information about the server's model or training data given access only to the results of predictions on arbitrary queries. There is no general defense against prediction API attacks beyond rate limiting and query auditing <ref type="bibr">[Jag+19]</ref>. However, there are defenses against specific classes of attacks. For example, one can use differentially private training [Sho+15; Aba+16] to train neural networks that that do not leak sensitive information about the underlying training data.</p><p>The guarantees of DELPHI are complementary to those provided by any such mitigations. Indeed, with sufficient effort, these techniques can be integrated into DELPHI to provide even stronger privacy guarantees; we leave this to future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.3">Neural architecture search</head><p>Recently, machine learning research has seen rapid advancement in the area of neural architecture search (NAS) (see [Els+19; Wis+19] for surveys). The aim of this field is to develop methods to automatically optimize properties of a neural network like accuracy and efficiency by optimizing the hyperparameters of the network. Examples of commonly optimized hyperparameters include the size of convolutional kernels, the number of layers, and parameters of the gradient descent algorithm like learning rate and momentum. In this work, we rely on NAS algorithms only for optimizing the placement of quadratic approximation layers within a network, as ReLU activations were the bottleneck in our system.</p><p>Common approaches to neural architecture search include those based on reinforcement-learning <ref type="bibr">[Zop+17]</ref>, evolutionary algorithms <ref type="bibr">[Yao99; Ber+13]</ref>, and random search [Ber+12; Jad+17]. DELPHI's planner uses the Population-Based Training algorithm [Jad+17] to perform NAS. PBT can be seen as a hybrid of the evolutionary algorithm and random search approaches.</p><p>Security for linearly homomorphic encryption schemes requires the scheme to satisfy the following properties:</p><p>• Semantic security. For any two messages m, m , we require {pk, HE.Enc(pk, m)} ≈ c {pk, HE.Enc(pk, m )}, where the two distributions are over the random choice of pk and the random coins of the encryption algorithm.</p><p>• Function privacy. There exists a simulator Sim FP such that for every efficient adversary A, every linear function L, and every pair of messages m 1 , m 2 , we have that the following distributions are computationally indistinguishable:</p><formula xml:id="formula_10">          </formula><p>(r, r 1 , r 2 , c ) :</p><p>(r, r 1 , r 2 ) ← {0, 1} λ (pk, sk) ← HE.KeyGen(1 λ ; r) c 1 ← HE.Enc(pk, m 1 ; r 1 ) c 2 ← HE.Enc(pk, m 2 ; r 2 ) c ← HE.Eval(pk, c 1 , c 2 , L)</p><formula xml:id="formula_11">           ≈ c Sim FP (1 λ , m 1 , m 2 , L(m 1 , m 2 ))</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Security proofs</head><p>Proof of indistinguishability with corrupted client. We show that the real world distribution is computationally indistinguishable to the simulated distribution via a hybrid argument. In the final simulated distribution, the simulator does not use the weights for the server's model, and so a corrupted client learns nothing beyond the output prediction and the model architecture in the real world.</p><p>• Hyb 0 : This corresponds to the real world distribution where the server uses its input matrices M 1 , . . . , M −1 .</p><p>• Hyb 1 : This hybrid involves only a syntactic change. In the output phase, the simulator sends y − r to the client, where y is the output of the neural network on input x. Additionally, the simulator uses the knowledge of the client's random tape to begin the evaluation of the i-th layer with x i − r i . Since this is a syntactic change, Hyb 1 is distributed identically to Hyb 0 .</p><p>• Hyb 2 : We change the inputs that the server provides to each OT execution where it acts as the sender. Instead of providing the labels corresponding to 0 and 1 in each OT execution, the server provides label i,b where b is the input used by the client in that OT execution. Note that in the semi-honest setting, we know b as a result of setting the random tape as well learning the input of the corrupted client. It follows from the sender security of OT that Hyb 2 is indistinguishable from Hyb 1 .</p><p>• Hyb 3 : In this hybrid, for every layer of the neural network that uses garbled circuits, we generate C using Sim GS on input 1 λ , 1 |C| and C(z) where z is the input that the client uses to evaluate this circuit (this is again known in the semihonest setting as a result of setting the random tape and knowing the input). Note that C(z) is an OTP encryption and hence is distributed identically to a random string. It follows from the security of the garbled circuits that Hyb 3 is indistinguishable from Hyb 2 .</p><p>• Hyb 4 : In this hybrid, we generate the multiplication triples in the offline phase using the corresponding simulator for Beaver's protocol. It follows from the simulation security of this protocol that Hyb 4 is indistinguishable from Hyb 3 .</p><p>• Hyb 5 : In this hybrid, for every quadratic approximation layer, we use the simulator for Beaver's multiplication procedure. It again follows from the simulation security that this hybrid is indistinguishable to the previous hybrid. Notice that in this hybrid, the server is no longer using x i − r i , s i as well as the matrix M i to evaluate the i-th layer.</p><p>• Hyb 6 : For every homomorphic evaluation in the offline phase, we use the simulator Sim FP for the function privacy of HE. Note that Sim FP only requires the output M i · r i − s i to generate the homomorphically evaluated ciphertext. It follows from the function privacy of HE that Hyb 6 is computationally indistinguishable from Hyb 5 .</p><p>• Hyb 7 : In this hybrid, we replace the input −s i given to Sim FP with randomly sampled s i from R n (instead of the true value M i · r i − s i ). Thus Hyb 7 is distributed identically to Hyb 6 as s i is chosen uniformly at random. Finally, we note that Hyb 7 is identically distributed to the simulator's output, completing the proof. Proof of indistinguishability with corrupted server. We show that the real world distribution is computationally indistinguishable to the simulated distribution via a hybrid argument. In the final simulated distribution, the simulator does not use the user's input, and so a corrupted server learns nothing in the real world.</p><p>• Hyb 0 : This corresponds to the real world distribution where the client uses its actual input x.</p><p>• Hyb 1 : This hybrid involves only a syntactic change. For every layer that is evaluated by garbled circuits, instead of evaluating the circuits, we instead send OT P(x i+1 − r i+1 ) by using our knowledge of x, the matrices M i , and the random tape of the server. Similarly, in every quadratic approximation layer, we send a share in the final round such that when the server adds it with its own share it gets x i+1 − r i+1 . Because this change is only syntactic, Hyb 1 is identical to Hyb 0 .</p><p>• Hyb 2 : In this hybrid, we change the inputs that the client provides to each OT execution where it is acting as the receiver. Instead of providing the actual inputs, it provides some junk inputs, say 0. It follows from the receiver security of the underlying oblivious transfer protocol that Hyb 2 is computationally indistinguishable from Hyb 1 .</p><p>• Hyb 3 : In this hybrid, we generate the multiplication triples in the offline phase using the simulator for Beaver's multiplication protocol. It follows from the simulation security of this protocol that Hyb 4 is indistinguishable from Hyb 2 .</p><p>• Hyb 4 : In this hybrid, for every quadratic approximation layer of the neural network, we use the simulator for the Beaver's multiplication procedure. It follows from simulation security that Hyb 4 is indistinguishable from Hyb 3 .</p><p>• Hyb 5 : In this hybrid, we change the ciphertexts sent by the client in the offline phase. Instead of sending encryptions of r i , the client sends HE.Enc(pk, 0). It follows from the semantic security of the encryption scheme that Hyb 5 is computationally indistinguishable from Hyb 4 .</p><p>• Hyb 6 : In this hybrid, we make the following changes. For every layer that is evaluated by garbled circuits, we send OT P(r i+1 ) for a randomly chosen r i+1 . Similarly, in every quadratic approximation layer, we send a share in the final round that is chosen uniformly at random. Additionally, in the preamble phase, we send an uniformly chosen value r 1 . Hyb 6 is distributed identically to Hyb 5 . Finally, note that Hyb 6 is identically distributed to the simulator's output, completing the proof.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Cryptographic neural network inference. The lock indicates data provided in encrypted form.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: DELPHI's architecture. Orange layers represent quadratic approximations while blue ones represent ReLUs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: DELPHI's online phase.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: A circuit that computes ReLU.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Remark 4. 2</head><label>2</label><figDesc>(fixed-point arithmetic in finite fields). The dis- cussion so far assumes arithmetic over a finite ring. However, popular implementations of neural network inference perform arithmetic over floating-point numbers. We work around this by using fixed-point representations of floating-point num- bers, and embedding this fixed-point arithmetic in our ring arithmetic.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>DELPHI's planner takes the service provider's neural network model (as well as other constraints) and produces a new neural network architecture that meets the accuracy and efficiency goals of the service provider. At the heart of this planner is an algorithm for neural architecture search (NAS) that enables the service provider to automatically find such network ar- chitectures. Below we give a high level overview of this key component and describe how our planner uses it. Background: neural architecture search. Recently, ma- chine learning research has seen rapid advancement in the area of neural architecture search (NAS) [Els+19; Wis+19]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>DELPHI's cryptographic protocols are implemented in Rust and C++. We use the SEAL homomorphic encryption library [Sea] to implement HE, and rely on the fancy-garbling library 3 for garbled circuits. To ensure an efficient preprocess- ing phase, we reimplemented GAZELLE's efficient algorithms 3 https://github.com/GaloisInc/fancy-garbling/Let the number of non-linear layers in N be n. 2. Initialize set of output networks F . 3. For i in {n/2, . . . , n}: (a) Compute the set of best performing models with i quadratic approximation layers: S i ← PBT(N, D, score(·)). (b) Optimize hyperparameters for these models: S i ← PBT(S i , D, score(·)). (c) If for any N j ∈ S i the accuracy of N j is less than t, discard N j . (d) Define N i to be the network with the maximum score among the remaining networks. (e) Set F := F ∪ {N i }. 4. Output F .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Pseudocode for DELPHI's planner.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: CIFAR-10 accuracy of 7-layer MiniONN networks found by our planner.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: CIFAR-100 accuracy of ResNet32 networks found by our planner.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Number of ReLU activations in ResNet32 networks found by our planner.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 10 :</head><label>10</label><figDesc>Figure 10: Total execution time on the best planned network (DELPHI) and the all-ReLU baseline (GAZELLE).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 11 :</head><label>11</label><figDesc>Figure 11: Total communication on the best planned network (DELPHI) and the all-ReLU baseline (GAZELLE).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 12 :Figure 13 :</head><label>1213</label><figDesc>Figure 12: Comparison of DELPHI with GAZELLE on the ResNet-32 architecture.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>) Sample r i ← R n Sample s i ← R n enc(M i r i −s i )</head><label></label><figDesc></figDesc><table>Association 
29th USENIX Security Symposium 2509 

Client 

Server 

enc(r i M i r i −s i 
s i 

˜ 
C i 

Garbled 
circuits 

Beaver's 
triples 
F pre 

Beaver 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>1 . The client and the server run the</head><label>1</label><figDesc></figDesc><table>Beaver's multiplication 
procedure to evaluate the polynomial approximating 
this layer. At the end of the procedure, the client holds 
[x i+1 ] 1 and the server holds [x i+1 ] 2 . 
2. The client computes [x i+1 ] 1 − r i+1 and sends them to 
the server. The server adds [x i+1 ] 2 to this value to obtain 
x i+1 − r i+1 . 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Running time and communication cost of ResNet-32 convolutions in DELPHI. 

0 
1 
2 
3 
4 
5 
6 
7 

Number of non-ReLU layers 

40 

50 

60 

70 

80 

Accuracy (%) 

all-ReLU baseline 
ReLU + Quadratic 
ReLU + Identity 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Running time and communication cost of ResNet-32 con-
volutions in DELPHI when run on the GPU across different batch 
sizes b. 

activation 
function 

time (µs) 
comm. (kB) 
preproc. online preproc. online 

Quad 
6 
0.03 
0.152 
0.008 

ReLU 
154.9 
85.3 
17.5 
2.048 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Amortized running time and communication cost of indi-
vidual ReLU and quadratic activations in DELPHI. 

</table></figure>

			<note place="foot" n="4"> https://github.com/chiraag/gazelle_mpc</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Acknowledgements</head><p>We thank Liam Li for the suggestion to use the PBT algorithm to perform NAS, Joey Gonzalez for answering questions about PBT, Robert Nishihara for the suggestion to use ReLU's gradients to guide gradient descent, Chiraag Juvekar for providing the code for GAZELLE, and our shepherd Siddharth Garg and the anonymous reviewers for their invaluable feedback. This work was supported by the NSF CISE Expeditions Award CCF-1730628, as well as gifts from the Sloan Foundation, Bakar and Hellman Fellows Fund, Alibaba, Amazon Web Services, Ant Financial, Arm, Capital One, Ericsson, Facebook, Google, Intel, Microsoft, Scotiabank, Splunk and VMware.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">B</forename><surname>Mcmahan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Mironov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Talwar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<title level="m">Deep Learning with Differential Privacy</title>
		<imprint/>
	</monogr>
	<note>CCS &apos;16</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Scalable and Secure Logistic Regression via Homomorphic Encryption</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Aono</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hayashi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">T</forename><surname>Phong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>In: CODASPY &apos;16</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Apple</surname></persName>
		</author>
		<ptr target="https://www.apple.com/business/docs/site/iOS_Security_Guide.pdf" />
		<title level="m">iOS Security</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Hacking smart machines with smarter ones: How to extract meaningful data from machine learning classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Ateniese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">V</forename><surname>Mancini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Spognardi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Villani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Vitali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Felici</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page">IJSN</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Garbling Gadgets for Boolean and Arithmetic Circuits</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ball</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Malkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rosulek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CCS &apos;16</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Garbled Neural Networks are Practical</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ball</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Carmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Malkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rosulek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Schimanski</surname></persName>
		</author>
		<idno>2019/338</idno>
		<imprint/>
	</monogr>
<note type="report_type">ePrint Report</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Secure Evaluation of Private Linear Branching Programs with Medical Applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Barni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Failla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Lazzeretti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sadeghi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Schneider</surname></persName>
		</author>
		<idno>ESORICS &apos;09</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">The year Alexa grew up</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Barrett</surname></persName>
		</author>
		<ptr target="https://www.wired.com/story/amazon-alexa-2018-machine-learning/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Secure Evaluation of Quantized Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Barak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Escudero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dalskov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Keller</surname></persName>
		</author>
		<idno>2019/131</idno>
		<imprint/>
	</monogr>
<note type="report_type">ePrint Report</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Precomputing Oblivious Transfer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Beaver</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CRYPTO &apos;95</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Foundations of garbled circuits</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bellare</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">T</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rogaway</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CCS &apos;12</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Learning long-term dependencies with gradient descent is difficult</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">Y</forename><surname>Simard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Frasconi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Networks</title>
		<imprint>
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Random Search for Hyper-Parameter Optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bergstra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page">JMLR</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Making a Science of Model Search: Hyperparameter Optimization in Hundreds of Dimensions for Vision Architectures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bergstra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yamins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">D</forename><surname>Cox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML &apos;13</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bost</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Popa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Goldwasser</surname></persName>
		</author>
		<title level="m">Machine Learning Classification over Encrypted Data&quot;. In: NDSS &apos;15</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Fast Homomorphic Evaluation of Deep Discretized Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Bourse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Minelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Minihold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Paillier</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>In: CRYPTO &apos;18</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Function Secret Sharing: Improvements and Extensions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Boyle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Gilboa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ishai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CCS &apos;16</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Homomorphic Secret Sharing: Optimizations and Applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Boyle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Couteau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Gilboa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ishai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Orrú</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CCS &apos;17</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Brakerski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vaikuntanathan</surname></persName>
		</author>
		<title level="m">Efficient Fully Homomorphic Encryption from (Standard) LWE&quot;. In: FOCS &apos;11</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Software Grand Exposure: SGX Cache Attacks Are Practical</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Brasser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dmitrienko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kostiainen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Capkun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sadeghi</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>In: WOOT &apos;17</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Low Latency Privacy Preserving Inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Brutzkus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Elisha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Gilad-Bachrach</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Arxiv</surname></persName>
		</author>
		<idno>cs.CR 1812.10659</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">EzPC: Programmable, Efficient, and Scalable Secure Two-Party Computation for Machine Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Chandran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rastogi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tripathi</surname></persName>
		</author>
		<idno>2017/1109</idno>
		<imprint/>
	</monogr>
<note type="report_type">ePrint Report</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Beal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yeung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Haque</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<title level="m">Faster CryptoNets: Leveraging Sparsity for Real-World Encrypted Inference</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Arxiv</surname></persName>
		</author>
		<idno>cs.CR 1811.09953</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">BinaryConnect: Training Deep Neural Networks with binary weights during propagations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Courbariaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>David</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS &apos;18</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">CHET: An optimizing compiler for fully-homomorphic neural-network inferencing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Dathathri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Saarikivi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">E</forename><surname>Lauter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maleki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Musuvathi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mytkowicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PLDI &apos;19</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">PrivacyPreserving Multivariate Statistical Analysis: Linear Regression and Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">S</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<idno>SDM &apos;04</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A public key cryptosystem and a signature scheme based on discrete logarithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Inf. Theory</title>
		<imprint>
			<date type="published" when="1985" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Neural Architecture Search: A Survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Elsken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Metzen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page">JMLR</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A Randomized Protocol for Signing Contracts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Even</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Goldreich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lempel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CRYPTO &apos;82</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Somewhat Practical Fully Homomorphic Encryption</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Vercauteren</surname></persName>
		</author>
		<idno>2012/144</idno>
		<imprint/>
	</monogr>
<note type="report_type">ePrint Report</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Privacy in Pharmacogenetics: An End-to-End Case Study of Personalized Warfarin Dosing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fredrikson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Lantz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Page</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ristenpart</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>In: USENIX Security &apos;14</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Model Inversion Attacks that Exploit Confidence Information and Basic Countermeasures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fredrikson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ristenpart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CCS &apos;15</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Fully homomorphic encryption using ideal lattices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gentry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">STOC &apos;09</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Implementing Gentry&apos;s Fully-Homomorphic Encryption Scheme</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gentry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Halevi</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>In: EUROCRYPT &apos;11</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">SafetyNets: Verifiable Execution of Deep Neural Networks on an Untrusted Cloud</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ghodsi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Garg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS &apos;17</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Gilad-Bachrach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Dowlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lauter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Naehrig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wernsing</surname></persName>
		</author>
		<title level="m">CryptoNets: Applying Neural Networks to Encrypted Data with High Throughput and Accuracy&quot;. In: ICML &apos;16</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">How to Play any Mental Game or A Completeness Theorem for Protocols with Honest Majority</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Goldreich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Micali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wigderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">STOC &apos;87</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Google Lens</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Google</surname></persName>
		</author>
		<ptr target="https://lens.google.com/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Cache Attacks on Intel SGX</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Götzfried</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Eckert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Schinzel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Müller</surname></persName>
		</author>
		<idno>EU- ROSEC &apos;17</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">HighResolution Side Channels for Untrusted Operating Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hähnel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Peinado</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Faster Homomorphic Linear Transformations in HElib</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Halevi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Shoup</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CRYPTO &apos;18</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">An Improved RNS Variant of the BFV Homomorphic Encryption Scheme</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Halevi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Polyakov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Shoup</surname></persName>
		</author>
		<idno>CT-RSA &apos;19</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">MLCapsule: Guarded Offline Deployment of Machine Learning as a Service</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Hanzlik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Grosse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Salem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Augustin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Backes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fritz</surname></persName>
		</author>
		<idno>cs.CR 1808.00590</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiV</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Deep Residual Learning for Image Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR &apos;16</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">CryptoDL: Deep Neural Networks over Encrypted Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hesamifard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Takabi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ghasemi</surname></persName>
		</author>
		<idno>cs.CR 1711.05189</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiV</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Extending Oblivious Transfers Efficiently</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ishai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kilian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Nissim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Petrank</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CRYPTO &apos;03</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Population Based Training of Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jaderberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Dalibard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Osindero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Czarnecki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Razavi</surname></persName>
		</author>
		<idno>cs.LG 1711.09846</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiV</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">High-Fidelity Extraction of Neural Network Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jagielski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kurakin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Papernot</surname></persName>
		</author>
		<idno>cs.LG 1909.01838</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiV</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">GAZELLE: A Low Latency Framework for Secure Neural Network Inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Juvekar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vaikuntanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chandrakasan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">USENIX &apos;18</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Convolutional Deep Belief Networks on CIFAR-10</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<ptr target="http://www.cs.utoronto.ca/~kriz/conv-cifar10-aug2010.pdf" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Kuna AI</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kuna</surname></persName>
		</author>
		<ptr target="https://getkuna.com/blogs/news/2017-05-24-introducing-kuna-ai" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Cryptographically private support vector machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Laur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lipmaa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mielikäinen</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">Tune: A Research Platform for Distributed Model Selection and Training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Liaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Nishihara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Moritz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Stoica</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Oblivious Neural Network Predictions via MiniONN Transformations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Juuti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Asokan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CCS &apos;17</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">A survey of deep neural network architectures and their applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">E</forename><surname>Alsaadi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>In: Neurocomputing</note>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">FinePruning: Defending Against Backdooring Attacks on Deep Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Dolan-Gavitt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Garg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">Innovative instructions and software model for isolated execution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Mckeen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Alexandrovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Berenzon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">V</forename><surname>Rozas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Shafi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Shanbhogue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><forename type="middle">R</forename><surname>Savagaonkar</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>In: HASP &apos;13</note>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">CacheZoom: How SGX Amplifies the Power of Cache Attacks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Moghimi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Irazoqui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Eisenbarth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CHES &apos;17</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">SecureML: A System for Scalable Privacy-Preserving Machine Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mohassel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE S&amp;P &apos;17</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">Pruning Convolutional Neural Networks for Resource Efficient Inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Molchanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tyree</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Karras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Aila</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kautz</surname></persName>
		</author>
		<idno>ICLR &apos;17</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Privacypreserving matrix factorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Nikolaenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioannidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Weinsberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Joye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Taft</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Boneh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CCS &apos;13</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">PrivacyPreserving Ridge Regression on Hundreds of Millions of Records</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Nikolaenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Weinsberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioannidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Joye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Boneh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Taft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE S&amp;P &apos;13</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Public-Key Cryptosystems Based on Composite Degree Residuosity Classes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Paillier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EUROCRYPT &apos;99</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">How To Exchange Secrets with Oblivious Transfer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">O</forename><surname>Rabin</surname></persName>
		</author>
		<idno>TR-81</idno>
	</analytic>
	<monogr>
		<title level="j">Harvard University Technical Report</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">On lattices, learning with errors, random linear codes, and cryptography</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Regev</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page">JACM</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Chameleon: A Hybrid Secure Computation Framework for Machine Learning Applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Riazi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Weinert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Tkachenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">M</forename><surname>Songhori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Koushanfar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AsiaCCS &apos;18</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<title level="m" type="main">XONN: XNORbased Oblivious Deep Neural Network Inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Riazi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Samragh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lauter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Koushanfar</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>In: USENIX &apos;19</note>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title level="m" type="main">DeepSecure: Scalable Provably-secure Deep Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">D</forename><surname>Rouhani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Riazi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Koushanfar</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>In: DAC &apos;18</note>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">k-Nearest Neighbor Classification over Semantically Secure Encrypted Relational Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">K</forename><surname>Samanthula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Elmehdwi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Knowl. Data Eng</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
		<title level="m" type="main">TAPAS: Tricks to Accelerate (encrypted) Prediction As a Service</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sanyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kusner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gascón</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kanade</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>In: ICML &apos;18</note>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<title level="m" type="main">Malware Guard Extension: Using SGX to Conceal Cache Attacks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schwarz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Weiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gruss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Maurice</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mangard</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>In: DIMVA &apos;17</note>
</biblStruct>

<biblStruct xml:id="b73">
	<monogr>
		<title level="m" type="main">Make Some ROOM for the Zeros: Data Sparsity in Secure Distributed Machine Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Schoppmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gascon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Raykova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Pinkas</surname></persName>
		</author>
		<idno>2019/281</idno>
		<imprint/>
	</monogr>
<note type="report_type">ePrint Report</note>
</biblStruct>

<biblStruct xml:id="b74">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seal</forename><surname>Microsoft</surname></persName>
		</author>
		<ptr target="https://github.com/Microsoft/SEAL.MicrosoftRe-search" />
		<imprint>
			<pubPlace>Redmond, WA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">PrivacyPreserving Deep Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Shokri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Shmatikov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CCS &apos;15</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Shokri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stronati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Shmatikov</surname></persName>
		</author>
		<title level="m">Membership Inference Attacks Against Machine Learning Models&quot;. In: S&amp;P &apos;17</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">&amp;quot;</forename><surname>Tf Encrypted</surname></persName>
		</author>
		<ptr target="https://github.com/mortendahl/tf-encrypted" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Privado: Practical and Secure DNN Inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tople</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Grover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shinde</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bhagwan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ramjee</surname></persName>
		</author>
		<idno>cs.CR 1810.00602</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiV</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Stealing Machine Learning Models via Prediction APIs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Tramèr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Juels</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">K</forename><surname>Reiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ristenpart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">USENIX Security &apos;16</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<monogr>
		<title level="m" type="main">Slalom: Fast, Verifiable and Private Execution of Neural Networks in Trusted Hardware</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Tramer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Boneh</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>In: ICLR &apos;19</note>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Foreshadow: Extracting the Keys to the Intel SGX Kingdom with Transient Out-of-Order Execution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Van Bulck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Minkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Weisse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Genkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kasikci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Piessens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Silberstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">F</forename><surname>Wenisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yarom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Strackx</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">USENIX Security &apos;18</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<monogr>
		<title level="m" type="main">SecureNN: Efficient and Private Neural Network Training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wagh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Chandran</surname></persName>
		</author>
		<idno>2018/442</idno>
		<imprint/>
	</monogr>
<note type="report_type">ePrint Report</note>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Leaky Cauldron on the Dark Land: Understanding Memory Side-Channel Hazards in SGX</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Bindschaedler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">A</forename><surname>Gunter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CCS &apos;17</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wistuba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rawat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pedapati</surname></persName>
		</author>
		<idno>cs.LG 1905.01392</idno>
		<title level="m">A Survey on Neural Architecture Search&quot;. ArXiV</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<monogr>
		<title level="m" type="main">Privately Evaluating Decision Trees and Random Forests</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Naehrig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">E</forename><surname>Lauter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page">PoPETs</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">A Methodology for Formalizing Model-Inversion Attacks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fredrikson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Naughton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CSF &apos;16</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<monogr>
		<title level="m" type="main">Wyze: Contact and Motion Sensors for Your Home</title>
		<ptr target="https://www.wyze.com/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">How to Generate and Exchange Secrets (Extended Abstract)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">FOCS &apos;86</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Evolving artificial neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE</title>
		<meeting>the IEEE</meeting>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Neural Architecture Search with Reinforcement Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR &apos;17</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">S</forename><surname>Sim</surname></persName>
		</author>
		<title level="m">given input 1 λ , 1 |C| , and C(x), outputs˜C outputs˜ outputs˜C</title>
		<imprint/>
	</monogr>
	<note>{label i } i∈[n] such that this output is computationally indistinguishable to ( ˜ C, {label i,x i }) generated by GS.Garble</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
