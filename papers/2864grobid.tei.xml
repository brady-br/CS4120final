<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2020-09-29T02:54+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Parakeet: A Just-In-Time Parallel Accelerator for Python</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Rubinsteyn</surname></persName>
							<email>alexr@cs.nyu.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">New York University</orgName>
								<address>
									<postCode>10003</postCode>
									<settlement>New York</settlement>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Hielscher</surname></persName>
							<email>hielscher@cs.nyu.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">New York University</orgName>
								<address>
									<postCode>10003</postCode>
									<settlement>New York</settlement>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathaniel</forename><surname>Weinman</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">New York University</orgName>
								<address>
									<postCode>10003</postCode>
									<settlement>New York</settlement>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dennis</forename><surname>Shasha</surname></persName>
							<email>shasha@cs.nyu.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">New York University</orgName>
								<address>
									<postCode>10003</postCode>
									<settlement>New York</settlement>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Parakeet: A Just-In-Time Parallel Accelerator for Python</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>High level productivity languages such as Python or Mat-lab enable the use of computational resources by non-expert programmers. However, these languages often sacrifice program speed for ease of use. This paper proposes Parakeet, a library which provides a just-in-time (JIT) parallel accelerator for Python. Parakeet bridges the gap between the usability of Python and the speed of code written in efficiency languages such as C++ or CUDA. Parakeet accelerates data-parallel sections of Python that use the standard NumPy scientific computing library. Parakeet JIT compiles efficient versions of Python functions and automatically manages their execution on both GPUs and CPUs. We assess Parakeet on a pair of benchmarks and achieve significant speedups.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Numerical computing is an indispensable tool to professionals in a wide range of fields, from the natural sciences to the financial industry. Often, users in these fields either (1) aren't expert programmers; or (2) don't have time to tune their software for performance. These users typically prefer to use productivity languages such as Python or Matlab rather than efficiency languages such as C++. Productivity languages facilitate non-expert programmers by trading off program speed for ease of use <ref type="bibr" target="#b22">[23]</ref>.</p><p>One problem, however, is that the performance tradeoff is often very stark -code written in Python or Matlab <ref type="bibr" target="#b18">[19]</ref> often has much worse performance than code written in C++ or Fortran. This problem is getting worse, as modern processors (multicore CPUs as well as GPUs) are all parallel, and current implementations of productivity languages are poorly suited for parallelism. Thus a common workflow involves prototyping algorithms in a productivity language, followed by porting the performance-critical sections to a lower level language. This second step can be time-consuming, error-prone, and it diverts energy from the real focus of these users' work.</p><p>In this paper, we present Parakeet, a library that provides a JIT parallel accelerator for NumPy, the commonly-used scientific computing library for Python <ref type="bibr" target="#b21">[22]</ref>. Parakeet accelerates performance-critical sections of numerical Python programs to be competitive with efficiency language code, obviating the need for the above-mentioned "prototype, port" cycle.</p><p>The Parakeet library intercepts programmer-marked functions and uses high-level operations on NumPy arrays (e.g. mapping a function over the array's elements) as sources of parallelism. These functions are just-in-time compiled to either x86 machine code using LLVM <ref type="bibr" target="#b16">[17]</ref> or GPU code that can be executed on NVIDIA GPUs via the CUDA framework <ref type="bibr" target="#b19">[20]</ref>. These native versions of the functions are then automatically executed on the appropriate hardware. Parakeet allows complete interoperability with all of the standard Python tools and libraries.</p><p>Parakeet currently supports JIT compilation to parallel GPU programs and single-threaded CPU programs. While Parakeet is a work in progress, our current results clearly demonstrate its promise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Overview</head><p>Parakeet is an accelerator library for numerical Python algorithms written using the NumPy array extensions <ref type="bibr" target="#b21">[22]</ref>. Parakeet does not replace the standard Python runtime but rather selectively augments it. To run a function within Parakeet a user must wrap it with the decorator @PAR. For example, consider the following NumPy code for averaging the value of two arrays:</p><formula xml:id="formula_0">@PAR def avg(x,y):</formula><p>return (x+y) / 2.0</p><p>If the decorator @PAR were removed, then avg would run as ordinary Python code. Since NumPy's library functions are compiled separately they always allocate result arrays (even when the arrays are immediately consumed). By contrast, Parakeet specializes avg for any distinct input type, optimizes its body into a singled fused map (avoiding unnecessary allocation) and executes it as parallel native code. Parakeet is not meant as a general-purpose accelerator for all Python programs. Rather, it is designed to execute array-oriented numerical algorithms such as those found in machine learning, financial computing, and scientific simulation. In particular, the sections of code that Parakeet accelerates must obey the following constraints:</p><p>• Due to the difficulty of implementing efficient nonuniform data structures on the GPU, we require all values within Parakeet to be either scalars or NumPy arrays. No dictionaries, sets, or user-defined objects are allowed.</p><p>• To compile Python into native code we must assign types to each expression. We are still able to retain some of Python's polymorphism by specializing different typed versions of a function for each distinct set of argument types. However, expressions whose types depend on dynamic values are disallowed (e.g. 42 if bool_val else "sausage").</p><p>• Only functions which don't modify global state or perform I/O can be executed in parallel. Local mutabable variables are always allowed.</p><p>A Parakeet function cannot call any other function which violates these restrictions or one which is not implemented in Python. To enable the use of NumPy library functions Parakeet must provide equivalent functions written in Python. In general, these restrictions would be onerous if applied to an entire program but Parakeet is only intended to accelerate the computational core of an algorithm. All other code is executed as usual by the Python interpreter. Though Parakeet supports loops, it does not parallelize them in any way. Parallelism is instead achieved through the use of the following data parallel operators:</p><formula xml:id="formula_1">• map(f, X 1 , ..., X n , fixed=[], axis=None)</formula><p>Apply the function f to each element of the array arguments. By default, f is passed each scalar element of the array arguments. The axis keyword can be used to specify a different iteration pattern (such as applying f to all columns). The fixed keyword is a list of closure arguments for the function f.</p><p>• allpairs(f,</p><formula xml:id="formula_2">X 1 , X 2 , fixed=[], axis=0)</formula><p>Apply the function f to each pair of elements from the arrays X 1 and X 2 .</p><p>• reduce(f, X 1 , ..., X n , fixed=[], axis=None, init=None) Combine all the elements of the array arguments using the (n + 1)-ary commutative function f . The init keyword is an optional initial value for the reduction. Examples of reductions are the NumPy functions sum and product.</p><p>• scan(f, X 1 , ..., X n , fixed=[], axis=None, init=None) Combine all the elements of the array arguments and return an array containing all cumulative intermediate values of the combination. Examples of scans are the NumPy functions cumsum and cumprod.</p><p>For each occurrence of a data parallel operator in a program, Parakeet may choose to synthesize parallel code which implements that operator combined with its function argument. It is not always necessary, however, to explicitly use one of these operators in order to achieve parallelization. Parakeet implements NumPy's array broadcasting semantics by implicitly inserting calls to map into a user's code. Furthermore, NumPy library functions are reimplemented in Parakeet using the above data parallel operators and thus expose opportunities for parallelism.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Parakeet Runtime and Internals</head><p>We will refer to the following code example to help illustrate the process by which Parakeet transforms and executes code. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Listing 1: Vector Norm in Parakeet</head><p>When the Python interpreter reaches the definition of norm, it invokes the @PAR decorator which parses the function's source and translates it into Parakeet's untyped internal representation. There is a fixed set of primitive functions from NumPy and the Python standard library, such as math.sqrt, which are translated directly into Parakeet syntax nodes. The helper functions add and sum would normally be in the Parakeet module but they are defined here for clarity. These functions are non-primitive, so they themselves get recursively parsed and translated. In general, the @PAR decorator will raise an exception if it encounters a call to a non-primitive function which either can't be parsed or violates Parakeet's semantic re- </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Type Specialization</head><p>Parakeet intercepts calls to norm and uses the argument types to synthesize a typed version of the function. During specialization, all functions called by norm are themselves specialized for particular argument types. In our code example, if norm were called with a 1D float array then sum would also be specialized for the same input type, whereas add would be specialized for pairs of scalar floats.</p><p>In Parakeet's typed representation, every function must have unambiguous input and output types. To eliminate polymorphism Parakeet inserts casts and map operators where necessary. When norm is specialized for vector arguments, its use of the multiplication operator is rewritten into a 1D map of a scalar multiply.</p><p>The actual process of type specialization is implemented by interleaving an abstract interpreter, which propagates input types to infer local types, and a rewrite engine which inserts coercions where necessary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Optimization</head><p>In addition to standard compiler optimizations (such as constant folding, function inlining, and common subexpression elimination), we employ fusion rules <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b15">16]</ref> to combine array operators. Fusion enables us to increase the computational density of generated code and to avoid the creation of unnecessary array temporaries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Execution</head><p>We have implemented three backends for Parakeet thus far: CPU and GPU backends for JIT compiling native code, as well as an interpreter for handling functions that cannot themselves be parallelized but may contain nested parallelizable operators.</p><p>Once a function has been type specialized and optimized, it is handed off to Parakeet's scheduler which is responsibile for choosing among these three backends. For each array operator, the scheduler employs a costbased heuristic which considers nested array operators, data sizes, and memory transfer costs to decide where to execute it.</p><p>Accurate prediction of array shapes is necessary both for the allocation of intermediate values on the GPU as well as for the above cost model to determine placement of computations. We use an abstract interpreter which propagates shape information through a function using the obvious shape semantics for each operator. For example, a reduce operation collapses the outermost dimension of its argument whereas a map preserves a shape's outermost dimension.</p><p>When the scheduler encounters a nested array operator -e.g. a map whose payload function is itself a reduceit needs to choose which operator, if any, will be parallelized. If an array operator is deemed a good candidate for native hardware execution, the function argument to the operator is then inlined into a program skeleton that implements the operator. Parakeet flattens all nested array computations within the function argument into sequential loops.</p><p>Several systems similar to Parakeet <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b8">9]</ref> generate GPU programs by emitting CUDA code which is then compiled by NVIDIA's CUDA nvcc toolchain. Instead, Parakeet emits PTX (a GPU pseudo-assembly) directly, since the compile times are dramatically shorter. To generate CPU code we use the LLVM compiler framework <ref type="bibr" target="#b16">[17]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Evaluation</head><p>We evaluate Parakeet on two benchmarks: Black-Scholes option pricing, and K-Means Clustering. We compare Parakeet against hand-tuned CPU and GPU implementa- tions. Due to space constraints, and since at the time of writing our CPU backend only supports single-threaded execution, we only present GPU results for Parakeet. For Black-Scholes, the CPU reference implementation is taken from the PARSEC <ref type="bibr" target="#b3">[4]</ref> benchmark suite, and the GPU implementation is taken from the CUDA SDK <ref type="bibr" target="#b20">[21]</ref>. For K-Means Clustering both the CPU and GPU reference versions come from the Rodinia benchmark suite <ref type="bibr" target="#b10">[11]</ref>. For both benchmarks, we ported the reference implementations as directly as possible from their source languages to Parakeet.</p><p>We ran all of our benchmarks on a machine running 64-bit Linux with an Intel Core i7 3.2GHz 960 4-core CPU and 16GB of RAM. The GPU used in our system was an NVIDIA Tesla C1060 with 240 vector lanes, a clock speed of 1.296 GHz, and 4GB of memory.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Black-Scholes</head><p>Black-Scholes option pricing <ref type="bibr" target="#b4">[5]</ref> is a standard algorithm used for data parallel benchmarking. We compare Parakeet against the multithreaded OpenMP CPU implementation from the PARSEC <ref type="bibr" target="#b3">[4]</ref> suite with both 1 and 8 threads and the GPU version in the CUDA SDK <ref type="bibr" target="#b20">[21]</ref>. We modified the benchmarks to all use the input data from the PARSEC implementation so as to have a direct comparison of the computation alone. We also modified the CUDA version to calculate only one of the call or put price per option so as to match the behavior in PARSEC.</p><p>In <ref type="figure" target="#fig_1">Figure 2</ref>, we see the total execution times of the various versions. These times include the time it takes to transfer data to and from the GPU in the GPU benchmarks. As expected, Black Scholes performs very well on the GPU as compared with the CPU. We see that Parakeet performs very similarly to the hand-written CUDA version, with overheads decreasing as a percentage of the run time as the data sizes grow since most of them are fixed costs related to dynamic compilation.</p><p>In <ref type="figure" target="#fig_2">Figure 3</ref>, we break down Parakeet's performance as compared with the hand-written CUDA version. The Parakeet run times range from 24% to 2.4X slower than those of CUDA, with Parakeet performing better as the data size increases. We can see that transferring data to and from the GPU's memory is expensive and dominates the runtime of this benchmark. The GPU programs that Parakeet generates are slightly less efficient than those of the CUDA version, with approximately 50% higher run time on average. Most of this slowdown is due to compilation overheads.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">K-Means Clustering</head><p>We also tested Parakeet on K-Means clustering, a commonly used unsupervised learning algorithm. We chose K-Means since it includes both loops and nested array operators, and thus illustrates Parakeet's support for both. The Parakeet code we used to run our benchmarks can be seen in Listing 2.</p><p>In <ref type="figure">Figure 4</ref>, we see the total run times of K-Means for the CPU and GPU versions with K = 3 clusters and 30 features on varying numbers of data points. Here, the distinction between the GPU and the CPU is far less stark. In fact, for up to 64K data points the 8-thread CPU version outperforms the GPU. Further, we see that for more than 64K data points, Parakeet actually performs better than both the CPU and GPU versions.  The reason Parakeet is able to perform so well with respect to the CUDA version is due to the difference in how they compute the new average centroid for the new clusters in each iteration. The CUDA version brings the GPU-computed assignment vectors back to the CPU in order to perform this reduction, as it involves many unaligned memory accesses and so has the potential to perform poorly on the GPU. Parakeet's scheduler chooses to execute this code on the GPU instead, prefering to avoid the data transfer penalty. For such a small number of clusters, the Parakeet method ends up performing far better. However, for larger numbers of clusters (roughly 30 and above), the fixed overhead of launching an individual kernel to average each cluster's points overwhelms the performance advantage of the GPU and Parakeet ends up performing worse than the CUDA version. We are currently implementing better code placement heuristics based on dynamic information, in order to use the GPU only when it would actually be advantageous. In <ref type="figure" target="#fig_4">Figure 5</ref>, we present the run times of K-Means for 30 features and K = 30 clusters. In this case, the handwritten CUDA version performs best in all cases, though its advantage over the CPU increases and its advantage over Parakeet decreases with increasing data size. As discussed, the Parakeet implementation suffers from the poorly performing averaging computation that it executes on the GPU, with a best case of an approximate 2X slowdown over the CUDA version. transfers. Importantly, the Parakeet implementation of KMeans also has orders of magnitude fewer lines of code than the CUDA implementation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Work</head><p>The earliest attempts to accelerate array-oriented programs were sequential compilers for APL. Abrams <ref type="bibr" target="#b0">[1]</ref> designed an innovative two-stage compiler wherein APL was first statically translated to a high-level untyped intermediate representation and then lazily compiled to a lowlevel scalar architecture. Inspired by Abrams' work, Van Dyke created an APL environment for the HP 3000 <ref type="bibr" target="#b24">[25]</ref> which also dynamically compiled delayed expressions and cached generated code using the type, rank, and shape of variables.</p><p>More recently, a variety of compilers have been created for the Matlab programming language <ref type="bibr" target="#b18">[19]</ref>. FAL-CON <ref type="bibr" target="#b13">[14]</ref> performs source-to-source translation from Matlab to Fortran 90 and achieves parallelization by adding dependence annotations into its generated code. MaJIC <ref type="bibr" target="#b2">[3]</ref> accelerates Matlab by pairing a lightweight dynamic compiler with a static translator in the same spirit as FALCON. Both FALCON and MaJIC infer simultaneous type and shape information for local variables by dataflow analysis.</p><p>The use of graphics hardware for non-graphical computation has a long history <ref type="bibr" target="#b17">[18]</ref>. The Brook language extended C with "kernels" and "streams", exposing a programming model similar to what is now found in CUDA and OpenCL <ref type="bibr" target="#b6">[7]</ref>. Over the past decade, there have been several attempts to use an embedded DSL to simplify the arduous task of GPGPU programming. Microsoft's Accelerator <ref type="bibr" target="#b23">[24]</ref> was the first project to use high level (collection-oriented) language constructs as a basis for GPU execution. Accelerator's programming model does not support function abstractions (only expression trees) and its underlying parallelism construct is limited to the production of map-like kernels. Accelerate <ref type="bibr" target="#b9">[10]</ref> is a firstorder array-oriented language embedded in Haskell which attains good performance on preliminary benchmarks but is unable to describe nested computations and requires user annotations to move data onto the GPU. A more sophisticated runtime has been developed for the Delite project <ref type="bibr" target="#b5">[6]</ref>, which is able to schedule complex computations expressed in Scala across multiple backends.</p><p>Parakeet and Copperhead <ref type="bibr" target="#b7">[8]</ref> both attempt to parallelize a numerical subset of Python using runtime compilation structured around higher-order array primitives. Parakeet and Copperhead also both support nested array computations and are able to target either GPUs or CPUs. Since Copperhead uses a purely functional intermediate language, its subset of Python is more restrictive than the one which Parakeet aims to accelerate. Unlike Copperhead, Parakeet allows loops and modification of local variables. Copperhead infers a single type for each function using an extension of the Hindley-Milner <ref type="bibr" target="#b12">[13]</ref> inference algorithm. This simplifies compilation to C++ templates but disallows both polymorphism between Python scalars and "array broadcasting" <ref type="bibr" target="#b21">[22]</ref>. Parakeet, on the other hand, is able to support polymorphic language constructs by specializing a function's body for each distinct set of argument types and inserting coercions during specialization. Copperhead does not use dynamic information when making scheduling decisions and thus must rely on user annotations. Parakeet's scheduler dynamically chooses which level of a nested computation to parallelize.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>Parakeet allows the programmer to write Python code using a widely-used numerical computing library while achieving good performance on modern parallel hardware. Parakeet automatically synthesizes and executes efficient native binaries from Python code. Parakeet is a usable system in which moderately complex programs can be written and executed efficiently. On two benchmark programs, Parakeet delivers performance competitive with hand-tuned GPU implementations. Parakeet code can coexist with standard Python code, allowing full interoperability with all of Python's tools and libraries. We are currently extending our CPU backend to use multiple cores and improving dynamic scheduling and compilation decisions.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>return parakeet.reduce(add, x) @PAR def norm(x): return math.sqrt(sum(x * x))</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Black Scholes Total Times</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Black Scholes GPU Execution Times</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Figure 4: K-Means Total Times with 30 Features, K = 3</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: K-Means Total Times with 30 Features, K = 30</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>import parakeet as par from parakeet import PAR def sqr_dist(x, y): sqr_diff = (x-y) * (x-y) return par.sum(sqr_diff) def minidx(C, x): dists = par.map(sqr_dist, C, fixed=[x]) return par.argmin(dists) def calc_centroid(X, a, cluster_id): return par.mean(X[a == cluster_id]) @PAR def kmeans(X, assignments): k = par.max(assignments) cluster_ids = par.arange(k) C = par.map(calc_centroid, cluster_ids, fixed=[X, a]) converged = False while not converged: last = assignments a = par.map(minidx, X, fixed=[C]) C = par.map(calc_centroid, cluster_ids, fixed=[X, a]) converged = par.all(last == assignments) return C Listing 2: K-Means Parakeet Code</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 showsFigure 6 :</head><label>66</label><figDesc>Figure 6: K-Means GPU Times with 30 Features, K = 3</figDesc></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abrams</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">S</forename><surname>An</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1970" />
			<pubPlace>Stanford, CA, USA</pubPlace>
		</imprint>
	</monogr>
<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Improving the performance of virtual memory computers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abu-Sufah</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">A.-K</forename></persName>
		</author>
		<imprint>
			<date type="published" when="1979" />
			<pubPlace>Champaign, IL, USA</pubPlace>
		</imprint>
	</monogr>
<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Compiling matlab for speed and responsiveness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alm´asialm´</forename><surname>Alm´asi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Padua</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Majic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PLDI &apos;02: Proceedings of the 2002 ACM SIGPLAN conference on Programming Languages Design and Implementation</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="294" to="303" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The PARSEC benchmark suite: Characterization and architectural implications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bienia</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">I</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PACT &apos;08: Proceedings of the 17th International Conference on Processors, Architectures, and Compilation Techniques</title>
		<imprint>
			<date type="published" when="2008-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The pricing of options and corporate liabilities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scholes</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Political Economy</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="page" from="637" to="654" />
			<date type="published" when="1973" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A heterogeneous parallel framework for domain-specific languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sujeeth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Rompf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chafi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Odersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olukotun</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Parallel Architectures and Compilation Techniques (PACT), 2011 International Conference on</title>
		<imprint>
			<date type="published" when="2011-10" />
			<biblScope unit="page" from="89" to="100" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Brook for GPUs: stream computing on graphics hardware</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Buck</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Foley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Horn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sugerman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Fa-Tahalian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Houston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanrahan</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGGRAPH 2004 Papers</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page" from="777" to="786" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Copperhead: Compiling an embedded data parallel language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Catanzaro</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Garland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keutzer</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th ACM Symposium on Principles and Practice of Parallel Programming</title>
		<meeting>the 16th ACM Symposium on Principles and Practice of Parallel Programming</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="47" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A domain-specific approach to heterogeneous parallelism</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chafi</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Sujeeth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Atreya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">R</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olukotun</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th ACM Symposium on Principles and Practice of Parallel Programming</title>
		<meeting>the 16th ACM Symposium on Principles and Practice of Parallel Programming<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="35" to="46" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Accelerating Haskell array codes with multicore GPUs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chakravarty</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Keller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mcdon-Nel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grover</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth Workshop on Declarative Aspects of Multicore Programming</title>
		<meeting>the Sixth Workshop on Declarative Aspects of Multicore Programming</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="3" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Rodinia: A benchmark suite for heterogeneous computing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Che</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Boyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tarjan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sheaf-Fer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-H</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Skadron</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Symposium on Workload Characterization (IISWC)</title>
		<meeting>the IEEE International Symposium on Workload Characterization (IISWC)</meeting>
		<imprint>
			<date type="published" when="2009-10" />
			<biblScope unit="page" from="44" to="54" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Efficiently computing static single assignment form and the control dependence graph</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cytron</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ferrante</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rosen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">K</forename><surname>Wegman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">N</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zadeck</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">K</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Program. Lang. Syst</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="451" to="490" />
			<date type="published" when="1991-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Principal type-schemes for functional programs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Damas</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milner</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th ACM SIGPLAN-SIGACT symposium on Principles of programming languages</title>
		<meeting>the 9th ACM SIGPLAN-SIGACT symposium on Principles of programming languages<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1982" />
			<biblScope unit="page" from="207" to="212" />
		</imprint>
	</monogr>
	<note>POPL &apos;82, ACM</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Falcon: A matlab interactive restructuring compiler</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Derose</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Gallivan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gallopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Mar-Solf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Padua</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LANGUAGES AND COM-PILERS FOR PARALLEL COMPUTING</title>
		<imprint>
			<publisher>SpringerVerlag</publisher>
			<date type="published" when="1995" />
			<biblScope unit="page" from="269" to="288" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Playing by the rules: rewriting as a practical optimisation technique in GHC</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jones</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">P</forename><surname>Tolmach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hoare</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2004 Haskell Workshop</title>
		<meeting>the 2004 Haskell Workshop</meeting>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Typed fusion with applications to parallel and sequential code generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kennedy</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mckinley</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">S</forename></persName>
		</author>
		<imprint>
			<date type="published" when="1993" />
		</imprint>
	</monogr>
<note type="report_type">Tech. rep</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">LLVM: An infrastructure for multi-stage optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lattner</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename></persName>
		</author>
		<ptr target="http://llvm.cs.uiuc.edu" />
		<imprint>
			<date type="published" when="2002-12" />
			<pubPlace>Urbana, IL</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Computer Science Dept., University of Illinois at Urbana-Champaign</orgName>
		</respStmt>
	</monogr>
	<note>Master&apos;s thesis</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Real-time robot motion planning using rasterizing computer graphics hardware</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lengyel</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Reicher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Donald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">R</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greenberg</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SIGGRAPH</title>
		<meeting>SIGGRAPH</meeting>
		<imprint>
			<date type="published" when="1990" />
			<biblScope unit="page" from="327" to="335" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">MATLAB -an interactive matrix laboratory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moler</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">B</forename></persName>
		</author>
		<idno>369</idno>
		<imprint>
			<date type="published" when="1980" />
		</imprint>
		<respStmt>
			<orgName>University of New Mexico. Dept. of Computer Science</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nvidia</forename><surname>Cuda Zone</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nvidia</forename><surname>Nvidia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sdk</surname></persName>
		</author>
		<ptr target="http://www.nvidia.com/cuda" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Python for scientific computing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oliphant</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computing in Science and Engineering</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="10" to="20" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Are scripting languages any good? a validation of Perl</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prechelt</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Python</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rexx</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C++</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Java</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Computers</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page" from="205" to="270" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Accelerator: Using data parallelism to program GPUs for generalpurpose uses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tarditi</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Puri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oglesby</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ASPLOS &apos;06: Proceedings of the 12th International Conference on Architectural Support for Programming Languages and Operating Systems</title>
		<imprint>
			<date type="published" when="2006-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A dynamic incremental compiler for an interpretive language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Van Dyke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Hewlett-Packard Journal</title>
		<imprint>
			<biblScope unit="page" from="17" to="24" />
			<date type="published" when="1977-07" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
