<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2020-09-29T02:11+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">The TURBO Diaries: Application-controlled Frequency Scaling Explained The TURBO Diaries: Application-controlled Frequency Scaling Explained</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>June 19-20. 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jons-Tobias</forename><surname>Wamhoff</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Diestelhorst</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christof</forename><surname>Fetzer</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jons-Tobias</forename><surname>Wamhoff</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Diestelhorst</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christof</forename><surname>Fetzer</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Marlier</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Felber</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dave</forename><surname>Dice</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Dave Dice</orgName>
								<orgName type="institution" key="instit1">Technische Universät Dresden</orgName>
								<orgName type="institution" key="instit2">Patrick Marlier and Pascal Felber</orgName>
								<orgName type="institution" key="instit3">Université de Neuchâtel</orgName>
								<address>
									<country>Oracle Labs</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">USENIX Association</orgName>
								<orgName type="institution" key="instit2">Technische Universtät</orgName>
								<address>
									<settlement>Dresden</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">Université de Neuchâtel</orgName>
								<address>
									<country>Switzerland, USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">The TURBO Diaries: Application-controlled Frequency Scaling Explained The TURBO Diaries: Application-controlled Frequency Scaling Explained</title>
					</analytic>
					<monogr>
						<title level="m">2014 USENIX Annual Technical Conference</title>
						<meeting> <address><addrLine>Philadelphia, PA</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page">193</biblScope>
							<date type="published">June 19-20. 2014</date>
						</imprint>
					</monogr>
					<note>This paper is included in the Proceedings of USENIX ATC &apos;14: Open access to the Proceedings of USENIX ATC &apos;14: 2014 USENIX Annual Technical Conference is sponsored by USENIX.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Most multi-core architectures nowadays support dynamic voltage and frequency scaling (DVFS) to adapt their speed to the system&apos;s load and save energy. Some recent architectures additionally allow cores to operate at boosted speeds exceeding the nominal base frequency but within their thermal design power. In this paper, we propose a general-purpose library that allows selective control of DVFS from user space to accelerate multi-threaded applications and expose the potential of heterogeneous frequencies. We analyze the performance and energy trade-offs using different DVFS configuration strategies on several benchmarks and real-world workloads. With the focus on performance, we compare the latency of traditional strategies that halt or busy-wait on contended locks and show the power implications of boosting of the lock owner. We propose new strategies that assign heterogeneous and possibly boosted frequencies while all cores remain fully operational. This allows us to leverage performance gains at the application level while all threads continuously execute at different speeds. We also derive a model to help developers decide on the optimal DVFS configuration strategy, e.g, for lock implementations. Our in-depth analysis and experimental evaluation of current hardware provides insightful guidelines for the design of future hardware power management and its operating system interface.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>While early generations of multi-core processors were essentially homogeneous with all cores operating at the same clock speed, new generations provide finer control over the frequency and voltage of the individual cores. A major motivation for this new functionality is to maximize processor performance without exceeding the thermal design power (TDP), as well as reducing energy consumption by decelerating idle cores <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b34">35]</ref>.</p><p>Two main CPU manufacturers, Intel and AMD, have proposed competing yet largely similar technologies for dynamic voltage and frequency scaling (DVFS) that can exceed the processor's nominal operation frequency, respectively named Turbo Boost <ref type="bibr" target="#b38">[39]</ref> and Turbo CORE <ref type="bibr" target="#b2">[3]</ref>. When the majority of cores are powered down or run at a low frequency, the remaining cores can boost within the limits of the TDP. In the context of multi-threaded applications, a typical use case is the optimization of sequential bottlenecks: waiting threads halt the underlying core and allow the owner thread to speed up execution of the critical section.</p><p>Boosting is typically controlled by hardware and is completely transparent to the operating system (OS) and applications. Yet, it is sometimes desirable to be able to finely control these features from an application as needed. Examples include: accelerating the execution of key sections of code on the critical path of multi-threaded applications <ref type="bibr" target="#b8">[9]</ref>; boosting time-critical operations or high-priority threads; or reducing the energy consumption of applications executing low-priority threads. Furthermore, workloads specifically designed to run on processors with heterogeneous cores (e.g., few fast and many slow cores) may take additional advantage of applicationlevel frequency scaling. We argue that, in all these cases, finegrained tuning of core speeds requires application knowledge and hence cannot be efficiently performed by hardware only.</p><p>Both Intel and AMD hardware implementations are constrained in several ways, e.g., some combination of frequencies are disallowed, cores must be scaled up/down in groups, or the CPU hardware might not comply with the scaling request in some circumstances. Despite the differences of both technologies, our comparative analysis derives a common abstraction for the processor performance states (Section 2). Based on the observed properties, we present the design and implementation of TURBO, a general-purpose library for application-level DVFS control that can programmatically configure the speed of the cores of CPUs with AMD's Turbo CORE and Intel's Turbo Boost technologies, while abstracting the low-level differences and complexities (Section 3).</p><p>The cost of frequency and voltage transitions is subject to important variations depending on the method used for modifying processor states and the specific change requested. The publicly available documentation is sparse, and we believe to be the first to publish an in-depth investigation on the latency, performance, and limitations of these DVFS technologies (Section 4). Unlike previous research, our goal is not energy conservation or thermal boosting <ref type="bibr" target="#b35">[36]</ref>, which is usually applied to mobile devices and interactive applications with long idle periods, but long running applications often found on servers. We target efficiency by focusing on the best performance, i.e., shorter run times or higher throughput using the available TDP. In this context, hardware is tuned in combination with the OS to use frequency scaling for boosting sequential bottlenecks on the critical path of multi-threaded applications. We use the TURBO library to measure the performance and power implications of both blocking and spinning locks (Section 4.2). Our evaluation shows that connecting knowledge of application behavior to programmatic control of DVFS confers great benefits on applications having heterogeneous load. We propose new configuration strategies that keep all cores operational and allow a manual boosting control <ref type="bibr">(Section 4.3</ref>   and their latencies, we derive a simplified cost model (Section 4.4) to guide developers at which size of a critical region a frequency transition pays off. Four case studies investigate the performance gains exploited by application-level frequency control based on real-world benchmarks (Section 5).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Hardware Support for Boosting</head><p>With both AMD's Turbo CORE and Intel's Turbo Boost, performance levels and power consumption of the processor are controlled through two types of operational states: P-states implement DVFS and set different frequency/voltage pairs for operation, trading off higher voltage (and thus higher power draw) with higher performance through increased operation frequency. P-states can be controlled through special machine-specific registers (MSRs) that are accessed through the rdmsr/wrmsr instructions. The OS can request a P-state change by modifying the respective MSR. P-state changes are also not instantaneous: the current needs to be adapted and frequencies are ramped, both taking observable time. C-states are used to save energy when a core is idle. C0 is the normal operational state. All other C-states halt the execution of instructions and trade different levels of entry/wakeup latency for lower power draw. The OS can invoke C-states through various means such as the hlt and monitor/mwait instructions. We argue in this paper that there are benefits in keeping selected cores operational, albeit at a lower frequency, and that manipulating P-states can be more efficient in terms of latency than manipulating C-states.</p><p>We base our work on AMD's FX-8120 <ref type="bibr" target="#b0">[1]</ref> and Intel's i7-4770 <ref type="bibr" target="#b18">[19]</ref> CPUs, whose characteristics are listed in <ref type="table" target="#tab_1">Table 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">AMD's Turbo CORE</head><p>The architecture of the AMD FX-8120 processor is illustrated in <ref type="figure" target="#fig_0">Figure 1</ref>. The cores of a package are organized by pairs in modules that share parts of the logic between the two cores.</p><p>Our processor supports seven P-states summarized in Table 2. We introduce a TURBO naming convention to abstract from the manufacturer specifics. AMD uses P-state numbering based on the ACPI standard with P0 being the highest performance state. The two topmost are boosted P-states <ref type="bibr">(</ref>  = 2) that are by default controlled by the hardware. The remaining five P-states can be set by the OS through the MSRs 1 .</p><p>The boosting of the frequency beyond the nominal P-state (P base ) is enabled by the hardware's Turbo CORE technology if operating conditions permit. The processor determines the current power consumption and will enable the first level of boosting (P1 HW ) if the total power draw remains within the TDP limit and the OS requests the fastest software P-state. A multithreaded application can boost one module to P1 HW while others are in P base if it does not use all features of the package to provide the required power headroom, e.g., no FPUs are active. The fastest boosting level (P turbo ) is entered automatically if some cores have furthermore reduced their power consumption by entering a deep C-state. Note that Turbo CORE is deterministic, governed only by power draw and not temperature, such that the maximum frequency is workload dependent. During a P-state transition, the processor remains active and capable of executing instructions, and the completion of a P-state transition is indicated in an MSR available to the OS.</p><p>The Turbo CORE features can be enabled or disabled altogether, i.e., no core will run above P base . Selected AMD processors allow developers to control the number of hardwarereserved P-states by changing #P boosted through a configuration MSR. To achieve manual control over all P-states, including boosting, one can set #P boosted = 0. The core safety mechanisms are still in effect: the hardware only enters a boosted P-state if the TDP limit has not been reached. In contrast to the processor's automatic policy, the manual control of all P-states can enable P turbo with all other cores in C0 but running at P slow .</p><p>Due to the pairwise organization of cores in modules, the effect of a P-and C-state change depends on the state of the sibling core. While neighboring cores can request P-states independently, the fastest selected P-state of the two cores will apply to the entire module. Since the wrmsr instruction can only access MSRs of the current core, it can gain full control over the frequency scaling if the other core is running at P slow . A module only halts if both cores are not in C0.</p><p>The processor allows to read the current power draw (P) that it calculates based on the load. Out of the total TDP, 14.24W are reserved for the northbridge (NB) (including L3 cache) and logic external to the cores. Each of the four modules is a voltage (V ) and frequency ( f ) domain defined by the P-state. The package requests V defined by the fastest active P-state of any module from the voltage regulator module (VRM).</p><p>Hardware P-state P39 P34 P20 P8</p><p>TURBO naming P turbo P base P slow Frequency (GHz) 3.9 3.4 2.0 0.8 Voltage (mV) 1860 n/a n/a 707 Power nop (W) -39 20 11 Power ALU (W) -51 25 12 Power mwait (W) 25 19 11 8 <ref type="table">Table 3</ref>: Default P-state configuration of Intel i7-4770. <ref type="table" target="#tab_3">Table 2</ref> lists P with (1) all cores in the same P-state executing nop instructions, (2) execution of integer operations with ALU, (3) three modules in P slow except one in the given Pstate, and (4) all modules halted using mwait except one active core. The consumed active P depends on V , f and the capacitance (C) that varies dynamically with the workload (P= V 2 * f * C dyn ). Therefore, for the nop load all cores can boost to P1 HW , while for integer loads all cores can run only at P base . Boosting under load can be achieved when other modules are either in P slow or halted. Mwait provides the power headroom to automatically boost to P turbo . The manual boosting control allows to run one module in P turbo if the others run at P slow .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Intel's Turbo Boost</head><p>Intel's DVFS implementation is largely similar to AMD's but more hardware-centric and mainly differs in the level of manual control. All cores are in the same frequency and voltage domain but can each have an individual C-state. The P-states are based on increasing multipliers for the stepping of 100MHz, non-predefined ACPI P-states in the opposite order. Our processor supports frequencies from 0.8GHz to 3.9GHz corresponding to 32 P-states that are summarized in <ref type="table">Table 3</ref>. In TURBO terms, P base corresponds to P34 HW , leaving 5 boosted P-states. All active cores in C0 symmetrically run at the highest requested frequency, even if some cores requested slower P-states. The consumed power was measured in a fashion analogous to that in Section 2.1, with hyper-threading enabled and all cores always in the same P-State.</p><p>The processor enables Turbo Boost if not all cores are in C0. The level of boosting depends on the number of active cores, estimated power consumption, and additionally the temperature of the package. This "thermal boosting" allows the processor to temporarily exceed the TDP using the thermal capacitance of the package. In contrast to AMD, the maximum achievable frequency also depends on the recent execution history, which relates to the current package temperature and makes it somewhat stateful. While boosting can be enabled or disabled altogether, the boosted P-states are always controlled automatically by the processor and no manual control by software is possible.</p><p>Intel's design choice targets to speed up critical periods of computation, e.g., boosting sequential bottlenecks by putting waiting cores to sleep using C-states or providing temporarily peak performance for interactive applications as on mobile devices or desktops. Our focus is on multi-threaded applications mostly found on servers that run for long periods without much idle time. Thermal boosting is not applicable to such workloads because on average one cannot exceed the TDP. Instead, our goal is to improve the performance within the TDP limits.  <ref type="figure">Figure 2</ref>: Overview of TURBO library components.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">TURBO Library</head><p>The TURBO library, written in C++ for the Linux OS, provides components to configure, control, and profile processors from within applications. Our design goals are twofold: we want to provide a set of abstractions to (1) make it convenient to improve highly optimized software based on DVFS; and (2) set up a testbed for algorithms that explore challenges of future heterogeneous cores <ref type="bibr" target="#b1">[2]</ref>, such as schedulers. The components of the TURBO library are organized in layers with different levels of abstraction as shown in <ref type="figure">Figure 2</ref>. All components can be used individually to support existing applications that use multiple threads or processes. The layered architecture allows an easy extension to future hardware and OS revisions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Processor and Linux Kernel Setup</head><p>The default configurations of the processors and Linux kernel manage DVFS transparently for applications: All boosted P-states are controlled by the processor and the Linux governor will adapt the non-boosted P-states based on the current processor utilization ("ondemand") or based on static settings that are enforced periodically ("performance", "userspace").</p><p>We must disable the influence of the governors and the processor' power saving features in order to gain explicit control of the P-states and boosting in user space using our library. Note that the "userspace" governor provides an alternative but inefficient P-state interface <ref type="bibr" target="#b15">[16]</ref>. Therefore, we disable the CPU frequency driver (cpufreq) and turn off AMD's Cool'n'Quiet speed throttling technology in the BIOS. To control all available P-states in user space, we can either disable automatic boosting altogether, which is the only solution for Intel, or for AMD set #P boosted = 0 to enable manual boosting control (for details see Section 2). Changing the number of boosted P-states also changes the frequency of the time stamp counter (tsc) for AMD processors so we therefore disable tsc as a clock source for the Linux kernel and instead use the high precision event timer (hpet). Note that these tweaks can easily be applied to production systems because we only change BIOS settings and kernel parameters.</p><p>The processor additionally applies automatic frequency scaling for the integrated NB that can have a negative impact on memory access times for boosted processor cores.</p><p>Therefore, NB P-states are disabled and it always runs at the highest possible frequency.</p><p>Linux uses the monitor and mwait instructions to idle cores and change their C-state. When another core writes to the address range specified by monitor, then the core waiting on mwait wakes up. The monitor-mwait facility provides a "polite" busy-waiting mechanism that minimizes the resources consumed by the waiting thread. For experiments on AMD, we enable these processor instructions for user space and disable the use of mwait in the kernel to avoid lockouts. Similarly, we must also disable the use of the hlt instruction by the kernel, because otherwise we cannot guarantee that at least one core stays in C0. We restrict the C-state for the Linux kernel to C0 and use the polling idle mode. These changes are required in our prototype only for the evaluation of C-state transitions and are not necessary in a production system.</p><p>The presented setup highlights the importance of the configuration of both hardware and OS for sound benchmarking. Multi-threaded algorithms should be evaluated by enforcing P base and C0 on all cores to prevent inaccuracies due to frequency scaling and transition latencies. All other sources of unpredictability should be stopped, e.g., all periodic cron jobs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Performance Configuration Interface</head><p>The library must be aware of all threads even if they are managed explicitly by the application. Therefore, the thread registry is used first to create or register all threads. Next, the threads are typically assigned to distinct cores based on the processor's topology, which is discovered during initialization. If thread migration to another core is required at runtime, it must be performed using our library to allow an update of the core specific configuration, e.g., the P-state.</p><p>The easiest way to benefit from DVFS is to replace the application's locks with thread control wrappers that are decorated with implicit P-state transitions, e.g., boosting the lock owner at P turbo , waiting at P slow , and executing parallel code at P base .</p><p>If the wrappers are not sufficient, the application can request an explicit performance configuration that is still independent of the underlying hardware. Threads can request the executing core to run at P turbo , P base , or P slow , and can alternatively specify the P-state in percent based on the maximum frequency. The actual P-state is derived from the selected setup, e.g., if boosting is enabled and controlled manually. The current P-state configuration is cached in the library in order to save the overheads from accessing the MSRs in kernel space. If a P-state is requested that is already set or cannot be supported by the processor's policy or TDP limits, then the operation has no effect. <ref type="bibr" target="#b1">2</ref> Threads can also request to temporarily migrate to a dedicated processor core that runs at the highest possible frequency and stays fully operational in C0.</p><p>The lowest layer presents hardware abstractions for the machine specific interfaces and DVFS implementations, as well as the Linux OS. The Linux kernel provides a device driver that lets applications access MSRs as files under root privilege using pread and pwrite. We implemented a lightweight TURBO kernel driver for a more streamlined access to the processor's MSRs using ioctl calls. The driver essentially provides a wrapper for the wrmsr/rdmsr instructions to be executed on the current core. Additionally, it allows kernel space latency measurements, e.g., for P-state transition time, with more accuracy than from user space. We derive the topology from the Linux ACPI driver and use sysfs for AMD's package configuration using PCI functions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Performance and Power Profiling</head><p>The TURBO library provides means to profile highly optimized applications and algorithms for heterogeneous cores. The profiling can be used to first identify sections that can benefit from frequency scaling and later to evaluate the performance and power implications of different configurations.</p><p>Again, the simplest ways to obtain statistics is to use thread control wrappers, which exist to replace locks, barriers, and condition variables. The wrappers can be decorated with profiling capabilities of the performance monitor, which uses the aperf/mperf and tsc counters of the processor <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b18">19]</ref> and the perf event facilities of the Linux kernel to access the processor's performance monitoring unit (PMU).</p><p>The performance monitor operates in intervals, e.g., defined by a lock wrapper, for which it captures the cycles, frequency, and C-state transitions. Additional counters such as the number of cache misses or stalled cycles can be activated, e.g., to analyze the properties of a critical section. The PMU also provides counters to read the running average power limit (RAPL) on Intel and the processor power in TDP on AMD.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Processor Evaluation</head><p>On top of the TURBO library presented in Section 3, we implemented a set of benchmark applications that configure and profile the underlying processor. In this section, we present (1) the static transition latencies introduced by the OS and hardware, (2) the overheads of blocking upon contended locks and when it pays off regarding speed and energy compared to spinlocks, and (3) new static and dynamic P-state transition strategies that optimize spinlocks and allow applications to expose heterogeneous frequencies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Hardware Transition Latency</head><p>The latency for DVFS results from a combination of OS overhead to initiate a transition and hardware latency to adjust the processor's state. Therefore, we present in <ref type="table" target="#tab_6">Tables 4 (AMD)</ref> and 5 (Intel) the overhead for system calls, P-state requests and the actual transition latencies in isolation.   System calls for device-specific input/output operations (ioctl) have a low overhead and are easily extensible using the request code parameter. The interface of the TURBO driver (trb) is based on ioctl, while the Linux MSR driver (msr) uses a file-based interface that can be accessed most efficiently using pread/pwrite. The difference in speed between msr and trb (both use rdmsr/wrmsr to access the MSRs) results mostly from additional security checks and indirections that we streamlined for the TURBO driver. The cost in time for system calls depends on the P-state, i.e., reading the current P-state scales with the selected frequency, here P base .</p><p>Observation 1: P-state control should be made available through platform-independent application program interfaces (APIs) or unprivileged instructions. The latter would eliminate the latency for switching into kernel space to access platformspecific MSRs but require that the OS's DVFS is disabled.</p><p>We measured the cost of the wrmsr instruction that initiates a P-State transition of the current core, as well as the latency until the transition is finished, by busy waiting until the frequency identifier of the P-state is set in the status MSR. Both measurements are performed in the TURBO driver, removing the inaccuracy due to system call overheads.</p><p>For AMD, requesting a P-state faster than the current one (e.g., P slow →P base ) has low overhead in itself, but the entire transition has a high latency due to the time the VRM takes to reach the target voltage. The request to switch to a slower P-state (e.g., P base →P slow ) has almost the same latency as the entire transition, i.e., the core is blocked during most of the transition. We suspect that this blocking may be caused by a slow handshake to coordinate with the other module's core to see if an actual P-state change will occur. Overall, the transition has a lower latency because the frequency can already be reduced before the voltage regulator is finished. If only switching to a slow P-state for a short period, the transition to a faster P-state will be faster if the voltage was not dropped completely.</p><p>On the Intel CPU, total latency results are very similar: A P-state transition also takes tens of microseconds but depends on the distance between the current and requested P-state. A significant difference to AMD, however, lies in the faster execution of the wrmsr request of a P-state transition going slower (e.g., P base →P slow ) because Intel does not need to perform additional coordination.</p><p>Observation 2: The frequency transitions should be asynchronous, triggered by a request and not blocking, i.e., keeping the core operational. The API should include the ability to read or query P-state transition costs for building a cost model that allows DVFS-aware code to adapt at runtime.</p><p>We additionally show costs related to the OS. In the mwait experiment, one core continuously updates a memory location while the other core specifies the location using monitor and calls mwait. The core will immediately return to execution because it sees the memory location changed, so the numbers represent the minimal cost of executing both instructions. Although AMD allows the use of mwait from user space, the feature is typically used by the OS's futex system call when the kernel decides to idle. The pthread setaffinity function migrates a thread to a core with a different L2 Cache that is already in C0 state and returns when the migration is finished. Thread migration typically results in many cache misses but the benchmark keeps only minimal data in the cache.</p><p>Observation  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Blocking vs. Spinning Locks</head><p>We evaluate the boosting capabilities using a thread on each core that spends all its time in critical sections (CS). The CS is protected by a single global lock implemented as an MCS queue lock <ref type="bibr" target="#b28">[29]</ref> in the TURBO library. The lock is decorated such that upon contention, the waiting thread either spins or blocks using mwait (AMD only) or futex. The sequence is illustrated in <ref type="figure" target="#fig_1">Figure 3a</ref> and 3b, respectively. In all cases, the thread-local MCS node is used for the notification of a successful lock acquisition. Inside the CS, a thread-local counter is incremented for a configurable number of iterations (∼10 cycles each). While the global lock prevents any parallelism, the goal of the concurrent execution is to find the CS length that amortizes the DVFS cost. We want to discuss when blocking is preferable over spinning, both in terms of performance and energy, using the default configuration of hardware and OS: The P-states are managed automatically by the processor and the setup from Section 3.1 is not applied. We run the application for 100 seconds and count the number of executed CS, which gives us the cycles per CS including all overheads. Separately, we measure the cycles per CS without synchronization at P base , i.e., the cycles doing real work. The effective frequency inside a CS is: The results are shown in <ref type="figure">Figure 4</ref>. The spin strategy runs all cores at P base and is only effected by synchronization overhead, with decreasing impact for larger sizes of CS. The mwait and futex strategies are additionally effected by C-state transitions that halt the core while blocking, which allows to boost the active core. The C-state reached by mwait is not deep enough to enable P turbo , probably because it is requested from user space. Still, CS are executed at P1 HW and the low overhead lets mwait outperform spin already at a CS size of ∼4k cycles. Using futex has the highest overhead because it is a system call. The C-state reached depends on t wait (see <ref type="figure" target="#fig_1">Figure 3b)</ref>, which explains the performance drop: Deep C-states introduce a high latency (see <ref type="table" target="#tab_7">Table 5</ref>) but are required to enable P turbo . We verified this behavior using aperf/mperf, which showed that the frequency in C0 is at P turbo only after the drop. The futex outperforms spin and mwait at ∼1.5M cycles for AMD and ∼4M cycles for Intel, which also boosts spin 2 steps. Note that an optimal synchronization strategy for other workloads also depends on the conflict probability and t wait , but our focus is on comparing boosting initiated by the processor and on application-level.</p><formula xml:id="formula_0">f CS = f</formula><p>The sampled power values do not vary for different sizes of CS (see <ref type="table" target="#tab_3">Tables 2 and 3</ref> for ALU and mwait), except for futex, which varies between 55-124W for AMD depending on the reached C-state. The reduction in energy consumption due to deeper C-states must first amortize the introduced overhead before it is more efficient than spinning. With only a single core active at a time, futex is the most energy efficient strategy for AMD after a CS size of ∼1M cycles, which results for 8 threads in t wait =∼7M cycles because the MCS queue lock is fair. Intel is already more energy efficient after ∼10k cycles, indicating that it trades power savings against higher latencies. Boosting provides performance gains for sequential bottlenecks and halting amortizes the active cores' higher energy consumption <ref type="bibr" target="#b30">[31]</ref>. The default automatic boosting is not energy efficient for scalable workloads because all energy is consumed only by a single core without performance benefit <ref type="bibr" target="#b11">[12]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Application-level P-state Transition Strategies</head><p>Our goal is to enable application-level DVFS while keeping all cores active. Therefore, we enable manual P-state control with the setup described in Section 3.1 and restrict the following discussion to just AMD. For the evaluation, we use the same application as in the previous Section 4.2 but with a different set of decorations for the lock: The strategy one executes iterations only on a single core that sets the P-state statically during initialization to either P slow , P base or P turbo . All other threads run idle on cores at P slow in C0. This provides the baseline for different P-state configurations without P-state transition overheads but includes the synchronization. The dynamic strategies ownr and wait are illustrated in <ref type="figure" target="#fig_1">Figure 3c</ref>. For ownr, all threads are initially set to P slow and the lock owner dynamically switches to P turbo during the CS. For wait, all threads initially request P turbo and dynamically switch to P slow while waiting. The processor prevents an oversubscription and allows P turbo only if 3 modules are in P slow . The remaining strategies use only a subset of the cores for executing CS: dlgt uses only 1 thread per module and delegates the P-state transition request to the thread executing on the neighboring core. The strategy is otherwise the same as ownr. mgrt uses only 6 cores on 3 modules running at P slow . The remaining module runs at P turbo and the current lock owner migrates to a core of the boosted module during the CS.</p><p>The results are presented in <ref type="figure" target="#fig_2">Figure 5</ref>. The dynamic strategies ownr and wait introduce overhead in addition to the synchronization costs because two P-state transitions must be requested for each CS. This overhead is amortized when the resulting effective frequency of the CS is above one with P base , starting at CS sizes of ∼600k cycles. Both strategies behave similarly because the application does not execute parallel code between CS. Otherwise, the idea is that wait hides the slow blocking transition to P slow (see Section 4.1) within t wait , whereas ownr must perform this transition after releasing the lock. To that extent, dlgt shifts the P-state transition cost entirely to the other core of the module and can outperform one already at ∼200k cycles, but only half of the processor cores can be used. The mgrt strategy does not include overhead from P-state transitions but costly thread migrations. Still, it outperforms one at ∼400k cycles. A real-world benchmark would show worse results because it suffers from more cache misses on the new processor core than our synthetic benchmark that keeps only little data in the cache <ref type="bibr" target="#b29">[30]</ref>. Additionally, initiating a migration at P slow will be executed slowly until the thread reaches the boosted core. Overall, we observe that application-level DVFS is more effective than C-state control because it allows to outweigh overheads for CS of sizes smaller than ∼1.5M cycles.</p><p>Observation 4: The P-state transition should be as fast as possible so that short boosted sections can already amortize the transition cost. It exists hardware that can switch to arbitrary frequencies within one clock cycle <ref type="bibr" target="#b16">[17]</ref>.</p><p>As long as one modules runs at P turbo , which is the case here, the processor consumes the maximal TDP of 125W. The consumed energy solely depends on the overheads of each strategy because of the serialized execution. Note that the energy for executing one with a static P-state is almost identical for P slow , P base and P turbo , indicating that the energy consumption is proportional to the P-state. In fact, we get for a single module in P turbo 29% more speed using 25% more power compared to P base (see <ref type="table" target="#tab_3">Table 2</ref>). Compared to mwait and futex, application-level DVFS allows less power savings because all cores stay in C0, but it can be applied to parallel workloads, which we investigate in Section 5.</p><p>Observation 5: Processors should support heterogeneous frequencies individually for each core to provide headroom for boosting while staying active. The design should not limit the frequency domain for a package (Intel) or module (AMD). An integrated VRM supports fine grained voltage domains to allow higher power savings at low speeds. Additionally, for some workloads it would be beneficial to efficiently set remote cores to P slow in order to have local boosting control.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Performance Cost Model</head><p>Based on our experimental results, we derive a simplified cost model for AMD's boosting implementation to guide developers when boosting pays off regarding performance. We first present a model for boosting sequential bottlenecks that formalizes the results from Section 4.3. We then specialize it for boosting CS that are not a bottleneck as well as for workloads that contain periods with heterogeneous workload distributions.</p><p>We make the following simplifying assumptions: (1) the application runs at a constant rate of instructions per cycle (IPC), regardless of the processor frequency; (2) we do not consider costs related to thread synchronization; (3) the frequency ramps linearly towards faster P-states (e.g., f P slow → f P turbo ); and (4) the frequency transition to a slower P-state takes as long as the P-state request. Assumption <ref type="formula">(4)</ref> is a direct result of our latency measurement, (1) and (2) allow an estimation without taking application specifics into account. We will revisit assumptions (1) and (2) when looking at actual applications that depend on memory performance and thus exhibit varying IPC with changing frequency (due to the changed ratio of memory bandwidth, latency and operation frequency).</p><p>For sequential bottlenecks, we follow the strategy ownr described in Section 4.3 and illustrated in <ref type="figure" target="#fig_1">Figure 3c</ref>. Boosting will pay off if we outperform the CS that runs at f P base : t CS f P turbo ≤t CS f P base . The minimal t CS must be greater than the combined P-state request latencies and the number of cycles that are executed during the P-State transition (t ramp , i.e., the difference between wrmsr and wait in The minimal wait time t wait to acquire the lock should simply be larger than the time to drop to f P slow : t wait ≥t P base →P slow . With the results from Section 4.1, on AMD this equals to a minimal t CS of ∼436,648 cycles (∼109µs). Note that optimized strategies can reach the break even point already earlier (e.g., dlgt in <ref type="figure" target="#fig_2">Figure 5</ref>). Based on the above cost model for sequential bottlenecks, we can derive a cost model for boosting CS by one step (see <ref type="figure" target="#fig_1">Figure 3d)</ref>:</p><formula xml:id="formula_1">t CS ≥ f P1 HW f P1 HW − f P base ·(t P base →P1 HW +t P1 HW →P base )+ 1 2 ·t ramp</formula><p>We never move below P base and boosting pays off if t CS is longer than ∼336,072 cycles (∼84µs).</p><p>Besides boosting sequential bottlenecks, another interesting target are periods of heterogeneous workload distributions. These workloads can run one thread temporarily at a higher priority than other active threads or have an asymmetric distribution of accesses to CS from threads. Typically, such critical regions are longer because they combine several CS, thus improving the chances of amortizing the transition cost. Based on the presented cost model, we compute the minimal duration of such periods instead of the CS size. We present examples in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Boosting Applications</head><p>We evaluated the TURBO library using several real-world applications with user space DVFS on the AMD FX-8120. We chose these workloads to validate the results from our synthetic benchmarks and the cost model to boost sequential bottlenecks (5.1); highlight gains by using application knowledge to assign heterogeneous frequencies (5.2); show the trade-offs when the IPC depends on the core frequency, e.g., due to memory accesses (5.3); and outweigh the latency cost of switching P-states by delegating critical sections to boosted cores (5.4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Python Global Interpreter Lock</head><p>The Python Global Interpreter Lock (GIL) is a well known sequential bottleneck based on a blocking lock. The GIL must always be owned when executing inside the interpreter. Its latest implementation holds the lock by default for a maximum of 5ms and then switches to another thread if requested. We are interested in applying some of the P-state configuration strategies presented in Section 4.3 to see if they provide practical benefits. For this evaluation, we use the ccbench application that is included in the Python distribution (version 3.4a).</p><p>The benchmark includes workloads that differ in the amount of time they spent holding the GIL: (1) the Pi calculation is implemented entirely in Python and spends all its time in the interpreter; (2) the computation of regular expressions (Regex) is implemented in C with a wrapper function that does not release the GIL; and (3) the bz2 compression and SHA1 hashing have wrappers for C functions that release the GIL, so most time is spent outside the interpreter. <ref type="table" target="#tab_12">Table 6</ref> summarizes the characteristics of the workloads.</p><p>We evaluate the following P-state configuration strategies in <ref type="figure">Figure 6</ref>. Base runs at P base and, hence, does not incur P-state configuration overheads. Dyn waits for the GIL at P slow , then runs at P turbo while holding the GIL and switches to P base after releasing it. While the workloads Pi and Regex do   not scale, Dyn supports at least the execution at P turbo . The performance and power implications are in line with our synthetic benchmark results (Section 4.3) and the cost model (python in <ref type="table" target="#tab_12">Table 6</ref> greater than t CS in Section 4.4). For the workloads bz2 and SHA1, the performance benefit reaches its maximum at 4 threads because we pin the threads such that each runs on a different module, giving the thread full P-state control. When two threads run on a module, more P-state transitions are required per package that eliminate the performance benefit at 8 threads.</p><p>Own runs all threads at P base and boosts temporarily to P1 HW while holding the GIL. This manifests in a higher throughput when the GIL is held for long periods but for bz2 and SHA the cost of requesting a P-state transition is not amortized by the higher frequency. Wait runs at P turbo if permitted by the TDP and only switches to P slow while waiting for the GIL. This strategy works well with high contention but introduces significant cost if the waiting period is too short (see <ref type="table" target="#tab_12">Table 6</ref>).</p><p>In <ref type="figure">Figure 7</ref> we compare Intel's results for boosting disabled (Base) and enabled automatically by the processor (Auto). Overall, the results are similar to the ones obtained on AMD and what we expect from Section 4.2: The level of boosting depends on the number of halted cores, which enables P turbo  for Pi and Regex. SHA1 and bz2 boost slightly because not all processor features are used. The performance drop beyond 4 threads is due to hyper-threading.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Software Transactional Memory</head><p>FastLane <ref type="bibr" target="#b42">[43]</ref> is a software transactional memory (STM) implementation that processes a workload asymmetrically.</p><p>The key idea is to combine a single fast master thread that can never abort with speculative helper threads that can only commit if they are not in conflict. The master thread has a very lightweight instrumentation and runs close to the speed of an uninstrumented sequential execution. To allow helper threads to detect conflicts, the master thread must make the in-place updates of its transactions visible (by writing information in the transaction metadata). The helpers perform updates in a write-log and commit their changes after a validation at the end of the transaction. The benefit is a better performance for low thread counts compared to other state-of-the art STM implementations (e.g., TinySTM <ref type="bibr" target="#b12">[13]</ref>) that suffer from instrumentation and bookkeeping overheads for scalability.</p><p>We used integer sets that are implemented as a red-black tree (RB), a linked list (LL), a skip list (SL), or a hash set (HS) and perform random queries and updates <ref type="bibr" target="#b12">[13]</ref>. The parameters are the working set size and the update ratio. Either all threads run at P base (FL) or the master statically runs at P turbo (FL-BM) and the helpers at P slow , except the helper running on the same module as the master. Note that the master thread is determined dynamically. Moreover, we compare with TinySTM (Tiny) and uninstrumented sequential execution (Seq) at P base . Our evaluation on the AMD processor shows in <ref type="figure">Figure 8</ref> that running the master and helpers at different speeds (FL-BM) enables high performance gains compared to running all threads at P base (FL). The higher throughput can outweigh the higher power (50% vs. 2% for LL), thus, being more energy efficient. Tiny wins per design for larger thread counts.  This workload highlights the importance of making P-state configuration accessible from the user space. It allows to expose properties of the application that would otherwise not be available to the processor. For applications that contain larger amounts of non-transactional code, supporting the ability to remotely set P-states for other cores would be very helpful. When a master transaction is executed, it could slow down the other threads in order to get fully boosted for a short period.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Hash Table Resize in Memcached</head><p>Memcached is a high performance caching system based on a giant hash table. While for the normal operation a fine-grained locking scheme is used, the implementation switches to a single global spinlock that protects all accesses to the hash table during the period of a resizing. The resize is done by a separate maintenance thread that moves items from the old to the new hash table and processes a configurable number of buckets per iteration. Each iteration acquires the global lock and moves the items in isolation.</p><p>Our evaluation was conducted with Memcached version 1.4.15 and the mc-crusher workload generator. We used the default configuration with 4 worker threads that we pinned on 2 modules. The maintenance thread and mc-crusher run on their own modules. The workload generator sends a specified number of set operations with distinct keys to Memcached, which result in a lookup and insert on the hash table that will eventually trigger several resizes. The hash table is resized when it reaches a size of 2 x × 10MB. The cache is initially empty and we insert objects until the 7th resize of 2 7 ×10MB (1280MB) is finished.</p><p>For the intervals in which the maintenance thread was active, we gathered for the first (10MB) and the last (1280MB) resize interval. These are reported in <ref type="table" target="#tab_16">Table 8</ref>: number of items that are moved during one iteration (bulk move, configurable), rate of set operations during the entire experiment (ops/s), length of the resize interval (ms), the number of (stalled) instructions and average frequency achieved by the maintenance thread (freq).</p><p>We applied the following strategies during the resizing period: baseline runs all threads at P base , stat resizer runs the maintenance thread at P turbo for the entire period, dyn resizer switches to P turbo only for the length of an bulk move iteration and causes additional transition overheads, dyn worker switches to P slow while waiting for the maintenance thread's iteration to finish. The last strategy does not show a performance improvement because the cost cannot be amortized especially when the bulk move size gets smaller. The stat resizer shows the best performance because it reduces the resizing duration.</p><p>While the benchmark shows the benefit of assigning heterogeneous frequencies, an interesting observation is that the speedup achieved by boosting is limited because the workload is mainly memory-bound. Compared to baseline, stat resizer shows only a speedup of the resize interval between 7%-9% while it runs at a 22% higher frequency. The higher the frequency, the more instructions get stalled due to cache misses that result from the large working set. The number of stalled instructions effectively limit the number of instructions that can be executed faster at a higher frequency. On the other hand, the high cost of the P-state transitions in the dynamic strategy dyn resizer is hidden by an decreased number of stalled instructions but it still cannot outweigh the transition latency. Memcached's default configuration performs only a single move per iteration, which according to our results shows the worst overall duration of the experiment (ops/s). A better balance between worker latency and throughput is to set bulk move to 100. With this configuration, memcached spends 15% of its execution time for resizes, which we can boost by 10%. This reduces the total execution time by 1.5% and allows 1.5% more ops/s because the worker threads spent less time spinning. Combined, this amortizes the additional boosting energy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Delegation of Critical Sections</head><p>We have shown that critical sections (CS) need to be relatively large to outweigh the latencies of changing P-states. Remote core locking <ref type="bibr" target="#b26">[27]</ref> (RCL) is used to dedicate a single processor core to execute all application's CS locally. Instead of moving the lock token across the cores, the actual execution of the critical section is delegated to a designated server. We leverage this locality property by statically boosting the RCL server and eliminate the P-state transition overhead for small CS.</p><p>We experiment with three of the SPLASH-2 benchmarks <ref type="bibr" target="#b43">[44]</ref> and the accompanying version of BerkeleyDB <ref type="bibr" target="#b32">[33]</ref>.</p><p>We report speedup for all workloads over the single-threaded baseline P-state in <ref type="figure" target="#fig_4">Figure 9</ref>, and find that we obtain only incremental performance gains for the boosted cases. We show various combinations of worker P-states (reported as "W Px") and P-states for the RCL server core ("R Px"), and contrast these with configurations where all cores run at P base ("All P2") and P4 HW ("All P4") for comparison. Note that we do show standard deviation of 30 trials, but there is hardly any noise visible. We do not reduce the P-state for the waiting workers (due to latency reasons), but it seems there is enough TDP headroom for the brief RCL invocations to run even at P1 HW and we get speedups of 4% -9%. As expected, the relative boost is larger if we start from a lower baseline at P4 HW .   Overall, scalability of the benchmarks is good, reserving one core exclusively for RCL will cap scalability at 7 (worker) threads. The authors of RCL claim, however, that reserving this single core pays off in comparison to cache coherence traffic arising from spinlock ownership migrating between cores. Focusing our attention on the CS, we find them to be short (with a peak at ∼488ns) for the selected benchmarks. To better understand the cost of communication and its behavior under various boosting scenarios, we implemented the core of the RCL mechanism, simple cross-thread polling message passing with two threads, in a small micro-benchmark. We report results for select configurations in <ref type="table" target="#tab_18">Table 9</ref> for AMD, which reflect unloaded latency with no competition for communication channels. Overall we were surprised by the round-trip delay when crossing modules, 480ns, vs. 91ns when communicating inside a module (both at P base ). Intra-module communication benefits greatly from boosting (91ns vs. 70ns), due to both communication partners and the communication link (shared L2 cache) being boosted. Communicating cross-module, boosting has a smaller performance impact on the communication latency (480ns vs. 445ns, via L3 cache), which helps to explain the small benefit seen in our workloads with short CS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related Work</head><p>The field of DVFS is dominated by work about improving energy efficiency <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b13">14]</ref>. DVFS is proposed as a mid-term solution to the prediction that, in future processor generations, the scale of cores will be limited by power constraints <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b1">2]</ref>. In the longer term, chip designs are expected to combine few large cores for compute intensive tasks with many small cores for parallel code on a single heterogeneous chip. Not all cores can be active simultaneously due to thermal constraints <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b21">22]</ref>. A similar effect is achieved by introducing heterogeneous voltages and frequencies to cores of the same ISA <ref type="bibr" target="#b9">[10]</ref>. Energy efficiency is achieved by reducing the frequency and it was observed that the overall performance is only reduced slightly because it is dominated by memory <ref type="bibr" target="#b24">[25]</ref> or network latencies.</p><p>Semeraro et al. <ref type="bibr" target="#b39">[40]</ref> propose multiple clock domains with individual DVFS. Inter-domain synchronization is implemented using existing queues to minimize latency, and frequency can be reduced for events that are not on the application's critical path. The energy savings can be extended by profile-based reconfiguration <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b4">5]</ref>. Another interesting approach to save power is to combine DVFS with inter-core prefetching of data into caches <ref type="bibr" target="#b20">[21]</ref>. This can improve performance and energy efficiency, even on serial code, when more cores are active at a lower frequency. Choi et al. <ref type="bibr" target="#b7">[8]</ref> introduce a technique to decompose programs into CPU-bound (on-chip) and memory-bound (off-chip) operations. The decomposition allows fine tuning of the energy-performance trade-off, with the frequency being scaled based on the ratio of the on-chip to off-chip latencies. The energy savings come with little performance degradation on several workloads running on a single core. <ref type="bibr">Hsu et al. [18]</ref> propose an algorithm to save energy by reducing the frequency with HPC workloads. Authors also present and discuss transition latencies. A recent study <ref type="bibr" target="#b23">[24]</ref> on the Cray XT architecture, which is based on AMD CPUs, demonstrates that significant power savings can be achieved with little impact on runtime performance when limiting both processor frequency and network bandwidth. The P-states are changed before the application runs. It is recommended that future platforms provide DVFS of the different system components to exploit the trade-offs between energy and performance. Our work goes in the same direction, by investigating the technical means to finely control the states of individual cores.</p><p>While energy efficiency has been widely studied, few researchers have addressed DVFS to speed up workloads <ref type="bibr" target="#b14">[15]</ref>. <ref type="bibr">Park et al. [34]</ref> present a detailed DVFS transition overhead model based on a simulator of real CPUs. For a large class of multi-threaded applications, an optimal scheduling of threads to cores can significantly improve performance <ref type="bibr" target="#b36">[37]</ref>. <ref type="bibr">Isci et al. [20]</ref> propose using a lightweight global power manager for CPUs that adapts DVFS to the workload characteristics. Suleman et al. <ref type="bibr" target="#b40">[41]</ref> optimize the design of asymmetric multi-cores for critical sections. A study of Turbo Boost has shown that achievable speedups can be improved by pairing CPU intensive workloads to the same core <ref type="bibr" target="#b5">[6]</ref>. This allows masking delays caused by memory accesses. Results show a correlation between the boosting speedup and the LLC miss rate (high for memory-intensive applications). DVFS on recent AMD processors with a memory-bound workload limits energy efficiency because of an increase of static power in lower frequencies/voltages <ref type="bibr" target="#b25">[26]</ref>. <ref type="bibr">Ren et al. [38]</ref> investigate workloads that can take advantage of heterogeneous processors (fast and slow) and show that throughput can be increased by up to 50% as compared with using homogeneous cores.</p><p>Such workloads represent interesting use cases for DVFS.</p><p>Our TURBO library complements much of the related work discussed in this section, in that it can be used to implement the different designs and algorithms proposed in these papers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>We presented a thorough analysis of low-level costs and characteristics of DVFS on recent AMD and Intel multi-core processors and proposed a library, TURBO 3 , that provides convenient programmatic access to the core's performance states. The current implementation by hardware and OS is optimized for transparent power savings and for boosting sequential bottlenecks. Our library allows developers to boost performance using properties available at application-level and gives broader control over DVFS. We studied several real-world applications for gains and limitations of automatic and manual DVFS. Manual control exposes asymmetric application characteristics that would be otherwise unavailable for a transparent optimization by the OS. Limitations arise from the communication to memory and other cores that restict the IPC. Our techniques, while useful today, also bring insights for the design of future OS and hypervisor interfaces as well as hardware DVFS facilities.</p><p>For the future, we plan to add an automatic dynamic tuning mechanism: based on decorated thread control structures, e.g., locks, we can obtain profiling information and predict the optimal frequency for each core. We also envision use cases beyond optimizing synchronization, such as DVFS for flowbased programming with operator placement (deriving the frequency from the load factor) or data routing (basing DVFS on deadlines or priorities). Finally, the TURBO library provides a research testbed to simulate future heterogeneous multi-core processors with fast/slow cores, as well as to evaluate algorithms targeting energy efficiency or undervolting.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Organization of an AMD FX-8120 processor.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Frequency sequence for (a) spinning, (b) blocking, (c) frequency scaling and (d) critical regions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Characteristics of manual P-state control.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 6 :Figure 7 :</head><label>67</label><figDesc>Figure 6: ccbench throughput (AMD FX-8120).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Throughput of SPLASH-2 and BerkeleyDB.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Specification of the AMD and Intel processors. 

Package 

Northbridge: L3 cache, Integrated memory controller 

Module 

L2 cache 

L1 data cache 

x86 Core 
FPU 
x86 Core 

L1 instr. cache L1 data cache 

Module 
Module 
Module 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>#P boosted Hardware P-state P0 P1 P2 P3 P4 P5 P6 TURBO naming P turbo P base P slow Frequency</head><label></label><figDesc></figDesc><table>(GHz) 4.0 
3.4 
3.1 
2.8 2.3 1.9 1.4 
Voltage (mV) 1412 1412 1275 1212 1087 950 875 
Power 4×nop (W) -123.3 113.6 97.2 70.1 49.9 39.3 
Power 4×ALU (W) -
-122.6 104.3 74.6 52.9 41.2 
Power 3×P slow , 1×P0..6 (W) 125.0 119.8 100.5 87.4 65.5 48.5 41.2 
Power 3×mwait, 1×P0..6 (W) 120.1 116.5 90.9 77.6 55.5 40.5 32.8 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Default P-state configuration of AMD FX-8120. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>) &amp; wait P slow →P turbo 226988 56747 84 21 wrmsr(pstate, P base ) &amp; wait P slow →P base 183359 45839 130 32 wrmsr(pstate, P turbo ) &amp; wait P base →P turbo 94659 23664 87 21 wrmsr(pstate, P base ) P turbo →P base 23203 5800 36 9 wrmsr(pstate, P base ) &amp; wait P turbo →P base 24187 6046 139 34 wrmsr(pstate, P1 HW ) P base →P1 HW 974 234 132 33 wrmsr(pstate, P1 HW ) &amp; wait P base →P1 HW 94642 23660 136 34 wrmsr(pstate, P base ) &amp; wait P1 HW →P base 24574</head><label></label><figDesc></figDesc><table>Throughout 
our evaluation, we use a Linux kernel 3.11 that is configured 
according to Section 3.1. We use only the x86 cores (ALU) P-State 
Mean 
Deviation 
Operation 
Transition Cycles 
ns Cycles 
ns 
System call overheads for futex and TURBO driver 
syscall(futex wait private) 
-
1321 
330 
42 
10 
ioctl(trb) 
-
920 
230 
14 
3 
P-state MSR read/write cost using msr or TURBO driver 
pread(msr, pstate) 
-
3044 
761 
43 
10 
ioctl(trb, pstate) 
-
2299 
574 
30 
7 
pwrite(msr, pstate, P base ) P base →P base 
2067 
741 
110 
27 
ioctl(trb, pstate, P base ) 
P base →P base 
1875 
468 
42 
10 
Hardware latencies for P-state set (wrmsr) and transition (wait) (kernel space) 
wrmsr(pstate, P slow ) 
P base →P slow 28087 7021 
105 
26 
wrmsr(pstate, P slow ) &amp; wait P base →P slow 29783 7445 
120 
30 
wrmsr(pstate, P turbo ) 
P slow →P turbo 
1884 
471 
35 
8 
wrmsr(pstate, P turbo 6143 
138 
34 
Hardware latencies for C-state transitions (in user space) 
monitor &amp; mwait 
-
1818 
454 
18 
4 
Software and hardware latency for thread migration 
pthread setaffinity 
-
26728 6682 
49 
12 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 4 :) &amp; wait P slow →P base 48937 14393 86 25 wrmsr(pstate,P slow ) P base →P slow 2015 592 61 17 wrmsr(pstate,P slow ) &amp; wait P base →P slow 58782 17288 65 19 wrmsr(pstate,P turbo ) P base →P turbo 2012 591 44 12 wrmsr(pstate,P turbo ) &amp; wait P base →P turbo 41451</head><label>4</label><figDesc></figDesc><table>Latency cost (AMD FX-8120, 100,000 runs). 

P-State 
Mean 
Deviation 
Operation 
Transition Cycles 
ns Cycles 
ns 
System call overheads for futex and TURBO driver 
syscall(futex wait private) 
-
1431 
366 
32 
8 
ioctl(trb) 
-
1266 
324 
64 
16 
P-state MSR read/write cost using msr or TURBO driver 
pread(msr, pstate) 
-
2638 
775 
24 
7 
ioctl(trb, pstate) 
-
2314 
680 
54 
16 
pwrite(msr, pstate, P base ) P base →P base 
4246 1248 
122 
35 
ioctl(trb, pstate, P base ) 
P base →P base 
3729 1096 
72 
21 
Hardware latencies for P-state set (wrmsr) and transition (wait) (kernel space) 
wrmsr(pstate,P base ) 
P slow →P base 44451 13073 
131 
38 
wrmsr(pstate,P base 12191 
78 
22 
Hardware latencies for C-state transitions (in kernel space) 
monitor &amp; mwait C1 
-
4655 1369 
25 
7 
monitor &amp; mwait C2 
-
36500 10735 1223 
359 
monitor&amp;mwait C6 
-
74872 22021 
672 
197 
Software and hardware latency for thread migration 
pthread setaffinity 
-
12145 3572 
81 
23 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Latency cost (Intel i7-4770, 100,000 runs). 

and no FPU or MMX/SSE/AVX to preserve the required 
headroom for manual boosting. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" validated="false"><head>f P turbo f P base f P slow t CS t wait t wait t CS a) t wait t CS t CS f P1 HW Acquire entry Acquire exit t P base →C halt t C halt →P base t P turbo →P base t P base →P slow t P slow →P turbo t P turbo →P base t P base →P1 HW t P1 HW →P base Release t ramp t ramp t ramp</head><label></label><figDesc></figDesc><table>3: The OS should keep the current frequency 
in the thread context to better support context switches and 
thread migrations. Ideally, the OS would expose a new set 
of advisory platform-independent APIs to allow threads to set 
their desired DVFS-related performance targets. Furthermore, 
the OS kernel (and potentially a virtual machine hypervisor) 
would moderate potentially conflicting DVFS resource 
requests from independent and mutually unaware applications. b) 
c) 
d) 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" validated="false"><head>base inside CS: E =E sample * cycles mcs cycles nosync .</head><label></label><figDesc>base * cycles nosync cycles mcs . The energy results are based on the proces- sor's TDP/RAPL values, from which we take samples during another execution. We compute the energy it takes to execute 1 hour of work at P</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10" validated="false"><head>Table 4 ) to P turbo : t CS ≥t P slow →P turbo +t ramp +t P tubo →P base + cycles CS −cycles ramp f P turbo Based on the P-state transition behavior that we observed in Section 4.3, we can compute the minimal t CS as follows:(t P slow →P turbo + t P turbo →P base )</head><label>4</label><figDesc></figDesc><table>t CS ≥ 
f P turbo 
f P turbo − f P base 
· + 
1 
2 
· 
f P turbo − f P slow 
f P turbo − f P base 
· t ramp 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12" validated="false"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table>ccbench characteristics: average time (µs) per 
iteration spent in interpreter (python), executing native code 
without GIL (native) and waiting for GIL acquisition (wait). 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14" validated="false"><head>Table 7 :</head><label>7</label><figDesc></figDesc><table>Commit ratio of the master thread (% of all commits). 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15" validated="true"><head>Table 7 shows that the master can asymmetrically process more transactions at P turbo . While the helpers at P slow can have more conflicts caused by</head><label>7</label><figDesc></figDesc><table>Bulk 
Resize 10MB 
Resize 1280MB 
Move Strategy Ops/s ms stalled freq 
ms stalled freq 
10k 
baseline 535k 16 63% 3099 2937 67% 3099 
10k stat resizer 547k 15 82% 3999 2666 88% 4000 
10k dyn resizer 547k 15 81% 3980 2691 87% 3987 
10k dyn worker 535k 18 82% 3971 3155 88% 3982 
100 
baseline 529k 24 66% 3099 4021 68% 3100 
100 stat resizer 540k 22 86% 3999 3647 90% 3999 
100 dyn resizer 508k 30 56% 3259 4799 59% 3252 
100 dyn worker 461k 48 60% 3211 7970 60% 3265 
1 
baseline 237k 770 72% 3099 103389 72% 3099 
1 stat resizer 245k 721 94% 3999 98056 95% 4000 
1 dyn resizer 209k 893 62% 3112 120430 63% 3113 
1 dyn worker 90k 1886 64% 3111 252035 65% 3113 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16" validated="false"><head>Table 8 : Memcached hash table resize statistics. the</head><label>8</label><figDesc>master, the conflict rate caused by other slow helpers does not change. Dynamically boosting the commits of the helpers did not show good results because the duration is too short.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_18" validated="false"><head>Table 9 :</head><label>9</label><figDesc></figDesc><table>Core to core memory transfer latency (ns) for an aver-
age round-trip (work iterations: N Worker :N RCL , 0.65ns each). 

</table></figure>

			<note place="foot" n="1"> The numbering in software differs from the actual hardware P-states: P HW = P SW + #P boosted . With a default of #P boosted =2: P base = P0 SW = P2 HW and P turbo = P0 HW . P0 SW is the fastest requestable software P-state.</note>

			<note place="foot" n="2"> In practice, we write our request in MSR P cmd and can read from MSR P val what the CPU actually decided. We can either (a) wait until both MSRs match, i.e., another core makes room in the TDP, (b) return the CPU&apos;s decision, or (c) just write and provide best-effort guarantees (default). Deterministic hardware without thermal boosting does not overwrite MSR P cmd .</note>

			<note place="foot" n="3"> https://bitbucket.org/donjonsn/turbo</note>
		</body>
		<back>

			<div type="acknowledgement">
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Kernel Developer&apos;s Guide (BKDG) for AMD Family 15h Models 00h-0Fh Processors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amd</forename><surname>Bios</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">The future of microprocessors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Borkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Chien</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>ACM CACM</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Branover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Foley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Steinman</surname></persName>
		</author>
		<title level="m">AMD Fusion APU: Llano. IEEE Micro</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A dynamic voltage scaled microprocessor system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">D</forename><surname>Burd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">A</forename><surname>Pering</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Stratakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">W</forename><surname>Brodersen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE JSSC</title>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Meeting points: Using thread criticality to adapt multicore hardware to parallel regions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>González</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Rakvic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Magklis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Chaparro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>González</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PACT</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Evaluation of the intel core i7 turbo boost feature</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Charles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Jassi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ananth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sadat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fedorova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IISWC</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">10x10: A general-purpose architectural approach to heterogeneity and energy efficiency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Chien</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Snavely</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gahagan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>ELSEVIER PCS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Fine-grained dynamic voltage and frequency scaling for precise energy and performance trade-off based on the ratio of off-chip access to on-chip computation times</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Soma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pedram</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">DATE</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">US Patent Application 20130047011 -Turbo Enablement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dice</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shavit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">J</forename><surname>Marathe</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Razor: a low-power pipeline based on circuit-level timing speculation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ernst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ziesler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Blaauw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Austin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Flautner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mudge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICRO</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Dark silicon and the end of multicore scaling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Esmaeilzadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Blem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>St</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Amant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sankaralingam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Burger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISCA</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Looking back on the language and hardware revolutions: measured power, performance, and scaling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Esmaeilzadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Blackburn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">S</forename><surname>Mckinley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ASPLOS</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Dynamic performance tuning of word-based software transactional memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Felber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fetzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Riegel</surname></persName>
		</author>
		<editor>PPoPP</editor>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Analysis of dynamic voltage/frequency scaling in chip-multiprocessors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Herbert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Marculescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISPLED</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Amdahl&apos;s law in the multicore era</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Marty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Reconciling application power control and operating systems for optimal power and performance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hillenbrand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Furuyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hayashi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Mikami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kimura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kasahara</surname></persName>
		</author>
		<editor>ReCoSoC</editor>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A Compact Clock Generator for Heterogeneous GALS MPSoCs in 65-nm CMOS Technology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hoppner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Eisenreich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Henker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Walter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Ellguth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Schuffny</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TVLSI</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A power-aware run-time system for high-performance computing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-C</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SC</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Intel 64 and IA-32 Architectures Software Developers Manual</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Intel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">An analysis of efficient multi-core global power management policies: Maximizing performance for a given power budget</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Isci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Buyuktosunoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-Y.</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bose</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Martonosi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<pubPlace>In MICRO</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Underclocked software prefetching: More cores, less energy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kamruzzaman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Swanson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tullsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Micro</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Single-isa heterogeneous multi-core architectures: the potential for processor power reduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Farkas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Jouppi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ranganathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tullsen</surname></persName>
		</author>
		<editor>MICRO</editor>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Heterogeneous chip multiprocessors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tullsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Jouppi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ranganathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Energy based performance tuning for large scale high performance computing systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Laros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iii</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">T</forename><surname>Pedretti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">T</forename><surname>Vaughan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HPC</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Reducing energy usage with memory and computation-aware dynamic frequency scaling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Laurenzano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Meswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Carrington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Snavely</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tikir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Poole</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Euro-Par</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Dynamic voltage and frequency scaling: The laws of diminishing returns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>Sueur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Heiser</surname></persName>
		</author>
		<editor>HotPower</editor>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Remote core locking: migrating critical-section execution to improve the performance of multithreaded applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-P</forename><surname>Lozi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lawall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Muller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">USENIX ATC</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Profile-based dynamic voltage and frequency scaling for a multiple clock domain microprocessor</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Magklis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">L</forename><surname>Scott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Semeraro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H</forename><surname>Albonesi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Dropsho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISCA</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Algorithms for scalable synchronization on shared-memory multiprocessors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Mellor-Crummey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">L</forename><surname>Scott</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991" />
			<publisher>ACM TOCS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">The effect of seance communication on multiprocessing systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mendelson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Gabbay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM TOCS</title>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Critical power slope: understanding the runtime effects of frequency scaling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Miyoshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lefurgy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Van Hensbergen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Rajamony</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Rajkumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICS</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A 32-bit PowerPC system-on-a-chip with support for dynamic voltage scaling and dynamic frequency scaling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Nowka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Carpenter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ngo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Brock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ishii</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Burns</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE JSSC</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Olson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bostic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Seltzer</surname></persName>
		</author>
		<title level="m">USENIX ATC</title>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
<note type="report_type">Berkeley db</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Accurate modeling of the delay and energy overhead of dynamic voltage and frequency scaling in modern microprocessors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pedram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TCAD</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Dynamic voltage scaling on a low-power microprocessor</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pouwelse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Langendoen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Sips</surname></persName>
		</author>
		<editor>MobiCom</editor>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Raghavan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Emurian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Papaefthymiou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">P</forename><surname>Pipe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">F</forename><surname>Wenisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Martin</surname></persName>
		</author>
		<title level="m">Computational Sprinting on a Hardware/Software Testbed. In ASPLOS</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Cherry-picking: exploiting process variations in dark-silicon homogeneous chip multi-processors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Raghunathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Turakhia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Garg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Marculescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">DATE</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Exploiting processor heterogeneity for interactive services</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Elnikety</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">S</forename><surname>Mckinley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICAC</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Power-management architecture of the intel microarchitecture code-named sandy bridge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Rotem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Naveh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rajwan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ananthakrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Weissmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Micro</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Energy-efficient processor design using multiple clock domains with dynamic voltage and frequency scaling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Semeraro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Magklis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Balasubramonian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Albonesi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Dwarkadas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Scott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HPCA</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Accelerating critical section execution with asymmetric multi-core architectures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Suleman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Mutlu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">K</forename><surname>Qureshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">N</forename><surname>Patt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ASPLOS</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Conservation cores: reducing the energy of mature computations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Venkatesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sampson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Goulding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Bryksin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lugo-Martinez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Swanson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">B</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ASPLOS</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Fastlane: improving performance of software transactional memory for low thread counts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-T</forename><surname>Wamhoff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fetzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Felber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Rivì Ere</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Muller</surname></persName>
		</author>
		<editor>PPoPP</editor>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">The SPLASH-2 programs: characterization and methodological considerations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C</forename><surname>Woo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ohara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Torrie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISCA</title>
		<imprint>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
