<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2020-09-29T04:01+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Reading Thieves&apos; Cant: Automatically Identifying and Understanding Dark Jargons from Cybercrime Marketplaces Reading Thieves&apos; Cant: Automatically Identifying and Understanding Dark Jargons from Cybercrime Marketplaces</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>August 15-17. 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kan</forename><surname>Yuan</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Indiana University Bloomington</orgName>
								<orgName type="institution" key="instit2">Indiana University</orgName>
								<address>
									<addrLine>Bloomington</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoran</forename><surname>Lu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Indiana University Bloomington</orgName>
								<orgName type="institution" key="instit2">Indiana University</orgName>
								<address>
									<addrLine>Bloomington</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojing</forename><surname>Liao</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Indiana University Bloomington</orgName>
								<orgName type="institution" key="instit2">Indiana University</orgName>
								<address>
									<addrLine>Bloomington</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaofeng</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Indiana University Bloomington</orgName>
								<orgName type="institution" key="instit2">Indiana University</orgName>
								<address>
									<addrLine>Bloomington</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kan</forename><surname>Yuan</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Indiana University Bloomington</orgName>
								<orgName type="institution" key="instit2">Indiana University</orgName>
								<address>
									<addrLine>Bloomington</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoran</forename><surname>Lu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Indiana University Bloomington</orgName>
								<orgName type="institution" key="instit2">Indiana University</orgName>
								<address>
									<addrLine>Bloomington</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojing</forename><surname>Liao</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Indiana University Bloomington</orgName>
								<orgName type="institution" key="instit2">Indiana University</orgName>
								<address>
									<addrLine>Bloomington</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaofeng</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Indiana University Bloomington</orgName>
								<orgName type="institution" key="instit2">Indiana University</orgName>
								<address>
									<addrLine>Bloomington</addrLine>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Reading Thieves&apos; Cant: Automatically Identifying and Understanding Dark Jargons from Cybercrime Marketplaces Reading Thieves&apos; Cant: Automatically Identifying and Understanding Dark Jargons from Cybercrime Marketplaces</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 27th USENIX Security Symposium</title>
						<meeting>the 27th USENIX Security Symposium <address><addrLine>Baltimore, MD, USA</addrLine></address>
						</meeting>
						<imprint>
							<date type="published">August 15-17. 2018</date>
						</imprint>
					</monogr>
					<note>Open access to the Proceedings of the 27th USENIX Security Symposium is sponsored by USENIX. https://www.usenix.org/conference/usenixsecurity18/presentation/yuan-kan This paper is included in the</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Underground communication is invaluable for understanding cybercrimes. However, it is often obfuscated by the extensive use of dark jargons, innocently-looking terms like &quot;popcorn&quot; that serves sinister purposes (buy-ing/selling drug, seeking crimeware, etc.). Discovery and understanding of these jargons have so far relied on manual effort, which is error-prone and cannot catch up with the fast evolving underground ecosystem. In this paper, we present the first technique, called Cantreader, to automatically detect and understand dark jargon. Our approach employs a neural-network based embedding technique to analyze the semantics of words, detecting those whose contexts in legitimate documents are significantly different from those in underground communication. For this purpose, we enhance the existing word embedding model to support semantic comparison across good and bad corpora, which leads to the detection of dark jargons. To further understand them, our approach utilizes projection learning to identify a jargon&apos;s hypernym that sheds light on its true meaning when used in underground communication. Running Cantreader over one million traces collected from four underground forums, our approach automatically reported 3,462 dark jargons and their hy-pernyms, including 2,491 never known before. The study further reveals how these jargons are used (by 25% of the traces) and evolve and how they help cybercriminals communicate on legitimate forums.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Underground forums are communication hubs for cybercriminals, helping them promote attack toolkits and services <ref type="bibr" target="#b14">[25]</ref>, coordinate their operations, exchange information and seek collaborations <ref type="bibr" target="#b13">[24]</ref>. For example, Silk Road, a forum with estimated 30K-150K active users <ref type="bibr" target="#b18">[30]</ref>, served as a breeding ground for narcotics and other illegal drug businesses, leaving 214 communica-  jargons are highlighted in blue color. The first example exhibits jargon "rat" which means "remote access trojan"; The second example shows the jargon "blueberry" for "marijuana", while "athena" is the jargon for a kind of botnet framework in the third example.</p><p>tion traces every day. Such traces provide a deep insight into the ways cybercrimes are committed, criminals' strategies, capabilities, infrastructures and business models, and can even be used to predict their next moves. However, they are often written in "thieves' cant", using encoded words like popcorn (marijuana), cheese pizza (child pornography) to cover their meanings. Such dark jargons are often innocent-looking terms (e.g., popcorn), which are extensively used for online purchasing/selling drug, seeking cybercrime wares' developers, doxing Blackhat SEO techniques etc. <ref type="figure" target="#fig_0">Figure 1</ref> presents some dark jargons and their semantics in the underground forums Silk Road and Darkode. Such deceptive content makes underground communication less conspicuous and difficult to detect, and in some cases, even allows the criminals to communicate through public forums (Section 6). Hence, automatic discovery and understanding of these dark jargons are highly valuable for understanding various cybercrime activities and mitigating the threats they pose.</p><p>Reading thieves' cant: challenges. With their pervasiveness in underground communication, dark jargons are surprisingly elusive and difficult to catch, due to their innocent-looking disguises and the ways they are used, which can be grammatically similar to the normal usages of these terms (e.g., sell popcorns). Even more challenging is to discover their semantics -the underground meanings they are meant to hide. So far, most dark jargons have been collected and analyzed manually from various underground sources, an approach neither scalable nor reliable <ref type="bibr" target="#b9">[19]</ref>.</p><p>Some prior researches on cybercrimes report the finding of dark jargons, though these automatic or semiautomatic analyses approaches are not aimed at these underground cants. A prominent example is the study on dark words, the terms promoted by blackhat SEO <ref type="bibr" target="#b34">[46]</ref>. The study introduces a technique that looks for the query words leading to the search results involving malicious or compromised domains, which however is not to detect dark jargons but blackhat SEO targeted dark words (see detail in Section 6, under "innocent-looking dark jargon"). Also, another prior study <ref type="bibr" target="#b19">[31]</ref> shows that the names of illicit products (e.g., bot) automatically discovered from underground marketplaces include some jargons (e.g., "fud" which means "fully undetectable exploit"). None of these approaches, however, are designed to find dark jargons, not to mention automatically revealing their hidden meanings. Addressing these issues needs new techniques, which have not been studied before.</p><p>Cantreader. In our research, we propose a new technique, called Cantreader, that utilizes a new neural language model to capture the inconsistencies between a phrase's semantics during its legitimate use and in underground communication. Fundamentally, a dark jargon can only be captured by analyzing the semantic meaning using the context in which it appears. A key observation we utilize to automate such analysis is that an innocentlooking term covering dark semantics tends to appear in a totally different context during underground communication than when it is used normally. For example, on a dark market forum, "cheesepizza" is usually presented together with "shot", "photo", "nude" and others, while on other occasions, the term comes with "food", "restaurant", "papa johns" etc. Thus, the key of identifying the jargon in the cybercrime marketplaces is to find its semantic discrepancy with itself when used a legitimate reference corpus.</p><p>To this end, we need to address several technique challenges: (1) how to model a term's semantic discrepancy between two corpora? (2) how to handle the terms that have been used differently even in the legitimate corpora? (3) how to understand a dark jargon which is not explicitly explained in the communication traces? To address these issues, we enhanced the standard neural language model by doubling the number of its input layer's neurons to process the sentences from two different corpora. Such a neural network outputs two vectors for each input word, one for the good set and the other for the bad set, automatically making the semantic gap between the word's context measurable (Section 4.1). To control the false positives introduced by the variations in a term's legitimate use, our approach runs the new model to compare the semantics of the terms in the good set (legitimate communication traces) and their meanings in a reputable interpretative corpus (such as Wikipedia and dictionary). Any inconsistency detected here indicates that the term can have a large variation in its legitimate semantics (e.g., "damage" is a slang for game in some legitimate corpora, see detail in Section 4), and therefore should be filtered out to avoid false positives. Finally, to understand a discovered dark jargon, we propose a hypernym ("is-a" relation) based semantic interpretation technique, which uncovered a terms with "is-a" relation to the jargon (e.g., "popcorn" is a "drug").</p><p>We implemented Cantreader and evaluated its efficacy in our research (Section 5). Using four underground forum corpora and one corpus from a legitimate forum, our system automatically analyzed 117M terms and in the end, reported 3,462 dark jargons and their hypernyms. With its high precision (91%), Cantreader also achieved over 77% recall rate. Our code and the datasets are available at <ref type="bibr" target="#b15">[26]</ref>.</p><p>Discoveries. Running on over one million communication traces collected from four underground forums across eight years <ref type="bibr">(2008)</ref><ref type="bibr">(2009)</ref><ref type="bibr">(2010)</ref><ref type="bibr">(2011)</ref><ref type="bibr">(2012)</ref><ref type="bibr">(2013)</ref><ref type="bibr">(2014)</ref><ref type="bibr">(2015)</ref><ref type="bibr">(2016)</ref>, Cantreader automatically identifies 3,462 dark jargons along with their hypernyms. By inspecting these dark jargons together with their hypernyms and the underground communication traces involving jargons, we are able to gain an unprecedented understanding of the characteristics of dark jargons, as well as their security implications. More specifically, we found that dark jargons are extremely prevalent in underground communication: 25% of the traces using at least one jargon. Interestingly, our research reveals the possible ways cybercriminals choose jargons: drug criminals tend to use fruit names for the drugs with different flavors such as "pineapple", "blueberry", "orange" and "lemon", while, hacking tool developers prefer mythological figures like "zeus", "loki" and "kraken". Also, given the long timespan of the corpora, we are able to observe the evolution of the jargons: e.g., roughly 28 drug jargons appear each month, with the increase rate of 5.2%.</p><p>In terms of their security implications, we were able to utilize the dark jargons to discover and analyze criminal communication on public forums. Particularly, we detected 675 such traces on Reddit, the largest US forum. These criminal traces are related to various criminal activities such as illicit drug trade or sharing the "drug trip" experience. Also interestingly, using dark jargons, we even found 478 black words, which are another criminal cant that unlike innocent-looking jargons, barely appear in legitimate communication: e.g., "chocolope" for marijuana, 'li0n" for crypter and "Illusi0n" for trojan.</p><p>Contributions. The contributions of the paper are as follows:</p><p>• Novel dark jargon discovery technique. We present Cantreader, the first fully-automated technique for dark jargon discovery and interpretation, which addresses the challenge in effective analysis of massive cybercriminial communication traces. Our approach leverages a new neural language model to compare the semantics of the same term in different corpora and further identify their hypernyms. Our evaluation shows that Cantreader can effectively recover and interpret dark jargons from underground forum traces, which cannot be done by any existing techniques, to the best of our knowledge.</p><p>• New findings. Running Cantreader on 375,993 communication traces collected from four underground forums across eight years, our study sheds new light on the characteristics of dark jargon, and the possible implications that they may have on criminal traces recognition and black word identification. The new understandings are invaluable for threat intelligence gathering and analysis, contributing to the better understanding of threat landscape.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Cybercrime Communication</head><p>Underground forum. As mentioned earlier, the underground forum is an important component of the cybercrime ecosystem, a critical communication channel for coordination of malicious activities and doing underground business. These forums are known to host some of the world's most infamous cybercriminials. For example, the members of the "Lizard Squad" group were active members of Darkode <ref type="bibr">[4]</ref>, multiple drug dealers sold drug through Silk Road on a large-scale <ref type="bibr" target="#b8">[17]</ref>. Hence, communication traces in the underground forum are considered to be an important source of cyber threat intelligence gathering. The rich information disclosed by such communication sheds light on the adversary's strategy, tactics and techniques, and provides the landscape of the fast-evolving cybercrime.</p><p>In our research, we studied the communication that took place on four infamous underground forums: Darkode (sale and trade of hacking services and tools), Hack Forums (blackhat hacking activities discussion), Nulled (data stealing tool and service) and Silk Road (illegal drug), including 375,993 traces (i.e., threads of posts) from 03/2008 to <ref type="bibr">05/2016 (4132 per month)</ref>. In addition, we observe the number of the communication traces increases rapidly in all underground forums, which makes manual semantic analysis increasingly difficult.</p><p>Dark jargon. In our research, we consider a dark jargon to be an innocent-looking term used in the criminal community to cover its crime-related meaning. Such jargons often represent illicit goods, services, criminal tactics, etc., for the purpose of evading the law enforcement's detection. For example, drug traffickers have a long history to use dark jargon to describe illegal drugs to confuse eavesdropping federal agents. These jargons serve as a barrier for the "outsider" to understand criminals' conversations. Hence, identifying and understanding them are considered as a critical task for fighting against cybercrimes. For example, to better understand the drug trade business, Drug Enforcement Administration (DEA) intelligence program compiled a set of dark jargons to decipher forensic data and evidence or information gathered like traffickers' receipts.</p><p>Due to the dynamic and fast-evolving nature of cybercrimes, the vocabulary of dark jargons continues to change, adding new terms and dropping old ones. Also, every subgroup of criminals such as drug traffickers create their own jargons. Hence, it is important to continuously discover and interpret new jargons, timely updating the vocabulary list. This is by no means trivial. As an example, the drug jargons released by DEA have been complained to be misinformed and decades behind the time <ref type="bibr" target="#b9">[19]</ref>. Considering the huge amount of underground communication traces collected, new techniques need to be developed to automate dark jargon identification and understanding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Neural Language Model</head><p>Neural language model has been found very efficient for learning high-quality distributed representations of words (word embedding), which capture a large number of precise syntactic and semantic word relationships <ref type="bibr" target="#b16">[28,</ref><ref type="bibr" target="#b24">36,</ref><ref type="bibr" target="#b25">37]</ref>. It aims at finding a parameterized function mapping a given word to a high-dimensional vector (200 to 500 dimensions), e.g., v man = (0.2, −0.4, 0.7,...), that represents the word's relations with other words. Such a mapping can be learned with different neural network architectures, e.g., using the continual bag-of-words model and skip-gram, to analyze the contexts of input words from a large corpus <ref type="bibr" target="#b25">[37]</ref>. Such a vector representation ensures that syntactically or semantically related words are given similar vectors, while unrelated words are mapped to dissimilar ones.</p><p>Architecture. Given the training set of a neural language model represented by a sequence w 1 , w 2 ,..w |V | of words, the objective is to learn a "good model" f (w 1 ,..w |V | ) =  <ref type="bibr" target="#b17">[29]</ref>. Neural language model architectures are essentially feed-forward networks, usually but not necessarily limited to only a single hidden layer. <ref type="figure">Figure 2</ref> shows a typical neural network with one hidden layer used by the skip-gram model, an instance of neural language model allowing fast training. The input layer consists of |V | neurons accepting a word w i as a one-hot vector c(w i ). For a word vector with |H| features, the hidden layer with |H| neurons takes the vector as the input, and output a |H|-dimension word vector. The output layer is a softmax regression classifier with |V | neurons. Specifically, each output neuron has a weight vector that multiplies with the word vector from the hidden layer, before applying the softmax function to the result.</p><p>Sub-sampling. In large corpora, the most frequent words (e.g., "in", "the", "a") usually provide less information than rare words. For example, observing the co-occurrence of "woman" and "queen" is more valuable than seeing the co-occurrences of "queen" and "a". To counter the imbalance between the rare and frequent words, some neural language models such as the skipgram model apply a simple subsampling approach: each word w i in the training set is discarded with a probability determined as by computing P(w i ) = 1 − 񮽙 t f (w i ) where f (w i ) is the frequency of the word w i and t is a chosen threshold, typically around 10 −5 . The formula here aggressively subsamples words whose frequency is greater than t, while preserving the ranking of the frequencies. It accelerates learning and significantly improves the accuracy of the learned vectors of the rare words.</p><p>Word vector properties. Interestingly, the vector representations of neural language model capture the syntactic/semantic relations between words: e.g., the vectors for the words 'queen', 'king', 'man' and 'woman' have the following relation: v queen − v king ≈ v man − v woman . Also, the same property also applies to hypernymhyponym relations. For example, v womon − v queen ≈ v man − v king where 'woman' is the hypernym of the hyponym 'queen' and 'man' is the hypernym of the hyponym 'king'.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Hypernym identification</head><p>Hypernym Identification is an NLP technique to identify a generic term (hypernym) with a broad meaning that more specific instance (hyponym) falls under. For example, "woman" is a hypernym of "queen". Hypernym describes an important lexical-semantic relation and information abut it helps understand the semantics of its instance: e.g., knowing that "Tom Cruise" (hyponym) is an "actor" (hypernym) helps a question answering system answer the question "which actors are involved in Scientology?". Hypernym identification can be addressed by either distributional or path based approaches. The former <ref type="bibr" target="#b29">[41,</ref><ref type="bibr" target="#b20">32]</ref> uses distributional representations (such as word embedding) of the terms for hypernym identification. The latter <ref type="bibr" target="#b31">[43,</ref><ref type="bibr" target="#b32">44]</ref> leverages the lexico-syntactic path connecting the terms to detect hypernym. In our research, we utilize the distributional based method to find out the hypernym of a jargon so as to understand its semantics. This is because the path based methods require corpora following strict grammar structure, and also the hypernym and hyponym terms should occur together in the corpus, which is often not the case for underground forum data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Cantreader: Overview</head><p>Cybercriminals on underground forums often pick common, innocent-looking words as their jargons to obfuscate their illegal communication. Identifying such dark jargons and discovering their semantic meaning, is difficult due to the stealthy nature of dark jargons. However, regardless of what a word looks like, its true semantics can be observed from its context. For example, when the "popcorn" means a snack, it often comes with "eat" or "chocolate", while when it refers to marijuana, "nugz", "buds" and others would show up around the word.</p><p>This observation is the key to the automated discovery and understanding of dark jargons and is fully leveraged in the design of Cantreader. Our approach utilizes a novel neural language model to learn a word's semantics from its context during legitimate conversations and in underground communication respectively, and then compares the semantics to identify the consistency that indicates its potential use as a dark jargon. For each discovered jargon, we further perform a hypernymy-based semantic analysis to discover its underground meaning. Below we present the high-level design of this technique and explicate how it works through an example.</p><p>Architecture. <ref type="figure" target="#fig_2">Figure 3</ref> illustrates the architecture of Cantreader, which includes two components: the discoverer and the interpreter. The discoverer analyzes the words included in an underground communication corpus and compares their semantics with that learned from legitimate corpora to identify dark jargons. More specifically, the component first filters out the words from the dark corpus, whose semantics is either insignificant or unlikely to be accurately learned with the neural language model. It then applies the Semantics Comparison Model (Section 4.1) to calculate two semantic similarities, Sim dark,legit and Sim legit,rep , for each input word: the former between a dark forum corpus and a legitimate forum corpus, and the later between the legitimate forum corpus and a reputable interpretative corpus. A word is reported as a jargon only if Sim dark,legit is small and Sim legit,rep is large. The interpreter, on the other hand, uses a learning-based automatic hypernym discovery technology to interpret dark jargons by finding their hypernyms. From the public ontology (e.g., Wikidata), we collect a set of hypernym candidates of interest. The interpreter can predict whether any of them is actually a hypernym of a dark jargon.</p><p>An example. We take "popcorn" as an example, which normally, means a snack, but is also used as a slang for marijuana on the underground market such as Silk Road. Here we use Silk Road as the dark corpus (C dark ), Reddit as the legitimate corpus (C legit ), and English Wikipedia as the reputable interpretative corpus (C rep ), to demonstrate how Cantreader could discover and interpret the jargon.</p><p>After preprocessing all the corpora, Cantreader first trains two Semantic Comparison Models on (C dark ,C legit ), and (C legit ,C rep ) respectively. Both models output a pair of word vectors for "popcorn". The similarity between these two vectors (cosine similarity in our research) describes the similarity of the word's semantics in the two corpora. For "popcorn", we have Sim dark,legit = 0.256 and Sim legit,rep = 0.474. This indicates that "popcorn" carries very different meanings in the dark and legit corpora, but more similar ones across the legit and reputable corpora. So, it is labeled dark jargon by the discoverer. To find out the dark semantics of the word, we leverage an public ontology <ref type="bibr" target="#b10">[20]</ref> including the terms of cybercriminal activities and illegal products exchanged on underground markets (such as RAT and marijuana), and a projection learning model to determine whether the word has an "is-a" relation with a class under the ontology. In the example, our model reports a probability of 93% that "popcorn" is a jargon for "marijuana".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Design and Implementation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Semantic Comparison Model</head><p>Fundamentally, Cantreader's jargon identification procedure is based on the fact that a word covering dark semantics tends to appear in a totally different context during underground communication than when it is used normally. In order to uncover such a difference, we propose our Semantic Comparison Model, which extends the neural network (NN) architecture of Word2Vec <ref type="bibr" target="#b24">[36,</ref><ref type="bibr" target="#b25">37]</ref> to analyze and compare the contexts for a given term.</p><p>Word2Vec model. Word2Vec <ref type="figure">(Figure 2</ref>) is a neural word embedding approach that uses shallow, two-layer neural network to learn a statistical language model (e.g. skipgram model) from a large corpus. The NN applies onehot encoding at the input layer, and identity activation function at its hidden layer. As an unsupervised learning model, when the training is done, Word2Vec outputs the weights of the hidden layer M in the form of a |V | × |H| matrix, where |V | is the size of the input vocabulary and |H| is the size of hidden layer. Con-</p><formula xml:id="formula_0">sider M = [v 1 , v 2 , ..., v |V | ] T .</formula><p>For a word w i (whose onehot vector has 1 at its i-th entry), the model assigns the i-th row in M, v i , as the word's the embedded vector. Thus, Word2Vec maps words to vectors in |H| dimension space.</p><p>The intuition behind Word2Vec is that if two different words have similar contexts in a corpus, then given the contexts, the NN is supposed to make similar predictions for these two words. Hence the training process will learn the weights to produce similar hidden layer outputs for these two words. Since the NN applies the identity activation function at hidden layer, the hidden layer output of the word w i is exactly v i , i.e. the embedded vector of that word. Therefore, embedded vectors are justified representations of the contexts of words, which, in turn, represent the semantics of words. Also the similarity between these vectors describes the similarity between the semantics of these words (see Section 2).</p><p>Our model. Word2Vec can be very useful if we want to find the semantic similarity of different words whose vector representations are trained over the same corpus. However, for dark jargon detection, we need to compare the semantics of the same word across different corpora, e.g., one for legitimate conversation and the other for underground communication. This cannot be done by simply combining these corpora together, which loses a word's context information in individual corpora. Nor can we train two separate models on the two different corpora, since the relations between the input layer and the hidden layer are nondeterministic, due to the random initial state for the Word2Vec NN, and the randomness introduced during sub-sampling and negative sampling (Section 2.2). As a result, for a given word, the NN produces different vectors each time when it is trained on the same corpus, which makes cross-model semantic comparison meaningless.</p><p>So the key challenge here is how to make a word's vectors trained from different corpus comparable. To address this challenge, we designed Semantic Comparison Model (SCM), a new network architecture based on Word2Vec NN, which doubles the size of the input layer without expanding either the hidden or the output layer. The idea is to let the same word from two different corpora to build their separate relations, in terms of weights, from the input to the hidden layer during the training, based upon their respective datasets, while ensure that the contexts of the word in both corpora are combined and jointly contribute to the output of the NN through the hidden layer. In this way, every word has two vectors, each describing the word's relations with other words in one corpus. In the meantime, these two vectors are still comparable, because they are used together in the NN to train a single skip-gram model for predicting the surrounding windows of context words.</p><p>To formally describe SCM, we first define an extended one-hot encoding:</p><formula xml:id="formula_1">e(w) = 񮽙 [v zeros , v onehot (w)] if w is from corpus 1 [v onehot (w), v zeros ]</formula><p>if w is from corpus 2 (1) where v zeros is an all-zero vector of |V | dimensions, and v onehot (w) is the standard one-hot vector of word w in the input vocabulary. This encoding function converts words from two corpora to one-hot vectors of 2|V | dimensions, which enables SCM to get input from two corpora during the training stage. It also gives different distributed representation for the same word from different corpora, which ensures the two corpora to be treated differently by the model.</p><p>Since we double the size of the input layer, the weights of the connections between the input and the hidden layer M can now be represented as a 2|V | × |H| To analyze this architecture, we ran SCM on the Text8 corpus <ref type="bibr" target="#b0">[1]</ref>, which is a 100MB subset of Wikipedia. The experiment settings is described in <ref type="table" target="#tab_1">Table 1</ref> and results are elaborated below. Experiment 1. In the experiment, we used Text8 as both input corpora for our SCM. For each word in the vocabulary, the model generated a pair of vectors, each representing its semantics in the corresponding corpus. Since the two input corpora here are identical, the cosine similarity of every vector pair should all be close to 1, if SCM can capture the words' semantics in both corpora correctly. Our experiment shows that for every word in the corpora, the average cosine similarity between its two vectors is 0.98, with a standard deviation 0.006.</p><p>As a reference, we trained a Word2Vec model on the same corpus twice, and calculated the cosine similarities between the vectors of the same words. Here the average similarity is 0.49 and standard deviation 0.078, indicating that the vectors from the two models cannot be com-  pared, due to the training randomness. <ref type="figure" target="#fig_3">Figure 4</ref> presents the cumulative distribution of the results.</p><p>Experiment 2. We then looked into SCM's capability to capture a word's cross-corpus semantic difference, which is at the center of jargon discovery. To this end, We randomly chose 5 words from the Text8 corpus and replaced them with 5 other words (see <ref type="table" target="#tab_2">Table 2</ref>) to construct a new corpus Text8 syn . In this way, these replacements become "jargons" of the original words in the new corpus Text8 syn . Then we trained our architecture on Text8 and Text8 syn , which took in both corpora to learn a SCM. From the new model, again we compared the similarity between each word's two vectors (one from Text8 and the other from Text8 syn ). The results are presented in <ref type="table" target="#tab_2">Ta- ble 2</ref>. Since the replacing word's contexts (e.g., archie) in Text8 syn became different to those in Text8 as recorded in replaced trace rate, all the replaced words were found to have small similarities in two corpora: the average similarity is 0.98 with a standard deviation of 0.01. This experiment shows that our SCM is able to capture a word's cross-corpora semantic difference.</p><p>Experiment 3. Finally, we want to measure the quality of the word vectors generated by SCM. For this purpose, we utilized the code and the test set provided by Tomas Mikolov <ref type="bibr">[22]</ref> for evaluating the quality of word vectors. The test set includes a list of syntactic and semantic relations (such as capital of the country, adjective-adverb, etc.), and a number of test cases (such as Athens-Greece, Baghdad-Iraq) under each such a relation. The quality of word vectors is determined by semantic relations among these vectors: e.g., v Athens − v Greece + v Iraq is supposed to result in a vector very close to v Baghdad . In this experiment, we trained an SCM using Text8 along with a snapshot of Nulled <ref type="bibr">[12]</ref>, a collection of communication traces from an underground forum. On the word vectors produced by the model, we ran Tomas Mikolov's code to evaluate their qualities. The idea is to compare the vectors related to the Type8 corpus with those produced by the Word2Vec model trained over the same corpus. The experiment demonstrates that indeed the quality of the SCM vector (an accuracy of 46%) is in line with those generated by Word2Vec (50%), indicating that the benefit of semantic comparison across corpora does not come with the cost of vector quality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Jargon Discovery</head><p>At the high-level, the discoverer is designed to find a word that tend to appear in different contexts on a dark forum than on a legitimate one. Such a semantic inconsistency can be captured by SCM.</p><p>Specifically, the discoverer takes a dark forum corpus (C dark ), a legitimate forum corpus (C legit ), and a reputable interpretative corpus (C rep ) as its input. After preprocessing these input corpora to build a shared vocabulary, it computes the cross-corpus similarities for each word by training two SCMs, one on C dark and C legit , and the other on C legit and C rep . After filtering out the words with special meanings in C legit , our approach detects jargons whose similarities are low in the first model and high in the second. Here we elaborate on these individual steps.</p><p>Vocabulary building. Bootstrapping the whole discovery process is the generation of a vocabulary from the three input corpora. The vocabulary of SCM is the input word set for the model, including all "words of interest" in the intersection of good and bad corpora C dark 񮽙 C legit , which we will explain later. Every word in the vocabulary corresponds to a specific dimension on the one-hot vector V . As mentioned earlier, the whole input of an SCM is two such vectors, one for each corpus (i.e., C legit and C dark , or C legit and C rep ). From the dark corpus, the "words of interest" are chosen by dropping all the "non-interesting" words. Specifically, we first filter out all stop words (common words like "the", "on", etc.), since their semantics is insignificant for finding jargons. In our research, these words are identified using NLTK <ref type="bibr">[11]</ref>'s English stop words list.</p><p>Also importantly, we need to remove the words whose semantics cannot be effectively learned from the corpora. Particularly, the embedding techniques like Word2Vec and SCM all rely on a word's context to deduce its semantics and embed it into a vector space. If such contexts are not sufficiently diverse in a corpus, the embedded vector becomes biased and specific to the corpus.</p><p>Standard Word2Vec implementation uses a parameter min count for this purpose. Those words whose occurrences in a corpus go below that parameter are excluded since they may not be effectively learned from the infor-mation provided by the corpus. This approach, however, does not work well for our purpose: on forums, people tend to quote each other's posts, repost, and copy-paste published content to their own text. As a result, the same piece of text may appear on a forum repeatedly, and the words involved, though may occur across the corpus for many times, are always under the same context, whose semantics therefore cannot be effectively learned.</p><p>To address this issue, we introduce a new metric, called windowed context, to measure a word's context diversity. Given a window size k, the windowed context of a word w is a contiguous sequence of words start at k words before w and ends at k words after. For example, in the sentence "The quick brown fox jumps over the lazy dog", with a window size 2, the windowed context of word "fox" is ("quick", "brown", "fox", "jumps", "over"). Using this metric, we measure a word's diversity based upon its number of unique windowed context (num wc) in a corpus. Those with a diversity below a given threshold in either C dark or C legit are removed from our vocabulary. In our research, we set the window size to 5 for the discoverer and the threshold to 20.</p><p>Jargon semantics comparison. After the vocabulary is built, the discoverer trains an SCM using the targeted dark corpus C dark and a reference corpus C legit . The purpose is to compare every word's two embedded vectors (one for each corpus) by calculating their cosine similarity Sim dark,legit , for the sake of identifying those with discrepant meanings across the corpora.</p><p>However, just because a word has different semantics across the dark forum and the legitimate corpus does not always mean that it is a dark jargon. Particularly, if the legitimate corpus includes formal documents such as those from Wikipedia and news articles, false positives can be introduced. This is because words are used differently in these documents than in less formal forum posts. For example, on forums, "man" is commonly used as an expression of greeting, or an interjection to express anger or displeasure, while in a more formal context, it usually means an adult male. Another example is "peace", which is frequently used as a way to say goodbye in the forum language. To avoid misidentifying those "forum terms" as jargons, Canreader utilizes posts on a legitimate forum as the reference C legit . Specifically in our research, the legitimate data were collected from reddit.com.</p><p>Unique context. Using legitimate forums as the reference corpus, we can avoid most false positives introduced by the semantic comparison. However, still we cannot eliminate the situations where some less harmful terms are treated as dark jargons, due to their unique contexts in the legitimate corpus, which can be different from their generic semantics actually used on dark forums. For example, we found that the word "damage" on reddit.com often appear during the discussion of computer games and as a result, its context becomes very much biased towards settings in the games (such as "heal", "stun" and "dps"); on Silk Road, however, "damage" preserves its original meaning.</p><p>To filter out the terms unique to the good set (C legit ), the discoverer compares every vocabulary word in the set to the same word in another legitimate corpus, in terms of their semantics. The new corpus, which we call reputable set C rep , is supposed to include more formally-written documents that largely use each word's dictionary meaning. In our implementation, we chose Wikipedia as C rep . Training an SCM on C legit and C rep , the discoverer is able to compare each word's semantics on both corpora (Sim dark,legit ) to detect and remove those carrying unorthodox contexts in the good set.</p><p>Threshold selection. As mentioned earlier, the discoverer reports a word as a dark jargon if its semantic similarity in C dark and C legit is below a threshold (different meanings across good and bad sets), while its similarity in C legit and C rep is above the threshold (similar meaning in two good sets). The challenge is, however, how to determine the threshold, which turns out to be non-trivial. In our research, we found that SCM tends to give larger cosine similarities to the words with diverse semantics. This is because a word with more meanings usually covers more different words in its context, so for such a word, its contexts in one corpus tend to have a larger overlap with that in another. Hence, we need different thresholds: a larger one for those with diverse semantics, and a smaller one for those with fewer meanings.</p><p>For this purpose, the discoverer first groups all vocabulary words into different classes according to their semantic diversities, as estimated using the numbers of synsets in WordNet <ref type="bibr" target="#b12">[23]</ref>. Our implementation defines 4 classes: words having 0 synsets (not covered in the wordnet), between 1 to 4, between 5 to 8, and larger than 8. Over the classes, our approach runs a statistical outlier detection based on z-score <ref type="bibr" target="#b17">[29]</ref> to find the thresholds. In our research, we use z = 1.65, so for each class, the discoverer simply computes the mean μ and standard deviation σ for the cosine similarities of the vector pairs as produced by an SCM for individual words and set μ − 1.65σ as the threshold for that model. Assuming in each class, the similarities follow a Gaussian distribution, the threshold we selected ensures that a normal sample (a word with similar semantics in two corpora) has only 5% chance to go below the threshold, in terms of the cosine similarity between its two embedded vectors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Jargon Understanding</head><p>Once a possible jargon has been discovered, Cantreader runs the interpreter to make sense of it. Finding the pre- Figure 5: SPARQL example cise meaning of a dark jargon is challenging, due to lack of enough information to differentiate the contexts of related terms, particularly with the succinct expressions typically used on forums. On the other hand, we found that it is possible to gain some level of understanding of a jargon, by classifying it to a certain category under a specific hypernym. For example, though we may not have enough information to interpret "horse" as heroin, we may still be able to determine that it is a kind of illegal drug. Such understanding can also help a human analyst quickly decrypt the term, to find out its exact semantics.</p><p>This understanding is automatically generated by the interpreter as follows. First, it produces a set of hypernym candidates from the common products people trade on underground forums. Then our approach analyzes the semantics (in terms of embedded vectors) of a given jargon and all the candidates, running a classifier to find out whether any of them is a hypernym of the jargon. Hypernym candidates generation. Our interpreter automatically expands a set of seeds to find hypernym candidates. These seeds are picked manually, including a small set of product categories discovered from underground forums as illustrated in <ref type="table" target="#tab_6">Table 6</ref>. Using the seeds, the interpreter discovers other hypernym candidates by querying the Wikidata <ref type="bibr" target="#b10">[20]</ref> database for the subclasses of the entities in the seed set.</p><p>Wikidata is a free and open knowledge base. It provides the Wikidata Query Service <ref type="bibr" target="#b11">[21]</ref> that enables users to query its ontology using the SPARQL language <ref type="bibr">[18]</ref>. <ref type="figure">Figure 5</ref> shows the example to search for the subclasses under "software", where wdt:P279 represents the subclass of relation, and wd:Q7397 describes the software entity.</p><p>For each category (e.g., drug) in the seed set, we use Wikidata to find all its direct and indirect subclasses, and generate a tree rooted at the category in the seed. In this way, our approach generates a forest (a set of trees) out of the seeds where each node is a hypernym candidate. Projection learning. Prior research demonstrates that an effective way to find hypernym relations is using a model learned from the semantic links between words, using the embedding techniques <ref type="bibr" target="#b20">[32]</ref>. In our research, we follow the similar idea to build our interpreter. Specifi- cally, for a given jargon, our approach uses its embedded vector together with a hypernym candidate's vector (from the same SCM) as a feature to determine the probability that they indeed have the hypernym relation. For this purpose, we adopt a binary random forest classifier, which unlike the multi-output linear regression model used in the prior research <ref type="bibr" target="#b20">[32]</ref>, can leverage the information not only from positive but also from negative samples to identify the decision boundary. This classifier was trained in our research using our hypernymy dataset described in Section 5.1.</p><p>Recursive hypernym discovery. For each dark jargon, the interpreter takes the following steps to uncover its hidden meaning. First, we look at the roots of the hypernym candidates forest. If none of them is a valid hypernym of the jargon, as determined by the classier, we label the jargon "unknown". Otherwise, we choose the most probable root (again based upon the output of the classifier) and continue to analyze its children. If none of them is found to be a hypernym for the jargon, their parent is returned. Otherwise, the most probable child is picked and the same procedure is followed recursively on its subtree.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experiment Setting</head><p>In our study, we ran our implementation of Cantreader on 375,993 communication traces collected from four underground forums, using an R730xd server with 40 Intel Xeon E5-2650 v3 2.3GHz, 25M Cache cores and 16 of 16GB memories. Here we describe the datasets used in the study and the parameter settings of our system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Datasets.</head><p>We used four datasets in our study: dark corpora, benign corpora, hypernymy dataset, and groundtruth dataset with known jargons.</p><p>• Dark corpora. Dark corpora consist of communication traces from the four underground forums. In our research, we parsed the underground forum snapshots collected by the darknet marketplace archives programs and other research projects <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b19">31]</ref>, to get four dark corpora: the Silk Road corpus <ref type="bibr" target="#b8">[17]</ref> consists of 195,403 traces (i.e., threads of posts) from the underground market-place Silk Road mainly discussing illicit products (such as drugs and weapons) trading; the Darkode corpus <ref type="bibr">[4]</ref> includes 7,417 traces from a hacking technique forum about cybercriminal wares; the Hack forums corpus <ref type="bibr">[9]</ref> has 52,670 traces from a blackhat technique forum; and the Nulled corpus <ref type="bibr">[12]</ref> contains 121,499 traces from a forum talking about data stealing tools and services. Table 3 summarizes the dark corpora we used.</p><p>• Benign corpora. As mentioned earlier, Cantreader uses two different benign corpora: a legitimate reference corpus, and a reputable interpretative corpus. In our implementation, traces of Reddit are used as the legitimate reference corpus. Reddit is the most popular forum in the U.S., receiving around 470,000 posts per day during the past ten years <ref type="bibr">[15]</ref>. It includes rich informal language elements in English such as forum slangs, common acronyms, and abbreviations (e.g. "hlp" for "help" and "IMO" for "in my opinion"), which are also commonly used in the underground forums, and therefore it serves as a good reference corpus. To build this corpus, we ran a crawler that scraped 1.2 million traces from 1,697 top subreddits in terms of the number of subscribers <ref type="bibr">[27]</ref>. Also, Wikipedia <ref type="bibr">[10]</ref> is used as the reputable interpretative corpus. This is because it is large, comprehensive, formally written, and reputable. <ref type="table" target="#tab_3">Table 3</ref> presents the benign corpora used in our research.</p><p>• Hypernymy dataset. The interpreter component of Cantreader needs a labeled hypernymy dataset to train its classifier. In our implementation, we reuse the hypernymy dataset that Shwartz et. al generate in the previous research <ref type="bibr" target="#b5">[7,</ref><ref type="bibr" target="#b30">42]</ref>. The dataset is constructed by extracting the entity pairs with "is-a" relation from 4 lexical/ontology databases: WordNet <ref type="bibr" target="#b12">[23]</ref>, DBPedia <ref type="bibr" target="#b3">[5]</ref>, Wikidata <ref type="bibr" target="#b10">[20]</ref> and Yago <ref type="bibr" target="#b33">[45]</ref>. It includes 14,135 positive hypernym relations and 84,243 negative ones.</p><p>• Groundtruth dataset. The groundtruth dataset, with 774 known dark jargons and their corresponding hypernyms, is used in the evaluation of our system. The dataset was collected from two sources: DEA drug code words list <ref type="bibr" target="#b4">[6]</ref> and the cybercrime marketplace product list <ref type="bibr" target="#b19">[31]</ref>. The DEA drug code words list is the drug jargon list released by Department of Defense Drug Enforcement Administration (DEA), which includes 1,734 drug code words. The cybercrime marketplace product list is a dataset published by academic researchers, which includes 1,292 illegitimate products manually annotated from Nulled, Hack Forums, and Darkode. Note that not all the terms appear on the two lists are actually used as dark jargons in our dark corpora because DEA's drug list includes many out-of-date and uncommon slang names for drugs, and the cybercrime marketplace product list, on the other hand, focuses mostly on illegitimate products, which are not always referred to in dark jargons. Thus we carefully analyzed these terms with the traces containing them and generated a set of 774 groundtruth dark jargons and their corresponding hypernyms of high confidence.</p><p>Parameter settings. In the experiments, the parameters of our prototype system are set as follow:</p><p>• Neural network settings. We used similar SCM training parameters as shown in <ref type="table" target="#tab_1">Table 1</ref>, except that we set iterations = 100. We also used num wc = 20 with a window size = 5) to replace the min count parameter due to larger corpora.</p><p>• Thresholds. <ref type="table" target="#tab_4">Table 4</ref> lists the thresholds we used in our experiments.</p><p>• Projection learning classifier. We implemented the projection learning with scikit-learn's <ref type="bibr">[16]</ref> RandomForestClassifier.</p><p>The classifier was trained with the following settings: n estimators = 200, max features = auto, min samples split = 2, and class weight = balanced.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Evaluation Results</head><p>Accuracy and coverage.</p><p>In our study, we ran our system over the dark corpora and benign corpus across 1,497,735 traces and 117M words. Altogether, Cantreader automatically identified 3,462 dark jargons and their hypernyms. To understand the accuracy and coverage of the results, we first used the groundtruth dataset to validate our results.</p><p>Among the 774 jargon words in the groundtruth set, 598 were successfully detected by Cantreader, which gives a recall of 77.2%. We carefully checked the false negatives (i.e., jargons in the groundtruth set but being considered non-jargons by Cantreader), and found that some of false negatives do not show any semantic inconsistency in our corpora. This might be due to the limitation of our corpora, or those terms were not used as jargons during our monitoring timespan. For example, we carefully investigated all the communication traces involving the jargon "car" labeled by DEA. No indicator shows that it is used as "cocaine". In fact, DEA drug code words lists also announce the possible and invertible dataset error due to the dynamics of drug scenes <ref type="bibr" target="#b4">[6]</ref>. For the rest 2,864 dark jargons detected by Cantreader, we randomly picked 200 samples for manual validation, where 182 terms were confirmed to be true dark jargons. It concludes that Cantreader achieves a precision of 91%. Performance.</p><p>To understand the performance of Cantreader, we measured the time it took to process 180,899 communication traces (containing 100M total words, where 75,419 unique words are in the vocabulary) in the dark corpora and the breakdowns of the overhead at each analysis stage, the discoverer and the interpreter. In the experiment, our prototype was running on our R730xd server, using 30 threads. It took around 17 hours to inspect 180,899 traces, as illustrated in <ref type="table" target="#tab_5">Table 5</ref>.</p><p>The results provide strong evidence that Cantreader can be easily scaled to a desirable level to process a massive amount of underground forums every day.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Measurement</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Landscape</head><p>Scope and magnitude. In total, Cantreader identified 3,462 dark jargons and their corresponding hypernyms from 1,497,735 underground communication traces. Our study shows that criminals indeed widely use dark jargons for underground communication. 376,989 (25%) of the traces include at least one dark jargon. <ref type="figure">Figure 6a</ref> illustrates the cumulative distributions for the number of dark jargons per communication trace. We observe that 80% of the traces using the number of dark jargons less than ten. Later, we study the trace volume of dark jargons. <ref type="figure">Figure 6b</ref> shows the cumulative distributions for the number of communication traces per dark jargon. We observe 80% of dark jargons used by less than 956 traces. It also indicates the effectiveness of our model to capture dark jargons leveraging limited communication traces. <ref type="table" target="#tab_6">Table 6</ref> presents the 5 categories of dark jargons found by Cantreader in terms of their popularity. We observe that a large portion of dark jargons is drug, which is related to 736 innocent-looking terms. Among them, 692 drug jargons are not included in the drug jargon lists reported by DEA (see Section 5), but prevalent in underground forums such as "cinderella", "pea" and "mango". For example, "mango", the jargon for "marijuana", was found in 540 criminal communication traces about drug trading.</p><p>We looked into the distribution of dark jargon across different underground forums. We found that Silk Road has most jargons <ref type="bibr" target="#b1">(2,</ref><ref type="bibr">570)</ref>. When it comes to the diversity, the communication traces in all four forums include the aforementioned five popular types of dark jargons. This indicates that various kinds of malicious activities  discussed on the underground forums tend to use dark jargons to protect their communication.</p><p>Innocent-looking dark jargon. To understand how the criminals choose dark jargons, we study their explicit/innocent meanings. Specifically, we regard the terms' interpretations in WordNet <ref type="bibr" target="#b12">[23]</ref> as their innocent meaning, and then seek their nearest common ancestors in the hypernym tree to determine their categories. <ref type="table" target="#tab_7">Table 7</ref> shows the innocent meanings of top 8 jargon categories (in terms of instance number). Most of the dark jargons are deliberate typos and abbreviations (28.24%), followed by person names (4.10%) and locations (3.38%). Interestingly, we found that drug dealers tend to use drug flavors as jargons, e.g., "pineapple", "blueberry", "orange" and "lemon". Meanwhile, hackers prefer mythological figures like "zeus", "loki" and "kraken". <ref type="figure" target="#fig_6">Figure 7a</ref> shows the Google search interests of dark jargons when they are used as search terms. Google search interest is recorded by Google Trend <ref type="bibr" target="#b6">[8]</ref>, which measures the number of searches for each keyword during a time period. The higher search interests means  the higher competitiveness of a search term, indicating that it becomes more difficult for less relevant and less reputable websites to get to the top of the search results under the term through SEO. Due to the generality of the dark jargons' meanings, most of the them (60%) have high search interests. In fact, almost all the top 10 Google search results for each of the dark jargons we found are reputable websites. <ref type="figure" target="#fig_6">Figure 7b</ref> shows the cumulative distribution of the average websites ranking in search results per dark jargon. We observe that websites in 60% of the dark jargons' search results have the average website rankings below 100k (highly reputable sites). None of them are labeled as malicious websites by Google Safe browsing. This indicates that unlike the black keywords reported in the prior research <ref type="bibr" target="#b34">[46]</ref>, these dark jargons not only look innocent but are indeed less likely related to compromised or attack sites, thereby providing good covers for underground communication.</p><p>Ever-changing dark jargon. <ref type="figure">Figure 6c</ref> shows the evolution of the number of newly-appeared dark jargons on Hack Forums. On average, around 25 dark jargons emerge each month. The trend line in the figure demonstrates two increase tides in 2010 and 2013. Meanwhile, we found that some dark jargons have continued to show up in the communication traces for a long time. For example, "ccs" (credit cards) has been observed from 03/2008 to 05/2016 and is still being used on the underground market.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Implications of Dark Jargon</head><p>Criminal trace identification in benign corpora. The availability of dark jargons enables us to investigate the criminal communication traces on public forums. Specifically, for each communication trace in Reddit, we evaluated whether it includes dark jargons and their cooccurrence terms. The co-occurrence terms are those commonly used in criminal activities on underground forums. For example, "escrow" is a highly-frequent cooccurrence term in the drug advertisement of "blueberry" (marijuana). In this way, we discovered 675 communication traces in Reddit related to criminal activities. Interestingly, among them, 48.3% of the traces with dark jargons do not include their corresponding hypernyms. It means that the criminals intend to use dark jargons to cover its explicit meaning.</p><p>To investigate criminal activities of the criminal communication traces using dark jargons, we extracted the keywords using RAKE from the criminal traces and clustered the traces based on those keywords using the classic k-Nearest-Neighbor (k-NN) algorithm <ref type="bibr" target="#b17">[29]</ref>. Then, we inspected each cluster manually, and found that most of the communication traces are related to illicit drug trading and drug vendor review. Also interesting, we discovered that drug vendors aggressively post illicit drug trading ads on Reddit: 33 traces about drug trading come from the same vendor humboldtgrows. Also, even though Reddit prohibits the posts related to criminal activities <ref type="bibr" target="#b7">[14]</ref>, we found that the communication traces with dark jargons enjoyed a long lifetime. 73 criminal traces have been there more than one year.</p><p>Black words. Cantreader utilizes the semantic inconsistency of dark jargons in the dark corpora and legitimate corpora for identification. However, another type of criminal related terms (called black words) are only used by criminals and barely seen on legitimate forums, which cannot be recognized by Cantreader directly. However, we found that such dedicated black words can actually be identified and understood by leveraging the dark jargons we discovered. Specifically, for each word that appears frequently in the dark corpus but has been excluded during the vocabulary building (e.g., due to its absence in C legit , see Section 4.2), we look for its top 40 similar words in the dark corpus (in terms of the cosine distance between word vectors), and examine their overlap with a list of dark jargons we discovered. This jargon list consists of 200 most frequent dark jargons we manually verified. We consider the word to be a black word when the overlap is no less than 5. For such a word, we further used the most common hypernym of the overlapping jargons to interpret it. For example, we found that "chocolope", a kind of marijuana, which does not appear in C legit , frequently co-occurs with multiple drug jargons Figure 8: Trace volume of four jargons across month such as "blueberry", "diesel" and "kush" in C dark . In this way, we discovered 522 black words related to 14 hypernyms. We manually examined and confirmed that 478 were indeed black words, which gives an accuracy of 91.57%. <ref type="figure">Figure 6d</ref> shows the cumulative distribution of the number of similar jargons per black word. We found that 50% of the black words are similar to more than 10 dark jargons on the list. <ref type="table" target="#tab_8">Table 8</ref> presents the top 5 hypernyms of black words with most instances. Here, "sedatives" have most black words (14.4%), followed by "narcotics" (13.2%) and "stimulants" (9.6%). Also interestingly, criminals utilize obfuscated terms as black words, e.g., "li0n" (crypter) and "Illusi0n" (trojan).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Case Study</head><p>Our research discovers many jargons related to malware or cyber attack services. We found that identifying such jargons helps cyber threat intelligence gathering from the underground forum to better understand various threats. For example, "rat" (remote access trojan) is mentioned in 9,445 unique criminal communication traces, in the contexts of trojan development, new trojan promotion and exploit package purchase/sell. <ref type="figure">Figure 8</ref> illustrates the trace volume of the dark jargons "rat", "loki", "xtreme" and "ivy" per month from 05/2008 to 03/2015 in Hack Forum, where "loki", "xtreme" and "ivy" are different kinds of "rat". From the figure, we can see the prevalence of "rat" (including all these jargons) discussion across years, in terms of the number of traces. Overall, 350 traces are related to "ivy", 261 to "xtreme" and 46 to "loki". In fact, compared to "loki" and "xtreme", "ivy" is a more popular "rat" since its release, due to its wide availability and easy-to-use features <ref type="bibr">[13]</ref>. We also find that 10% of criminal communication involving "ivy" talks about free download addresses. The traces containing "xtreme" are most for seeking the source code of "xtreme" and its variants. We notice a spree of the trace volume of "rat" from 02/2009 to 10/2011 due to the popularity of multiple kinds of "rat" like "loki", "xtreme" and "ivy". In 02/2015, we observe a small peak of "rat". This is because that Darkcomet 5.3 <ref type="bibr" target="#b1">[2]</ref>, a kind of "rat", is released and several configuration issues discussions correspond to that.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Discussion</head><p>Semantic comparison model. As mentioned earlier, we propose a semantic comparison model to address the challenge in comparing the semantics of a word from different corpora. Our current application domain of the model is jargon discovery. We believe that this semantic comparison model could also be used in any polysemy identification scenario if proper corpora exist. We conducted open domain experiments as reported in Section 3, which indicates the effectiveness of the proposed model on open domain corpora.</p><p>Also, even only accepting two corpora in jargon discovery, the semantic comparison model can accept n corpora for comparison by setting the input layer to n times of the word size, where the word size is the intersection words of all n corpora. Such scalability offers the effectiveness to processing and comparing multiple corpora at the same time. In fact, we can further optimize the performance of jargon discovery: consider the example mentioned in Section 3; we can modify the semantic comparison model to accept three corpora legit, dark <ref type="bibr" target="#b0">1</ref> and dark 2 where dark 1 and dark 2 are related to the similar criminal activity such as drug trading. Then, the model calculates Sim dark 1 ,legit and Sim dark 1 ,dark 2 and utilizes Sim dark 1 ,dark 2 to further validate the correctness of dark jargon.</p><p>Limitation. The main idea of Cantreader is based on the semantic inconsistency of an innocent-looking term in underground communication and in the legitimate corpus. The performance of Cantreader is corpus related. The adversary may play evasion tricks by adding more legitimate terms to their underground communication traces to affect the semantic comparison results. However, even in the presence of relevant content, the dark jargon could still be identified when we select the underground corpora carefully to limit the impact of corpora pollution: such as only selecting a limited number of communication traces from a specific user or including more semantic relevant corpora from different sources. Moreover, our semantic comparison model only conducts word-level semantic inconsistency check and does not support phrase-level jargon detection. A follow-up step is to optimize the model to identify jargon phrases. A possible solution is to find the possible phrases in underground corpus based on n-gram frequency and concatenate those words into a single term as the input of the semantic comparison model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Related Work</head><p>Recently, researchers leverage natural language processing for security and privacy research. Examples include analyzing web privacy policies <ref type="bibr" target="#b38">[49]</ref>, generating app privacy policies <ref type="bibr" target="#b35">[47]</ref>, analyzing descriptions to infer required app permissions <ref type="bibr" target="#b28">[40,</ref><ref type="bibr" target="#b27">39]</ref>, detecting compromised web sites <ref type="bibr" target="#b22">[34]</ref>, identifying sensitive user input from apps <ref type="bibr" target="#b21">[33,</ref><ref type="bibr" target="#b26">38]</ref>, and collecting threat intelligence <ref type="bibr" target="#b23">[35]</ref>. Our work proposes a novel NLP analysis model and identifies a novel application of NLP security, i.e., automatically identifying and understanding dark jargons in underground communication traces.</p><p>One recent work that is closest to our study introduces a technique to detect search engine keywords referring to illicit products or services <ref type="bibr" target="#b34">[46]</ref>. This work utilizes several search engine result features (such as the number of compromised websites in the search results) to determine whether a search keyword is related to the underground economy. This approach, however, is not suitable for dark jargon detection, because dark jargons are mainly short and innocent-looking terms, which have high search engine competition, i.e., search engine results of dark jargons are mainly highly-reputable websites. Hence, the search engine result features cannot capture dark jargons' illicit semantics but only their innocent semantics. Another relevant work <ref type="bibr" target="#b19">[31]</ref> identifies illicit product names in the underground forums. The authors presentes a data annotation methods and utilizes the labeled data to train a supervised learning-based classifier. This work relies on a large amount of human effort for the data annotation and is designed not for dark jargon identification but underground economy product. Also, neither of the previous two works is able to reveal the hidden meaning of the detected dark words automatically. Finally, <ref type="bibr" target="#b37">[48]</ref> proposes to use word embedding to analyze the semantics of jargons in Chinese underground market. But their endeavors stopped at a rather initial stage, finding semantically similar words of previous-detected jargons using cosine similarity of embedded vectors. Further manual inspection of those similar words is still required to understand the meaning of dark jargons. Moreover, the author fails to address the problem of how to identify dark jargon from the underground market.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Conclusion</head><p>In this paper, we present Cantreader, a novel technique for automatically identifying and understanding dark jargons from underground forums. Cantreader is designed to specialize the neural language model for semantic comparison. Our approach can efficiently capture the semantic inconsistency of a term appearing in different corpora, and then further understand such term by identifying its hypernym. Our evaluation of over one million underground communication traces further reveals the prevalence and characteristics of dark jargons, which highlights the significance of this first step toward effective and automatic semantic analysis of criminal communication traces.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>( 1 )</head><label>1</label><figDesc>My fav is slayers new rat , its open source , gonna have his rootkit implemented into it . (2) Strains i manage these days are BLUEBERRY and NYC Diesel . (3) I vouch for this user he crypted my athena code .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Example sentences with dark jargons, where dark</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Overview of the Cantreader infrastructure.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Results of experiment 1 in CDF.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>(</head><label></label><figDesc>Figure 6: Characteristic and implication of dark jargons.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Innocent-looking dark jargons.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>∏ t=1 ∏ −m≤ j≤m P(w t+ j |w t ) where m is the size of training</head><label></label><figDesc></figDesc><table>񮽙񮽙񮽙񮽙񮽙񮽙 
񮽙񮽙񮽙񮽙񮽙񮽙 

񮽙񮽙񮽙񮽙񮽙񮽙񮽙񮽙񮽙񮽙 
񮽙񮽙񮽙񮽙񮽙񮽙 

񮽙񮽙񮽙񮽙񮽙񮽙񮽙񮽙񮽙񮽙񮽙񮽙 
񮽙񮽙񮽙񮽙񮽙񮽙񮽙񮽙񮽙 

񮽙񮽙񮽙񮽙񮽙 
񮽙񮽙 
񮽙񮽙񮽙񮽙񮽙񮽙񮽙񮽙 

񮽙񮽙񮽙 

񮽙񮽙񮽙 

񮽙񮽙񮽙 

񮽙񮽙񮽙 
񮽙񮽙񮽙񮽙 

񮽙񮽙񮽙 

񮽙񮽙񮽙񮽙񮽙 
񮽙񮽙񮽙񮽙񮽙񮽙 

񮽙񮽙񮽙񮽙 

Figure 2: An example of neural language model. 

|V | 

context, in a sense that it produces the highest likelihood 
for observing the context words {w t+ j , −m ≤ j ≤ m}, 
given the target word w t and the training set, in terms of 
a softmax function e x 
∑ e x </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 1 : Training settings] T and M 2] T . As we can see here, for each word i, SCM outputs a pair of |H|-dimensional vectors: v i,1 learned from corpus 1 and v i,2 from corpus 2 .</head><label>1</label><figDesc></figDesc><table>parameter 
value 
parameter 
value 

language model 
skip-gram 
minimal word occurrence 
10 
hidden layer size 
200 
hierarchical softmax 
off 
window size 
10 
sub-sampling 
1e-4 
negative sampling 
25 
iterations 
30 

matrix. We split it into 2 |V | × |H| matrices, M = 
[M 1 , M 2 ], where M 1 = [v 1,1 , v 2,1 ,...,v |V |,1 = 
[v 1,2 , v 2,2 ,...,v |V |,2 The word's 
cross-corpora similarity can be measured by the similar-
ity of these two vectors. 

Model effectiveness analysis. Our new architecture 
fully preserves the property of the Word2Vec model, in 
terms of comparing the semantic similarity between two 
words. Consider any two words from the corpora, no 
matter whether they come from the same dataset or not, 
if they are similar semantically, they should have similar 
contexts, that is, similar co-occurred words in the cor-
pora. As a consequence, the NN should generate similar 
outputs for the two words. The output of the NN is de-
termined by the output of the hidden layer and their con-
nections with the hidden layer nodes, in terms of weights. 
Since the same set of output-layer weights is shared by 
all input word, similar NN outputs lead to similar word 
vectors. In the meantime, unlike Word2Vec, SCM uses 
two different corpora but learns every word's context 
from just one of them. So a word may have two contexts, 
one from each corpus. This property preserves a word's 
semantics in different scenarios (legitimate interactions 
vs. underground communication), which is critical for 
detecting dark jargons. 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Results of Experiment 2 

replacing word pair 
similarity 

(chemist → archie) 
0.65 
(ft → proton) 
0.56 
(universe → wealth) 
0.67 
(educational → makeup) 
0.66 
(nm → famicom) 
0.45 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="true"><head>Table 3 : Summary of the corpora</head><label>3</label><figDesc></figDesc><table>corpus 
# traces 
# unique 
words 

words 
per trace 
timespan 

Silk Road 
195,403 
1,183,506 
1,321 
6/2011 -11/2013 
Darkode 
7,418 
20,036 
419 
3/2008 -3/2013 
Hack Forum 
52,654 
30,020 
211 
5/2008 -3/2015 
Nulled 
120,518 
264,173 
484 
11/2012 -5/2016 
Reddit 
1,190,346 
3,497,646 
1,190 
-
Wiki 
249,336 
9,045,012 
557 
-

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 4 : Thresholds for different models</head><label>4</label><figDesc></figDesc><table>SCM 
th c1 
th c2 
th c3 
th c4 

Silk Road vs. Reddit 
0.094 
0.161 
0.184 
0.214 
Cybercrime Corpora vs. Reddit 
0.086 
0.142 
0.182 
0.209 
Reddit vs. Wiki 
-0.039 
0.0865 
0.127 
0.154 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 5 : Running time at different stages</head><label>5</label><figDesc></figDesc><table>stage 
running time 
traces per second 

the discoverer 
17.09 hr 
2.94 
the interpreter 
203.33 s 
889.68 
overall 
17.15 hr 
2.93 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table>Dark jargons in categories 

category 
# hyper-
nyms 

# 
jargons 
# traces 
examples of jargons 

drug 
304 
736 
830,270 
blueberry, popcorn, mango 
person 
1,517 
591 
460,261 
stormtrooper, zulu 
software 
300 
650 
512,379 
athena, rat, zeus 
porn 
1 
33 
2,926 
cheesepizza, hardcandy 
weapon 
672 
80 
12,055 
biscuit, nine, Smith 
others 
-
1,372 
479,789 
liberty, ats, omni 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="true"><head>Table 7 : Top 8 categories of innocent-meanings of dark jar- gons</head><label>7</label><figDesc></figDesc><table>Type 
# jargons 
examples of jargons 

acronym and abbreviation 
910 
cp, b1g, delt 
name 
132 
bob, kyle, freeman 
location 
109 
madison, southwest, florence 
animal 
102 
rat, hound, pony 
fictional character 
56 
zeus, loki, pluto 
plant 
39 
lavender, oak 
food 
31 
blueberry, popcorn, cheesecake 
vehicle 
30 
wagon, dandy 

(a) CDF of Google Trend's in-
terest score 

(b) CDF of search result rank-
ings 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" validated="false"><head>Table 8 : Top 3 hypernyms with most black words</head><label>8</label><figDesc></figDesc><table>Hypernym 
# black words 
percentage 

sedative 
69 
14.4 
narcotics 
63 
13.2 
stimulant 
46 
9.6 

</table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10">Acknowledge</head><p>We are grateful to Jiang Guo and Dmitry Evtyushkin for their valuable feedback and the anonymous reviewers for their insightful comments. This work is supported in part by the NSF 1408874, 1527141, 1618493 and ARO W911NF1610127.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title/>
		<ptr target="http://mattmahoney.net/dc/textdata.html" />
	</analytic>
	<monogr>
		<title level="j">About the Test Data</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Darkcomet</surname></persName>
		</author>
		<ptr target="https://en.wikipedia.org/wiki/DarkComet" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Darknet</forename><surname>Market Archives</surname></persName>
		</author>
		<ptr target="https://www.gwern.net/DNM-archives" />
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">DBPedia. wiki.dbpedia.org</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
				<ptr target="https://ndews.umd.edu/sites/ndews.umd.edu/files/dea-drug-slang-code-words-may2017.pdf" />
		<title level="m">DEA drug code words</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Integrated Path-based and Distributional Method for Hypernymy Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Github -Hypenet</surname></persName>
		</author>
		<ptr target="https://github.com/vered1986/HypeNET" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Google</forename><surname>Trend</surname></persName>
		</author>
		<ptr target="https://trends.google.com/trends/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Reddit Content Policy</surname></persName>
		</author>
		<ptr target="https://www.reddit.com/help/contentpolicy/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Silk Road(marketplace</title>
		<ptr target="https://en.wikipedia.org/wiki/SilkRoad(marketplace" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">The DEAs list of drug slang is hilarious and bizarre</title>
		<ptr target="https://news.vice.com/enus/article/8xmbpb/the-deas-list-of-drug-slang-is-hilarious-and-bizarre" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welcome To Wikidata</surname></persName>
		</author>
		<ptr target="https://www.wikidata.org/wiki/Wikidata" />
		<imprint>
			<publisher>Main Page</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Wikidata:SPARQL query service/Query Helper</title>
		<ptr target="https://www.wikidata.org/wiki/Wikidata:SPARQLqueryservice/QueryHelper" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wordnet</surname></persName>
		</author>
		<ptr target="https://wordnet.princeton.edu" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Cybercrime economy: An analysis of cybercriminal communication strategies</title>
		<ptr target="https://www.flashpoint-intel.com/blog/cybercrime/cybercriminal-communication-strategies/" />
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Underground black market: Thriving trade in stolen data, malware, and attack services</title>
		<ptr target="https://www.symantec.com/connect/blogs/underground-black-market-thriving-trade-stolen-data-malware-and-attack-services" />
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cantreader</surname></persName>
		</author>
		<ptr target="https://sites.google.com/view/cantreader" />
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A neural probabilistic language model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ducharme</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Jauvin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1137" to="1155" />
			<date type="published" when="2003-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Statistical inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Casella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">L</forename><surname>Berger</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="volume">2</biblScope>
			<pubPlace>Duxbury Pacific Grove, CA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Traveling the silk road: A measurement analysis of a large anonymous online marketplace</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Christin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd international conference on World Wide Web</title>
		<meeting>the 22nd international conference on World Wide Web</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="213" to="224" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Identifying products in online cybercrime marketplaces: A dataset for fine-grained domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Durrett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">K</forename><surname>Kummerfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Berg-Kirkpatrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Portnoff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Afroz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mccoy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Levchenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Paxson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Learning semantic hierarchies via word embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1199" to="1209" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Supor: Precise and scalable sensitive user input detection for android apps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">24th USENIX Security Symposium (USENIX Security 15)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="977" to="992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Seeking nonsense, looking for trouble: Efficient promotional-infection detection through semantic inconsistency search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of S&amp;P&apos;16</title>
		<meeting>S&amp;P&apos;16</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Acing the ioc game: Toward automatic discovery and analysis of open-source cyber threat intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Beyah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CCS&apos;16</title>
		<meeting>CCS&apos;16</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1301.3781</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Uipicker: Userinput privacy identification in mobile applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Nan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">24th USENIX Security Symposium (USENIX Security 15)</title>
		<meeting><address><addrLine>Washington, D.C.</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-08" />
			<biblScope unit="page" from="993" to="1008" />
		</imprint>
	</monogr>
	<note>USENIX Association</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Whyper: Towards automating risk assessment of mobile applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pandita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Enck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Presented as part of the 22nd USENIX Security Symposium (USENIX Security 13)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="527" to="542" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Autocog: Measuring the description-to-permission fidelity in android applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Rastogi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 ACM SIGSAC Conference on Computer and Communications Security</title>
		<meeting>the 2014 ACM SIGSAC Conference on Computer and Communications Security</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1354" to="1365" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Distributional lexical entailment by topic coherence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the 14th Conference of the European Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="511" to="519" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Improving hypernymy detection with an integrated path-based and distributional method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Shwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Dagan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.06076</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Learning syntactic patterns for automatic hypernym discovery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Snow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="1297" to="1304" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Semantic taxonomy induction from heterogenous evidence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Snow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics</title>
		<meeting>the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="801" to="808" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Yago: A large ontology from wikipedia and wordnet</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">M</forename><surname>Suchanek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kasneci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Web Semantics: Science, Services and Agents on the World Wide Web</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="203" to="217" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">How to learn klingon without a dictionary: Detection and measurement of black keywords used by the underground economy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Security and Privacy (SP), 2017 IEEE Symposium on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="751" to="769" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Autoppg: Towards automatic generation of privacy policy for android applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th</title>
		<meeting>the 5th</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
			</analytic>
	<monogr>
		<title level="m">Smartphones and Mobile Devices</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="39" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Chinese underground market jargon analysis based on unsupervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intelligence and Security Informatics (ISI), 2016 IEEE Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="97" to="102" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Privee: An architecture for automatically analyzing web privacy policies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zimmeck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Bellovin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">23rd USENIX Security Symposium (USENIX Security 14)</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1" to="16" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
