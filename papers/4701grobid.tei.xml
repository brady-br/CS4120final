<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2020-09-29T04:29+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">How Sharp is SHARP ?</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dixit</forename><surname>Kumar</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chavhan</forename><forename type="middle">Sujeet</forename><surname>Yashavant</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Biswabandan</forename><surname>Panda</surname></persName>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vishal</forename><surname>Gupta</surname></persName>
							<email>vishalgupta7972@gmail.com</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Indian Institute of Technology Kanpur</orgName>
								<orgName type="institution" key="instit2">Indian Institute of Technology</orgName>
								<address>
									<settlement>Kanpur</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Indian Institute of Technology</orgName>
								<address>
									<settlement>Kanpur</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">Manipal University Jaipur and Indian Institute of Technology</orgName>
								<address>
									<settlement>Kanpur</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">How Sharp is SHARP ?</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Cross-core last-level cache based side-channel attacks are becoming practical, affecting all forms of computing devices like mobiles, desktops, servers, and cloud based systems. Mitigating last-level cache based side channel attacks has become an active area of research and many proposals target to mitigate cross-core based conflict attacks. Secure Cache Hierarchy Aware Replacement Policy (SHARP) is one of the recent proposals that mitigate the conflict attacks by changing the underlying last-level cache replacement policy. Though SHARP is an elegant proposal; there are many subtle points, which were not part of the original SHARP proposal that appeared in the ISCA &apos;17. Through this paper, we discuss and debate the subtle issues that are left unanswered in the original SHARP paper.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Cache conflict timing attacks at the last-level cache (LLC) are becoming ubiquitous, and one of the fundamental reasons behind many attacks at the LLC is its inclusiveness property. An inclusive LLC is a super-set (in terms of cache contents) of the per-core private caches. This creates a security loophole when exploited carefully as an eviction of a cache block from the LLC, back-invalidates cache blocks in private caches. A backinvalidation is a normal invalidation request that is triggered by the LLC controller (on every LLC eviction) to invalidate the cache blocks corresponding to the evicted address that are present at the private caches. Moreover, future accesses by the victim incur cache misses at its private caches, forcing the victim to access the LLC. There are flush based attacks such as Flush+Reload <ref type="bibr" target="#b18">[20]</ref> and Flush+Flush <ref type="bibr" target="#b3">[5]</ref>, where the attacker does not exploit the inclusiveness nature of the LLC, rather uses a clflush instruction to flush a cache block address from all the cache levels and later reloads the same block address. While reloading, if it gets a hit, then the attacker concludes that the victim has accessed the cache block.</p><p>Many proposals have been proposed to mitigate LLC timing attacks by changing the cache layout, cache replacement policies, cache addressing, and fuzzing the timers <ref type="bibr" target="#b9">[11,</ref><ref type="bibr" target="#b10">12,</ref><ref type="bibr" target="#b12">14,</ref><ref type="bibr" target="#b15">17,</ref><ref type="bibr" target="#b16">18,</ref><ref type="bibr" target="#b19">21]</ref>. One of the recent proposals that claim to mitigate the LLC timing attacks is an LLC replacement policy named secure hierarchy-aware cache replacement policy (SHARP) that appeared in one of the flagship Computer Architecture Conferences named ISCA '17 <ref type="bibr" target="#b17">[19]</ref>. In this work, we ask a few subtle and interesting questions and try to answer them one by one.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">A Primer on SHARP</head><p>SHARP is an LLC replacement policy that prevents cross-core back-invalidations (inclusion victims) at the private caches, nullifying the cross-core attacks that exploit the inclusiveness property. The premise used by SHARP is that cross-core back-invalidations make the attacker successful at the LLC. SHARP can be applied to any baseline cache replacement policy like LRU or a more recent re-reference interval prediction (RRIP) <ref type="bibr" target="#b7">[9]</ref> based policies. SHARP affects the underlying replacement policy as follows: Whenever an LLC miss happens, SHARP kicks in. If that miss causes a cross-core eviction (meaning a core i evicting a cache block that was brought by core j) of a cache block then SHARP kicks in and it does not allow the cross-core eviction if the block that selected for eviction is present in other cores' private caches. SHARP searches for a cache block (as per the priority order of the underlying cache replacement policy). The eviction process happens in three stages, as follows: (i) a block that is not present in any cores' private caches, (ii) if stage (i) fails then it searches for block(s) that is present only in the attacker's private cache (it allows eviction of block(s) that cause intra-core back-invalidation), and (iii) in the worst case, if SHARP cannot find a suitable cache block then it goes for a random replacement policy and replaces a random block and increments an alarm counter (which is a per core counter) for the core that is causing the cross-core back-invalidation, anticipating an attack. <ref type="figure" target="#fig_0">Figure 1</ref> shows the three stages of interest from SHARP's point of view. Whenever a random block is replaced by SHARP it increments an alarm counter and the moment the counter crosses a predefined threshold, the core generates an interrupt to the operating system (OS). However, SHARP does not explain what exactly the OS does. Some possible OS responses include: (i) de-schedule the application that crosses the alarm counter threshold, (ii) migrate the application to another socket of a multi-core system if available, or (iii) it may have to kill the application.</p><p>For clflush based attacks, SHARP argues that "there is no need to use clflush in user mode for pages that are read-only or executable". The argument holds for most of flush based attacks that use shared library code that are either read-only or executable. Next, we ask a series of questions pertinent to SHARP.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Questions of Interest</head><p>SHARP raises some interesting questions that follows:</p><p>• Does SHARP mitigate all kinds of LLC eviction attacks?</p><p>If the blocks of interest are writable then the attacker may first invalidate the victim blocks in the victim L2 through cache coherence, and then evict them from the LLC. In such cases, the LLC eviction will not cause backinvalidation hits at the private cache of the victim. So, SHARP does not seem to cover all possible cross-core conflict based LLC side channels.</p><p>• Does SHARP mitigate few cross-core attacks and facilitate a few more attacks? For example, does SHARP help to mount a new Denial of Service (DOS) attack? To fool the SHARP if an application occupies the entire L1, L2, and LLC with the overlapping data with the same set index. Now, any eviction made by another application to the first application's block will be prevented if it hits at the first application's L2. So this is some form of DOS attack where a fixed number of blocks of a cache set are locked, decreasing the effective LLC capacity usage? (Section 4)</p><p>• Does the threshold used by SHARP based on alarm counter can affect legitimate applications? Can a SHARP-aware attacker play with SHARP to mount new form of tricky attacks that are only possible because of SHARP? (Sections 5 and 6)</p><p>• What exactly the OS does when it receives an interrupt (whenever the alarm counter crosses the threshold)? (Section 6)</p><p>• How secure is SHARP in terms of information leakage? (Section 7)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head><p>This section provides background on different cross-core conflict based side-channel attacks (miss type and hit type) at the LLC. In miss type attacks, the attacker is interested in observing longer cache access time, because of cache misses (miss access can be either from the victim or the attacker). In contrast, in hit-based attacks, the attacker is interested in shorter access time (hits). All the attacks measure LLC access time. However, some attacks do it precisely per memory access (access based attacks), and some accumulate the timing information for the entire security-critical accesses (timing based attacks). Primarily, there are three different strategies such as (i) Evict+Reload <ref type="bibr" target="#b4">[6]</ref> (a variant of Flush+Reload attack where the Flush operation is replaced by the Evict operation), (ii) Evict+Time <ref type="bibr" target="#b13">[15]</ref>, and (iii) Prime+Probe <ref type="bibr" target="#b14">[16]</ref>.</p><p>In flush based attacks such as Flush+Reload <ref type="bibr" target="#b18">[20]</ref>, the attacker uses clflush instruction to flush a cache block address from all the cache levels and later reloads the same block address. While reloading, if it gets a hit, then the attacker concludes that the victim has accessed the cache block.</p><p>Evict+Time <ref type="bibr" target="#b13">[15]</ref>: In this attack, the spy observes the execution time of the victim over a large number of intervals. First, the spy evicts cache blocks from a few set(s) at the LLC. Later, when the victim accesses the evicted block(s), it results in a longer access time and the spy observes the same.</p><p>Evict+Reload <ref type="bibr" target="#b4">[6]</ref>: In Evict+Reload attack, the spy evicts a cache block from the LLC. After an interval (predetermined fixed value), the spy reloads the same address and if it gets a shorter access time (an LLC hit), then it concludes that the victim has accessed the same cache block.</p><p>Prime+Probe <ref type="bibr" target="#b14">[16]</ref>: In this attack, the attacker loads its cache blocks by evicting the blocks of the victim (the prime part). Then the victim executes its secure operation and in the process, gets LLC misses, evicts the blocks brought by the attacker. Next, the attacker probes its execution time by reloading its blocks, to see whether it gets longer access time because the victim has evicted the block (an LLC miss).</p><p>As per SHARP, all these attacks are successful because of cross-core back-invalidation hits. Out of all these attacks, Evict+Reload attack demands the notion of sharing of OS pages between the victim and the spy. The attack is more precise (operates at specific block addresses).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">SHARP and a Series of Attacks</head><p>In this section, we showcase some of the attacks that are possible with SHARP using huge OS pages. SHARP claims that it mitigates all kinds of cross-core conflict based attacks. However, we find that there are still a good number of attacks that are successful in the presence of SHARP. The premise used by SHARP to mitigate the cross-core conflict based attacks is that it does not create cross-core inclusion victims and prevents cache replacement that can lead to creation of inclusion victim. However, what if the attacker makes sure that it attacks a cache set where the blocks that are present in that set at the LLC are not present in its L1 or L2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Simulation Methodology</head><p>We use the ChampSim <ref type="bibr" target="#b0">[1]</ref> simulator to simulate SHARP replacement policy on a 16-core system. As SHARP is not yet implemented on real machines, we simulate it using an architectural simulator. We use dynamic RRIP (DRRIP) <ref type="bibr" target="#b7">[9]</ref> as the baseline replacement policy and apply SHARP on it. ChampSim is a trace driven simulator used for Cache Replacement Championship held with ISCA '17. <ref type="table" target="#tab_0">Table 1</ref> shows the parameters used in our simulated system. Note that the parameters correlate to Intel machines that used to have inclusive LLCs. Next, we discuss a series of attacks that are still possible with SHARP and with huge OS page. Note that we showcase </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">SHARP with Huge OS Page</head><p>The original SHARP proposal shows its effectiveness with a small OS page size of 4KB. However, if modern systems employ huge pages (in MBs and GBs) to improve system performance. <ref type="figure">Figure 2</ref> shows the effect of huge pages on LLC indexing as most of the lsbs do not get changed from the virtual to physical address translation. For example, for a 4MB OS page, the lower 22 bits remain the same. As mentioned in prior works like <ref type="bibr" target="#b11">[13]</ref>, it is easier for an attacker to mount the cross-core attacks as the attacker knows the LLC set index from its virtual address itself.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Prime+Reprime+Probe Attack [8]</head><p>For this attack, we simulate a 16-core system using ChampSim, sharing an LLC of 32MB having 16 ways, with huge OS page size of 4MB. The attacker uses cooperative threads using multi-threading so that 15 attacker threads mapped to 15 physical cores, can access a particular cache set, which is also the cache set of interest. In a nutshell, the attacker does the following: (i) the attacker primes the LLC by evicting victim's data. However, SHARP does not allow evicting victim's blocks. To fool the SHARP, attacker threads make sure that SHARP does not evict their data. To accomplish this the attacker makes sure that the data present in the LLC is also present in their respective private caches. At this point, if one of the core tries to evict a block, SHARP finds that all the blocks are failing stage-1 and stage-2 and it evicts a block randomly ( 1 of <ref type="figure" target="#fig_2">Figure 3</ref>). (ii) Next all the attacker threads re-prime ( 2 ) so that their own data get evicted from their respective L1 and L2s as mentioned in <ref type="bibr" target="#b6">[8]</ref>.</p><p>(iii) Now, the victim accesses LLC and gets LLC misses. Victim evicts attacker's blocks ( 3 ) even with SHARP because the attackers have already ensured that the blocks present at the LLC are not present in their private caches. So at this stage, the security guarantee of the SHARP is compromised.</p><p>(iv) Attacker probes ( 4 ) the LLC addresses (using the 15 threads) and depending on the #accesses made by the victim in step (iii), the attacker finds out whether the victim has accessed the cache set (longer LLC access time) or not (shorter access time).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">SHARP induced New Attacks</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Prime+Reprime+Reprime Attack</head><p>With SHARP, a cross-core attacker cannot prime the entire LLC cache set, which already indicates there is a valid copy in the victim's private L2 cache, which is some form of information leakage already. Assuming the attacker knows SHARP is used at the LLC, the attacker can perform a Prime+Reprime+Reprime attack to know the behavior of a victim's private caches: Prime: At time t1, the attacker primes the LLC by filling a cache set (with w lines) with its own data. In our case, with SHARP, w can be 16 or less than 16, for a 16-way LLC.</p><p>Reprime: The attacker reads data from the w cache blocks and measures how many of them are loaded from LLC (e.g., k out of w).</p><p>Reprime: After a fixed interval, say at time t2, the attacker reads data from the w memory blocks again and measures how many of them are loaded from LLC (e.g., k').</p><p>The attacker now learns the following information: at time t1, w-k memory blocks that map to this cache set of LLC are used by the victim in the private cache; at time t2, w-k memory blocks that map to this cache set of LLC are used by the victim in the private cache. The difference, k'-k, indicates the changes of victim's memory accesses during this period. This provides the cache occupancy information about the victim's private cache. As per SHARP, "Hence, it is theoretically possible for a spy to exploit the capacity and conflict misses in the private cache of the victim to bypass SHARP's protection and mount a cache-based side channel attack. In practice, mounting such an attack is very difficult.."</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Denial of Service Attack</head><p>With SHARP, if the attacker deliberately occupies its entire private cache space (L1 and L2) with non-overlapping data and it also occupies this part in the LLC then any prevention of back-invalidation hits from LLC would lead to blocking of LLC space. This could be used to mount a denial of service attacks on specific critical cache sets. It also reduces the LLC capacity. <ref type="figure" target="#fig_3">Figure 4</ref> explains the attack where a 4-threaded attacker (for better illustration, we use four threads only) can mount a denial of service on a 4-way LLC. The same can be done on a 16-way LLC using 16 threads. The attacker can find the critical sets of interest based on the attack that we discuss in the previous subsection (Prime+Reprime+Probe attack). Once the attacker(s) know the critical sets then a multi-threaded attacker can occupy the entire cache set and the attackers can make sure that the contents of 16 ways at the LLC are present in 16 private caches (in one of the ways of L1s/L2s) ( 1 of <ref type="figure" target="#fig_3">Figure 4</ref>). Then when the victim comes, it finds the cache set full and SHARP tries its best to prevent cross-core eviction. However, as all the blocks are present in private caches too, SHARP does a random eviction evicting one of the attacker blocks ( 2 ). After this, all future accesses of the victim leads to eviction of victim's block only as SHARP prefers evictions of cache blocks that cause intra-  core back-invalidation hits over inter-core back-invalidation hits. In this way, the attackers always occupy the 15 ways of a 16-way LLC, blocking the cache capacity of critical sets of the victim and the victim keeps on evicting its own blocks ( 3 , 4 , and 5 ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">The Threshold Dilemma</head><p>As per SHARP, "When the alarm event counter of any core reaches a threshold, a processor interrupt is triggered. The operating system is thus notified that there is suspicious activity currently in the system. Any relatively low value of the threshold suffices, as a real spy will produce many alarms to be able to obtain any substantial information." SHARP argues an alarm threshold of 2000 per one billion cycles is needed to trigger the OS event anticipating that the application is an attacker and SHARP is unable to prevent it completely. This means if an application crosses the value of 2000 in terms of inter-core back-invalidation then this application must be an attacker application. So, once SHARP detects the attacker application, the OS kicks in. However, the role of an OS is not clear. SHARP does not explain what exactly is the role of an OS. We speculate the OS can delay that application by de-scheduling, migrating the application if the system is a multi-socket system, or in the worst case, the OS may kill the application. SHARP showcases threshold numbers by running different LLC thrashing and LLC fitting applications. An LLC thrashing application is an application with high memory footprint and has higher misses per kilo instruction (MPKI) whereas a LLC fitting application is an application with LLC MPKI closer to zero meaning the memory footprint fits into the LLC. We reproduce the experiments of SHARP but for a 16-core system sharing 16-way LLC and with huge page ON. We find that the inter-core back-hit count crosses the threshold mentioned by SHARP. Multi-core combinations: We consider four combinations of 16-core experiments: (i) 16-0 (16 thrashing applications running on a 16-core system), (ii) 12-4 (12 thrashing applications running along with four fitting applications on a 16-core system), (iii) 8-8 (eight thrashing applications running along with eight fitting applications), and finally (iv) 4-12 (four thrashing applications running along with 12 fitting applications). In total, we use 10 thrashing applications from SPEC CPU 2017 benchmark suite (traces collected from <ref type="bibr" target="#b2">[4]</ref>) as mentioned in <ref type="table" target="#tab_1">Table 2</ref>. These benchmarks are picked from their region of interests (marked with an instruction count followed by billions of instructions). For fitting application, we use 641.leela-1052B. In the baseline, we use the dynamic RRIP (DRRIP) <ref type="bibr" target="#b7">[9]</ref> policy. <ref type="figure">Figure 5</ref> shows the inter-core backhit rate for DRRIP replacement policy without SHARP for four different combinations of thrashing and fitting benchmarks, with ten specific thrashing applications as mentioned in <ref type="table" target="#tab_1">Table 2</ref>. For a better understanding, the plot with 16-0 means 16 thrashing applications running on a 16-core system, where the thrashing application is denoted by the benchmark id, as mentioned in <ref type="table" target="#tab_1">Table 2</ref>. So, the sixth point in the X-axis says 16 copies of 620.omnetpp-874B are running concurrently on a 16-core simulated system. It is clear from <ref type="figure">Figure 6</ref> that SHARP is successful in reducing the inter-core back hit rate.</p><p>As expected SHARP reduces the inter-core back-hit rate, as it prioritizes intra-core eviction over cross-core eviction during the eviction of a cache block. In combination, 12-4 (12 thrashing applications running with four fitting applications), for thrashing applications, the inter-core back-hit rate reduces from a maximum of 12% to 0.5%. However, 0.5% of inter-core back-hit rate for thrashing applications is still good enough for exceeding the alarm counter threshold. To X-Y : LLC_Thrashing-LLC_Fitting Combination thrashing fitting <ref type="figure">Figure 5</ref>: Inter-core back-hit rate without SHARP for four different 16-core combinations involving LLC thrashing and LLC fitting applications. IB rate: Inter-core back-hit rate.</p><p>understand the situation better, <ref type="figure">Figure 7</ref> shows the average MPKI numbers averaged across thrashing applications at the L2 and LLC. As we can see, thrashing applications have high MPKI, so even a small inter-core back-hit rate can magnify itself to large alarm counter values. Effect on the alarm counter: <ref type="figure" target="#fig_4">Figure 8</ref> shows the range of alarm counter values that we see for four 16-core combinations. As, we can see, with 16-0 combination (16 different copies of thrashing applications running concurrently), 607.cactubssn-2421B has a counter value of 264,479, which is 132X times more the threshold set by SHARP. For other combinations, counter values in the range of above 40,000 is observed (for combinations 4-12 and 12-4). Note that these counter values are per one billion cycles and SHARP resets these counters after every one billion cycles. It is obvious that with 16-0 combination, the counter value becomes so large as all 16 applications are mapped to same cache sets thanks to the 4MB huge page. This causes significant cross-core evictions by SHARP raising the alarm counter 132X times of the SHARP threshold. For combinations like 12-4 and 4-12, this number reduces, but it is still 20X more than the SHARP threshold. In 4-12 and 12-4 combinations,  <ref type="figure">Figure 6</ref>: Inter-core back-hit rate with SHARP for four different 16-core combinations involving LLC thrashing and LLC fitting applications. IB rate: Inter-core back-hit rate.</p><p>thrashing applications cause cross-core evictions of fitting applications. This shows that SHARP can treat legitimate applications as attackers. SHARP can increase the threshold and make it core count specific. However, SHARP claims the following and we quote: "Empirically, we find that, in a successful side-channel attack, the time between consecutive evictions is about 2,500-10,000 cycles. So, the attackers will need to cause an alarm every 10,000 cycles. In practice, since the operation evicts a random line in the set, for a 16-way associative cache, they will need 16 times more alarms to evict the victim line. Let us assume that we have 16 attacker threads and the worst case that each attacker creates an equal number of alarms. We then have that each attacker thread will increment its counter at least 100,000 times in 1 billion cycles". Our experiment shows that 16-0 combination of legitimate applications show alarm counter value of 264,479. An immediate solution is to increase the threshold value to a high number, say 300,000. However, we find that 300,000 crosscore evictions is more than enough for any Evict+Reload and Prime+Probe attacker attacking applications mentioned in the SHARP paper like GnuPG <ref type="bibr">[2]</ref> and Poppler <ref type="bibr" target="#b1">[3]</ref>. So, a better  <ref type="table" target="#tab_1">Table 2</ref>. CPBC: counter per billion cycles.</p><p>in the high priority mode then these applications will finish quickly as the shared resource contention will be less. However, this policy may not work if the number of applications that cross the threshold does not follow a uniform distribution.</p><p>• To migrate: This is one of the simple but costly options where the OS can choose to migrate the application from one socket to another socket provided the multi-core system consists of multiple sockets <ref type="figure" target="#fig_5">(Figure 9</ref>). However, as we see in the behavior of 16-0 combination, SHARP causes the system to enter a situation where an OS will have a ping-pong effect, migrating multiple applications from one socket to another socket after one billion cycles or after a smaller interval than one billion cycles (if it reaches the threshold before one billion cycles). If we run 32 copies of 649.fotonik on a 32-core system having two sockets, each having 16 cores them each of them will have performance overhead as the migration cost is highly non-deterministic and it can go up to millions of cycles.</p><p>. . .  <ref type="table">Table 3</ref>: Conditional probabilities of events of interest based on PIFG. Events p1 Memory block getting mapped into a cache set p2 Cache block selected for replacement given the cache set p3 Cache block selected by the replacement policy is evicted p4 Evicted block when accessed again gets an LLC miss and the very next access gets a hit. p5 LLC hit/miss getting mapped to the shorter/longer access time.</p><p>We try to quantify the effect of de-scheduling and migration on the execution time slowdown. <ref type="figure" target="#fig_0">Figure  10</ref> shows the slowdown in the execution time. Out of 16 applications that are mapped to 16 cores, more than 50% of the applications experience slowdown. For delay of less than 1M cycles, the slowdown is negligible. However, beyond that, there are slowdowns of 2.5X and 30X for delay of 16M and 256M cycles, respectively. Latency numbers of 16M to 256M are some of the worst case latency numbers that we observe on a real 16-core machine.</p><p>• To kill: The last option any OS designer will prefer is to kill an application. As we discuss in the previous Section, if killing is an option then all legitimate applications can get killed. We do not believe, this is a viable solution. <ref type="figure" target="#fig_0">Figure 11</ref> shows the fraction of applications that can get descheduled, migrated, and killed if the OS chooses to de-schedule, migrate, or kill the applications that have cross the threshold. For combinations like 16-0 and 8-8, almost 100% applications get affected. So we do not show the same in <ref type="figure" target="#fig_0">Figure 11</ref>.</p><p>Not specifying the OS response to alarm counter threshold is a limitation of the SHARP proposal. In the discussion above we show that several intuitive approaches have detrimental effect on the system performance. We are not aware of potential approaches for handling alarm counter threshold that do not affect system performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">SHARP Threshold Aware Attack</head><p>Apart from the threshold dilemma that we discussed in the previous section, we believe, a new kind of attack can be proposed, which we describe next. SHARP maintains alarm counter per core and not per process. Second, the alarm counter gets reset in one of these two cases: when alarm counter reaches the threshold value of 2000 or after every one billion cycles. An attacker can first experiment to find out the alarm counter value. It can be easily done depending on the OS role and attacker's own execution time. To do this, the attacker can perform a lot of cross-core eviction by thrashing the LLC. Assuming, the attacker knows the threshold value, the attacker can run for a while doing cross-core eviction until it reaches counter value nearer to the threshold. At this point, the attacker forces itself to sleep, fooling the OS. Then the OS schedules another process and the moment that process starts doing cross-core eviction, the processor core generates an interrupt and the recently scheduled process gets de-scheduled, migrated, or killed as per the OS functionality defined based on SHARP. Note that, the attacker has to make sure it reaches nearer to threshold within one billion cycle window else the counter will be reset. <ref type="figure" target="#fig_0">Figure 12</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="0">1 2 3 4 5 6 7 8 9 111 12 13 14 15</head><p>Core-id</p><p>1.000x</p><p>1.002x</p><p>1.004x</p><p>1.006x</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>64K Cycles IPC Slowdown</head><p>Figure 10: Slowdown with OS de-schedule and migration for 16-0 combination running on core id 0 to 15.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">SHARP and Information Leakage</head><p>To compare different micro-architecture techniques in terms of information leakage, metrics such as true positive rate (TPR), which is the ratio of true critical accesses observed by the attacker and the number of critical accesses of the victim and Cache side-channel vulnerability (CSV) <ref type="bibr" target="#b8">[10]</ref> (Pearson's correlation coefficient between the victim and attacker traces at the LLC) are proposed. Recently, He and Lee proposed a nice and more generic model called Probabilistic information flow graph (PIFG) <ref type="bibr" target="#b5">[7]</ref> to quantify the probability of attack success (PAS). A PAS value closer to 0 is better and secure. PAS <ref type="bibr" target="#b5">[7]</ref>: <ref type="table">Table 3</ref> shows conditional probabilities of interest through which the information flows from the victim to the attacker, for all various cross-core eviction based attacks at the LLC. For a detailed overview on PIFG, please refer <ref type="bibr" target="#b5">[7]</ref>. p1: 1.00, conventional mapping in which a DRAM address mapped to a particular cache set with probability 1.00 and it is known to the attacker. If it is not known to the attacker, then it will be less than 1.00. p2: 1.00, for a successful attack, the attacker should be able to replace the cache block(s) of interest before the victim reloads. For a w-way cache, the attacker should access a particular set at-least w times for LRU based policy and ¯ w ( ¯ w can be less than equal to w or greater than w) times for RRIP <ref type="bibr" target="#b7">[9]</ref>  eviction policies. p3: 1.00, this probability will change if we prevent replacement of the block of interest. p4: 1.00, the attacker observes an LLC miss/hit in miss/hit type attacks. p5: 1.00, a direct correlation between miss/hit with the LLC access time. So the PAS of the baseline system is 1 (p1 × p2 × p3 × p4 × p5). Next, we show the PAS for crosscore miss-type attacks, which is easy to understand followed by the hit-type attacks. If SHARP is secure then the expected PAS with SHARP should be zero indicating no information leakage. However, we believe that it is not the case. With SHARP, an additional event of interest comes into the picture, which is the probability of an evicted block creating an cross-core backinvalidation hit. Theoretically, for an LRU replacement policy, the worst case probability will be (n−1)×L2size</p><p>LLCsize . However, this number may come out small. If we change the replacement policy to say some variant of RRIP (like DRRIP) then the probability shoots up significantly.</p><p>We add an additional probability (p) that provides the probability of an LLC eviction resulting in cross-core inclusion victim. So, the baseline PAS will be extended to PAS×p. SHARP will be secure if p becomes zero. However, there are applications that can be created to exploit the cache hierarchy and the LLC replacement policy to have p value closer to 0.25. So, with non-zero inter-core back-hit rate, which makes the security guarantee of SHARP probabilistic in nature. This is a serious concern, because for applications like GnuPG, if an attacker can leak a few bits then rest can be extracted through a brute-force approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion</head><p>Through this paper, we discussed and debated a few subtle issues that were unanswered in the original SHARP paper. We discussed new possible attacks, issues with the alarm threshold, and the role of operating system. We believe, these issues are important and the community should look at these issues and try to find out better solutions. Fixing these subtle issues will make SHARP sharper in mitigating cross-core last-level cache based side-channel attacks.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Different stages of SHARP in a nutshell. LLC-only block is the block that is present only in the LLC and not present in any core's private caches. Intra-core is the block that is present only in the evictor's private cache and the LLC.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Figure 2: Effect of the huge page on LLC indexing. VA: virtual address and PA: Physical address.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Prime+Reprime+Probe attack with SHARP. in ( 4 , attacker gets misses for blocks A and B if victim accesses ( 3a ) and hits if the victim has not accessed ( 3b )) .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Denial of Service attack with SHARP. A particular way is used by the victim and rest are denied by the attacker.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Average and maximum values of alarm counter (in thousands) with SHARP. The X-axis shows the thrashing benchmarks used as per Table 2. CPBC: counter per billion cycles.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Thread migration with multiple sockets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 11 :</head><label>11</label><figDesc>Figure 11: Fraction of applications (out of 16) that can get de-scheduled, migrated, or killed with SHARP.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 12 :</head><label>12</label><figDesc>Figure 12: SHARP threshold ware attack.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Parameters of the simulated system. 
Processor 
16-cores, out of order 
L1 D/I, L2 
8 KB (8 way), 256KB (8 way, inclu-
sive) 
Shared L3 
2MB× cores, #slices=#cores, 16 way, 
inclusive 
MSHRs 
8, 16, 32×16 MSHRs 
at L1, L2, L3 
Cache line size 
64B in L1, L2 and L3 
Replacement pol-
icy 

DRRIP and SHARP with DRRIP 

DRAM controller 4 controllers for 16-cores, Open Row, 
48 read/write queues, FR-FCFS, 
drain-when-full 
DRAM bus 
split-transaction, 800 MHz, BL=8 
DRAM 
DDR3 1600 MHz (11-11-11) 
Max bandwidth/channel -12.8 
GB/sec 

the same on non-crypto applications like SPEC CPU 2017 
benchmarks. Also, because of space limitations, we do not 
explain all the details related to all the attacks. Instead, we 
provide a top level view on each of these attacks. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Thrashing benchmarks used in 16 core combinations. 
Mix 
No. 

Thrashing Benchmarks 

1 
605.mcf-484B 
2 
605.mcf-665B 
3 
605.mcf-994B 
4 
607.cactubssn-2421B 
5 
620.omnetpp-141B 
6 
620.omnetpp-874B 
7 
621.wrf-6673B 
8 
623.xalancbmk-10B 
9 
649.fotonik-10881B 
10 
654.roms-523B 

</table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">ACKNOWLEDGEMENT</head><p>We would like to thank all the anonymous reviewers for their helpful comments and suggestions. We would also like to thank members of CARS research group (especially Upasana Singh) for their feedback on the initial draft. This work is supported by the SRC grant SRC-2853.001.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Role of an Operating System</head><p>SHARP does not explicitly mention the role of an OS. OS gets an interrupt when a processor core crosses the SHARP threshold for the alarm counter. We debate and discuss about three possibilities that an OS can explore:</p><p>• To de-schedule: The OS can de-schedule the application running on a particular core that has crossed the threshold. However, as we have seen, there are combinations where all 16 applications cross the threshold. So the OS has to de-schedule all 16 applications within the interval of one billion cycles. Note that thrashing applications like mcf and fotonik take trillions of cycles to complete their execution. So, we believe, it will have a serious impact on the execution time of individual applications that are part of the 16-0 combination.</p><p>The most practical solution that we can think of is the OS can provide a time quantum to each of the applications that have crossed the threshold. </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Champsim</surname></persName>
		</author>
		<ptr target="https://www.gnupg.org/software/index.html" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Poppler</surname></persName>
		</author>
		<ptr target="https://poppler.freedesktop.org/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<ptr target="http://hpca23.cse.tamu.edu/champsim-traces/speccpu/" />
		<title level="m">Spec 2017 traces</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Flush+flush: A fast and stealthy cache attack</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Gruss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clémentine</forename><surname>Maurice</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Wagner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Mangard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Conference on Detection of Intrusions and Malware, and Vulnerability Assessment</title>
		<meeting>the 13th International Conference on Detection of Intrusions and Malware, and Vulnerability Assessment<address><addrLine>New York, NY, USA; New York, Inc</addrLine></address></meeting>
		<imprint>
			<publisher>SpringerVerlag</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">9721</biblScope>
			<biblScope unit="page" from="279" to="299" />
		</imprint>
	</monogr>
	<note>DIMVA 2016</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Cache template attacks: Automating attacks on inclusive last-level caches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Gruss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raphael</forename><surname>Spreitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Mangard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">24th USENIX Security Symposium, USENIX Security 15</title>
		<meeting><address><addrLine>Washington, D.C., USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="897" to="912" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">How secure is your cache against side-channel attacks?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zecheng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruby</forename><forename type="middle">B</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 50th Annual IEEE/ACM International Symposium on Microarchitecture, MICRO-50 &apos;17</title>
		<meeting>the 50th Annual IEEE/ACM International Symposium on Microarchitecture, MICRO-50 &apos;17<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="341" to="353" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">S$a: A shared cache attack that works across cores and defies vm sandboxing -and its application to aes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Irazoqui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Eisenbarth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sunar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE Symposium on Security and Privacy</title>
		<imprint>
			<date type="published" when="2015-05" />
			<biblScope unit="page" from="591" to="604" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">High performance cache replacement using re-reference interval prediction (RRIP)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aamer</forename><surname>Jaleel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><forename type="middle">B</forename><surname>Theobald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><forename type="middle">C</forename><surname>Steely</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><forename type="middle">S</forename><surname>Emer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">37th International Symposium on Computer Architecture (ISCA 2010)</title>
		<meeting><address><addrLine>Saint-Malo, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="60" to="71" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">HASP 2013, the second workshop on hardware and architectural support for security and privacy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ruby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weidong</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<publisher>ACM</publisher>
			<pubPlace>tel-aviv, israel</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Catalyst: Defeating last-level cache side channel attacks in cloud computing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yarom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Mckeen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rozas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Heiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">B</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Symposium on High Performance Computer Architecture (HPCA)</title>
		<imprint>
			<date type="published" when="2016-03" />
			<biblScope unit="page" from="406" to="418" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Random fill cache architecture</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fangfei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruby</forename><forename type="middle">B</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 47th Annual IEEE/ACM International Symposium on Microarchitecture, MICRO-47</title>
		<meeting>the 47th Annual IEEE/ACM International Symposium on Microarchitecture, MICRO-47<address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="203" to="215" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Last-level cache side-channel attacks are practical</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fangfei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuval</forename><surname>Yarom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qian</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gernot</forename><surname>Heiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruby</forename><forename type="middle">B</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 IEEE Symposium on Security and Privacy, SP &apos;15</title>
		<meeting>the 2015 IEEE Symposium on Security and Privacy, SP &apos;15<address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="605" to="622" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Rethinking timekeeping and performance monitoring mechanisms to mitigate side-channel attacks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Demme</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simha</forename><surname>Sethumadhavan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Timewarp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 39th Annual International Symposium on Computer Architecture, ISCA &apos;12</title>
		<meeting>the 39th Annual International Symposium on Computer Architecture, ISCA &apos;12<address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="118" to="129" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Cache attacks and countermeasures: The case of aes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arne</forename><surname>Dag</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adi</forename><surname>Osvik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eran</forename><surname>Shamir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tromer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2006 The Cryptographers&apos; Track at the RSA Conference on Topics in Cryptology, CT-RSA&apos;06</title>
		<meeting>the 2006 The Cryptographers&apos; Track at the RSA Conference on Topics in Cryptology, CT-RSA&apos;06<address><addrLine>Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="1" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Cache missing for fun and profit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Percival</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of BSDCan</title>
		<meeting>of BSDCan</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Secdcp: Secure dynamic cache partitioning for efficient timing channel protection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Ferraiuolo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danfeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">C</forename><surname>Myers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">Edward</forename><surname>Suh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Design Automation Conference, DAC &apos;16</title>
		<meeting>the 53rd Annual Design Automation Conference, DAC &apos;16<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="page" from="1" to="74" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">New cache designs for thwarting software cache-based side channel attacks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenghong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruby</forename><forename type="middle">B</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th Annual International Symposium on Computer Architecture, ISCA &apos;07</title>
		<meeting>the 34th Annual International Symposium on Computer Architecture, ISCA &apos;07<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="494" to="505" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Secure hierarchy-aware cache replacement policy (sharp): Defending against cache-based side channel atacks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengjia</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bhargava</forename><surname>Gopireddy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Shull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josep</forename><surname>Torrellas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 44th Annual International Symposium on Computer Architecture, ISCA &apos;17</title>
		<meeting>the 44th Annual International Symposium on Computer Architecture, ISCA &apos;17<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="347" to="360" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Flush+reload: A high resolution, low noise, l3 cache side-channel attack</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuval</forename><surname>Yarom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katrina</forename><surname>Falkner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd USENIX Conference on Security Symposium, SEC&apos;14</title>
		<meeting>the 23rd USENIX Conference on Security Symposium, SEC&apos;14<address><addrLine>Berkeley, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="719" to="732" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A software approach to defeating side channels in lastlevel caches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziqiao</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">K</forename><surname>Reiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinqian</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security, CCS &apos;16</title>
		<meeting>the 2016 ACM SIGSAC Conference on Computer and Communications Security, CCS &apos;16<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="871" to="882" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
