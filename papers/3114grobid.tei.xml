<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2020-09-29T03:01+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Improved Support for Machine-Assisted Ballot-Level Audits</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2013-08">August 2013</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Kim</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Berkeley</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Carlini</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Berkeley</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Chang</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Berkeley</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Yiu</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Berkeley</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Wang</surname></persName>
							<affiliation key="aff4">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>San Diego</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Wagner</surname></persName>
							<affiliation key="aff5">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Berkeley</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Improved Support for Machine-Assisted Ballot-Level Audits</title>
					</analytic>
					<monogr>
						<title level="j" type="main">USENIX Journal of Election Technology and Systems (JETS)</title>
						<imprint>
							<biblScope unit="volume">1</biblScope>
							<biblScope unit="issue">1</biblScope>
							<date type="published" when="2013-08">August 2013</date>
						</imprint>
					</monogr>
					<note>88</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>This paper studies how to provide support for ballot-level post-election audits. Informed by our work supporting pilots of these audits in several California counties, we identify gaps in current technology in tools for this task: we need better ways to count voted ballots (from scanned images) without access to scans of blank, unmarked ballots; and we need improvements to existing techniques that help them scale better to large, complex elections. We show how to meet these needs and use our system to successfully process ballots from 11 California counties, in support of the pilot audit program. Our new techniques yield order-of-magnitude speedups compared to the previous system, and enable us to successfully process some elections that would not have reasonably feasible without these techniques.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Post-election audits form one of the most compelling tools for providing transparency and securing elections that use electronic technology. Recent research has shown that ballot-level machineassisted audits <ref type="bibr" target="#b8">[Calandrino et al. 2007;</ref><ref type="bibr" target="#b6">Benaloh et al. 2011</ref>] can offer significant improvements over current practice: significantly better assurance, at lower cost. Unfortunately, the voting systems currently deployed in the US do not support ballot-level post-election audits.</p><p>In this paper, we develop tools to facilitate ballot-level machine-assisted audits of elections conducted using current voting systems. We have been working with the State of California and various California counties to pilot new methods for ballot-level machine-assisted election audits. The approach involves re-tabulating the election using a second system that was designed from the start with support for ballot-level audits, checking that the second system selects the same winners as the official results, and then conducting an efficient ballot-level audit of the results from the second system <ref type="bibr" target="#b16">[Lindeman et al. 2013]</ref>. This work focuses on the design of such a second system, called OpenCount, intended for this task.</p><p>One might wonder, why build a new system to re-tabulate the election from scratch? An alternative approach would be to extend deployed voting systems with the support needed for ballot-level machine-assisted audits. However, many of the major commercial vendors are focusing their development efforts primarily on their next-generation systems rather than on upgrading deployed systems; the deployed systems are proprietary, so it is not easy for third parties to develop extensions without vendor assistance; and updates to legacy systems may require that the entire system be first certified under new EAC standards, which may be impossible, as those systems were not designed to meet the new EAC standards. More fundamentally, many existing systems cannot be retrofitted in this way due to hardware limitations: in many deployed systems, the precinct-count optical scanners do not have the hardware capacity to record scanned images of all ballots, and there is no way to link each individual ballot to its scanned record. Therefore, pragmatically it may be easier to deploy ballot-level audits by re-tabulating the ballots using a second system that was designed with machine-assisted auditing in mind. That is the path we explore in this work. Of course, our work may be of direct relevance to future generations of voting systems that wish to provide support for efficient audits.</p><p>This work extends OpenCount [ <ref type="bibr" target="#b25">Wang et al. 2012</ref>] to provide better support for ballot-level audits, based upon our experience using it to support pilots in several California counties. This experience has helped us gain a better understanding of what is needed to allow ballot-level audits to be used in practice. In particular, we identified two major shortcomings of the previous version of OpenCount. First, the previous version required election officials to compile a collection of all blank ballots (one of each possible ballot style). Due to the number of ballot types, this process proved to be laborintensive for election officials and was a hurdle to deployment. Second, we learned that the previous version of OpenCount did not scale to large, complex elections. When there are many ballot styles, operator data entry of contest titles, candidate names, and ballot attributes (e.g., language, precinct, tally group) became extremely tedious and time-consuming. Each of these two is an independent barrier to being able to use OpenCount in large elections; either alone would be a showstopper, so we must solve both problems.</p><p>In this paper, we show how to solve both of these two problems. First, we develop new techniques to eliminate the need for scanned blank ballots. This allows us to re-tabulate an election given only scans of the voted ballots (and without access to the election database from the official voting system). Second, we develop new methods to reduce the human effort so that OpenCount will scale to large elections with many ballot types. We implement these improvements in OpenCount.</p><p>We found that these improvements are enough that we can now successfully handle large, complex elections and meet the needs of the California pilots. We evaluate the improved OpenCount on over 560,000 ballots from 12 different elections in 11 California counties and 1 Florida county. Our experiments show that these new methods enable order-of-magnitude speedups on medium-sized elections (∼ 30k ballots) with many ballot styles, and enable us to process large elections (∼ 120k double-sided ballots) that could not reasonably have been processed without them.</p><p>This paper makes the following contributions: -We develop new methods to analyze and decode ballot styles, from scans of only the voted ballots (without needing scans of blank ballots or other external information). We show how to rapidly identify the ballot style of each voted ballot, how to reverse-engineer the structure of contests on the ballot, and how to recognize precinct numbers and decode barcodes that identify the ballot style of each voted ballot. -We develop new methods to reduce the amount of human effort needed to re-tabulate an election.</p><p>We show how to robustly identify multiple instances of the same contest on different ballot styles (so that the operator only needs to enter in candidate names once), how to associate voting targets with contests, how to infer the bounding box of each contest robustly, and how a human operator can verify that the results of these automated methods are accurate. -We build a tabulation system that election officials can use to conduct ballot-level audits of their elections, and that researchers can use as a basis for future research.</p><p>The system is open source and is publicly available at https://code.google.com/p/opencount/.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>OpenCount was inspired by the pioneering work of TEVS <ref type="bibr" target="#b24">[Trachtenberg 2008]</ref> and Votoscope <ref type="bibr" target="#b13">[Hursti 2005]</ref>, which aim to solve the same problem. BallotTool ] is a related system which assists an operator in retabulating a set of scanned ballots. Our work distinguishes itself in our tight integration of computer vision techniques with focused operator interaction. In , the authors develop a system that segments voter marks from the ballot form. However, no attempt is made to classify the marks as filled or unfilled.</p><p>[ <ref type="bibr" target="#b26">Xiu et al. 2009</ref>] introduces specialized classifiers that fully automate the voter intent classification task. As future work, we intend to explore applying classifiers to further improve the ballot interpretation stages. Document analysis is a field that considers many of the same challenges as ballot analysis. In document analysis, researchers develop systems that automatically infer the structure of documents such as forms or articles. The X-Y Cut algorithm <ref type="bibr" target="#b21">[Nagy et al. 1992]</ref>, shape-directed cover algorithm <ref type="bibr" target="#b5">[Baird et al. 1990]</ref>, and whitespace cover algorithm <ref type="bibr" target="#b7">[Breuel 2002</ref>] are methods which excel at segmenting documents with white backgrounds and rectangular layouts. See <ref type="bibr" target="#b20">[Mao et al. 2003;</ref><ref type="bibr" target="#b22">Namboodiri and Jain 2007]</ref> for a survey of the document analysis field.</p><p>Ballot analysis distinguishes itself in that it requires near-perfect accuracy in its interpretation of voted ballots. Thus, any approach must be designed with this requirement in mind -towards that  end, OpenCount combines automated analysis with operator interaction to accurately and efficiently process ballots.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Overview of the OpenCount Architecture</head><p>Audit Process. OpenCount is designed to support a transitive audit <ref type="bibr" target="#b17">[Lindeman and Stark 2012]</ref>, where one re-tabulates the election using a second system (in this case, OpenCount), checks that the second system declares the same winners as the official results, and then audits the second system. We focus on elections conducted using paper ballots.</p><p>The audit process works as follows. After an election, election workers collect all the cast ballots and scan them all using an ordinary document scanner. Then, OpenCount processes those scanned images to extract cast vote records (CVRs) that describe the votes present on each ballot. Election officials tally the cast vote records, check that they declare the same winners as the official results, and then commit to the OpenCount CVRs. Finally, election officials conduct a public, risk-limiting audit of the ballots. During this audit process, officials repeatedly select a random ballot, pull the corresponding paper ballot, visually compare the marks on the paper ballot to the electronic CVR produced by OpenCount, and confirm that they match. Because the paper ballots are retained in the same order they were scanned, it is possible to uniquely associate each paper ballot to its corresponding CVR, which enables the ballot-level audit. Standard methods can be used to calculate how many ballots to examine and compute the level of confidence thus attained.</p><p>For instance, this process was successfully used in Napa County to audit their June 2012 primary election <ref type="bibr" target="#b10">[Farivar 2012]</ref>. Election officials scanned 6,809 ballots, and OpenCount was used to process those scanned ballot images. Then, election officials used the CVRs produced by OpenCount to audit the election in a very close contest. Napa County officials audited 559 ballots, and found that in every case the votes on the ballots exactly matched the CVRs produced by OpenCount.</p><p>In this paper, we focus on the design of OpenCount and the algorithmic techniques needed to successfully analyze scanned images of ballots and produce CVRs. OpenCount is designed to avoid relying upon election definition files from the official voting system or other external information; we would like OpenCount to rely only on scanned images, with no further external information. The need to re-derive this information, the scale of elections, the diversity of ballot formats and voter marks, and the imperfections in scanned images make this a challenging image-processing task.</p><p>Architecture. There are four main stages to OpenCount's processing <ref type="figure" target="#fig_0">(Figure 1)</ref>. First, grouping divides the ballots into groups, where all ballots within a group share the same ballot style (that is, the same layout and same contests). We present improvements to the grouping state that allows OpenCount to scale to larger elections. Second, in layout annotation, a human operator assists OpenCount in identifying the structure of the ballot (location of contests, candidates, and voting targets) and enters the titles of contests and the names of candidates. The operator only must annotate one ballot from each group. We develop novel methods to reduce the workload of layout annotation on the operator; this is crucial to enabling us to scale. One challenge here is to analyze the structure of the ballot robustly despite the presence of voter marks. Third, ballot interpretation involves automated processing to identify voter marks and associate them with the corresponding contest and candidate. Fourth, and finally, in target verification, a human operator checks OpenCount's interpretation of voter marks and inspects ambiguous or marginal marks. The output is a cast vote record for each ballot that identifies all votes found on that ballot. Ballot interpretation and target verification remain mostly unchanged, compared to the previous version of OpenCount [ <ref type="bibr" target="#b25">Wang et al. 2012]</ref>; our new work primarily affects the first two stages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Design</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Terminology</head><p>A voted ballot is the ballot after a voter has marked his/her ballot and cast it. Each ballot contains a set of contests. A contest includes a list of candidates, with one voting target per candidate. A voting target is an empty oval, broken arrow, or other location on the ballot where the voter should mark her ballot, if she wants to indicate a vote for the associated candidate. A cast vote record (CVR) is a record of all selections made by the voter on a single voted ballot.</p><p>The ballot style is the set of contests found on the ballot as well as the visual organization and location of these contests on the ballot. 1 For example, an English-language ballot may have the same set of contests as a Spanish-language ballot, but because their text is different, we consider them as two different ballot styles. Similarly, two ballots may contain identical contests, but the order of candidates in the contests may not be the same; in this case, we consider them as distinct ballot styles. Ballots may also contain a precinct number or a tally group (e.g., absentee vs. polling-place) for accumulation.</p><p>Min/Max Overlay Verification. OpenCount uses overlays <ref type="bibr" target="#b9">[Cordero et al. 2010]</ref> to help the human operator verify the correctness of automated computations. Overlays help the operator quickly verify that a set of images is identical, or carries the same meaning. For instance, in <ref type="figure" target="#fig_2">Figure 3</ref>(b) the operator can immediately verify that all the images contain the word "Democratic".</p><p>Let S be a set of grayscale images of uniform dimension. The min-overlay of S is the image S min where the intensity value at (x, y) is the lowest intensity value at (x, y) out of every image in S. The max-overlay of S is the image S max where the intensity value at (x, y) is the highest intensity value at (x, y) out of every image in S. Intuitively, if any image in S has a black pixel at (x, y), then so does S min . Similarly, if S max has a white pixel at (x, y), then at least one image in S does.</p><p>If the min and max overlays of the images in S suggest to the operator that not all the images in S match, then the operator can choose to split S into two smaller sets. The split operation uses the k-means algorithm <ref type="bibr" target="#b19">[MacQueen 1967</ref>] (with k = 2) on the images in S. The feature representation of each image is simply the pixel intensities arranged row-by-row into a vector, with the L2 norm as the distance metric. This method works well, provided there are two image classes present that exhibit different spatial-visual distributions. If there are more than two image classes present in the set S, the operator may need to perform several consecutive splits to further refine the results until each cluster is homogeneous. See <ref type="figure" target="#fig_1">Figure 2</ref>(b,c) for an illustration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Grouping</head><p>In the first step of the pipeline, OpenCount separates the input set of voted ballots into groups, so that all ballots within a given group have the same ballot style. This stage reduces the effort required in later stages: rather than asking a human operator to annotate each individual ballot, we ask the operator to annotate only one ballot from each group. <ref type="table" target="#tab_1">Table I</ref> summarizes the number of groups (the number of distinct styles) for a range of elections that we processed. Notice that the number of groups is orders of magnitude smaller than the number of voted ballots. Also, the number of groups does not necessarily scale linearly with the size of an election. Instead, the number of groups scales with the number of possible precincts, political party affiliations, languages, and tally groups. For instance, although Leon County has four times more voted ballots than Marin County, Leon actually has fewer groups than Marin.</p><p>In the previous version of OpenCount [ <ref type="bibr" target="#b25">Wang et al. 2012</ref>], we grouped ballots by matching each voted ballot to a corresponding blank ballot. However, this required election officials to gather and scan one of every possible kind of blank ballot, which we discovered is very burdensome. Therefore, we cannot rely on knowing all ballot styles a priori. Instead, our approach is to decode the barcodes present on optical scan ballots, supplemented by additional information when necessary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1.">Vendor-Specific Barcodes</head><p>In deployed optical scan systems, the scanners rely on the presence of specialized, vendor-specific barcodes to determine ballot metadata such as the ballot style. These barcodes can range from simple binary bit-strings to more complex encodings ( <ref type="figure">Figure 7</ref>). In most cases, the barcodes present on each ballot fully determine the ballot style, so we can group ballots by decoding the barcode and then put ballots with the same barcode into the same group. (Section 4.2.3 describes how to handle exceptional cases where the barcode alone is not enough.)</p><p>OpenCount does not require knowledge of the semantic meaning of the barcodes; we merely need to be able to decode them to bit-strings. That said, we have reverse-engineered the semantic meaning of most of the barcodes 2 . For instance, several vendors incorporate a checksum in the barcode; when possible, we verify that the checksum is valid during the decoding process.</p><p>OpenCount currently has built-in support for paper ballots from four major election vendors: Hart InterCivic, Premier Election Solutions (formerly Diebold Election Systems), Sequoia Voting Systems, and Election System &amp; Software (ES&amp;S). It would not be difficult to add more vendors to OpenCount in the future.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2.">Ballot Attributes</head><p>To facilitate comparison of OpenCount's results to the official results, OpenCount includes support to identify the precinct number and tally group of each ballot. This information is not always encoded in the barcode, but it is always printed in human-readable form on the ballot. Therefore, we provide support to enable a human operator to identify these features on the ballot; OpenCount then uses this information to automatically decode these ballot attributes. The previous system <ref type="bibr" target="#b25">[Wang et al. 2012</ref>] did include a mechanism for this purpose. However, there were two major shortcomings present in the previous design that we address here. First, we extend the automated annotation process to make it more robust to variations in visual appearance, such as varying background colors and patterns. Second, we introduce a novel approach to decoding precinct number stamps on ballots. Decoding ballot attributes is a two-step process: attribute definition, and then (if necessary) exemplar detection. Attribute Definition. Within OpenCount, the operator declares a number of "ballot attributes" for each desired property (precinct number, tally group, etc.), and then defines the possible attribute values. Additionally, the operator associates each attribute value with an image patch where this value is present in human-readable form on the ballot.</p><p>Workflow. The operator workflow is as follows. At any given moment, there is a set of ballots that have not been fully labeled. First, an unlabeled ballot is displayed. The operator draws a bounding box around the location of the desired attribute <ref type="figure" target="#fig_2">(Figure 3(a)</ref>), and specifies an attribute type and value (e.g., "party: independent"). OpenCount then searches the remaining unlabeled ballots to find ballots containing a matching image patch. Matches are identified using normalized crosscorrelation (NCC) and a fixed threshold.</p><p>OpenCount then displays an overlay for all matches, so the operator can confirm that all detected matches are indeed a true match <ref type="figure" target="#fig_2">(Figure 3(b)</ref>). This process is repeated until all ballots have a label for every defined attribute type. Precinct-number attributes are handled separately (see Section 4.2.4 for details).</p><p>When defining an attribute, the operator indicates whether the value of the attribute is known to be consistent within each group. If the attribute is known to be group-consistent, then OpenCount will select one ballot from each group, perform the above process, and apply the discovered labels to all ballots automatically; no further processing is needed. Otherwise, to allow for the possibility that an attribute value may vary within a single group, OpenCount randomly selects 20% of the ballots from each group, and applies the above process to each of them; then, OpenCount applies exemplar detection and automatic annotation, detailed next.</p><p>Robust Exemplar Detection. At this point, only one image patch is defined for each attribute value. Depending on the election, a single image patch may not be sufficient to annotate the ballots. In <ref type="figure" target="#fig_3">Figure 4</ref>, the difference in background color (white vs. grey) overwhelms the difference in printed number ("005" vs. "006"). The image patch in <ref type="figure" target="#fig_3">Figure 4</ref>(c) is misclassified as "006" because it shares the same background as the "006" representative.</p><p>More generally, we would like visual distractions such as the background style to not affect the matching process. The previous system <ref type="bibr" target="#b25">[Wang et al. 2012</ref>] did not have a sufficient mechanism in place to handle such variations, leading to failure cases such as <ref type="figure" target="#fig_3">Figure 4</ref>. Thus, we introduce the following extension. Rather than use only one image patch for each attribute value, OpenCount instead selects multiple representative image patches for each attribute value. These representative image patches are chosen such that they capture the possible diversity present in the dataset. The algorithm is a fixed-point iteration that takes advantage of the fact that, at this point, the software already has a set of image patches labeled with their correct attribute values (done by the operator during attribute definition). For each attribute value, we initially choose a single image patch as the first representative patch. The algorithm then classifies all image patches with the current set of representative image patches. If an image patch is misclassified (i.e., a "democratic" patch was mistaken for a "republican" patch), then it is likely that this image patch contains some significant variation. Thus, we add this image patch to the set of representatives for that attribute value, and repeat the process.</p><p>To classify a new patch, we compare it to each representative and choose the attribute value whose sum-of-squared-difference (SSD) between the patch and the representative patch is minimized. To allow for translation and rotation invariance, we first align the image patch to the representative patch prior to computing each error score. The algorithm terminates when all image patches are classified correctly by the current set of representative image patches. OpenCount chooses the initial representative values by selecting the image patch with the highest average pixel intensity.</p><p>Automatic Attribute Annotation. Once the operator has defined the desired attributes and representative patches, OpenCount determines the attribute values of each voted ballot. For brevity, we refer the reader to Section 4.5 of [ <ref type="bibr" target="#b25">Wang et al. 2012]</ref>, as the core approach remains unchanged.</p><p>Once the automated annotation is complete, OpenCount asks the user to verify the resulting labels using overlays (see <ref type="figure" target="#fig_1">Figure 2</ref>(b-c)). The operator is able to correct any errors by manually relabeling any misclassified image patches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3.">Additional Grouping</head><p>In some cases, the ballot style may not be completely encoded within the barcodes. For instance, the choice of language on Sequoia-style ballots affects the location of voting targets. However, the language is not encoded in the barcodes-thus, in this case grouping by the barcodes is insufficient. In this scenario, one may use attributes as an additional grouping criterion after the barcode-based grouping has been performed. For instance, in the Sequoia example the operator should define a ballot attribute for the language 3 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.4.">Precinct Number Recognition</head><p>We added support for OpenCount to determine the precinct of each ballot, based upon the precinct number printed on the ballot. The previous version of OpenCount used the attribute decoding process described above for this purpose. However, while processing ballots from the June 2012 primary, we found that this approach was inadequate: the number of different precincts is large enough that this imposes an overwhelming burden on the operator. Additionally, without precinct number recognition we would require one attribute per precinct; since grouping runs linear in the number of different groups, this becomes prohibitively slow.</p><p>Therefore, we designed an alternative method for decoding precinct numbers. After experimenting with off-the-shelf OCR software, we found it was not accurate enough for our purposes. Instead, The overlay of all matches is presented to the user. After splitting once, we obtain two groups, shown stacked vertically. The top overlay shows that all digits in that group are clearly a "0". In contrast, the bottom overlay reveals that the group contains some mismatches, e.g., "6" or "8". (c) The accepted matches are labeled with their value ("0").</p><p>we designed a novel solution to this problem, which works by recognizing each individual digit and taking advantage of the fact that all digits within the same election are printed in the same font. The algorithm works in two steps: digit exemplar selection, and digit parsing.</p><p>Digit Exemplar Selection. In this step, we obtain an example of each digit (0-9) directly from the ballot images themselves. Once OpenCount knows what each digit looks like for this particular election, we can decode a precinct number by visually comparing the digits in the precinct region to its set of example digits.</p><p>To obtain examples of each digit, OpenCount displays all the precinct numbers in a grid 4 , one patch from each group. See <ref type="figure" target="#fig_4">Figure 5</ref>(a). The operator selects an unlabeled digit and draws a bounding box around that digit, and enters the correct digit value (e.g., "0"). OpenCount then uses template matching across all precinct patches to find all matches for the selected digit. Any matches whose NCC (normalized cross-correlation) score exceeds a fixed threshold is retained as a potential candidate, and the operator confirms all candidate matches using an overlay verification step ( <ref type="figure" target="#fig_4">Figure  5(b)</ref>). After the verification is complete, the operator-accepted matches can be labeled with their value (as shown in <ref type="figure" target="#fig_4">Figure 5(c)</ref>). The task is finished once all digits in all precinct patches have been labeled. To account for possible background pattern variations, OpenCount employs the same robust exemplar patch detection technique from Section 4.2.2 for each digit.</p><p>Digit Parsing. Once OpenCount has example image patches for each digit, it can begin to interpret the precinct patches (i.e., given an image containing a precinct number, recover the decimal string). Intuitively, each unknown digit in the precinct patch could be decoded by comparing it against all exemplars to find its closest match. However, we would like our approach to not require an initial segmentation of the unknown precinct patch into its individual digits. Ballots may not be scanned at very high resolution, and coupled with scanner noise, segmentation algorithms are likely to output incorrect results. This is exacerbated by the fact that precinct stamps are often printed in a small font. Instead, we implemented a dynamic programming algorithm to simultaneously identify the location of all digits in the unknown patch and find each digit's best match among the exemplars.</p><p>The core of our approach is a scoring algorithm that compares a representative digit against a particular precinct number through a combination of the individual digit match confidence scores and spatial relationships between adjacent pairs of digits. More formally, let L = (l 1 , ..., l n ) represent a configuration of an n-digit precinct number on a ballot where l i is the (x, y) coordinate of the i th digit. Let m(l (c) i ) be the match cost of a digit, c at location l i . We compute this as the NCC score between the template image of that digit and the ballot at location l i . Now let M(l i ) = max c l (c) i store the best match score of all digits at a given location and Q(l i ) = argmax c l (c) i store the identities of the digits at those locations. Finally, let d(l i , l j ) represent the pairwise penalty of two adjacent digits placed at l i and l j . In our case, the ideal location for l j given l i is to be one character's width away on the x-axis while being on the same y-axis. We set d(l i , l j ) to be a quadratic cost for deviations from the ideal location. Our algorithm solves for the optimal configuration L * , using the function:</p><formula xml:id="formula_0">L * = argmin L   n ∑ i=1 M i (l i ) + ∑ (v i ,v j )∈E d i j (l i , l j )  <label>(1)</label></formula><p>The cost of any configuration of digits L is the sum of the cost of their individual match scores and sum of pairwise spatial costs. Our formulation draws from the Pictorial Structures work of <ref type="bibr" target="#b12">[Fischler and Elschlager 1973;</ref><ref type="bibr" target="#b11">Felzenszwalb and Huttenlocher 2005]</ref> and a solution can be found efficiently using dynamic programming. This algorithm allows us to efficiently and accurately decode precinct numbers on all ballots, using the exemplars selected by the operator in the previous stage. Once the precinct decoding is complete, OpenCount asks the user to verify the labeling results via overlay verification. The user can correct any misclassified digits here, if necessary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Layout Annotation</head><p>After OpenCount has grouped the ballots, the operator must then annotate the layout of one ballot from each group. In the previous version of OpenCount [ <ref type="bibr" target="#b25">Wang et al. 2012]</ref>, annotation of contests and candidates in very large elections required a lot of operator effort: directly proportional to the number of contests per ballot, times the number of different ballot styles. We designed several new methods to greatly reduce the workload on the operator in complex elections.</p><p>Detecting Voting Targets. OpenCount assists the operator in identifying the location of all voting targets in every group. When blank ballots are available, this is easy: the operator can identify one example of an empty voting target, and the system can find all matches on all blank ballots. Since the blank ballots do not have any voter marks, all matches should be clean. However, when we do not have blank ballots, more sophisticated methods are necessary. Our improved procedure works as follows. For each group, one ballot is arbitrarily selected and displayed to the operator. The operator then draws a bounding box around one of the voting targets. Once a voting target is selected, OpenCount automatically tries to detect as many matching voting targets as possible using template matching on all remaining unannotated groups. Any match whose NCC score is above a fixed threshold is accepted as a candidate voting target. To prevent multiple overlapping matches, once a match is processed, all other NCC scores within a fixed region around the match are suppressed. We apply smoothing with a Gaussian kernel to the template and ballot images prior to template matching to improve detection rates.</p><p>OpenCount applies an additional technique to further reduce operator effort. We select N representative ballots from each group, template match against all representatives, and union the results together <ref type="bibr">5</ref> . This is intended to solve the problem that voter marks often interfere with the template matching search. For instance, if the operator draws a bounding box around an empty voting target, filled targets will not be identified as matches during the template matching. However, the same voting target will be present on the other N − 1 representatives in that group, and it is likely that it will be empty in at least one of these cases; thus the union trick allows us to detect the location of that voting target. We set N = 5, which offers a good balance between convenience and performance.</p><p>Detecting Contest Bounding Boxes. We implement a method to identify the "bounding boxes" of contests on a ballot-a rectangular region that surrounds all of the voting targets in a contest. These bounding boxes help recognize which voting targets belong to the same contest, which is used for tabulation purposes. The contest bounding boxes also enable us to identify redundant contests by performing pair-wise comparisons between the set of detected contests; this enables a major reduction in the amount of data entry required. The previous version of OpenCount implemented a more naive approach. Instead of attempting to identify the actual contest bounding box, voting targets were instead grouped together by distance. However, as we experimented with large elections with many ballot styles, we discovered that this naive heuristic was both incorrect and could not find a box surrounding all candidate names.</p><p>We developed a new algorithm which is much more accurate, and also provides the full bounding boxes. We find it only makes errors the ballot has significant stray voter marks, and in those cases we provide a mechanism to select an alternate ballot in the same group without such marks. Our algorithm takes advantage of the fact that, on all ballot styles we have encountered, each contest is at least partially surrounded by horizontal and/or vertical lines that demarcate it from other contests.</p><p>First, OpenCount identifies all vertical and horizontal lines on the ballot. This is done by scanning over the ballot for pixels darker than some threshold, and attempting to identify if this is part of a long vertical or horizontal line segment. Only segments of a large enough size are retained. Line segments are identified by continuous segments of pixels darker than some threshold.</p><p>We then reduce all the scattered line segments through several intermediate steps. First, line segments are joined together if they extend in the same direction and are overlapping. Second, line segments are removed if they do not intersect with any perpendicular segments. Third, segments are removed if no voting target is located in the area it could possibly be extended to.</p><p>Next, we process the ballot to determine if there is some constant C where, if all lines were extended by a factor of C, significantly more intersections are found. This allows for cases where vertical and/or horizontal lines are present on the ballot, but do not fully intersect each other, as happens on several styles.</p><p>Finally, OpenCount searches over all candidate rectangles that can be formed by these lines (from smallest rectangle to largest), looking for rectangles that contain voting targets. When a rectangle does contain at least one voting target, all of the targets in its interior are removed and the process is repeated. For some vendors, it is necessary to combine multiple bounding boxes together to form the final set of bounding boxes; in these ballot styles, contests are finally merged. For example, <ref type="figure" target="#fig_5">Figure 6</ref> shows that each contest is contained within its own bounding box in the second image, but in the third image many are merged together to form the correct contest bounding boxes.</p><p>Once OpenCount infers all bounding boxes, it presents them to the operator, who can manually correct any errors. OpenCount can optionally detect bounding boxes on the other four representative ballots and warn the operator if the bounding boxes are not identical on all five.</p><p>Contest Data Entry. The final step in ballot annotation is to label all detected contests with the contest title and the candidate names. This is crucial information to allow OpenCount to output human-readable election results. In principle, this is not a difficult task-one can simply ask the operator to enter the relevant text on a representative ballot from each group. In fact, this is what was done in the previous version of OpenCount.</p><p>However, in many elections there are several hundred different groups, and manually annotating every contest on every group would take many hours of manual effort. To address this challenge, we developed new methods to detect contests that are duplicates of each other. While there may be hundreds of groups, each having several contests, there are typically only a few distinct contests in the entire election. If duplicates can be detected, the operator only needs to label one instance of each contest. In practice, we find that this speeds up the contest data entry process from between a factor of ten to a hundred for large elections, not counting computation time.</p><p>Unfortunately, detecting duplicate contests is a difficult task. We experimented with many strategies for recognizing when two contests are the same by comparing them as images, but all failed. There are three key challenges. First, contests that are semantically equivalent may not necessarily be visually identical. Examples of such visual discrepancies include varying image dimensions, text lines wrapped at different locations, and inconsistent spacing between the words in candidate names. Second, the order of candidates on a given contest may be different on two different instances, due to ballot rotation. And third, some contests do not fit on a single column of a ballot, but continue onto the next column.</p><p>We resolve the first challenge by using an off-the-shelf Optical Character Recognition (OCR) software as a preprocessor to extract the text from the contest images <ref type="bibr">6</ref> . We extract the title and the candidate names independently. To compare the similarity of two contests, we then use the Levenshtein (edit) distance <ref type="bibr" target="#b15">[Levenshtein 1966</ref>] between the extracted text of the two contests. By comparing the OCR outputs between two contests, rather than the contest images themselves, we remain invariant to the visual confounding factors mentioned previously. Crucially, this approach allows us to tolerate inaccuracies in the OCR output. For example, if the OCR were only accurate on 50% of the characters, we would expect the Levenshtein distance to be 25% smaller for two identical contests than for two different contests (of similar length). In practice, we found that Tesseract makes many errors, but it is still over 90% accurate on most ballot styles and languages.</p><p>Solving the second challenge requires more work. At a high level, whenever we test a pair of contests for equivalence, we search over all possible rotations of the candidate names and find the best match. For all elections we are aware of, candidate names are not permuted arbitrarily. Instead, they are simply rotated some number of positions, with one modification: the write-in candidate(s) always appear at the end. Therefore, our algorithm takes advantage of this fact. Once we have extracted both the contest title and the candidate names for each voting target, we attempt to determine (a) the number of write-in candidates and (b) the rotation amount. In particular, we search over all possible number of write-ins, and all possible rotations. We then treat two contests as duplicates if they have both the same number of write-in contests, and if they have a small Levenshtein distance between the names of corresponding candidates.</p><p>We solve the third challenge by letting the operator mark contests that span multiple columns while labeling the voted ballots: if the operator finds such a contest while entering text on the ballots, she clicks a button marking it as such, and continues on. <ref type="bibr">7</ref> OpenCount then performs another search over all consecutive pair of contests to attempt to identify other contests that also are split across two bounding boxes by comparing their similarity against the pair the operator marked.</p><p>We implement several optimizations to improve performance. First, contests are only compared if they have the same language and same number of targets; and second, we sort candidates by length and perform an initial linear scan where we compare consecutive contests, to detect some duplicates quickly. These two optimizations typically reduce computation time by a factor of a hundred on large elections. Finally, the we present operator with an overlay of the contests. We align candidates independently, and merge them together to form a single overlay. The user then verifies that the resulting overlays indeed correspond to the same contest. See <ref type="figure">Figure 8</ref> (Right) for an example overlay.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Ballot Interpretation and Result Generation</head><p>Once the operator has annotated a representative of each group, OpenCount uses this information to interpret the remaining ballots. We did not need to make major improvements or changes to this stage from the previous version of OpenCount [ <ref type="bibr" target="#b25">Wang et al. 2012]</ref>, though we did take the opportunity to improve performance in several places. For convenience, we summarize this stage: -Extract voting targets. In each group, OpenCount takes a representative and globally aligns all other ballot to it. OpenCount then locally aligns each voting target to the corresponding voting target on the representative, and extracts it. The current version runs on average three times faster. -Classify voting targets. OpenCount then presents the operator with a grid of targets sorted by average intensity, who then identifies which targets are filled. We added the capability for the operator to set filters to only show overvotes and undervotes or only targets from a given contest, or to run a second classifier over the voting targets and display only disagreements. -Handle quarantined ballots. Finally, the operator handles all ballots that were quarantined.</p><p>The operator manually indicates the votes for each contest, as well as the ballot attribute values. Partial information about each ballot is automatically populated when possible. For instance, if a ballot was quarantined after contests were inferred, this information is automatically filled. The previous version of OpenCount did not have this feature, making it much more labor-intensive. -Generate results. OpenCount generates CVRs and cumulative vote tallies. Each CVR specifies the candidates that the voter voted for. Overvotes and undervotes are identified as such. The cumulative vote tallies show the vote totals for each candidate in each contest. These totals are further broken down by precinct and tally group if those attributes are available, which assists in comparing with the official results at a finer granularity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Methodology</head><p>We ran OpenCount on the 12 elections listed in <ref type="table" target="#tab_1">Table I</ref>, and also ran the previous version of OpenCount [ <ref type="bibr" target="#b25">Wang et al. 2012</ref>] on a subset of the elections. We timed how long each took, on a six-core machine Intel i7-3930K processor with 16GB of RAM. <ref type="table" target="#tab_1">Table II</ref> records the results. Different operators ran different elections, so comparisons on timing statistics from election to election may not be meaningful. However, whenever we ran both versions of OpenCount on an election, the same operator ran both versions. On elections where both versions of OpenCount were run, the results between election runs match on ≥ 99.9% of ballots. <ref type="bibr">8</ref> The only differences were <ref type="table" target="#tab_1">Table II</ref>. Election timing data with OpenCount. Steps that require operator interaction are labeled with (H), and steps that only perform computation are labeled with (C). The second column identifies the version of OpenCount used; the 2013 version contains the improvements described in this paper, whereas the 2012 version does not. Times are rounded to the nearest minute, except for the "Total" column. Entries tagged with a * are extrapolated (see text for details).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>County</head><p>Version  almost always the result of the operator interpreting ambiguous marks differently (i.e., a mark that may either be caused by an erasure, or may be a lightly-filled in mark). OpenCount developers processed each elections. We also invited Tom Stanionis, an election official from Yolo county, to evaluate the OpenCount software. Mr. Stanionis was able to successfully process an election subset without any significant intervention from the developer conducting the evaluation. We gathered valuable feedback and constructive criticism about the software from a usability standpoint.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">2011 Elections</head><p>We analyzed five special elections from 2011 (the same ones evaluated in [ <ref type="bibr" target="#b25">Wang et al. 2012]</ref>): Stanislaus, Merced, Ventura, Alameda, and San Luis Obispo (SLO). All of these have only a few contests. Three have only a single ballot style. Alameda has 8 ballot styles, but is the smallest election we analyzed, with only 1,374 ballots. SLO has 27 ballot styles, but all styles contain the same two contests, differing only in precinct and tally group.</p><p>The results are given in <ref type="table" target="#tab_1">Table I</ref>. Because these elections are so small and contain so few contests and so few ballot styles, the 2011 elections do not stress-test the ability of OpenCount to handle complex elections with many ballot styles. For instance, Alameda shows the least benefit from our improvements: with so few ballots, very few of the additions have an impact on total running time. Instead, the total time spent is dominated by initial setup. As it happens, many ballots in the Alameda election were quarantined because the scanned ballot was missing the top portion of the ballot, which included the barcode, see <ref type="table" target="#tab_1">Table III</ref> for full quarantine statistics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">2012 Elections</head><p>We also analyzed ballots from the June 2012 primary in five counties. These elections were more complex. As a primary election, they contained many more ballot styles. Madera was by far the smallest, with only one ballot style, and we encountered no difficulties.</p><p>Napa. Napa had 28 ballot styles and we were able to process all 6,809 ballots using our improved version of OpenCount without incident. The previous version of OpenCount made serious errors during target extraction and extracted the wrong regions on nearly 50% of ballots. On ballots where targets were extracted correctly, the two versions matched with over 99.9% accuracy. On the remaining 50%, we randomly sampled 20 ballots and, in every case, the current version of the software was completely correct, and the previous version was wrong. Our improvements led to a modest (2.8×) speedup; however, with so few ballot styles, many of our improvements do not take effect.</p><p>Marin. The Marin election had 398 ballot styles, so it was a good stress test of our improvements to reduce operator effort. The improvements were crucial to our ability to successfully analyze this election. However, target extraction failed for 115 ballots, due to poor image alignment, and these ballots had to be flagged for manual processing. This dominated the time it took for us to process the Marin ballots.</p><p>Santa Cruz. Santa Cruz had fewer ballot styles, which made processing go quickly. However, verifying the interpretation of marks was made more challenging because Santa Cruz uses a Sequoia complete-the-arrow style ballot, and OpenCount's visualization tool is not as effective for these ballots. This is a good opportunity for further improvements. Also, target extraction failed for 84 ballots, which had to be flagged for manually processing. In each case, the initial image alignment between the ballot and the reference image was incorrect, causing a wildly inaccurate alignment to occur. See Section 6.2 for additional discussion about these alignment issues.</p><p>Yolo. Yolo was our second most complex and third-largest election. The time to label contests includes the 13 minutes of computation OpenCount spent detecting equivalent contests, which massively reduced the amount of data-entry required, from 4,603 contests to fewer than 50.</p><p>The absence of blank ballots made it significantly more challenging to identify all voting targets: this task took two times longer than on the previous version, when blank ballots were available. This is due both to the increase in the number of groups-there are 117 different blank ballots, but this increases to 623 groups when we do not have blank ballots-and to the increase in operator workload due to the presence of voter marks-the operator must repeatedly identify empty voting targets, to ensure all are found. As an experiment, we ran the ballot annotation process of the current version of OpenCount on the 117 blank ballots, and found that it ran six times faster.</p><p>We did not complete grouping verification in its entirety on the previous version of OpenCount. After finishing 5% of grouping verification (in two hours), we extrapolated that grouping verification would take about 40 hours. We used data from the current version of OpenCount to fill in the remaining data.</p><p>Leon. With 124,200 ballots, the November 2008 general election in Leon County, Florida was our second largest election processed. We only ran Leon on the most recent version of OpenCount; processing it with the previous version would have taken an unreasonable amount of time. The contest labeling step of Leon took much longer than that of Yolo, because Leon had several contests of the form "District court of appeals. Shall Justice be retained in office" for each of five different justices. This caused the contest equivalence class computation to erroneously infer that all of these contests were identical; we had to reject and manually label these contests, which took extra time.</p><p>Orange. Finally, we processed the Orange county June 2012 Presidential Primary Election, which consisted of 294,402 voted ballots with a variable number of sides per ballot, ranging from one to three. This election has as many ballots as all other elections combined. Similar to Leon County, we only processed the ballots with the most recent version of OpenCount.</p><p>This election dataset posed several significant challenges. First, the scan quality of these images is noticeably poorer than that of any of the other elections. Rather than rescanning the paper ballots with commercial scanners to obtain high-quality image scans, these images were output directly from the Hart voting systems. This is both good and bad; while no additional scanning effort was necessary, we had to modify OpenCount to handle much more challenging images due to scanning conditions outside of our control. Additionally, the images are binary images, thresholded by the Hart system, which further degraded the image quality through the loss of information. Second, the complexity of the election is by far the greatest: there are 1,839 distinct ballot styles 9 .</p><p>While completing the "Target Check" stage, we discovered that the target sorting metric currently used is inadequate for elections of this size, and requires the operator to inspect an overwhelming number of voting targets. The average-intensity heuristic used for sorting targets breaks down when voter marks are small in comparison to the voting target itself. Image noise then dominates the sorting metric, resulting in empty voting targets being mixed with filled-in voting targets, requiring many hours of manual corrections. It is worth noting that these sparsely filled-in voting targets are typically cases where the voter drew in an "X" or a line to indicate his or her vote. Improving this step is a focus for future work, and may draw upon ideas from the style-based mark classifier of <ref type="bibr" target="#b26">[Xiu et al. 2009</ref>]. Thus, we completed a small portion of the "Target Check" stage and extrapolated the total time required. The timing data for the "Label Contests" stage was similarly extrapolated.</p><p>Interestingly, Orange County had the lowest percentage of quarantined ballots <ref type="table" target="#tab_1">(Table III)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Discussion</head><p>One question we must consider is how well OpenCount will generalize. For this system to be useful, it must minimize the restrictive assumptions it makes on specific ballot details. We consider the major assumptions that OpenCount makes in this section.</p><p>Consequences and Relaxation. OpenCount is currently able to support optical scan ballots from Diebold (Premier), ES&amp;S, Hart, and Sequoia systems, which accounts for the overwhelming majority of opscan ballots in the US. Of the requirements listed above, the most stringent is the requirement that the ballot contain a barcode that can be used for grouping. Fortunately, all ballots that we have encountered to date meet this requirement. To relax this requirement, one could imagine applying algorithms that group ballots on visual appearance. However, we have not investigated the challenges associated with doing so. Finally, while OpenCount currently does not support voting schemes such as straight-party voting or fusion voting, it would be simple to modify the logic to accommodate such voting schemes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">Scanner Assumptions</head><p>In several stages of the pipeline, ballots are aligned to a representative ballot. The image alignment method used in OpenCount assumes a rigid transformation model, which allows translation and rotation variation. The simpler rigid model performed better than more complex models such as the affine model, as the rigid model has fewer parameters to solve for, typically leading to higherquality solutions. Additionally, in practice, almost all images can be aligned with only translations and rotations, and do not require other affine warps (scaling, shearing, etc.).</p><p>Our alignment scheme is able to tolerate a moderate amount of non-rigid warping, due to the fact that it performs two alignment steps: a coarse "global" alignment of the entire image, followed by a finer "local" alignment applied to small regions of the image. Both alignments still use rigid transformations. If an image contains non-uniform warping (e.g., the bottom-half of the image is stretched/skewed more than the top), then no precise global alignment will exist between this warped image and its reference image. However, a good local alignment can often still be recovered, allowing our scheme to tolerate a moderate amount of non-uniform warping. If ballots contain too much non-rigid warping, then mis-alignment errors will cause issues during target extraction. Such issues affected 0.2% of Santa Cruz ballots, as mentioned in Section 5.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.">Scalability</head><p>The improvements made to the OpenCount system in this paper have enabled the processing of significantly larger and more complex elections. The previous system was not able to reasonably process the Yolo county election, let alone the Leon or Orange datasets. The current proposed system, on the other hand, is able to process all three without trouble.</p><p>However, it remains to be seen how the system will scale to even larger elections. For instance, about 3.2 million ballots were cast in November 2012 in Los Angeles county <ref type="bibr" target="#b14">[LA-Registrar 2012]</ref>. This is roughly 11× larger than the Orange county election. Future work is needed to investigate whether OpenCount is able to efficiently handle elections of that magnitude.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusion</head><p>We have introduced several significant improvements to the original OpenCount system that enables OpenCount to scale to significantly larger elections, and process them an order of magnitude faster. The new system does not require the collection of blank ballots, which reduces the barrier on election officials; we also greatly reduce the amount of data entry required, which speeds the re-tabulation process. These improvements enabled OpenCount to successfully support audit pilots in 11 California counties and advance the state of the art in ballot image analysis.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Overview of the OpenCount architecture. The human outline indicates each steps that involve the operator. Steps with a dotted-line border may or may not be required.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. The min/max overlay-based verification process. (a) The set of images. (b) The min and max overlays. (c) A single "split" operation, and the resulting overlays.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Defining the "party" ballot attribute. (a) The operator draws a bounding box around the region where the party affiliation is printed on the ballot. (b) OpenCount finds other ballots that contain the same image patch and shows the min and max overlays of all matches to the operator. The operator uses the overlays to verify the matches. (c) The operator continues this labeling process until all ballots have been labeled.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. (a) The representative image patches for this attribute. (b) Matching an image patch to one of the representative patches. Error is computed with the SSD metric. (c) Due to background variation, the patch was misclassified as "006".</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. The user interface for selecting digit templates. (a) The user selects one example of a "0" digit. (b) The overlay of all matches is presented to the user. After splitting once, we obtain two groups, shown stacked vertically. The top overlay shows that all digits in that group are clearly a "0". In contrast, the bottom overlay reveals that the group contains some mismatches, e.g., "6" or "8". (c) The accepted matches are labeled with their value ("0").</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. The three stages of bounding box inference. First, all the lines on the ballot are identified. Second, lines are extended and extraneous lines are removed. Third, boxes are formed.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table I . General information on elections processed with OpenCount. County Number of Ballots Number of Styles Number of Sides Image Resolution</head><label>I</label><figDesc></figDesc><table>Alameda 
1,374 
8 
1 
1460x2100 
Merced 
7,120 
1 
1 
1272x2100 
San Luis Obispo 
10,689 
27 
1 
1700x2200 
Stanislaus 
3,151 
1 
1 
1700x2800 
Ventura 
17,301 
1 
1 
1403x3000 
Madera 
3,757 
1 
1 
652x1480 
Marin 
29,121 
398 
1 
1280x2104 
Napa 
6,809 
11 
2 
1968x3530 
Santa Cruz 
34,004 
136 
2 
2400x3840 
Yolo 
35,532 
623 
1 
1744x2878 
Leon 
124,200 
216 
2 
1400x2328 
Orange 
294,402 
1,839 
1-3 
1715x2847 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table III .</head><label>III</label><figDesc></figDesc><table>Quarantined ballots requiring manual processing. For entries marked 
with a (*), we processed 10% and extrapolated the required time. 

County 
Version 
Number of 
Fraction of 
Total 
Quarantined Ballots Election Size 
Time 

Stanislaus 
2013 
1 
0.03% 
29s 
Merced 
2013 
1 
0.01% 
48s 
Ventura 
2013 
1 
0.01% 
8s 
Alameda 
2013 
191 
13.90% 
1h 4m 22s* 
SLO 
2013 
14 
0.13% 
5m 46s 
Madera 
2013 
0 
0.00% 
0s 
Napa 
2013 
16 
0.23% 
7m 23s 
Marin 
2013 
129 
0.44% 
1h 46m 10s* 
Santa Cruz 
2013 
163 
0.48% 
2h 16m 30s* 
Yolo 
2013 
60 
0.17% 
1h 35m 0s* 
Leon 
2013 
602 
0.48% 
8h 11m 34s* 
Orange 
2013 
192 
0.00065% 
4h 14m* 

</table></figure>

			<note place="foot">This work was supported by National Science Foundation under grants CNS-0524745 and CCF-0424422.</note>

			<note place="foot" n="1"> Previous versions of OpenCount required one (unmarked) blank ballot per ballot style.</note>

			<note place="foot" n="2"> For details, see: https://code.google.com/p/opencount/wiki/Barcodes</note>

			<note place="foot" n="3"> We discovered that Sequoia election machines interpret voting targets via a vertical scan line through the middle of the complete-the-arrow targets, allowing invariance to vertical translation. This is in contrast to other optical scan systems, where the location of voting targets within a ballot style is fixed-hence why this additional grouping step is required. For instance, in the Alameda election, the Chinese-language ballots sometimes have voting targets at a different location than the corresponding Spanish-language ballot, because the Chinese-language candidate names used more vertical space.</note>

			<note place="foot" n="4"> The operator identifies the location where the precinct number is printed on the ballot during attribute definition.</note>

			<note place="foot" n="5"> Note that this requires all N representatives within a single group to be aligned to each other.</note>

			<note place="foot" n="6"> We use Tesseract [Smith 2007] for this task. OpenCount does support multiple languages for this task. As Tesseract is able to interpret a range of languages, if the operator defines a &quot;language&quot; ballot attribute (Section 4.2.2), then OpenCount will interpret each ballot with the correct language. 7 The user interface displays the ballot image during the data entry process, making it easy for the user to notice such contests.</note>

			<note place="foot" n="8"> Exception: The previous version of OpenCount produced inaccurate results in one election, Napa, as described below.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>We thank the California Secretary of State's office and election officials at Stanislaus, Merced, Ventura, Alameda, San Luis Obispo, Madera, Marin, Napa, Santa Cruz, Yolo, Orange, and Leon counties for sharing scanned ballots, and Clear Ballot for their assistance with obtaining ballot scans. This research would not have been possible without their generous assistance. We thank Philip Stark for helpful guidance and Tom Stanionis for providing feedback on OpenCount.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Appendix</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Also, contests must be roughly box-shaped and be at least partially surrounded by lines on at least three sides. Furthermore, each contest must contain the contest title followed by a list of candidate names, with one voting target corresponding to each candidate</title>
	</analytic>
	<monogr>
		<title level="m">that the barcode uniquely determines ballot style</title>
		<imprint/>
	</monogr>
	<note>including write-in candidates 10</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">OpenCount does support ballot rotation: the ordering of the candidate names displayed within a contest is allowed to vary from ballot to ballot. 11 Voting targets may be any consistent structure that the voter is asked to mark. This includes the common &quot;fill-in-the-bubble&quot; and</title>
		<imprint/>
	</monogr>
	<note>fill-in-the-arrow&quot; styles</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">We used a spreadsheet file output by the Hart voting system that mapped precinct number to</title>
		<imprint/>
	</monogr>
	<note>ballot type&quot; to do the grouping -otherwise there would be 22,025 ballot styles. This was a pragmatic decision on our part, as we would prefer not to rely on files generated by the voting system</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">OpenCount does not attempt to interpret handwriting for write-in votes-it only records the presence of write-in votes</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Our current implementation assumes that only rotations of the candidates are possible, not arbitrary permutations. So far, we have not observed an election that violates this assumption. However, if necessary, it would be trivial to extend OpenCount to support arbitrary permutations using maximum-weighted matching</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Image segmentation by shape-directed covers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">S</forename><surname>Baird</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">E</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Fortune</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICPR</title>
		<meeting>ICPR</meeting>
		<imprint>
			<date type="published" when="1990" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="820" to="825" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">SOBA: Secrecy-preserving Observable Ballot-level Audits</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josh</forename><surname>Benaloh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douglas</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">L</forename><surname>Lazarus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Lindeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><forename type="middle">B</forename><surname>Stark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EVT/WOTE</title>
		<meeting>EVT/WOTE</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Two Geometric Algorithms for Layout Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">M</forename><surname>Breuel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of DAS</title>
		<meeting>DAS</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="188" to="199" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Machine-Assisted Election Auditing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><forename type="middle">A</forename><surname>Calandrino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Alex</forename><surname>Halderman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><forename type="middle">W</forename><surname>Felten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EVT</title>
		<meeting>EVT</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Efficient user-guided ballot image verification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arel</forename><surname>Cordero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theron</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keaton</forename><surname>Mowery</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Wagner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EVT/WOTE</title>
		<meeting>EVT/WOTE</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Saving throw: securing democracy with stats, spreadsheets, and 10-sided dice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cyrus</forename><surname>Farivar</surname></persName>
		</author>
		<ptr target="http://arstechnica.com/tech-policy/2012/07/saving-american-elections-with-10-sided-dice-one-stats-profs-quest/.(24" />
		<imprint>
			<date type="published" when="2012-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Pictorial Structures for Object Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pedro</forename><forename type="middle">F</forename><surname>Felzenszwalb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><forename type="middle">P</forename><surname>Huttenlocher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="page" from="55" to="79" />
			<date type="published" when="2005-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The Representation and Matching of Pictorial Structures. Computers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Fischler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Elschlager</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on C</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="67" to="92" />
			<date type="published" when="1973" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harri</forename><surname>Hursti</surname></persName>
		</author>
		<ptr target="http://vote.nist.gov/commentharrihursti.pdf" />
		<title level="m">Votoscope Software</title>
		<imprint>
			<date type="published" when="2005-10-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Los Angeles County: Statement of Votes Cast Election Results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">La-Registrar</forename></persName>
		</author>
		<ptr target="http://www.lavote.net/VOTER/PDFS/STATEMENTVOTESCAST/11062012SVC.pdf." />
	</analytic>
	<monogr>
		<title level="j">General Election</title>
		<imprint>
			<date type="published" when="2012-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Binary Codes Capable of Correcting Deletions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vi Levenshtein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Insertions and Reversals. Soviet Physics Doklady</title>
		<imprint>
			<biblScope unit="page">10</biblScope>
			<date type="published" when="1966" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Retabulations, Machine-Assisted Audits, and Election Verification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Lindeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronald</forename><forename type="middle">L</forename><surname>Rivest</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><forename type="middle">B</forename><surname>Stark</surname></persName>
		</author>
		<ptr target="http://www.stat.berkeley.edu/∼stark/Preprints/retabulation13.htm" />
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A Gentle Introduction to Risk-limiting Audits</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Lindeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><forename type="middle">B</forename><surname>Stark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Security and Privacy</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
	<note>Special Issue on Electronic Voting</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A Document Analysis System for Supporting Electronic Voting Research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Lopresti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Nagy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elisa</forename><forename type="middle">Barney</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of DAS</title>
		<meeting>DAS</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="167" to="174" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Some Methods for Classification and Analysis of MultiVariate Observations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Macqueen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the fifth Berkeley Symposium on Mathematical Statistics and Probability</title>
		<meeting>of the fifth Berkeley Symposium on Mathematical Statistics and Probability</meeting>
		<imprint>
			<date type="published" when="1967" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="281" to="297" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Document structure analysis algorithms: a literature survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Azriel</forename><surname>Rosenfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tapas</forename><surname>Kanungo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SPIE</title>
		<meeting>SPIE</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">5010</biblScope>
			<biblScope unit="page" from="197" to="207" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A Prototype Document Image Analysis System for Technical Journals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Nagy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharad</forename><surname>Seth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mahesh</forename><surname>Viswanathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="10" to="22" />
			<date type="published" when="1992-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Document Structure and Layout Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Anoop</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anil</forename><forename type="middle">K</forename><surname>Namboodiri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jain</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">An Overview of the Tesseract OCR Engine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">Barney</forename><surname>Elisa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Lopresti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nagy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICPR. R. Smith</title>
		<meeting>ICPR. R. Smith</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">02</biblScope>
			<biblScope unit="page" from="629" to="633" />
		</imprint>
	</monogr>
	<note>Proceedings of ICDAR</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Trachtenberg Election Verification System (TEVS)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitch</forename><surname>Trachtenberg</surname></persName>
		</author>
		<ptr target="https://code.google.com/p/tevs/" />
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Operator-assisted tabulation of optical scan ballots</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Motyashov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Wagner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EVT/WOTE</title>
		<meeting>EVT/WOTE</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Style-Based Ballot Mark Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pingping</forename><surname>Xiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Lopresti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henry</forename><surname>Baird</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Nagy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elisa</forename><forename type="middle">Barney</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICDAR</title>
		<meeting>ICDAR</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
