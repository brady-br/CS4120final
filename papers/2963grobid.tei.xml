<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2020-09-29T02:56+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Efficient Memory Mapped File I/O for In-Memory File Systems</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jungsik</forename><surname>Choi</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Sungkyunkwan University</orgName>
								<orgName type="institution" key="instit2">ATTO Research</orgName>
								<orgName type="institution" key="instit3">Sungkyunkwan University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwon</forename><surname>Kim</surname></persName>
							<email>jiwon.kim@atto-research.com</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Sungkyunkwan University</orgName>
								<orgName type="institution" key="instit2">ATTO Research</orgName>
								<orgName type="institution" key="instit3">Sungkyunkwan University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hwansoo</forename><surname>Han</surname></persName>
							<email>hhan@skku.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Sungkyunkwan University</orgName>
								<orgName type="institution" key="instit2">ATTO Research</orgName>
								<orgName type="institution" key="instit3">Sungkyunkwan University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Efficient Memory Mapped File I/O for In-Memory File Systems</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Recently, with the emergence of low-latency NVM storage , software overhead has become a greater bottleneck than storage latency, and memory mapped file I/O has gained attention as a means to avoid software overhead. However, according to our analysis, memory mapped file I/O incurs a significant amount of additional overhead. To utilize memory mapped file I/O to its true potential, such overhead should be alleviated. We propose map-ahead, mapping cache, and extended madvise techniques to maximize the performance of memory mapped file I/O on low-latency NVM storage systems. This solution can avoid both page fault overhead and page table entry construction overhead. Our experimental results show throughput improvements of 38-70% in microbenchmarks and performance improvements of 6-18% in real applications compared to existing memory mapped I/O mechanisms.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Although CPU performance has increased dramatically, the performance of storage systems has not improved as rapidly as their capacity. Even though CPUs can process data quickly, systems have bottlenecks due to storage devices latency, and this wasted time is the most significant component of overhead for data-intensive workloads. These days, the ever-increasing data-intensive nature of recent applications requires significant improvements in performance, and in-memory data processing has drawn attention because it can process workloads much faster by eliminating I/O overhead. In addition, techniques to ensure the durability of data in the main memory have been actively studied <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b20">21]</ref>. Recently, an increase in the use of non-volatile DIMMs (NVDIMMs) has begun to provide high-performance memory storage by integrating DRAM with battery-backed NAND flash memory <ref type="bibr" target="#b19">[20]</ref>. Emerging non-volatile memories (NVMs), including high-density STT-MRAM <ref type="bibr" target="#b8">[9]</ref>, have an almost equivalent ability to DRAM, and these are often considered to be suitable for the main memory in the future, even replacing DRAM <ref type="bibr" target="#b2">[3]</ref>. With the use of modern memory technology, it is possible to develop high-performance storage devices, such as Intel and Micron's 3D XPoint <ref type="bibr" target="#b13">[14]</ref>. The use of nextgeneration storage technologies will help remove almost all storage latency that has plagued conventional storage devices.</p><p>However, existing operating systems (OSs) have been designed to manage fast CPUs and very slow block devices. For this reason, their resource management mechanisms inefficiently manage low-latency NVM storage devices and fail to take advantage of the potential benefits of NVM devices <ref type="bibr" target="#b0">[1]</ref>. In fact, software overhead has been identified as a new dominating overhead to be solved in the systems equipped with low-latency NVM storage devices <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b21">22]</ref>. Software overhead includes complicated I/O stacks, redundant memory copies, and frequent user/kernel mode switches. Such overhead is currently small enough to be ignored, but will be the largest overhead soon when storage latencies are significantly reduced by using the NVDIMMs and NVMs.</p><p>To fully exploit high-performance next-generation NVM storage, researchers have proposed various NVMaware file systems <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b14">15]</ref> and system software <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b7">8]</ref>. In most of these studies, memory mapped file I/O has been commonly proposed to provide fast file accesses. Mapping a file onto user memory space with an mmap system call enables users to access the file directly in the same way as data on the memory. Therefore, it is possible to avoid the use of a complicated I/O stack for existing OSs, as well as user/kernel mode switches from read/write system calls. Consequently, this minimizes the occurrence of user/kernel mode switching. In addition, no data copies are needed between kernel space and user space, which consequently minimizes overhead. For these reasons, the mmap system call has a high likelihood to become a critical interface in the future <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b24">25]</ref>.</p><p>However, our analysis indicates that memory mapped file I/O can have a large software overhead, and this overhead comes from three sources. First, the overhead to map files to memory is much higher than expected. A detailed description is given in ยง2. Second, memory mapped file I/O requires a special msync to guarantee consistency in the files. However, the sophisticated techniques that have been studied so far are only available in certain file systems with a high overhead <ref type="bibr" target="#b29">[30]</ref> or can only be used in secondary storage systems <ref type="bibr" target="#b22">[23]</ref>. Third, memory mapped file I/O can not append new data at the end of the memory mapped files. To append data to a memory mapped file, you first need to resize the file with fallocate and then recreate the file mapping. This is an inefficient method that results in further overhead.  <ref type="table">(sec)   file access  page table entry construction</ref> page fault overhead <ref type="figure">Figure 1</ref>: Sequential access to a 4GB file on Ext4-DAX These problems must be addressed to use memory mapped file I/O on NVMs or NVDIMMs. In this paper, we address the first problem, reducing the page mapping overhead. The second and third problems will be addressed in future work. To reduce the memory mapping overhead, we present map-ahead, mapping cache, and extended madvise techniques. With these techniques, the performance of the memory mapped file I/O improves by up to 38%, 18%, and 70%, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Motivation</head><p>To analyze the overhead in memory mapped file I/O, we evaluate existing mmap mechanisms along with read system calls. Our evaluation is conducted on a Linux machine with 32GB DRAM and 32GB NVDIMM-N <ref type="bibr" target="#b19">[20]</ref>. We installed an Ext4-DAX <ref type="bibr" target="#b27">[28]</ref> file system through a PMEM driver on the NVDIMM-N. The Ext4-DAX simplifies the Ext4 file system to directly access memory storage, bypassing the page cache. The microbenchmark in our analysis sequentially reads a 4GB file in units of 4KB. Read, shown in <ref type="figure">Figure 1</ref>, is the case where the read system call is used to access the file. Default-mmap in <ref type="figure">Figure 1</ref> is the case where mmap is called without any special flags and populate-mmap in <ref type="figure">Figure 1</ref> is the case where mmap is called with the MAP POPULATE flag. When the MAP POPULATE flag is used, mmap constructs all page table entries for the entire file, whereas default-mmap relies on a page fault handler to construct a page table entry for the referred page (minor page fault). Thus, populatemmap may take longer, but subsequent accesses to the memory mapped file can proceed without page faults. This is called a prefault mechanism. <ref type="figure">Figure 1</ref> shows the result of our microbenchmark test. It is interesting to note is that the memory mapped file I/O is not so fast as expected, when compared to the read system call. Reading a 4GB file sequentially takes 1.06 seconds, 1.42 seconds, and 1.02 seconds for read, default-mmap, and populate-mmap, respectively. As for the memory mapped file I/O, the time take for file access (copy from mapped area to user buffer) accounts for only about 40% of the total time. The rest of the time is spent to prepare the file accesses. For the default-mmap, each access to a page causes a page fault, and 11% of the total time is spent to call the page fault handler (page fault overhead). In addition, the time spent in the file access are different for the default-mmap and populate-mmap. A huge difference in TLB misses is the main reason. In sequential accesses, the TLB page walker implemented in the MMU sophisticatedly prefetches TLB entries from the page table. For the populate-mmap, the page table entries are already there to prefetch, but they are not ready for default-mmap. Since both default-mmap and populatemmap require page mapping of a 4GB file, they take the same time for page table entry construction, which accounts for 45% and 62% of the whole execution time, respectively. This is absolutely necessary work to access the memory mapped files, but it is more expensive than the cost of the file access.</p><p>As shown in <ref type="figure">Figure 1</ref>, memory mapped file I/O still possesses a high overhead to construct page table entries. In traditional storage systems, this overhead was negligible, but not now. Relying on the page fault mechanism or populating entries for the whole file is not adequate, either. In this paper, we propose a couple of extensions to existing memory mapped file I/O to reduce the overhead involved in page table entry construction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Related Works</head><p>There have been studies to reduce the page fault overhead. A premapping scheme <ref type="bibr" target="#b6">[7]</ref> uses the hint files of the page fault history which is obtained from profiling runs. According to the experimental results, memory access patterns were quite random, and the result of the profile was required to predict the page faults.</p><p>PMFS <ref type="bibr" target="#b12">[13]</ref> proposed file mapping with the use of hugepage or MAP POPULATE flag. Compared to the use of the general page size, the use of hugepage requires a far smaller amount of page mapping, which greatly reduces the TLB misses and page faults. However, hugepage may lead to internal fragmentation and expensive copy-onwrite (CoW). CoW is a popular technique to protect data consistency. If several MBs or GBs need to be copied simply to update several bytes to perform CoW on huge pages, it causes too much overhead. In the case of the MAP POPULATE flag, constructing the page table entries for the entire file may be too much overhead, if only a partial contents of the file is accessed. According to the study on file system workload, large files tend to be accessed only partially <ref type="bibr" target="#b23">[24]</ref>. In addition, analytic research on the file access pattern of the network file system reveals that partially accessed files amount to 67% of all files <ref type="bibr" target="#b15">[16]</ref>. Therefore, the MAP POPULATE flag should be used only when a sufficient portion of the file will be accessed.</p><p>In a study on memory mapped file I/O <ref type="bibr" target="#b24">[25]</ref>, researchers proposed a modified page reclamation method that tries to reclaim pages from its own process. They also used vectored I/O for write operations of reclaimed pages. This method reduces context-switch overheads and results in a 92% performance improvement on DRAM-based SSDs. When data-intensive workloads are running, this technique will improve the performance of memory mapped file I/O.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Design</head><p>To take full advantage of memory mapped file I/O on lowlatency NVM storage devices, the following issues need to be addressed. First, the page fault overhead should be reduced while minimizing the prefault overhead. Existing method (MAP POPULATE) is not enough, since it still contains a prefault overhead. Second, the overhead in the page table entry construction needs to be reduced. In low-latency NVM systems, both are a serious burden on the whole system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Map-ahead</head><p>We have designed our map-ahead mechanism to reduce the page fault overhead and prefault overhead in memory mapped file I/O. Our map-ahead technique follows the same principle as the read-ahead mechanism, but we apply it to page table entry construction. All files are maintained in the main memory for in-memory file systems on NVM storage devices. Since the purpose of read-ahead is to bring data from the secondary storage to the main memory, this stage is no longer needed for in-memory file systems. Our map-ahead technique maps the pages that are expected to be accessed before page faults occur. The virtual memory system in our OS is managed using a demand-paging policy that was designed in the late 1960s when the amount of the main memory was scarce. Despite radical developments in computer systems, it is still used until now <ref type="bibr" target="#b4">[5]</ref>. Modern computer systems have a much larger amount of memory and can even operate with in-memory file systems, and this new environment necessitates a new approach. When a page fault occurs, a conventional page fault handler processes only the corresponding page. If page faults occur often to access memory mapped files, the switches between the user mode and kernel mode also frequently occur to invoke the page fault handler. In low-latency NVM systems, frequent mode switches require overhead. Thus, the page fault handler would rather process additional pages that are expected to be accessed soon.</p><p>With existing memory mapped file I/O, it is possible to access files with memory operations. The kernel simply manages the memory mapped files as a part of the process address space without considering the file access patterns. However, our map-ahead mechanism dynamically analyzes the page fault patterns to predict the pages that are to be accessed. If page faults occur on sequentially placed pages, it is reasonable to predict that the next page will be accessed. In this way, the page fault handler additionally processes the predicted pages to reduce the number of page faults. Moreover, if sequential page faults occur continuously, the map-ahead window size increases. The map-ahead window size is the number of pages that are processed together within a page fault. A bigger window size can be used to reduce the number of page faults. On the other hand, if page faults occur in random locations, the map-ahead window size decreases. If a random page fault repeats, the map-ahead window size will be reduced to one page. In our experiments in ยง5, the map-ahead window size is doubled when a sequential page fault occurs and is reduced by half when a random page fault occurs.</p><p>If a sequential page fault occurs continuously, the map-ahead window size becomes very large. The response time of the page fault handler will also become too long since the pages to process at one page fault pile up. Even though many pages should be dealt with at once, the whole performance can improve by returning the control early to the application. We designed an asynchronous map-ahead method to ensure a short response time of the page fault handler, and this also hides the overhead of the page table entry construction. With the asynchronous map-ahead mechanism, the page fault handler synchronously processes only pages that are required immediately and returns to the application context right away. The rest of the pages are processed asynchronously by kernel threads.</p><p>In </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Mapping cache</head><p>When munmap is called, the kernel releases the virtual memory area (VMA) to which the file is mapped and removes its corresponding page table entries. In traditional systems, it is reasonable to delete them immediately because the memory mapping overhead is negligible compared to the cost of data read from the secondary storage (such as HDDs). Moreover, they will be reclaimed soon from the main memory. However, the memory mapping overhead in NVM storage systems is a huge burden, and the file pages of in-memory file systems remain in the main memory. Thus, new management techniques If the kernel continues to allocate new VMAs but not releases them, the process's address space may become scarce even in 64-bit address space. The kernel checks the threshold whenever VMAs are cached in the mapping cache. If the total amount of cached VMAs exceeds the threshold, excess VMAs are released from the tail of the LRU list. Those are the oldest and presumably have the least chance of being used in the near future. In our experiments in ยง5, we experimented with two thresholds: 2GB and no-limit.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Extended madvise</head><p>The existing madvise system call allows a process to give advice to the kernel about the access pattern of the specific memory range. For example, if a process gives a hint to the kernel that a specific memory range will be accessed sequentially (MADV SEQUENTIAL), the kernel aggressively performs read-ahead on the given memory range. If the madvise is used suitably, the performance of the applications will be greatly improved. Since madvise mainly helps paging between the main memory and the secondary storage, it is unrelated to in-memory file systems.</p><p>We have extended the madvise system call to take advantage of user hints in the in-memory file systems. In our mechanism, if the kernel receives the MADV SEQUENTIAL or MADV WILLNEED hint, the kernel performs an asynchronous map-ahead on a given range. The map-ahead predicts the access patterns through page fault patterns, but if the extended madvise is used, the kernel can predict the access patterns without tracking the page fault patterns. In the case in which the kernel receives the MADV RANDOM hint, the kernel decreases the map-ahead window size to one. In the case the kernel receives the MADV DONTNEED hint, the VMA of the memory mapped file is not cached in the mapping cache. With these extensions to madvise, we can manage the memory-mapped file I/O more effectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Evaluation</head><p>Our experiments were performed on a system with an Intel Xeon E5-2620 Processor, running Linux kernel 4.4 extended with our techniques. The main memory and file system settings are the same as the one described in ยง2 (32GB DRAM, 32GB NVDIMM-N, Ext4-DAX file system on NVDIMM-N).</p><p>We measured the performance of map-ahead and extended madvise by using fio benchmark <ref type="bibr" target="#b3">[4]</ref>. It repeatedly reads a 4GB memory mapped file for 30 seconds in a single thread. <ref type="figure">Figure 2(a)</ref> shows the results of a sequential read. When the record size is 4KB, populate-mmap improves the bandwidth by 46%, compared to default-mmap. This is achieved by the reduced page faults; populatemmap makes about 13 thousand page faults, while defaultmmap does about 16 million. Map-ahead makes about 14 thousand page faults, which is slightly larger than populate-mmap, but the achieved bandwidth is far better than populate-mmap. Since the overhead of the page table entry construction is mostly hidden by asynchronous kernel threads, the bandwidth is improved by 38% from populate-mmap. Applications can provide file access pat- terns via the madvise system call. Fio benchmark also provides MADV SEQUENTIAL on sequential file I/Os to pass the kernel user hint. Our extended madvise technique is designed to perform an asynchronous map-ahead based on the user hint. Thus, it improves the performance further by 23%, compared to map-ahead technique, which is a 70% improvement compared to populate-mmap. The performance of map-ahead and extended madvise still improve for bigger record sizes <ref type="bibr">(8, 16, 32, 64KB)</ref>. <ref type="figure">Figure 2</ref>(b) shows the results of a random read. The performance of populate-mmap is the worst for random read. Random read only accesses a partial pages of files, but populate-mmap pays the overhead for all pages of the entire file. As the record size increases, the bandwidth of map-ahead increases due to short sequential page accesses within a record. Since fio benchmark invokes madvise with MADV RANDOM for random access, extended madvise shows nearly the same performance as default-mmap.</p><p>We used MongoDB <ref type="bibr" target="#b16">[17]</ref> with MMAPv1 to evaluate the performance of map-ahead and extended madvise. MMAPv1, which is a storage engine provided by MongoDB, is implemented with memory mapped file I/O. For the workload, we used a database load workload in YCSB benchmark suite <ref type="bibr" target="#b11">[12]</ref>. The load workload was used to insert data into MongoDB. The total data size is 20GB, which is a collection of multiple files with various sizes (64MB-2GB). <ref type="figure">Figure 2(c)</ref> shows the result of the YCSB load on MongoDB. Compared to default-mmap, mapahead and extended madvise improve the performance by 14% and 17%, respectively. Compared to populate-mmap, their improvements are 6% and 9%, respectively. One thing to note is that populate-mmap may cause a large latency for the load operation if it is the first load operation for a database file. Since populate-mmap possesses a prefault overhead at the beginning, the latency of the first load transaction tends to be large. As for map-ahead, the performance improvement is rather small, even if the access pattern of the load workload is completely sequential. Since the data was divided into multiple files, aggregated performance improvements become small overall.</p><p>We evaluate the performance of Apache HTTP server <ref type="bibr" target="#b1">[2]</ref> with mapping cache technique. The server executes an Apache HTTP server to get requests from clients. The server has 10 thousand 1MB-size HTML files obtained as copies of Wikipedia page. The total size is about 10GB. In this experiment, we used eight additional machines for the clients. Each machine contains an X5550 Xeon CPU and 64GB of DRAM. Ten client threads from eight machines make requests to the server simultaneously. Each client thread executes httperf, a testing tool used to measure web server performance <ref type="bibr" target="#b17">[18]</ref>. The httperf tool requests several URLs in order of appearance in a file which follows a zipf-like distribution. <ref type="figure" target="#fig_1">Figure 3</ref> shows the breakdown of the CPU cycles for five-minute runs of Apache HTTP server. In this experiment, mapping cache reduces the number of page faults by 31-51%. As a result, it reduces the overhead involved in the page fault and page table construction. While the portions labeled as libphp, libc, and other do not change much, the CPU cycles used in the kernel are greatly reduced by 24-35% on mapping-cache. Compared to populate-mmap, the overall performance is improved by 12% for mapping cache with a 2GB limit and by 18% for mapping cache without limit.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>The overhead in the software layer is becoming larger than the storage latency as low-latency NVM storage devices become available. The main reason is that existing OSs do not reflect the characteristics of them. Thus, memory mapped file I/O is receiving attention as a way to avoid software overhead. The memory mapped file I/O still incurs expensive additional overhead, and this is mainly caused by the fact that the current mechanism in memory mapped file I/O involves resource management mechanisms that are designed for slow block devices. To exploit the benefits of memory mapped file I/O on low-latency NVM storage devices, we propose map-ahead, mapping cache, and extended madvise techniques that can effectively alleviate the overhead of the mapping files. In our experiments, map-ahead improved the performance by up to 38% over the prefault method (populate-mmap) and an additional 23% performance improvement could be achieved by using extended madvise. In addition, mapping cache improved the performance by up to 18% compared to the prefault method (populate-mmap).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Performance of mapping-cache</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head></head><label></label><figDesc>the Linux kernel x86-64, a multi-level page table is used for address translation. An entry in the page middle directory (PMD) points to a page table. This page table is 4KB in size and can contain 512 page table entries (PTEs). A PTE finally points to a page frame. When updating a PTE, the page table where it belongs to is spin- locked. Thus, our map-ahead mechanism synchronously processes pages in the same page table. If pages belong to other page tables, they are handled asynchronously. When we have pages to process across multiple page tables, asynchronous map-ahead can be processed in parallel.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head></head><label></label><figDesc>are needed for in-memory file systems. We propose a mapping cache technique to minimize the overhead as- sociated with memory mapping by reusing page table entries. When munmap is called, our mechanism does not release VMAs. Instead, the kernel caches the VMAs in the mapping cache to reuse them later. The mapping cache consists of two parts: a hash table and a LRU list. When the VMAs are cached in the map- ping cache, the VMAs are added to the hash table and the LRU list, respectively. The hash table is used to quickly find the cached VMAs, where its hash key is generated with the file path. When mmap is called, the kernel checks if the VMA of the file requested for memory mapping exists in the mapping cache. If there is a reusable VMA, the kernel does not allocate a new VMA, but reuses the cached VMA and its page table entries. The LRU list is then used to release the cached but not used VMAs.</figDesc><table>0 
1 
2 
3 
4 
5 
6 
7 

4 
8 16 32 64 

(a) fio: Sequential Read 

Bandwidth (GB/s) 

Record Size (KB) 

0 

1 

2 

3 

4 

4 
8 16 32 64 

(b) fio: Random Read 

Bandwidth (GB/s) 

Record Size (KB) 

0 

2 

4 

6 

8 

10 

12 

Load 

(c) YCSB: Load 

Throughput (kops/s) 

Workload 

default-mmap 
populate-mmap 
map-ahead 
extended madvise 

Figure 2: Performance of map-ahead and extended madvise 

</table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">DCS: A Fast and Scalable Device-centric Server Architecture</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahn</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kwon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ajdari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kim</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 48th International Symposium on Microarchitecture</title>
		<meeting>the 48th International Symposium on Microarchitecture</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page">48</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Http</forename><surname>Apache</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Server</surname></persName>
		</author>
		<ptr target="https://httpd.apache.org/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Let&apos;s Talk About Storage &amp; Recovery Methods for Non-Volatile Memory Database Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arulraj</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pavlo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dulloor</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data</title>
		<meeting>the 2015 ACM SIGMOD International Conference on Management of Data</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>SIGMOD &apos;15</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Axboe</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Fio</surname></persName>
		</author>
		<ptr target="https://github.com/axboe/fio" />
		<title level="m">Flexible IO Tester</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Efficient Virtual Memory for Big Memory Servers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Basu</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gandhi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Swift</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th Annual International Symposium on Computer Architecture</title>
		<meeting>the 40th Annual International Symposium on Computer Architecture</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Providing Safe, User Space Access to Fast, Solid State Disks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caulfield</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Mollov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">I</forename><surname>Eisner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Coburn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Swanson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventeenth International Conference on Architectural Support for Programming Languages and Operating Systems</title>
		<meeting>the Seventeenth International Conference on Architectural Support for Programming Languages and Operating Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
	<note>ASPLOS XVII</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Page fault behavior and two prepaging schemes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cho</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cho</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference Proceedings of the 1996 IEEE Fifteenth Annual International Phoenix Conference on Computers and Communications</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
	<note>IPCCC &apos;96</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">In-memory file system with efficient swap support for mobile smart devices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Choi</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ryu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Consumer Electronics</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="page" from="275" to="282" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">4Gbit density STT-MRAM using perpendicular MTJ realized with compact cell structure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chung</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">W</forename><surname>Kishi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Yoshikawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">S</forename><surname>Nagase</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Sunouchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kanaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">C</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noma</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Yamamoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Tsuchida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">I</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Y</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">S</forename><surname>Chun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">S</forename><surname>Oyamatsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE International Electron Devices Meeting</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>IEDM &apos;16</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Nv-heaps: Making persistent objects fast and safe with next-generation, nonvolatile memories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Coburn</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Caulfield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Akel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Grupp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">M</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">K</forename><surname>Jhala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Swanson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixteenth International Conference on Architectural Support for Programming Languages and Operating Systems</title>
		<meeting>the Sixteenth International Conference on Architectural Support for Programming Languages and Operating Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
	<note>ASPLOS XVI</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Better I/O Through Byteaddressable, Persistent Memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Condit</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Nightingale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">B</forename><surname>Frost</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ipek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Burger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Coetzee</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename></persName>
		</author>
		<idno>SOSP &apos;09</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGOPS 22nd Symposium on Operating Systems Principles</title>
		<meeting>the ACM SIGOPS 22nd Symposium on Operating Systems Principles</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Benchmarking Cloud Serving Systems with YCSB</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cooper</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">F</forename><surname>Silberstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ramakrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sears</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st ACM Symposium on Cloud Computing</title>
		<meeting>the 1st ACM Symposium on Cloud Computing</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">System Software for Persistent Memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dulloor</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Keshavamurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lantz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sankaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jackson</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth European Conference on Computer Systems</title>
		<meeting>the Ninth European Conference on Computer Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Micron&amp;apos;s 3d Xpoint</forename><surname>Intel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Technology</surname></persName>
		</author>
		<ptr target="https://www.micron.com/about/our-innovation/3d-xpoint-technology" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">In-memory file system for non-volatile memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kim</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ryu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Research in Adaptive and Convergent Systems</title>
		<meeting>the 2013 Research in Adaptive and Convergent Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note>RACS &apos;13</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Measurement and Analysis of Large-scale Network File System Workloads</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leung</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">W</forename><surname>Pasupathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Goodson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>And Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">L</forename></persName>
		</author>
		<idno>ATC &apos;08</idno>
	</analytic>
	<monogr>
		<title level="m">USENIX 2008 Annual Technical Conference</title>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mongodb</surname></persName>
		</author>
		<ptr target="https://www.mongodb.org" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Httperf -a Tool for Measuring Web Server Performance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mosberger</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jin</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGMETRICS Performance Evaluation Review</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="31" to="37" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Whole-system Persistence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Narayanan</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hodson</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventeenth International Conference on Architectural Support for Programming Languages and Operating Systems</title>
		<meeting>the Seventeenth International Conference on Architectural Support for Programming Languages and Operating Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
	<note>ASPLOS XVII</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Netlist</forename><surname>Nvvault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ddr4</forename><surname>Nvdimm-N</surname></persName>
		</author>
		<ptr target="http://www.netlist.com/products/vault-memory-storage/nvvault-ddr4-nvdimm" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">The RAMCloud Storage System</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ousterhout</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gopalan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kejriwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Montazeri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ongaro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Rosenblum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rumble</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Stutsman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Computer Systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page">55</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Annual Update on Interfaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pappas</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
		<ptr target="https://www.flashmemorysummit.com/English/Collaterals/Proceedings/2014/20140805_U3_Pappas.pdf" />
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Failure-atomic msync(): A simple and efficient mechanism for preserving the integrity of durable data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Park</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th ACM European Conference on Computer Systems</title>
		<meeting>the 8th ACM European Conference on Computer Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A Comparison of File System Workloads</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roselli</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lorch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anderson</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">E</forename></persName>
		</author>
		<idno>ATC &apos;00</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Conference on USENIX Annual Technical Conference</title>
		<meeting>the Annual Conference on USENIX Annual Technical Conference</meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Efficient Memory-Mapped I/O on Fast Storage Device</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">Y</forename><surname>Son</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yeom</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">Y</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Storage</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">27</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Flexible File-system Interfaces to Storage-class Memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Volos</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Nalli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Panneerselvam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Varadarajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Saxena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Swift</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Aerie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth European Conference on Computer Systems</title>
		<meeting>the Ninth European Conference on Computer Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Lightweight Persistent Memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Volos</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Tack</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Swift</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mnemosyne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixteenth International Conference on Architectural Support for Programming Languages and Operating Systems</title>
		<meeting>the Sixteenth International Conference on Architectural Support for Programming Languages and Operating Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
	<note>ASPLOS XVI</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Add support for NV-DIMMs to ext4</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wilcox</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
		<ptr target="https://lwn.net/Articles/613384" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">SCMFS: A File System for Storage Class Memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">U</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>And Reddy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 2011 International Conference for High Performance Computing, Networking, Storage and Analysis</title>
		<meeting>2011 International Conference for High Performance Computing, Networking, Storage and Analysis</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A Log-structured File System for Hybrid Volatile/Non-volatile Main Memories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><forename type="middle">U</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Swanson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">14th USENIX Conference on File and Storage Technologies</title>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page">16</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">When Poll is Better than Interrupt</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Minturn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">B</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hady</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">10th USENIX Conference on File and Storage Technologies</title>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
