<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2020-09-29T02:54+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Retrofitted Parallelism Considered Grossly Sub-Optimal</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><forename type="middle">E</forename><surname>Mckenney</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Linux Technology Center IBM Beaverton</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Retrofitted Parallelism Considered Grossly Sub-Optimal</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Maze solving has been used as an example parallel-programming problem for some years. Suggested solutions are often based on a sequential program, using work queues to allow multiple threads to explore different portions of the maze concurrently. This paper analyzes such an implementation, but also explores an alternative implementation based on strategies long used by human maze solvers. This alternative implementation outperforms the conventional approach on average, and furthermore exhibits large superlinear speedups. The paper uses insights into the cause of these superlinear speedups to derive a faster sequential algorithm, and finally considers further implications and future work.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Labyrinths and mazes have been objects of fascination for millenia <ref type="bibr" target="#b14">[15]</ref>, so it should come as no surprise that they are generated and solved using computers, including biological computers <ref type="bibr" target="#b0">[1]</ref>, GPGPUs <ref type="bibr" target="#b5">[6]</ref>, and even discrete hardware <ref type="bibr" target="#b9">[10]</ref>. Parallel solution of mazes is sometimes used as a class project in universities <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b13">14]</ref> and as a vehicle to demonstrate the benefits of parallelprogramming frameworks <ref type="bibr" target="#b7">[8]</ref>.</p><p>Common advice is to use a parallel work-queue algorithm (PWQ) <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8]</ref>. This paper evaluates this advice by comparing PWQ against a sequential algorithm (SEQ) and also against an alternative parallel algorithm, in all cases solving randomly generated square mazes. Section 2 discusses PWQ, Section 3 discusses an alternative parallel algorithm, Section 4 analyzes its anomalous performance, Section 5 derives an improved sequential algorithm from the alternative parallel algorithm, Section 6 makes further performance comparisons, and finally Section 7 presents future directions and concluding remarks. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Work-Queue Parallel Maze Solver</head><p>PWQ is based on SEQ, which is shown in <ref type="figure">Figure 1</ref>. The maze is represented by a 2D array of cells and a lineararray-based work queue named -&gt;visited.</p><p>Line 7 visits the initial cell, and each iteration of the loop spanning lines 8-21 traverses passages headed by one cell. The loop spanning lines 9-13 scans the -&gt;visited[] array for a visited cell with an unvisited neighbor, and the loop spanning lines 14-19 traverses one fork of the submaze headed by that neighbor. Line 20 initializes for the next pass through the outer loop.</p><p>The pseudocode for maze try visit cell() is shown on lines 1-12 of <ref type="figure">Figure 2</ref>. Line 4 checks to see if cells c and n are adjacent and connected, while line 5 checks to see if cell n has not yet been visited. The celladdr() function returns the address of the specified cell. If either check fails, line 6 returns failure.  This approach does provide significant speedups on a dual-CPU Lenovo TM W500 running at 2.53GHz, as shown in <ref type="figure">Figure 4</ref>, which shows the cumulative distribution functions (CDFs) for the solution times of the two algorithms, based on the solution of 500 different square 500-by-500 randomly generated mazes. The substantial overlap of the projection of the CDFs onto the x-axis will be addressed in Section 4. Interestingly enough, the sequential solution-path tracking works unchanged for the parallel algorithm. However, this uncovers a significant weakness in the parallel algorithm: At most one thread may be making progress along the solution path at any given time. This weakness is addressed in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Alternative Parallel Maze Solver</head><p>Youthful maze solvers are often urged to start at both ends, and this advice has been repeated more recently in the context of automated maze solving <ref type="bibr" target="#b13">[14]</ref>. This advice amounts to partitioning, which has been a powerful parallelization strategy in the context of parallel programming for both operating-system kernels <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b8">9]</ref> and applications <ref type="bibr" target="#b12">[13]</ref>. This section applies this strategy, using two child threads that start at opposite ends of the solution path, and takes a brief look at the performance and scalability consequences.</p><p>The partitioned parallel algorithm (PART), shown in <ref type="figure" target="#fig_2">Figure 5</ref>, is similar to SEQ, but has a few important differences. First, each child thread has its own visited . Line 7 stores a pointer to this array into the per-thread variable myvisited to allow access by helper functions, and similarly stores a pointer to the local visit index. Second, the parent visits the first cell on each child's behalf, which the child retrieves on line 8. Third, the maze is solved as soon as one child locates a cell that has been visited by the other child. When maze try visit cell() detects this, it sets a -&gt;done field in the maze structure. Fourth, each child must therefore periodically check the -&gt;done field, as shown on lines 13, 18, and 23. The ACCESS ONCE() primitive must disable any compiler optimizations that might combine consecutive loads or that might reload the value. A C++1x volatile relaxed load suffices <ref type="bibr" target="#b3">[4]</ref>. Finally, the maze find any next cell() function must use compare-and-swap to mark a cell as visited, however no constraints on ordering are required beyond those provided by thread creation and join.</p><p>The pseudocode for maze find any next cell() is identical to that shown in <ref type="figure">Figure 2</ref>, but the pseudocode for maze try visit cell() differs, and is shown in   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Performance Comparison I</head><p>The first reaction to a performance anomaly is to check for bugs. Although the algorithms were in fact finding valid solutions, the plot of CDFs in <ref type="figure">Figure 7</ref> assumes independent data points. This is not the case: The performance tests randomly generate a maze, and then run all solvers on that maze. It therefore makes sense to plot the CDF of the ratios of solution times for each generated maze, as shown in <ref type="figure" target="#fig_5">Figure 8</ref>, greatly reducing the CDFs' overlap. This plot reveals that for some mazes, PART is more than forty times faster than SEQ. In contrast, PWQ is never more than about two times faster than SEQ. A forty-times speedup on two threads demands explanation. After all, this is not merely embarrassingly parallel, where partitionability means that adding threads does not increase the overall computational cost. It is instead humiliatingly parallel: Adding threads significantly reduces the overall computational cost, resulting in large algorithmic superlinear speedups. Further investigation showed that PART sometimes visited fewer than 2% of the maze's cells, while SEQ and PWQ never visited fewer than about 9%. The reason for this difference is shown by <ref type="figure">Figure 9</ref>. If the thread traversing the solution from the upper left reaches the circle, the other thread cannot reach the upper-right portion of the maze. Similarly, if the other thread reaches the square, the first thread cannot reach the lower-left portion of the maze. Therefore, PART will likely visit a small fraction of the non-solution-path cells. In short, the superlinear speedups are due to threads getting in each others' way. This is a sharp contrast with decades of experience with parallel programming, where workers have struggled to keep threads out of each others' way. The fraction of cells visited by PWQ is similar to that of SEQ. In addition, PWQ's solution time is greater than that of PART, even for equal visit fractions. The reason for this is shown in <ref type="figure">Figure 11</ref>, which has a red circle on each cell with more than two neighbors. Each such cell can result in contention in PWQ, because one thread can enter but two threads can exit, which hurts performance <ref type="bibr" target="#b10">[11]</ref>. In contrast, PART can incur such contention but once, namely when the solution is located. Of course, SEQ never contends.</p><p>Although PART's speedup is impressive, we should not neglect sequential optimizations. <ref type="figure">Figure 12</ref> shows that SEQ, when compiled with -O3, is about twice as fast as unoptimized PWQ, approaching the performance of unoptimized PART. Compiling all three algorithms with -O3 gives results similar to (albeit faster than) those shown in <ref type="figure" target="#fig_5">Figure 8</ref>, except that PWQ provides almost no speedup compared to SEQ, in keeping with Amdahl's Law <ref type="bibr" target="#b1">[2]</ref>. However, if the goal is to double performance Cache alignment and padding often improves performance by reducing false sharing. However, for these maze-solution algorithms, aligning and padding the maze-cell array degrades performance by up to 42% for 1000x1000 mazes. Cache locality is more important than avoiding false sharing, especially for large mazes. For smaller 20-by-20 or 50-by-50 mazes, aligning and padding can produce up to a 40% performance improvement for PART, but for these small sizes, SEQ performs better anyway because there is insufficient time for PART to make up for the overhead of thread creation and destruction.</p><p>In short, the partitioned parallel maze solver is an interesting example of an algorithmic superlinear speedup. If "algorithmic superlinear speedup" causes cognitive dissonance, please proceed to the next section. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Alternative Sequential Maze Solver</head><p>The presence of algorithmic superlinear speedups suggests simulating parallelism via co-routines, for example, manually switching context between threads on each pass through the main do-while loop in <ref type="figure" target="#fig_2">Figure 5</ref>. This context switching is straightforward because the context consists only of the variables c and vi: Of the numerous ways to achieve the effect, this is a good tradeoff between context-switch overhead and visit percentage. As can be seen in <ref type="figure" target="#fig_7">Figure 13</ref>, this coroutine algorithm (COPART) is quite effective, with the performance on one thread being within about 30% of PART on two threads. oretical energy-efficiency breakeven against COPART at roughly the 200-by-200 maze size, given that power consumption rises as roughly the square of the frequency for high frequencies <ref type="bibr" target="#b11">[12]</ref>, so that 1.4x scaling on two threads consumes the same energy as a single thread at equal solution speeds. In contrast, PWQ shows poor scalability against both SEQ and COPART unless unoptimized: <ref type="figure" target="#fig_2">Figures 14 and 15</ref> were generated using -O3. <ref type="figure" target="#fig_3">Figure 16</ref> shows the performance of PWQ and PART relative to COPART. For PART runs with more than two threads, the additional threads were started evenly spaced along the diagonal connecting the starting and ending cells. Simplified link-state routing <ref type="bibr" target="#b4">[5]</ref> was used to detect early termination on PART runs with more than two threads (the solution is flagged when a thread is connected to both beginning and end). PWQ performs quite poorly, but PART hits breakeven at two threads and again at five threads, achieving modest speedups beyond five threads. Theoretical energy efficiency breakeven is within the 90% confidence interval for seven and eight threads. The reasons for the peak at two threads are (1) the lower complexity of termination detection in the twothread case and (2) the fact that there is a lower probability of the third and subsequent threads making useful forward progress: Only the first two threads are guaranteed to start on the solution line. This disappointing performance compared to results in <ref type="figure" target="#fig_2">Figure 15</ref> is due to the less-tightly integrated hardware available in the larger and older Xeon R system running at 2.66GHz.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Performance Comparison II</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Future Directions and Conclusions</head><p>Much future work remains. First, this paper applied only one technique used by human maze solvers. Others include following walls to exclude portions of the maze and choosing internal starting points based on the locations of previously traversed paths. Second, different choices of starting and ending points might favor different algorithms. Third, although placement of the PART algorithm's first two threads is straightforward, there are any number of placement schemes for the remaining threads. Optimal placement might well depend on the starting and ending points. Fourth, study of unsolvable mazes and cyclic mazes is likely to produce interesting results. Fifth, the lightweight C++11 atomic operations might improve performance. Finally, for mazes, humiliating parallelism indicated a more-efficient sequential implementation using coroutines. Do humiliatingly parallel algorithms always lead to more-efficient sequential implementations, or are there inherently humiliatingly parallel algorithms for which coroutine context-switch overhead overwhelms the speedups? This paper demonstrated and analyzed parallelization of maze-solution algorithms. A conventional workqueue-based algorithm did well only when compiler optimizations were disabled, suggesting that some prior results obtained using high-level/overhead languages will be invalidated by advances in optimization.</p><p>This paper gave a clear example where approaching parallelism as a first-class optimization technique rather than as a derivative of a sequential algorithm paves the way for an improved sequential algorithm. High-level design-time application of parallelism is likely to be a fruitful field of study. This paper took the problem of solving mazes from mildly scalable to humiliatingly parallel and back again. It is hoped that this experience will motivate work on parallelism as a first-class design-time whole-application optimization technique, rather than as a grossly suboptimal after-the-fact micro-optimization to be retrofitted into existing programs.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Figure 1: SEQ Pseudocode</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :Figure 3 :Figure 4 :</head><label>234</label><figDesc>Figure 2: SEQ Helper Pseudocode</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Partitioned Parallel Solver Pseudocode</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 6 .</head><label>6</label><figDesc>Lines 8-9 check to see if the cells are con- nected, returning failure if not. The loop spanning lines 11-18 attempts to mark the new cell visited. Line 13 checks to see if it has already been visited, in which case line 16 returns failure, but only after line 14 checks to see if we have encountered the other thread, in which case line 15 indicates that the solution has been located. Line 19 updates to the new cell, lines 20 and 21 update this thread's visited array, and line 22 returns success. Performance testing revealed a surprising anomaly, shown in Figure 7. The median solution time for PART</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 :Figure 7 :</head><label>67</label><figDesc>Figure 6: Partitioned Parallel Helper Pseudocode</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: CDF of SEQ/PWQ and SEQ/PART SolutionTime Ratios</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 10 Figure 10 :</head><label>1010</label><figDesc>Figure 10: Correlation Between Visit Percentage and Solution Time</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 13 :</head><label>13</label><figDesc>Figure 12: Effect of Compiler Optimization (-O3)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 15 :</head><label>15</label><figDesc>Figure 14: Varying Maze Size vs. SEQ</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>FiguresFigure 16 :</head><label>16</label><figDesc>Figures 14 and 15 show the effects of varying maze size, comparing both PWQ and PART running on two threads against either SEQ or COPART, respectively, with 90%-confidence error bars. PART shows superlinear scalability against SEQ and modest scalability against COPART for 100-by-100 and larger mazes. PART exceeds the-</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>I owe thanks to Josh Triplett, Jonathan Walpole, and Cheedoong Drung for many interesting discussions, and to the anonymous referees for many helpful suggestions. I am indebted to Jim Wasko for his support of this effort.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Legal Statement</head><p>This work represents the views of the author and does not necessarily represent the view of IBM. Linux is a registered trademark of Linus Torvalds. Xeon is registered trademark of Intel Corporation or its subsidiaries in the United States, other countries, or both. Other company, product, and service names may be trademarks or service marks of such companies. Open-source code available at git://git.kernel.org/ pub/scm/linux/kernel/git/paulmck/perfbook.git.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Slime mould solves maze in one pass</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adamatzky</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1108.4956" />
		<imprint>
			<date type="published" when="2011-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Validity of the single processor approach to achieving large-scale computing capabilities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amdahl</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AFIPS Conference Proceedings</title>
		<meeting><address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="1967" />
			<biblScope unit="page" from="483" to="485" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">VLSI assist in building a multiprocessor UNIX system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beck</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kasten</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">USENIX Conference Proceedings</title>
		<meeting><address><addrLine>Portland, OR</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1985-06" />
			<biblScope unit="page" from="255" to="275" />
		</imprint>
	</monogr>
	<note>USENIX Association</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Working draft, standard for programming language C++</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Becker</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename></persName>
		</author>
		<ptr target="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2011/n3242.pdf" />
		<imprint>
			<date type="published" when="2011-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bertsekas</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gallager</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">Data</forename><surname>Networks</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1987" />
			<publisher>PrenticeHall, Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Aiding pathfinding with cellular automata</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ericson</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename></persName>
		</author>
		<ptr target="http://realtimecollisiondetection.net/blog/?p=57" />
		<imprint>
			<date type="published" when="2008-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Parallel solver for a perfect maze</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eth</forename><surname>Zurich</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Scalable multithreaded programming with tasks. MSDN Magazine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fosner</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename></persName>
		</author>
		<ptr target="http://msdn.microsoft.com/en-us/magazine/gg309176.aspx" />
		<imprint>
			<date type="published" when="2010-11" />
			<biblScope unit="page" from="60" to="69" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Implementing loosely coupled functions on tightly coupled engines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Inman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">USENIX Conference Proceedings</title>
		<meeting><address><addrLine>Portland, OR</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1985-06" />
			<biblScope unit="page" from="277" to="298" />
		</imprint>
	</monogr>
	<note>USENIX Association</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Memristor processor solves mazes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kfc</surname></persName>
		</author>
		<ptr target="http://www.technologyreview.com/blog/arxiv/26467/" />
		<imprint>
			<date type="published" when="2011-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Is Parallel Programming Hard, And, If So, What Can You Do About It? kernel</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mckenney</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">E</forename></persName>
		</author>
		<ptr target="http://kernel.org/pub/linux/kernel/people/paulmck/perfbook/perfbook.html" />
		<imprint>
			<date type="published" when="2010" />
			<pubPlace>org, Corvallis, OR, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">POWER: A first-class architectural design constraint</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mudge</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="52" to="58" />
			<date type="published" when="2000-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The trouble with multicore</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patterson</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Spectrum</title>
		<imprint>
			<biblScope unit="page" from="52" to="53" />
			<date type="published" when="2010-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Parallel maze solving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">University</forename><surname>Of Maryland</surname></persName>
		</author>
		<ptr target="http://www.cs.umd.edu/class/fall2010/cmsc433/p3/,Novem-ber2010" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wikipedia</forename><surname>Labyrinth</surname></persName>
		</author>
		<ptr target="http://en.wikipedia.org/wiki/Labyrinth" />
		<imprint>
			<date type="published" when="2012-01" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
