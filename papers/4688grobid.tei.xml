<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2020-09-29T04:28+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Fishy Faces: Crafting Adversarial Images to Poison Face Authentication</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giuseppe</forename><surname>Garofalo Imec-Distrinet</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">U</forename><surname>Leuven</surname></persName>
						</author>
						<title level="a" type="main">Fishy Faces: Crafting Adversarial Images to Poison Face Authentication</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>Vera Rimmer imec-DistriNet, KU Leuven Tim Van hamme imec-DistriNet, KU Leuven Davy Preuveneers imec-DistriNet, KU Leuven Wouter Joosen imec-DistriNet, KU Leuven</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Face recognition systems are becoming a prevalent au-thentication solution on smartphones. This work is the first to deploy a poisoning attack against an authentica-tion system based on a state-of-the-art face recognition technique. The attack is executed against the underlying SVM learning model that classifies face templates extracted by the FaceNet deep neural network. We demonstrate how an intelligent attacker can undermine the reliability of the authentication system through injecting a single intelligently crafted adversarial image to its training data. The most successful attacks within our evaluation framework trigger an authentication error of more than 50%. Our research illustrates the urge to evaluate and protect face authentication against adversarial machine learning.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The inspiring idea of using face as a biometric trait dates back to the 1960s. The first successful face recognition system was designed in the early 90's <ref type="bibr" target="#b23">[24]</ref>. The latest advances in artificial intelligence made such systems more resilient to light conditions, face orientation, poor image quality and other sources of distortion. These improvements have recently led to many of the major smartphone manufacturers incorporating the most advanced face recognition techniques as a phone unlock mechanism, e.g. Apple's Face ID (2017), Samsung Galaxy S8 (2017), OnePlus 5T (2017), LG G6 (2017) and others. As a result, face recognition is swiftly becoming a new smartphone security standard.</p><p>When a technique is considered for security purposes, it has to be thoroughly assessed in an adversarial setting. Since face as a biometric has gained enormous popularity, a lot of effort has been dedicated to development of anti-spoofing techniques <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b16">17]</ref>. However, spoofing is not the only attack vector in the landscape of attack possibilities. Machine learning (ML) algorithms driving these face recognition systems can themselves become an easy target. Adversarial ML research reveals how intelligent attackers can exploit vulnerabilities of the learning algorithms by carefully crafting malicious data samples <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b1">2]</ref>. As a result, the security of the whole system relying on the ML model is compromised. The lack of universal adaptive defense mechanisms makes Adversarial ML an alarming challenge. Moreover, due to the complexity and unpredictable nature of such attacks, it is hard to assess upfront the effect that adversarial inputs will have on a particular system. All this underlines the urge of evaluating modern face recognition systems against Adversarial ML.</p><p>In this work, we evaluate the security of a state-ofthe-art face recognition system in the presence of an intelligent adversary who aims to deny service to authentic users or let impostors bypass the system. More specifically, we perform a poisoning attack on an authenticator based on the open-source face recognition framework OpenFace <ref type="bibr" target="#b0">[1]</ref> extended with a Support Vector Machine (SVM) classifier. OpenFace implements the FaceNet <ref type="bibr" target="#b18">[19]</ref> deep neural network (DNN) that extracts identifying features from faces. These feature vectors, also called templates, can be classified using classical ML algorithms, such as SVMs. The poisoning attack requires some control over the training set of the classifier, as it implies a possibility for the attacker to inject a crafted malicious data point to the training data. Most face unlock systems on mobile phones will periodically retrain their authenticators on new images of the authentic user in order to adapt to changes in their appearance <ref type="bibr" target="#b0">1</ref> . This continuous learning process gives an opportunity for the attacker to add adversarial images to the training set and poison the system.</p><p>As a result, we present the first execution of a poisoning attack in the area of face recognition. We explore the practical feasibility of applying a poisoning attack the OpenFace framework. It learns a mapping function from a face image to a low-dimensional feature vector that characterizes a person's face in a way that is most meaningful for authentication. The framework uses the FaceNet CNN model <ref type="bibr" target="#b18">[19]</ref>. This network has a deep multi-layered structure and is pre-trained with thousands of labeled input images through backpropagation. The loss function that the FaceNet model optimizes during training is a Triplet Loss function that minimizes the distance between all face images of the same identity and at the same time maximizes the distance between face images from different identities. This enables the network to find such a template from the image to the feature space that not only maps faces of the same identity onto a single point in the feature space, but also enforces discriminability to other identities. The source of the FaceNet's feature extraction power is manifold, and we refer the reader to their technical report <ref type="bibr" target="#b18">[19]</ref> for the indepth description of the neural network architecture and training algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Linear One-class SVM Classifier</head><p>The final step of the face authentication system, shown most right in <ref type="figure">Figure 1</ref>, is classification of the image representations retrieved by the feature extractor. Depending on the authentication problem, this may be a multinomial, binary or one-class classification, in case of multiple known identities, two identities or one known user respectively. In our study, we are considering an authentication system deployed on a personal device, which means that the system will only authenticate one identity, that is, the owner of the device. Every image that does not belong to this identity should be denied by the system as authentication material.</p><p>The corresponding classification algorithm that underpins the authentication process for a specific identity is a one-class SVM. The basic SVM paradigm is developed for supervised binary classification on high-dimensional data and therefore suggests training the classifier on both positive and negative examples. However, in case of our authentication system, it is more meaningful to train the classifier only on one person's images in order to learn a facial pattern of one target identity. Training the SVM authenticator with only one person's images implies using solely positive examples for training. Oneclass SVM is an extension of the SVM methodology which handles training using only positive information, i.e. samples of only that one class that the model is aiming to learn. Such learning model is also more practical for an authenticator, as it does not require training images that belong to other identities who should be denied by the system. Even though neural networks are also fit for one-class classification, SVMs are generally less computationally intensive.</p><p>One-class SVM was first suggested by Schölkopf et al. <ref type="bibr" target="#b17">[18]</ref>. The problem that one-class SVM classifier solves is as follows: given a dataset with a probability distribution P in the feature space, find a subset S of the feature space such that the probability of a test point from P lying outside S is less than or equal to some a priori specified bounding value ν ∈ {0, 1}. The problem is solved by learning a decision function f that is positive on S and negative on the complement set S:</p><formula xml:id="formula_0">f (x) = 񮽙 +1 if x ∈ S −1 if x ∈ S</formula><p>In the context of our authentication system, let x 1 , x 2 , ..., x n be multidimensional real feature vectors derived from training images of the user that belong to one class X which is a compact subset of R N . The linear SVM first maps these vectors into a feature space H by applying a linear kernel transformation function:</p><formula xml:id="formula_1">Φ : X → H.</formula><p>After transforming the training data of the user to another space, the SVM separates the mapped vectors from the origin by maximizing the distance or margin in between. As a result, the origin of the feature space becomes a single, artificial member of the negative class, which is separated from the positive samples by a learned separation hyperplane (the decision function). According to <ref type="bibr">Schölkopf et al.'</ref>s definition <ref type="bibr" target="#b17">[18]</ref>, in order to find the hyperplane that maximizes the margin between the positive data points and the origin, the following problem needs to be solved:</p><formula xml:id="formula_2">min 1 2 񮽙w񮽙 2 + 1 νn n ∑ i=1 ξ i − ρ, subject to (w · Φ(x i )) ≥ ρ − ξ i i = 1, 2, ..., n ξ i ≥ 0</formula><p>If such w and ρ exist that solve the problem, then the resulting function is learned:</p><formula xml:id="formula_3">f (x) = sign((w · Φ(x)) − ρ)</formula><p>This decision function will be positive for most training points x i , namely, for approximately ν · l of them, as ν denotes an upper-bound to the fraction of training errors (as well as a lower-bound to the fraction of training samples that become support vectors of the model).</p><p>The SVM learning algorithm optimizes the hinge loss function that maximizes the margin. For a test point x with a real label t = ±1 and an output SVM prediction y = f (x), the hinge loss function is computed as L(y) = max(0, 1 − t · y). As a result, L(y) equals 0 for correct predictions (when t and y have the same sign), while incorrect predictions return linearly increasing losses with the increase of y.</p><p>The bounding ν-value is a high-impact hyperparameter of the SVM model, as in the end it defines how likely the model is to classify a test point x i ∈ X as a positive one and a test point y i / ∈ X as a negative one. Basically, this parameter reflects a trade-off between the usability and security of the system: a small ν-value would enforce a more strict acceptance criteria by the authentication system, while a bigger ν-value would make the system more flexible. As a result, lower values will cause a higher false positive rate (FPR) of the authenticator, whereas higher values will increase the false negative rate (FNR). Another influential hyperparameter is n, the number of training instances. The bigger the n-value, the more training images are used to train the authenticator, which makes it more likely that the training set is truly representative of the user's facial features. However, demanding more images to train the system makes it slower and less practical in use. Therefore, the ν and n values are design choices which affect the usability and security of the authenticator.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Threat Model</head><p>Our work considers a threat model based on a theoretical model of an attacker formalized by Biggio et al. <ref type="bibr" target="#b1">[2]</ref> in the context of adversarial pattern recognition. It requires to make certain assumptions regarding the attacker's goal, knowledge and capabilities.</p><p>Goal Potential attacks against ML algorithms aim at violation of integrity, availability or confidentiality of the ML-based system. This work focuses on violation of the integrity and availability of a target system being the face authenticator. The integrity is breached when an attacker can successfully impersonate a specific identity. Such attack's objective is to significantly increase the amount of false positives (FP): the number of impostors with forged authentication material that are accepted by the system. Availability is violated when an authentic user is no longer able to access the system (analogous to the denial-of-service). The objective then becomes to increase the amount of false negatives (FN). The goal of our developed attack methodology, presented in Section 4, is to achieve a significant accuracy drop of the system predictions which will result in high FP and FN rates and basically undermine the reliability of the authenticator. In order to do so, the adversary has to possess sufficient knowledge about the target system and certain skills.</p><p>Knowledge For a thorough security evaluation of MLbased authentication systems, it is essential to consider a perfectly knowledgeable attacker. That allows to avoid security by obscurity and sets the focus on security by design, a much more desirable approach to secure authentication that anticipates malicious practices. The attacker therefore knows the following aspects of the target system:</p><p>1. The feature extraction algorithm: he knows how the OpenFace framework works. He is able to perform the exact preprocessing and feature extraction steps just like implemented in the authenticator itself. 2. The decision algorithm and its hyperparameters, i.e. the attacker knows that a one-class SVM learning model is used for classification, and its corresponding hyperparameter ν. 3. The training data used to learn the decision function. He knows what images were used to train the one-class SVM.</p><p>Capabilities A poisoning attack can only be deployed by a very capable attacker, that is an attacker who can modify training data. More specifically, we assume an attacker who can add a single image to the training data. In order for the injected malicious image to poison the model, a retraining of the SVM model has to be performed. The attacker should not necessarily be able to force the retraining on the malicious data point. However, because most authenticators follow a continuous updating strategy to evolve along with the user's biometric changes, it appears realistic for an adversary to rely on the periodic retraining. Therefore, we assume that the adversary may inject a poisoning training sample and await the retraining to take place.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Face Poisoning</head><p>This section describes the attack methodology developed in our study. After providing the high-level algorithm for the attack, we dive into technical details of the most important stages: 1) the search for the attack point that allows to achieve the attack goal when it is added to the templates used for training; 2) the reverse feature mapping strategy that converts the desired attack point to the image of a face, such that it can be added to the training data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Attack Methodology</head><p>Here we outline the attack methodology step-by-step: underlying distribution, craft malicious samples against it and transfer them to the actual target model. With this technique, the attacker might not require full information about the classifier at the core of the target authentication system, or might even treat it as a black-box. As previous research suggests, such approach is applicable to SVM classifiers and demonstrates similar performance <ref type="bibr" target="#b15">[16]</ref>. The feasibility of using transferability for poisoning authentication systems can be assessed by using a substitute One-Class SVM classifier trained on images of the victim which do not overlap with the actual training set, but are separately acquired by an adversary. Currently, the Adversarial ML research is focusing on generalized transferability of evasion and targeted poisoning attacks, which should allow to weaken the attacker model <ref type="bibr" target="#b22">[23]</ref>.</p><p>The effectiveness of the attack is shown to be highly correlated to the SVM hyperparameter tuning. This underlies the importance of taking into account security when training models in sensitive contexts. For instance, a careful system designer would proactively defend the authenticator by considering higher ν values for smaller training set sizes. This concern is likely to arise in the earliest deployment stages of an authenticator, when only few user images are available to the system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Related Work</head><p>Machine learning algorithms are more and more deployed to tackle a variety of problems. However, as their adaptation grows, the impact of unexpected side effects increases, giving rise to the emerging Adversarial ML area. Naturally, such a security-sensitive and ML heavy application as face recognition has drawn efforts of the Adversarial ML researchers, resulting in a number of evasion attacks. Sharif et. al. <ref type="bibr" target="#b19">[20]</ref> present physically realizable white-box attacks against face recognition that allow to evade recognition or impersonate another individual through altering the test inputs. Other attacks by Sharif et. al. <ref type="bibr" target="#b20">[21]</ref> build on Generative Adversarial Networks <ref type="bibr" target="#b6">[7]</ref> which are specifically trained to generate adversarial samples for evasion. These works, even though successful, do not touch upon poisoning attacks: the authors consider an attacker who gains access to the system only after it had been trained, and therefore cannot inject samples or alter training data. Moreover, the related work does not extend face recognition to the more complex task of face authentication.</p><p>As one of the first prominent examples of poisoning attacks against SVM, one may consider the study by Xiao and Eckert <ref type="bibr" target="#b24">[25]</ref>. The authors introduce the label flip attack (that later has been extended by Biggio et al. <ref type="bibr" target="#b2">[3]</ref>), where they consider theoretical poisoning attacks against SVM. It is this attack that we execute in practice against a face authenticator.</p><p>Another poisoning attack targeting face templates has been developed by Biggio et al. <ref type="bibr" target="#b1">[2]</ref>. The difference with our work is that they perform classification through distance metrics, thus not applying a learning function. Furthermore, their attack is considered only for PCA based face-verification, whereas modern face templates are powered by deep neural networks, which pose new challenges for adversaries. Our research bridges this gap by considering a modern authentication system design based on both a deep neural network and an SVM model.</p><p>The biometrics community has been mainly occupied with investigating which privacy sensitive information can be extracted from biometric templates <ref type="bibr" target="#b11">[12]</ref>. Other work focused on ensuring that biometric data is not being spoofed and satisfies the liveliness check <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b16">17]</ref>. These authentication system aspects are not considered in our work, for we advocate a system design that can solely withstand the threat of poisoning attacks instead of merely relying on a secure entry point for the data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion</head><p>We showed that poisoning attacks pose a threat against modern face authentication systems. By injecting an adversarial sample in the training set, we were able to fully violate the integrity of the system. The most successful execution of the attack led to an authentication error of over 50%, rendering the face authentication system entirely useless. Additionally, we proposed a novel black-box strategy to construct an adversarial image that approximates a desired attack point in the feature space.</p><p>Our practical security evaluation showed the impact of design parameters on the resilience of the underlying machine learning model against poisoning attacks. This illustrates that the system designer has to consider both usability and security in adversarial settings.</p><p>We believe that adversarial machine learning endangers current authentication techniques, and we advocate thorough security evaluation and proactive defensive measures for future authentication systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Summary of the empirical results for</head><p>varying one-class SVM parameters   </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>1 . Obtain the images used for training, D tr .</head><label>1</label><figDesc></figDesc><table>These 
are pictures of the victim. Furthermore, the at-
tacker must acquire validation data, D val . This 
data consists of other images of the victim and 
images of other identities, i.e. the attacker identities 
(e.g. obtained through social media). 
2. Calculate the face templates using OpenFace. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>The mean false positive rate and standard 
deviation for varying parameters: ν and training set car-
dinality. The evaluation is performed over the validation 
set following the experimental protocol as defined in 
Section 5.2. The classification error is evaluated three 
times: before attack point injection, when injecting the 
image corresponding to the initial attack point, after 
performing the full attack. 

nu 
size initial FPR injection FPR attack FPR 

0.05 30 
0.71 ±0.86 7.52 ±1.56 
43.62 ±7.71 
0.05 50 
1.71 ±1.09 7.12 ±1.29 
37.16 ±4.24 
0.05 70 
1.89 ±0.85 5.97 ±3.16 
25.70 ±4.23 
0.05 90 
1.64 ±0.85 4.06 ±1.24 
16.17 ±2.05 
0.1 
30 
0.35 ±0.38 2.60 ±0.94 
22.91 ±4.87 
0.1 
50 
0.43 ±0.44 1.47 ±0.51 
8.70 ±2.72 
0.1 
70 
0.62 ±0.52 1.27 ±0.68 
4.60 ±1.34 
0.1 
90 
0.68 ±0.38 0.86 ±0.47 
3.17 ±0.96 
0.15 30 
0.51 ±0.63 1.65 ±1.11 
8.84 ±4.11 
0.15 50 
0.32 ±0.31 0.66 ±0.40 
2.35 ±1.52 
0.15 70 
0.28 ±0.30 0.57 ±0.38 
1.77 ±0.85 
0.15 90 
0.29 ±0.19 0.45 ±0.25 
1.16 ±0.72 
0.2 
30 
0.15 ±0.19 0.49 ±0.35 
2.34 ±2.84 
0.2 
50 
0.14 ±0.28 0.31 ±0.37 
0.76 ±1.17 
0.2 
70 
0.14 ±0.18 0.30 ±0.24 
0.50 ±0.80 
0.2 
90 
0.17 ±0.20 0.28 ±0.29 
0.45 ±0.57 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 : The mean classification error and</head><label>2</label><figDesc></figDesc><table>standard 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 : The mean classification error and</head><label>3</label><figDesc></figDesc><table>standard 
</table></figure>

			<note place="foot" n="1"> For instance, Apple&apos;s Face ID and Sensory&apos;s AppLock both feature automatic adaptation to changes in the user&apos;s appearance.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This research is partially funded by the Research Fund KU Leuven.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Openface: A general-purpose face recognition library with mobile applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amos</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ludwiczuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Satyanarayanan</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
		<idno>CMU-CS-16-118</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
		<respStmt>
			<orgName>CMU School of Computer Science</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Tech. rep</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Poisoning attacks to compromise face templates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Biggio</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Didaci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fumera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roli</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2013 International Conference on Biometrics (ICB)</title>
		<imprint>
			<date type="published" when="2013-06" />
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Poisoning attacks against support vector machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Biggio</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Nelson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laskov</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1206.6389</idno>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The OpenCV Library. Dr. Dobb&apos;s</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bradski</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Software Tools</title>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Idnet: Smartphone-based gait recognition with convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gadaleta</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rossi</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="page" from="25" to="37" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Biometric antispoofing methods: A survey in face recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Galbally</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Marcel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fierrez</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1530" to="1552" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Goodfellow</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bengio</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2672" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Explaining and harnessing adversarial examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Goodfellow</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Szegedy</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Explaining and harnessing adversarial examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Goodfellow</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Szegedy</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Dlib-ml: A machine learning toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">King</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">E</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="1755" to="1758" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Adversarial examples in the physical world</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurakin</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bengio</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Your substance abuse disorder is an open secret! gleaning sensitive personal information from templates in an eeg-based authentication system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matovu</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serwadda</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE 8th International Conference on Biometrics Theory, Applications and Systems (BTAS)</title>
		<imprint>
			<date type="published" when="2016-09" />
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A data-driven approach to cleaning large face datasets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">G</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">W</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Winkler</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2014 IEEE International Conference on Image Processing (ICIP)</title>
		<imprint>
			<date type="published" when="2014-10" />
			<biblScope unit="page" from="343" to="347" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Fingerprint liveness detection using convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nogueira</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">F</forename><surname>De Alencar Lotufo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Machado</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">C</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Forensics and Security</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1206" to="1213" />
			<date type="published" when="2016-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Practical black-box attacks against machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Papernot</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Mcdaniel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Celik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><forename type="middle">B</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Swami</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security</title>
		<meeting>the 2017 ACM on Asia Conference on Computer and Communications Security<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="506" to="519" />
		</imprint>
	</monogr>
	<note>ASIA CCS &apos;17, ACM</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Transferability in machine learning: from phenomena to blackbox attacks using adversarial samples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Papernot</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Mcdaniel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">D</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Goodfellow</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">J</forename></persName>
		</author>
		<idno>CoRR abs/1605.07277</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Secure face unlock: Spoof detection on smartphones</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patel</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jain</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Forensics and Security</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2268" to="2283" />
			<date type="published" when="2016-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Support vector method for novelty detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sch¨olkopfsch¨</forename><surname>Sch¨olkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Williamson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shawe-Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Platt</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th International Conference on Neural Information Processing Systems</title>
		<meeting>the 12th International Conference on Neural Information Processing Systems<address><addrLine>Cambridge, MA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1999" />
			<biblScope unit="page" from="582" to="588" />
		</imprint>
	</monogr>
	<note>NIPS&apos;99</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Facenet: A unified embedding for face recognition and clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Schroff</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Kalenichenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philbin</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="815" to="823" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Accessorize to a crime: Real and stealthy attacks on state-of-the-art face recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharif</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bhagavatula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>And Reiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">K</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security</title>
		<meeting>the 2016 ACM SIGSAC Conference on Computer and Communications Security</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1528" to="1540" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Adversarial generative nets: Neural network attacks on state-of-the-art face recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharif</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bhagavatula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>And Re-Iter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">K</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1801.00349</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Malicious pdf detection using metadata and structural features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Smutz</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stavrou</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th Annual Computer Security Applications Conference</title>
		<meeting>the 28th Annual Computer Security Applications Conference<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="239" to="248" />
		</imprint>
	</monogr>
	<note>ACSAC &apos;12, ACM</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">When does machine learning fail? generalized transferability for evasion and poisoning attacks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suciu</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Marginean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Iii</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">D</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dumitras</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename></persName>
		</author>
		<idno>CoRR abs/1803.06975</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Face recognition using eigenfaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Turk</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pentland</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">P</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings. 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition</title>
		<meeting>1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="1991-06" />
			<biblScope unit="page" from="586" to="591" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Adversarial label flips attack on support vector machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eckert</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th European Conference on Artificial Intelligence</title>
		<meeting>the 20th European Conference on Artificial Intelligence<address><addrLine>Amsterdam, The Netherlands, The Netherlands</addrLine></address></meeting>
		<imprint>
			<publisher>IOS Press</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="870" to="875" />
		</imprint>
	</monogr>
	<note>ECAI&apos;12</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
