<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2020-10-16T20:10+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Deep Investigation of Cross-Language Plagiarism Detection Methods</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date type="published" when="2017-08-03">August 3, 2017. 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jérémy</forename><surname>Ferrero</surname></persName>
							<email>jeremy.ferrero@imag.fr</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Besacier</surname></persName>
							<email>laurent.besacier@imag.fr</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Didier</forename><surname>Schwab</surname></persName>
							<email>didier.schwab@imag.fr</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frédéric</forename><surname>Agnès</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Compilatio</orgName>
								<address>
									<addrLine>276 rue du Mont Blanc</addrLine>
									<postCode>74540</postCode>
									<settlement>Saint-Félix</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="laboratory">LIG-GETALP Univ. Grenoble Alpes</orgName>
								<orgName type="institution">LIG-GETALP Univ. Grenoble Alpes</orgName>
								<address>
									<country>France, France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="laboratory">LIG-GETALP Univ. Grenoble Alpes</orgName>
								<orgName type="institution">Compilatio</orgName>
								<address>
									<addrLine>276 rue du Mont Blanc</addrLine>
									<postCode>74540</postCode>
									<settlement>Saint-Félix</settlement>
									<country>France, France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Deep Investigation of Cross-Language Plagiarism Detection Methods</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 10th Workshop on Building and Using Comparable Corpora</title>
						<meeting>the 10th Workshop on Building and Using Comparable Corpora <address><addrLine>Vancouver, Canada</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="6" to="15"/>
							<date type="published" when="2017-08-03">August 3, 2017. 2017</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>This paper is a deep investigation of cross-language plagiarism detection methods on a new recently introduced open dataset, which contains parallel and comparable collections of documents with multiple characteristics (different genres, languages and sizes of texts). We investigate cross-language plagiarism detection methods for 6 language pairs on 2 granu-larities of text units in order to draw robust conclusions on the best methods while deeply analyzing correlations across document styles and languages.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Plagiarism is a very significant problem nowadays, specifically in higher education institutions. In monolingual context, this problem is rather well treated by several recent researches <ref type="bibr">(Pot- thast et al., 2014</ref>). Nevertheless, the expansion of the Internet, which facilitates access to documents throughout the world and to increasingly efficient (freely available) machine translation tools, helps to spread cross-language plagiarism. Crosslanguage plagiarism means plagiarism by translation, i.e. a text has been plagiarized while being translated (manually or automatically). The challenge in detecting this kind of plagiarism is that the suspicious document is no longer in the same language of its source. In this relatively new field of research, no systematic evaluation of the main methods, on several language pairs, for different text granularities and for different text genres, has been proposed yet. This is what we propose in this paper.</p><p>Contribution. The paper focus is on crosslanguage semantic textual similarity detection which is the main part (with source retrieval) in cross-language plagiarism detection. The evaluation dataset used <ref type="bibr" target="#b8">(Ferrero et al., 2016</ref>) allows us to run a large amount of experiments and analyses. To our knowledge, this is the first time that full potential of such a diverse dataset is used for benchmarking. So, the paper main contribution is a systematic evaluation of cross-language similarity detection methods (using in plagiarism detection) on different languages, sizes and genres of texts through a reproducible evaluation protocol. Robust conclusions are derived on the best methods while deeply analyzing correlations across document styles and languages. Due to space limitations, we only provide a subset of our experiments in the paper while more result tables and correlation analyses are provided as supplementary material on a Web link <ref type="bibr">1</ref> .</p><p>Outline. After presenting the dataset used for our study in section 2, and reviewing the stateof-the-art methods of cross-language plagiarism detection that we evaluate in section 3, we describe the evaluation protocol employed in section 4. Then, section 5.1 presents the correla-tion of the methods across language pairs, while section 5.2 presents a detailed analysis on only English-French pair. Finally, section 6 concludes this work and gives a few perspectives.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Dataset</head><p>The reference dataset used during our study is the new dataset 2 recently introduced by <ref type="bibr" target="#b8">Ferrero et al. (2016)</ref>. The dataset was specially designed for a rigorous evaluation of cross-language textual similarity detection. The different characteristics of the dataset are synthesized in <ref type="table">Table 1</ref>, while Table 2 presents the number of aligned units by subcorpus and by granularity.</p><p>More precisely, the characteristics of the dataset are the following:</p><p>• it is multilingual: it contains French, English and Spanish texts;</p><p>• it proposes cross-language alignment information at different granularities: document level, sentence level and chunk level;</p><p>• it is based on both parallel and comparable corpora (mix of Wikipedia, scientific conference papers, amazon product reviews, Europarl and JRC);</p><p>• it contains both human and machine translated texts;</p><p>• it contains different percentages of named entities;</p><p>• part of it has been obfuscated (to make the cross-language similarity detection more complicated) while the rest remains without noise;</p><p>• the documents were written and translated by multiple types of authors (from average to professionals);</p><p>• it covers various fields.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Overview of State-of-the-Art Methods</head><p>Textual similarity detection methods are not exactly methods to detect plagiarism. Plagiarism is a statement that someone copied text deliberately without attribution, while these methods only detect textual similarities. There is no way 2 https://github.com/FerreroJeremy/ Cross-Language-Dataset of knowing why texts are similar and thus to assimilate these similarities to plagiarism.</p><p>At the moment, there are five classes of approaches for cross-language plagiarism detection. The aim of each method is to estimate if two textual units in different languages express the same message or not. <ref type="figure">Figure 1</ref> presents a taxonomy of <ref type="bibr" target="#b17">Potthast et al. (2011)</ref>, enriched by the study of <ref type="bibr" target="#b7">Danilova (2013)</ref>, of the different cross-language plagiarism detection methods grouped by class of approaches. We only describe below the state-of-the-art methods that we evaluate in the paper, one for each class of approaches (those in bold in the <ref type="figure">Figure 1</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Cross-Language</head><p>Character N-Gram (CL-CnG) is based on <ref type="bibr" target="#b13">Mcnamee and Mayfield (2004)</ref> model. We use the CL-C3G Potthast et al. (2011)'s implementation. Only spaces and alphanumeric characters are kept. Any other diacritic or symbol is deleted and the texts are lower-cased. The texts are then segmented into 3-grams (sequences of 3 contiguous characters) and transformed into tf.idf vectors of character 3-grams. The metric used to compare two vectors is the cosine similarity.</p><p>Cross-Language Conceptual Thesaurus-based Similarity (CL-CTS) aims to measure the semantic similarity using abstract concepts from words in textual units. We reuse the idea of Pataki (2012) which, for each sentence, build a bag-ofwords by getting all the available translations of each word of the sentence. For that, we use a linked lexical resource called DBNary <ref type="bibr">(Sérasset, 2015)</ref>. The bag-of-words of a sentence is the merge of the bag-of-words of the words of the sentence. After, we use the Jaccard distance <ref type="bibr" target="#b11">(Jaccard, 1912)</ref> with fuzzy matching between two bag-ofwords to measure the similarity between two sentences.</p><p>Cross-Language Alignment-based Similarity Analysis (CL-ASA) was introduced for the first time by <ref type="bibr" target="#b2">Barrón-Cedeño et al. (2008)</ref> and developed subsequently by <ref type="bibr" target="#b16">Pinto et al. (2009)</ref>. The model aims to determinate how a textual unit is potentially the translation of another textual unit using bilingual unigram dictionary which contains translations pairs (and their probabilities) extracted from a parallel corpus. Our lexical dictionary is calculated applying the IBM-1 model   Cross-Language Explicit Semantic Analysis (CL-ESA) is based on the explicit semantic analysis model introduced for the first time by <ref type="bibr" target="#b10">Gabrilovich and Markovitch (2007)</ref>, which represents the meaning of a document by a vector based on the vocabulary derived from Wikipedia, to find a document within a corpus. It was reused by <ref type="bibr">Pot- thast et al. (2008)</ref> in the context of cross-language document retrieval. Our implementation uses a part of Wikipedia, from which our test data was removed, to build the vector representations of the texts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Translation + Monolingual Analysis (T+MA)</head><p>consists in translating suspect plagiarized text back into the same language of source text, in order to operate a monolingual comparison between them. We use the <ref type="bibr" target="#b14">Muhr et al. (2010)</ref>'s implementation which consists in replacing each word of one text by its most likely translations in the language of the other text, leading to a bags-of-words. We use DBNary <ref type="bibr">(Sérasset, 2015)</ref> to get the translations. The metric used to compare two texts is a monolingual matching based on strict intersection of bags-of-words.</p><p>More recently, <ref type="bibr">SemEval-2016</ref><ref type="bibr" target="#b0">(Agirre et al., 2016</ref> proposed a new subtask on evaluation of cross-lingual semantic textual similarity. Despite the fact that it was the first year that this subtask was attempted, there were 26 submissions from 10 teams. Most of the submissions relied on a machine translation step followed by a monolingual semantic similarity, but 4 teams tried to use learned vector representations (on words or sentences) combined with machine translation confidence (for instance the submission of <ref type="bibr" target="#b12">Lo et al. (2016)</ref> or <ref type="bibr" target="#b1">Ataman et al. (2016)</ref>). The method that achieved the best performance (Brychcin and Svoboda, 2016) was a supervised system built on a word alignment-based method proposed by <ref type="bibr" target="#b22">Sultan et al. (2015)</ref>. This very recent method is, however, not evaluated in this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Evaluation Protocol</head><p>We apply the same evaluation protocol as in <ref type="bibr">Fer- rero et al. (2016)</ref>'s paper. We build a distance matrix of size N x M , with M = 1,000 and N = |S| where S is the evaluated sub-corpus. Each textual unit of S is compared to itself (actually, since this is cross-lingual similarity detection, each source language unit is compared to its corresponding unit in the target language) and to M -1 other units randomly selected from S. The same unit may be selected several times. Then, a matching score for each comparison performed is obtained, leading to the distance matrix. Thresholding on the matrix is applied to find the threshold giving the best F 1 score. The F 1 score is the harmonic mean of precision and recall. Precision is defined as the proportion of relevant matches (similar crosslanguage units) retrieved among all the matches retrieved. Recall is the proportion of relevant matches retrieved among all the relevant matches to retrieve. Each method is applied on each subcorpus for chunk and sentence granularities. For each configuration (i.e. a particular method applied on a particular sub-corpus considering a particular granularity), 10 folds are carried out by changing the M selected units.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Investigation of Cross-Language</head><p>Similarity Performances <ref type="table" target="#tab_4">Table 3</ref> brings together the performances of all methods on all sub-corpora for each pair of languages at chunk and sentence level. In both subtables, at chunk and sentence level, the overall F 1 score over all sub-corpora of one method in one particular language pair is given.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Across Language Pairs</head><p>As a preliminary remark, one should note that CL-C3G and CL-ESA lead to the same results for a given language pair (same performance if we reverse source and target languages) due to their symmetrical property. Another remark we can make is that methods are consistent across language pairs: best performing methods are mostly the same, whatever the language pair considered. This is confirmed by the calculation of the Pearson correlation between performances of different pairs of languages, from <ref type="table" target="#tab_4">Table 3</ref> and reported in <ref type="table">Table 4</ref>. <ref type="table">Table 4</ref> represents the Pearson correlations between the different language pairs of the overall results of all methods on all sub-corpora. This result is interesting because some of these methods depend on the availability of lexical resources whose quality is heterogeneous across languages. Despite the variation of the source and target languages, a minimum Pearson correlation of 0.940 for EN→FR vs. FR→ES, and a maximum of 0.998 for EN→FR vs. EN→ES and ES→FR vs. FR→ES at chunk level is observed (see <ref type="table">Ta- ble 4</ref>). For the sentence granularity, it is the same order of magnitude: the maximum Pearson correlation is 0.997 for ES→EN vs. EN→ES and ES→FR vs. FR→ES, and the minimum is 0.913 for EN→ES vs. FR→ES (see <ref type="table">Table 4</ref>). In average the language pair EN→FR is 0.975 correlated with the other language pairs (0.980 at chunk-level and 0.971 at sentence-level), for instance. This correlation suggests the possibility to tune a method on one language and apply it to another language if needed.  <ref type="table" target="#tab_4">Tables 3 and 4</ref>. No matter the source and target languages or the granularity, CL-C3G generally outperforms the other methods. Then CL-ASA, CL-CTS and T+MA are also closely efficient but their behavior depends on the granularity. Generally, CL-ASA is better at the chunk granularity, followed by CL-CTS and T+MA. On the contrary, CL-CTS and T+MA are slightly more effective at sentence granularity. One explanation for this is that T+MA depends on the quality of machine translation, which may have poor performance on isolated chunks, while a short length text unit benefits the CL-CTS and CL-ASA methods because of their formula which   <ref type="table">Table 4</ref>: Pearson correlations of the overall F 1 score over all sub-corpora of all methods between the different language pairs (EN: English; FR: French; ES: Spanish).</p><p>will tend to minimize the number of false positives in this case. Anyway, despite these differences in ranking, the gap in term of performance values is small between these closest methods. For instance, we can see that when CL-CTS is more efficient than CL-C3G (ES→FR column at sentence level in <ref type="table" target="#tab_2">Table 3 and Table 5</ref> (b)), the difference of performance is very small (0.0068). <ref type="table" target="#tab_8">Table 6</ref> shows the Pearson correlations of the results (of all methods on all sub-corpora) by language pair between the chunk and the sentence granularity (correlations calculated from <ref type="table" target="#tab_4">Table 3</ref>, between the EN→FR column at chunk level with the EN→FR column at sentence level, and so on). We can see a strong Pearson correlation of the performances on the language pair between the chunk and the sentence granularity (an average of 0.9, with 0.907 for the EN→FR pair, for instance). This proves that all methods behave along a simi-     <ref type="table">Table 7</ref>: Pearson correlations of the results on all sub-corpora on all language pairs, between the chunk and the sentence granularity, by methods (calculated from <ref type="table" target="#tab_4">Table 3</ref>). and sentence granularity performances (correlations also calculated from <ref type="table" target="#tab_4">Table 3</ref>, between the CL-C3G line at chunk level with the CL-C3G line at sentence level, and so on), we notice that some methods exhibit a different behavior at both chunk and sentence granularities: for instance, this is the case for CL-ASA which seems to be really better at chunk level. In conclusion, we can say that the methods presented here may behave slightly differently depending on the text unit considered (chunk or sentence) but they behave practically the same no matter the languages of the compared texts are (as long as enough lexical resources are available for dealing with these languages).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Detailed Analysis for English-French</head><p>The previous sub-section has shown a consistent behavior of methods across language pairs (strongly consistent) and granularities (less strongly consistent). For this reason, we now propose a detailed analysis for different sub-corpora, for the English-French language pair -at chunk and sentence level -only. Providing these results for all language pairs and granularities would take too much space. Moreover, we also run those state-of-the-art methods on the dataset of the Spanish-English cross-lingual Semantic Textual Similarity task of <ref type="bibr">SemEval-2016</ref><ref type="bibr" target="#b0">(Agirre et al., 2016</ref> and <ref type="bibr">SemEval-2017</ref><ref type="bibr" target="#b5">(Cer et al., 2017</ref>, and propose a shallower but equally rigorous analysis. However, all those results are also made available as supplementary material on our paper Web page. <ref type="table" target="#tab_7">Table 8</ref> shows the performances of methods on the EN→FR sub-corpora. As mentioned earlier, CL-C3G is in general the most effective method. CL-ESA seems to show better results on comparable corpora, like Wikipedia. In contrast, CL-ASA obtains better results on parallel corpora such as JRC or Europarl collections. CL-CTS and T+MA are pretty efficient and versatile too. It is also interesting to note that the results of the methods are well correlated between certain types of sub-corpora. For instance, the Pearson correlation of the performances of all methods between the TALN sub-corpus and the APR sub-corpus, is 0.982 at the chunk level, and 0.937 at the sentence level. This means that a method could be optimized on a particular corpus (for instance APR) and applied efficiently on another corpus (for instance TALN which is made of scientific conference papers). Figure 2: Distribution histograms of some state-of-the-art methods for 1000 positives and 1000 negatives (mis)matches. X-axis represents the similarity score (in percentage) computed by the method, and Y-axis represents the number of (mis)matches found for a given similarity score. In white, in the upper part of the figures, the positives (units that needed to be matched), and in black, in the lower part, the negatives (units that should not be matched).</p><p>Beyond their capacity to correctly predict a (mis)match, an interesting feature of the methods is their clustering capacity, i.e. their ability to correctly separate the positives (cross-lingual semantic textual similar units) and the negatives (textual units with different meaning) in order to minimize  <ref type="table" target="#tab_3">Table 9</ref>: Precision (P), Recall (R) and F 1 score, reached at a certain threshold (T), of some stateof-the-art methods for a data subset made with 1000 positives and 1000 negatives (mis)matches -10 folds validation.</p><p>the doubts on the classification. To verify this phenomenon, we conducted another experience with a new protocol. We built a data subset by concatenating some documents of the previously presented dataset <ref type="bibr" target="#b8">(Ferrero et al., 2016)</ref>. More precisely we used 200 pairs of each sub-corpora at sentence level only. We compared 1000 English textual units to their corresponding unit in French, and to one other (not relevant) French unit. So, each English textual unit must strictly leads to one match and one mismatch, i.e. in the end, we have exactly 1000 matches and 1000 mismatches for a run. We repeat this experiment 10 times for each method, leading to 10 folds for each method.</p><p>The results of this experiment are reported on <ref type="table" target="#tab_3">Table 9</ref>, that shows the average for the 10 folds of the Precision (P), the Recall (R) and the F 1 score of some state-of-the-art methods, reached at a certain threshold (T). The results are also reported in <ref type="figure">Figure 2</ref>, in the form of distribution histograms of the evaluated methods for 1000 positives and 1000 negatives (mis)matches. X-axis represents the similarity score (in percentage) computed by the method, and Y-axis represents the number of (mis)matches found for a given similarity score. In white, in the upper part of the figures, the positives (units that needed to be matched), and in black, in the lower part, the negatives (units that should not be matched).</p><p>Distribution histograms on <ref type="figure">Figure 2</ref> highlights the fact that each method has its own fingerprint: even if two methods looks equivalent in term of performances (see <ref type="table" target="#tab_3">Table 9</ref>), their clustering capacity, and so the distribution of their (mis)matches can be different. For instance, we can see that a random distribution is a very bad distribution <ref type="figure">(Figure 2 (a)</ref>). We can also see that CL-C3G has a narrow distribution of negatives and a broad distribution for positives <ref type="figure">(Figure 2 (c)</ref>), whereas the opposite is true for CL-ASA <ref type="figure">(Figure 2 (e)</ref>). <ref type="table" target="#tab_3">Table 9</ref> confirms this phenomenon by the fact that the decision threshold is very different for CL-ASA (0.762) compared to the other methods (around 0.1). This means that CL-ASA discriminates more correctly the positives that the negatives, when it seems to be the opposite for the other methods. For this reason, we can make the assumption that some methods are complementary, due to their different fingerprint. These behaviors suggest that fusion between these methods (notably decision tree based fusion) should lead to very promising results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We conducted a deep investigation of crosslanguage plagiarism detection methods on a challenging dataset. Our results have shown a common behavior of methods across different language pairs. We revealed strong correlations across languages but also across text units considered. This means that when a method is more effective than another on a sufficiently large dataset, it is generally more effective in any other case. This also means that if a method is efficient on a particular language pair, it will be similarly efficient on another language pair as long as enough lexical resources are available for these languages.</p><p>We also investigated the behavior of the methods through the different types of texts on a particular language pair: English-French. We revealed strong correlations across types of texts. This means that a method could be optimized on a particular corpus and applied efficiently on another corpus.</p><p>Finally, we have shown that methods behave differently in clustering match and mismatched units, even if they seem similar in performance. This opens new possibilities for their combination or fusion.</p><p>More results supporting these facts are provided as supplementary material 6 .</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>MT</head><label></label><figDesc>Figure 1: Taxonomy of Potthast et al. (2011), enriched by the study of Danilova (2013), of different approaches for cross-language similarity detection.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>(</head><label></label><figDesc>a) Distribution histogram (fingerprint) of a random distribu- tion. (b) Distribution histogram (fingerprint) of the Length Model of Pouliquen et al. (2003). (c) Distribution histogram (fingerprint) of CL-C3G. (d) Distribution histogram (fingerprint) of CL-CTS. (e) Distribution histogram (fingerprint) of CL-ASA. (f) Distribution histogram (fingerprint) of T+MA.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Number of aligned documents, sentences and noun chunks by sub-corpus. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 5 synthesizes</head><label>5</label><figDesc>the top 3 methods for each language pair observed in</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>9</head><label>9</label><figDesc></figDesc><table>Chunk level 
Methods EN→FR FR→EN EN→ES ES→EN ES→FR FR→ES 
CL-C3G 
0.5071 
0.5071 
0.4375 
0.4375 
0.4795 
0.4795 
CL-CTS 
0.4250 
04116 
0.3780 
0.3881 
0.4203 
0.4169 
CL-ASA 0.4738 
0.4252 
0.4083 
0.3941 
0.3736 
0.3540 
CL-ESA 
0.1499 
0.1499 
0.1476 
0.1476 
0.1520 
0.1520 
T+MA 
0.3730 
0.3634 
0.3177 
0.3279 
0.3158 
0.3140 
Sentence level 
Methods EN→FR FR→EN EN→ES ES→EN ES→FR FR→ES 
CL-C3G 
0.4931 
0.4931 
0.3819 
0.3819 
0.4577 
0.4577 
CL-CTS 
0.4734 
0.4633 
0.3171 
0.3204 
0.4645 
0.4575 
CL-ASA 0.3576 
0.3523 
0.2694 
0.2531 
0.3098 
0.2843 
CL-ESA 
0.1430 
0.1430 
0.1337 
0.1337 
0.1383 
0.1383 
T+MA 
0.3760 
0.3692 
0.3505 
0.3526 
0.3673 
0.3525 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Overall F 1 score over all sub-corpora of the state-of-the-art methods for each language pair 
(EN: English; FR: French; ES: Spanish). 

Chunk level 
EN→FR FR→EN EN→ES ES→EN ES→FR FR→ES 
Overall Lang. Pair 
1.000 
0.991 
0.998 
0.995 
0.957 
0.940 
0.980 
EN→FR 
1.000 
0.990 
0.994 
0.980 
0.971 
0.987 
FR→EN 
1.000 
0.996 
0.967 
0.949 
0.983 
EN→ES 
1.000 
0.978 
0.965 
0.988 
ES→EN 
1.000 
0.998 
0.980 
ES→FR 
1.000 
0.970 
FR→ES 

Sentence level 
EN→FR FR→EN EN→ES ES→EN ES→FR FR→ES 
Overall Lang. Pair 
1.000 
1.000 
0.929 
0.922 
0.991 
0.982 
0.971 
EN→FR 
1.000 
0.931 
0.924 
0.989 
0.981 
0.971 
FR→EN 
1.000 
0.997 
0.925 
0.913 
0.949 
EN→ES 
1.000 
0.928 
0.922 
0.949 
ES→EN 
1.000 
0.997 
0.971 
ES→FR 
1.000 
0.966 
FR→ES 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Top 3 methods by source and target lan-
guage. 

lar trend at chunk and at sentence level, regardless 
of the languages on which they are used. How-
ever, we can see in Table 7 that if we collect cor-
relation scores separately for each method (on all 
sub-corpora, on all language pairs) between chunk </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 8 :</head><label>8</label><figDesc></figDesc><table>Average F 1 scores and confidence intervals of methods applied on EN→FR sub-corpora at 
chunk and sentence level -10 folds validation. 

Lang. Pair Correlation 
EN→FR 
0.907 
FR→EN 
0.946 
EN→ES 
0.833 
ES→EN 
0.838 
ES→FR 
0.932 
FR→ES 
0.939 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" validated="false"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table>Pearson correlations of the results of all 
methods on all sub-corpora, between the chunk 
and the sentence granularity, by language pair 
(EN: English; FR: French; ES: Spanish) (calcu-
lated from Table 3). 

Methods Correlation 
CL-C3G 
0.996 
CL-CTS 
0.970 
CL-ASA 0.649 
CL-ESA 
0.515 
T+MA 
0.780 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" validated="false"><head>12</head><label>12</label><figDesc></figDesc><table>Methods 

T 
P 
R 
F1 
Random baseline 0.003 0.501 0.999 0.668 
Length Model 
0.203 0.566 0.970 0.714 
CL-C3G 
0.087 0.972 0.953 0.962 
CL-CTS 
0.010 0.986 0.808 0.888 
CL-ASA 
0.762 0.937 0.772 0.847 
T+MA 
0.157 0.928 0.646 0.762 

</table></figure>

			<note place="foot" n="1"> https://github.com/FerreroJeremy/ Cross-Language-Dataset/tree/master/study</note>

			<note place="foot" n="3"> http://nlp.stanford.edu/software/ CRF-NER.shtml 4 https://wit3.fbk.eu/ 5 http://www.statmt.org/wmt13/ translation-task.html#download</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">SemEval-2016 Task 1: Semantic Textual Similarity, Monolingual and CrossLingual Evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eneko</forename><surname>Agirre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carmen</forename><surname>Banea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Cer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mona</forename><surname>Diab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aitor</forename><surname>Gonzalez-Agirre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rada</forename><surname>Mihalcea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janyce</forename><surname>Wiebe</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/S16-1081" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th In-6</title>
		<meeting>the 10th In-6<address><addrLine>SemEval; San Diego, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="497" to="511" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">FBK HLT-MT at SemEval-2016 Task 1: Cross-lingual semantic similarity measurement using quality estimation features and compositional bilingual word embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duygu</forename><surname>Ataman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">C</forename><surname>Jose</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Souza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matteo</forename><surname>Turchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Negri</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/S/S16/S16-1086.pdf" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation</title>
		<meeting>the 10th International Workshop on Semantic Evaluation<address><addrLine>SemEval; San Diego, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="570" to="576" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">On Cross-lingual Plagiarism Analysis using a Statistical Model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alberto</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Pinto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alfons</forename><surname>Juan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ECAI&apos;08 PAN Workshop: Uncovering Plagiarism</title>
		<meeting>the ECAI&apos;08 PAN Workshop: Uncovering Plagiarism<address><addrLine>Patras, Greece</addrLine></address></meeting>
		<imprint>
			<publisher>Authorship and Social Software Misuse</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="9" to="13" />
		</imprint>
	</monogr>
	<note>Benno Stein and Efstathios Stamatatos and Moshe Koppel</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The Mathematics of Statistical Machine Translation: Parameter Estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><forename type="middle">J Della</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><forename type="middle">A</forename><surname>Pietra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">L</forename><surname>Della Pietra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mercer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="263" to="311" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">UWB at SemEval-2016 Task 1: Semantic textual similarity using lexical, syntactic, and semantic information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Brychcin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukas</forename><surname>Svoboda</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/S/S16/S16-1089.pdf" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation</title>
		<meeting>the 10th International Workshop on Semantic Evaluation<address><addrLine>San Diego, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="588" to="594" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Semeval-2017 task 1: Semantic textual similarity multilingual and crosslingual focused evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Cer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mona</forename><surname>Diab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eneko</forename><surname>Agirre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Inigo</forename><surname>Lopezgazpio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/S17-2001" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017). Association for Computational Linguistics</title>
		<meeting>the 11th International Workshop on Semantic Evaluation (SemEval-2017). Association for Computational Linguistics<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Wit 3 : Web inventory of transcribed and translated talks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mauro</forename><surname>Cettolo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Girardi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Federico</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16 th Conference of the European Association for Machine Translation (EAMT)</title>
		<meeting>the 16 th Conference of the European Association for Machine Translation (EAMT)</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="261" to="268" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Cross-Language Plagiarism Detection Methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vera</forename><surname>Danilova</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/R/R13/R13-2008.pdf" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Student Research Workshop associated with RANLP 2013. Hissar, Bulgaria, Recent Advances in Natural Language Processing</title>
		<editor>Galia Angelova, Kalina Bontcheva, and Ruslan Mitkov</editor>
		<meeting>the Student Research Workshop associated with RANLP 2013. Hissar, Bulgaria, Recent Advances in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="51" to="57" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">A Multilingual, Multi-style and Multi-granularity Dataset for Cross-language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jérémy</forename><surname>Ferrero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frédéric</forename><surname>Agnès</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Besacier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Didier</forename><surname>Schwab</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Textual Similarity Detection</title>
		<idno>ISLRN: 723-785-513- 738-2</idno>
		<ptr target="http://islrn.org/resources/723-785-513-738-2/" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC&apos;16). European Language Resources Association (ELRA)</title>
		<meeting>the Tenth International Conference on Language Resources and Evaluation (LREC&apos;16). European Language Resources Association (ELRA)<address><addrLine>Portoroz, Slovenia</addrLine></address></meeting>
		<imprint>
			<biblScope unit="page" from="4162" to="4169" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Computing Semantic Relatedness using Wikipediabased Explicit Semantic Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeniy</forename><surname>Gabrilovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaul</forename><surname>Markovitch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th International Joint Conference on Artifical Intelligence (IJCAI&apos;07)</title>
		<meeting>the 20th International Joint Conference on Artifical Intelligence (IJCAI&apos;07)<address><addrLine>Hyderabad, India</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1606" to="1611" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The distribution of the flora in the alpine zone</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Jaccard</surname></persName>
		</author>
		<idno type="doi">10.1111/j.1469-8137.1912.tb05611.x</idno>
		<ptr target="https://doi.org/10.1111/j.1469-8137.1912.tb05611.x" />
	</analytic>
	<monogr>
		<title level="j">New Phytologist</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="37" to="50" />
			<date type="published" when="1912" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">CNRC at SemEval-2016 Task 1: Experiments in crosslingual semantic textual similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi-Kiu</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cyril</forename><surname>Goutte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Simard</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/S/S16/S16-1102.pdf" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation</title>
		<meeting>the 10th International Workshop on Semantic Evaluation<address><addrLine>San Diego, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="668" to="673" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Character N-Gram Tokenization for European Language Text Retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Mcnamee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Mayfield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Retrieval Proceedings</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="73" to="97" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">External and Intrinsic Plagiarism Detection Using a Cross-Lingual Retrieval and Segmentation System -Lab Report for PAN at CLEF 2010</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Muhr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roman</forename><surname>Kern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mario</forename><surname>Zechner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Granitzer</surname></persName>
		</author>
		<editor>Martin Braschler, Donna Harman, and Emanuele Pianta</editor>
		<imprint>
			<date type="published" when="2010" />
			<pubPlace>Notebook. Padua, Italy</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A New Approach for Searching Translated Plagiarism</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pataki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th International Plagiarism Conference</title>
		<meeting>the 5th International Plagiarism Conference<address><addrLine>Newcastle, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="49" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A Statistical Approach to Crosslingual Natural Language Tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Pinto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jorge</forename><surname>Civera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alfons</forename><surname>Juan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alberto</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<idno type="doi">10.1016/j.jalgor.2009.02.005</idno>
		<ptr target="https://doi.org/10.1016/j.jalgor.2009.02.005" />
	</analytic>
	<monogr>
		<title level="j">Journal of Algorithms</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="51" to="60" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Cross-Language Plagiarism Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alberto</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benno</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Rosso</surname></persName>
		</author>
		<idno type="doi">10.1007/s10579-009-9114-z</idno>
		<ptr target="https://doi.org/10.1007/s10579-009-9114-z" />
	</analytic>
	<monogr>
		<title level="j">Language Resources and Evaluation</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="45" to="62" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Overview of the 6th International Competition on Plagiarism Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Busse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Tippmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benno</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PAN at CLEF</title>
		<meeting><address><addrLine>Sheffield, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="845" to="876" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A Wikipedia-Based Multilingual Retrieval Model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benno</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maik</forename><surname>Anderka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">30th European Conference on IR Research (ECIR&apos;08</title>
		<meeting><address><addrLine>Glasgow, Scotland</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008" />
			<biblScope unit="volume">4956</biblScope>
			<biblScope unit="page" from="522" to="530" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Automatic Identification of Document Translations in Large Multilingual Document Collections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bruno</forename><surname>Pouliquen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralf</forename><surname>Steinberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Camelia</forename><surname>Ignat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference Recent Advances in Natural Language Processing (RANLP&apos;03)</title>
		<meeting>the International Conference Recent Advances in Natural Language Processing (RANLP&apos;03)<address><addrLine>Borovets, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="401" to="408" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">DBnary: Wiktionary as a Lemon-Based Multilingual Lexical Resource in RDF</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gilles</forename><surname>Sérasset</surname></persName>
		</author>
		<idno type="doi">10.3233/SW-140147</idno>
		<ptr target="https://doi.org/10.3233/SW-140147" />
	</analytic>
	<monogr>
		<title level="j">Semantic Web Journal (special issue on Multilingual Linked Open Data)</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="355" to="361" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">DLS@CU: Sentence similarity from word alignment and semantic vector composition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Md Arafat Sultan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tamara</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sumner</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/S15-2027" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th International Workshop on Semantic Evaluation</title>
		<meeting>the 9th International Workshop on Semantic Evaluation<address><addrLine>Denver, CO, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="148" to="153" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
