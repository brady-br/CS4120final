<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2020-09-29T02:26+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Libnvmmio: Reconstructing Software IO Path with Failure-Atomic Memory-Mapped Interface Libnvmmio: Reconstructing Software IO Path with Failure-Atomic Memory-Mapped Interface</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>July 15-17, 2020</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jungsik</forename><surname>Choi</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Sungkyunkwan University</orgName>
								<orgName type="institution" key="instit2">Sungkyunkwan University</orgName>
								<orgName type="institution" key="instit3">KAIST</orgName>
								<orgName type="institution" key="instit4">KAIST</orgName>
								<orgName type="institution" key="instit5">Sungkyunkwan University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungkyunkwan</forename><surname>University</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Sungkyunkwan University</orgName>
								<orgName type="institution" key="instit2">Sungkyunkwan University</orgName>
								<orgName type="institution" key="instit3">KAIST</orgName>
								<orgName type="institution" key="instit4">KAIST</orgName>
								<orgName type="institution" key="instit5">Sungkyunkwan University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">;</forename><surname>Jaewan</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Sungkyunkwan University</orgName>
								<orgName type="institution" key="instit2">Sungkyunkwan University</orgName>
								<orgName type="institution" key="instit3">KAIST</orgName>
								<orgName type="institution" key="instit4">KAIST</orgName>
								<orgName type="institution" key="instit5">Sungkyunkwan University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong</forename></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Sungkyunkwan University</orgName>
								<orgName type="institution" key="instit2">Sungkyunkwan University</orgName>
								<orgName type="institution" key="instit3">KAIST</orgName>
								<orgName type="institution" key="instit4">KAIST</orgName>
								<orgName type="institution" key="instit5">Sungkyunkwan University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youngjin</forename><surname>Kwon</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Sungkyunkwan University</orgName>
								<orgName type="institution" key="instit2">Sungkyunkwan University</orgName>
								<orgName type="institution" key="instit3">KAIST</orgName>
								<orgName type="institution" key="instit4">KAIST</orgName>
								<orgName type="institution" key="instit5">Sungkyunkwan University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaist</forename><forename type="middle">;</forename></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Sungkyunkwan University</orgName>
								<orgName type="institution" key="instit2">Sungkyunkwan University</orgName>
								<orgName type="institution" key="instit3">KAIST</orgName>
								<orgName type="institution" key="instit4">KAIST</orgName>
								<orgName type="institution" key="instit5">Sungkyunkwan University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hwansoo</forename><surname>Han</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Sungkyunkwan University</orgName>
								<orgName type="institution" key="instit2">Sungkyunkwan University</orgName>
								<orgName type="institution" key="instit3">KAIST</orgName>
								<orgName type="institution" key="instit4">KAIST</orgName>
								<orgName type="institution" key="instit5">Sungkyunkwan University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jungsik</forename><surname>Choi</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Sungkyunkwan University</orgName>
								<orgName type="institution" key="instit2">Sungkyunkwan University</orgName>
								<orgName type="institution" key="instit3">KAIST</orgName>
								<orgName type="institution" key="instit4">KAIST</orgName>
								<orgName type="institution" key="instit5">Sungkyunkwan University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaewan</forename><surname>Hong</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Sungkyunkwan University</orgName>
								<orgName type="institution" key="instit2">Sungkyunkwan University</orgName>
								<orgName type="institution" key="instit3">KAIST</orgName>
								<orgName type="institution" key="instit4">KAIST</orgName>
								<orgName type="institution" key="instit5">Sungkyunkwan University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youngjin</forename><surname>Kwon</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Sungkyunkwan University</orgName>
								<orgName type="institution" key="instit2">Sungkyunkwan University</orgName>
								<orgName type="institution" key="instit3">KAIST</orgName>
								<orgName type="institution" key="instit4">KAIST</orgName>
								<orgName type="institution" key="instit5">Sungkyunkwan University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hwansoo</forename><surname>Han</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Sungkyunkwan University</orgName>
								<orgName type="institution" key="instit2">Sungkyunkwan University</orgName>
								<orgName type="institution" key="instit3">KAIST</orgName>
								<orgName type="institution" key="instit4">KAIST</orgName>
								<orgName type="institution" key="instit5">Sungkyunkwan University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Libnvmmio: Reconstructing Software IO Path with Failure-Atomic Memory-Mapped Interface Libnvmmio: Reconstructing Software IO Path with Failure-Atomic Memory-Mapped Interface</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2020 USENIX Annual Technical Conference</title>
						<meeting>the 2020 USENIX Annual Technical Conference						</meeting>
						<imprint>
							<date type="published">July 15-17, 2020</date>
						</imprint>
					</monogr>
					<note>This paper is included in the 978-1-939133-14-4 Open access to the Proceedings of the 2020 USENIX Annual Technical Conference is sponsored by USENIX. https://www.usenix.org/conference/atc20/presentation/choi</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Fast non-volatile memory (NVM) technology changes the landscape of file systems. A series of research efforts to overcome the traditional file system designs that limit NVM performance. This research has proposed NVM-optimized file systems to leverage the favorable features of byte-addressability, low-latency, and high scalability. The work tailors the file system stack to reduce the software overhead in using fast NVM. As a further step, NVM IO systems use the memory-mapped interface to fully capture the performance of NVM. However, the memory-mapped interface makes it difficult to manage the consistency semantics of NVM, as application developers need to consider the low-level details. In this work, we propose Libnvmmio, an extended user-level memory-mapped IO, which provides failure-atomicity and frees developers from the crash-consistency headaches. Libnvmmio reconstructs a common data IO path with memory-mapped IO, providing better performance and scalability than the state-of-the-art NVM file systems. On a number of microbenchmarks, Lib-nvmmio gains up to 2.2× better throughput and 13× better scalability than file accesses via system calls to underlying file systems. For SQLite, Libnvmmio improves the performance of Mobibench and TPC-C by up to 93% and 27%, respectively. For MongoDB, it gains up to 42% throughput increase on write-intensive YCSB workloads.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The recent surge of non-volatile main memory (NVM) technology such as PCM <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b55">55]</ref>, STT-MRAM <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b29">30]</ref>, NVDIMMs <ref type="bibr" target="#b44">[45]</ref>, and 3D Xpoint memory <ref type="bibr" target="#b20">[21]</ref> allows applications to access persistent data via CPU load/store instructions directly. With the benefits of competitive performance, low power consumption, and high scalability, they are expected to complement or even replace DRAM in future systems <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b32">33]</ref>.</p><p>To leverage the performance and persistent features, researchers have proposed NVM-optimized file systems <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b66">65,</ref><ref type="bibr" target="#b68">67,</ref><ref type="bibr" target="#b69">68]</ref>. The most important challenge addressed in the series of work is to revise the inefficient behavior of the software IO stack, which presents a dominating overhead in fast NVM <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b70">69]</ref>. To reduce the overhead, state-of-the-art NVM-aware file systems discard the traditional block layer and the page cache layer in the IO path. Despite these optimizations, file accesses through the OS kernel's file system still incur significant overhead. For example, read and write system calls are still expensive ways to leverage the low latency of NVM, due to frequent user/kernel mode switches, data copies, and complicated VFS layers <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b58">57,</ref><ref type="bibr" target="#b63">62]</ref>.</p><p>A promising approach to further reduces IO overhead of NVM file systems is to use memory-mapped IO <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b59">58,</ref><ref type="bibr" target="#b61">60,</ref><ref type="bibr" target="#b68">67,</ref><ref type="bibr" target="#b69">68]</ref>. The memory-mapped IO naturally fits the characteristics of NVM. Applications can map files to their virtual address space and access files directly with load/store instructions without kernel interventions. Memory-mapped IO also minimizes the CPU overhead of file system operations by eliminating file operations such as indexing to locate data blocks and checking permissions <ref type="bibr" target="#b66">[65]</ref>. With these benefits, the mmap would be a critical interface for file IO in future NVM systems.</p><p>While memory-mapped IO exposes the raw performance of NVM to applications, a lot of responsibility is laid on applications as well. One thing to keep in mind for application programmers is that memory-mapped IO does not guarantee atomic-durability. If a system failure occurs during memorymapped IO, the file contents may be corrupted and inconsistent in the application context. In return for fast performance, developers should build application-specific crash-safe mechanisms. Cache lines should be flushed to ensure durability and memory barriers should be enforced to provide a correct persistent ordering for NVM updates. This mechanism often induces a serious software overhead, and makes it notoriously difficult to write accurate and efficient crash-proof code for NVM systems <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b50">[50]</ref><ref type="bibr" target="#b51">[51]</ref><ref type="bibr" target="#b52">[52]</ref><ref type="bibr" target="#b72">71]</ref>. For an instance, applying cache flush and memory barrier instructions correctly in the right locations is challenging; excessive use causes performance degradation, but omitting them in required locations leads to data corruption <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b71">70]</ref>. This is the major obstacle blocking the adoption of memory-mapped IO to fully exploit the advantages of NVM.</p><p>We propose Libnvmmio, a user library that provides failureatomic memory-mapped IO with msync. We add atomicity and ordering features to the existing msync at user-level. By separating failure-atomicity concerns from memory-mapped IO applications, Libnvmmio allows developers to focus on the main logic of programs. To make the msync failure-atomic, Libnvmmio uses user-level logging techniques. Our library stages written data to per-block, persistent logs and applies the updates to memory-mapped files in a failure-atomic manner on msync.</p><p>Implementing msync at user-level has many advantages. First, the user-level msync minimizes system call overhead. Existing msync imposes system call overhead, which takes locks and excessively serializes threads in a multi-threaded application. Second, it reduces write amplification. Kernel-level msync flushes rather large ranges whose size are multiples of the system page size (4KB, 2MB, or 1GB). Whereas, user-level msync can track dirty data at a cacheline granularity and flush them at cacheline level. Third, it avoids TLB-shootdown overhead. When applications invoke msync on NVM file systems, operating systems track down updated pages by searching for dirty bits in the page table and flush corresponding cache lines of those dirty pages to NVM. After the flush, they clear the dirty bits in the page table to enable tracking new updates. This incurs TLB invalidations in other cores, as dirty bit state is just kind of information in TLB along with the virtual to physical page mapping. As Libnvmmio's msync maintains user-level logs for update tracking, we can totally avoid TLB-shootdown overhead. Fourth, it takes advantage of non-temporal store instructions which bypass CPU caches with no need of cache flushing. Kernel-level msync flushes the entire range, even if updates are performed with non-terminal store instructions. In general, there is no other way to communicate with msync that the non-temporal stores are used. For all of these reasons, a user-level msync in Libnvmmio can perform better than a kernel-level msync.</p><p>Existing applications that use conventional file IO interface (e.g., read/write, fsync, etc.) can also benefit from memory-mapped IO using Libnvmmio. Like FLEX <ref type="bibr" target="#b67">[66]</ref> and SplitFS <ref type="bibr" target="#b23">[24]</ref>, Libnvmmio transparently intercepts the traditional file IO requests and then perform memory-mapped IO. When applications call fsync, Libnvmmio carries out its failure-atomic msync. Libnvmmio rebuilds the common IO path with efficient mechanisms for read and write performance, but the uncommon, complex file operations such as directory namespace and protection are passed to the slow path of the existing file systems.</p><p>Libnvmmio runs on any file systems that supports memory- mapped interface on NVM such as Ext4-DAX, XFS-DAX, PMFS <ref type="bibr" target="#b12">[13]</ref>, and NOVA <ref type="bibr" target="#b69">[68]</ref>. Libnvmmio running on NOVA performs better than NOVA by 2.5× and Ext4-DAX by 1.18× in Mobibench and TPC-C. Libnvmmio makes the following contributions:</p><p>• Libnvmmio extends the semantics of msync, providing failure-atomicity.</p><p>• With experimental evidences, Libnvmmio demonstrates lower-latency and higher-throughput with scalability than the state-of-the-art NVM file systems • Design and implementation of Libnvmmio, running on Ext4-DAX, XFS-DAX, PMFS, NOVA. Libnvmmio is publicly available at: https://github.com/chjs/libnvmmio.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Need for Memory-Mapped IO</head><p>The fundamental difference between memory-mapped IO and read-write IO is the data path. The read-write interface copies the user buffer into a kernel buffer 1 , searches the file system index to locate physical block address, and performs metadata operations if necessary. Whereas, the memorymapped interface allows direct accesses to storage, skipping the index searching and copying to the kernel buffer. The simplified data path in memory-mapped IO drastically reduces the software overhead compared to the read-write interface, which significantly improves IO performance in fast nonvolatile memory. To compare the performance, we run a micro-benchmark performing sequential reads on a 16 GB file. <ref type="figure">Figure 1</ref> shows the performance difference. Memorymapped IO shows 2.3× better performance than the read system call. The read system calls spends 43.9% out of the IO entire latency on copying user buffers to kernel buffers and 45.4% for the rest of kernel IO stack. Memory-mapped IO eliminates most of the software overhead. We observed that the total number of instructions to execute a single read is 69× less in the memory-mapped IO than the read system call.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Need for Atomic Updates</head><p>Modern processors guarantee only cache-sized, aligned stores (64 bit) to be atomic. The atomicity guarantee is not sufficient for general file IO which requires more complex and larger atomic updates. On writing a 4 KB or larger block, a crash may cause partially updated states, which needs significant costs to detect and recover the block. To avoid the hassle, researchers put an effort to make large updates failure-atomic in non-volatile memory file systems <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b68">67]</ref>. Existing file systems deploy a variety of techniques to implement the failure-atomicity guarantee: copy-on-write and journaling. These techniques work in different ways, and the advantages and disadvantages in terms of performance vary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Copy-on-Write</head><p>When updating a block, the Copy-on-Write (CoW) (or shadow-paging) <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b57">56,</ref><ref type="bibr" target="#b68">67,</ref><ref type="bibr" target="#b69">68]</ref> mechanism creates a copy of the original page and writes the new data to the copied page rather than updating the new data in place. Not only for data update but the CoW mechanism performs the out-of-place update for index. For a tree-based indexing structure, the CoW mechanism causes a change of a child node to update its parent node in an out-of-place manner, propagating all the changes of internal nodes up to the top of the tree (called wandering tree problem).</p><p>The CoW mechanism induce significant software overhead when used in the NVMM system. First, CoW dramatically increases write amplification. CoW usually performs writes at the page granularity, which is a typical node size of file systems indexing. Even if only a few bytes are updated, the entire page must be written. Besides, as the capacity of main memory has increased, the utilization of hugepages (e.g., 2MB or 1GB) is increasing <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b54">54]</ref>. This trend makes the use of the CoW technique more costly <ref type="bibr" target="#b8">[9]</ref>. Second, the CoW technique causes TLB-shootdown overhead in memory-mapped IO. If the CoW technique is applied to memory-mapped files, the mapping of the virtual address must be changed from the original page to the copied page, necessitating TLB-shootdown whenever an update occurs. When a CoW occurs, the kernel flushes the local TLB and send flush requests to remote cores through inter-processor interrupt (IPI). The remote cores flush their TLB entries according to the information received by the IPI and report back when completed. If the remote core has interrupts disabled, the IPI may be kept pending. The initiator core expects to receive all acknowledge the process of flushing the TLBs. This process could take microseconds, causing a notable overhead <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b62">61]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Journaling</head><p>Journaling (or logging) is a technique that is widely used in databases <ref type="bibr" target="#b42">[43]</ref> and journaling file systems <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b49">49,</ref><ref type="bibr" target="#b53">53]</ref> to ensure data-atomicity and consistency between data and metadata. It persists a copy of new or original data before updating the original file. If a system failure occurs during writing, the valid log can be used for recovery. Two logging policies are possible: undo logging and redo logging. Redo logging first writes new data to the redo log. When the new data becomes durable in the log, the data are overwritten to the original file. If a system failure occurs while updating the file, the new data in the log can be written again to the file. For read requests, applications need to check the log first because only the log may have the up-to-date data. Undo logging first copies the original data to the log. After the original data becomes persistent, undo logging updates the new data to the file in place. If a system failure occurs during the write, undo logging allows to roll back the original data using the undo log. Because the latest data are always in the file, applications can read the data directly from the file without checking the log. Therefore, undo logging is appropriate for the applications that perform read frequently ( §3.4).</p><p>Logging techniques require writing data twice: once to the log and once to the original file, which may cause software overhead. However, redo logging allows updating the original file out of the critical path of execution. Because the log has the persistent data, redo logging can postpone updating the file in the background ( §3.3). Besides, logging technique is convenient to implement the differential logging <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b35">36]</ref>. Unlike page-based logging, which logs an entire page, the differential logging only logs differential data at the bytegranularity. Differential logging can significantly reduce write amplification especially when it is used for byte-granularity storage devices such as NVM <ref type="bibr" target="#b26">[27]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Atomic Update for Memory-Mapped IO</head><p>While the direct access of memory-mapped IO is essential for reducing the software overhead in NVM file system, it pushes the burden of data atomicity to the application. The POSIX msync primitives provides durability and consistency between data and metadata but not atomicity. To support atomicity of large updates, application developers must implement their own reliability mechanism. However, implementing the inhouse mechanism is tedious and notoriously buggy <ref type="bibr" target="#b50">[50]</ref>.</p><p>Researchers have proposed adding the atomicity guarantee to the msync interface in traditional storage <ref type="bibr" target="#b50">[50]</ref> and NVM <ref type="bibr" target="#b68">[67]</ref>. To provide atomicity to memory-mapped files, they take journaling-like approaches; dirty pages are staged first and copied to the original file. Providing atomicity at the kernel-level has a fundamental limit which impacts good performance. For example, NOVA <ref type="bibr" target="#b68">[67]</ref> creates a replica page on a page fault and maps the replica page on the faulting virtual address. On msync, kernel copies the replica page to the original page atomically. The minimum unit of copying is a page size (4 KB or 2 MB), which causes write amplification for small IO requests.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Libnvmmio</head><p>The purpose of Libnvmmio is eliminating software overhead, while providing low-latency, scalable file IO with ensured data-atomicity. Libnvmmio is linked with applications as a library, providing the efficient IO path by using the mmap interface. In particular, Libnvmmio has following design goals and implementation strategies.</p><p>Low-latency IO. Reducing software overhead is crucial to take advantage of low latency NVM. Since Libnvmmio aims to make the common IO path efficient for low-latency IO, it avoids using the complicated kernel IO path including the slow journaling for common cases.</p><p>Efficient logging for data atomicity. Libnvmmio transparently intercepts file APIs and provides atomicity for data operations by using logging. As sustaining low-latency file IO is essential, Libnvmmio endeavors to minimize write amplification and software overhead for data logging.</p><p>High-throughput, scalable IO with high concurrency. To sustain high throughput across different IO sizes, Libnvmmio uses varying sizes of log entries depending on IO sizes. To this end, Libnvmmio deploys a flexible data structure for indexing the log entries and handles various log entry sizes. Additionally, Libnvmmio aims to achieve high concurrency through fine-grained logging and scalable indexing structure.</p><p>Data-centric, per-block based organization. Libnvmmio constructs most of its data structures and metadata as datacentric. For example, Libnvmmio builds per-block logs and metadata rather than per-thread or per-transaction based logs. Data-centric design allows a single instance of a data structure and metadata for a corresponding data block. The singleton design makes it easy to coordinate shared accesses with locks. As multiple threads access the same large file concurrently in recent applications, they require more fine-grained locks than entire file locks <ref type="bibr" target="#b39">[40]</ref>. With fine-grained locks at block level, Libnvmmio achieves scalability for data-centric logging. Perinode logging improves scalability, when multiple accesses are performed on different files <ref type="bibr" target="#b68">[67,</ref><ref type="bibr" target="#b69">68]</ref>. However, it provides a limited degree of scalability for multiple accesses to the same file.</p><p>Transparent to underlying file systems. On top of existing NVM file systems, Libnvmmio improves the performance While atomicity is useful, not all files need atomic update guarantees -it is unnecessary for temporal files. Libnvmmio extends open API to let applications indicate atomicity guarantee in a per-file basis. To communicate with the kernel, Libnvmmio translates the extended APIs to the conventional APIs with additional flags. With such a user-level extension design, Libnvmmio runs on any NVM file systems that support DAX-mmap, while enjoying file-system specific features such as fast snapshot and efficient block allocation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Overall Architecture</head><p>Libnvmmio runs in the address space of a target application as a library and interacts with underlying file systems. Libnvmmio intercepts IO requests and turns them into internal operations. For each IO request, Libnvmmio distinguishes data and metadata operations. For all data requests, Libnvmmio services them in the user-level library, bypassing the slow kernel code. Whereas, for complex metadata and directory operations, Libnvmmio lets the operations be processed by the kernel. This design is based on the observation that data updates are the common, performance-critical operations. On the other hand, the metadata and directory operations are relatively uncommon and include complex implementation to support POSIX semantics. Handling them differently, the architecture of Libnvmmio follows the design principle of making the normal case fast <ref type="bibr" target="#b30">[31]</ref> with a simple, fast user-level implementation. Memory-mapped IO. To directly access the NVM, Libnvmmio maps the file via mmap system call. Libnvmmio intercepts and replaces read calls with memcpy, and write calls with a non-temporal version of memcpy that uses the movnt instruction. There are two reasons why the memory-mapped IO allows faster NVM access than the traditional kernel-served read and write method. First, when persisting and obtaining data, the simple, the fast code path in Libnvmmio replaces the complex, slow kernel IO path <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b27">28]</ref>. Second, read and write system calls involve indexing operations to locate physical blocks, which causes a non-trivial software overhead for fast NVM accesses. Whereas, in memory-mapped IO, the kernel searches the complex index when it maps the file blocks to the user address space on page faults. After the mapping is established, Libnvmmio can access the file data simply with offset in the memory-mapped address, eliminating the indexing operations in the steady state. Besides, finding file blocks through virtual addresses is offloaded to the MMU (e.g., page table walkers, TLBs). Therefore, it reduces a sizable amount of the CPU overhead caused by file indexing <ref type="bibr" target="#b66">[65]</ref>.</p><p>Atomicity and durability with user-level logging. On SYNC 2 calls, Libnvmmio flushes the cache data and stores the data to NVM atomically via the logging mechanism. All write data are firstly persisted to the user-level log and later they are copied (called checkpoint) to the memory-mapped file. Data from both write and memcpy interfaces goes down the same path.</p><p>Providing atomicity via the user-level logging has several advantages over the kernel-level design. Using the user-level IO information, Libnvmmio can leverage the byteaddressability of NVM to log data in the fine-grained unit. On the other hand, in the kernel-level approach, the logging unit should be a page size, as msync relies on the page dirty bit to log the memory-mapped data, causing write amplification in case of small writes (i.e., less than a page size). After msync is done, kernel must clear the dirty bit in the page table followed by TLB shootdown. However, user-level design uses own data structure to track dirty data without relying on the page dirty mechanism, saving unnecessary TLB shootdowns.</p><p>Application transparency. For applications using read and write, Libnvmmio can transparently replace them with the memory mapped IO operations. For applications using mmap, Libnvmmio can redirect the memory operations to NVM memory-mapped IO operations without effort.</p><p>Providing atomic-durability on top of the mmap interface makes the case challenging, as Libnvmmio cannot distinguish the memcpy operations that requires atomic-durability from the ones that do not require.</p><p>Guaranteeing atomicity to all IO operations is prohibitively expensive. Some IO requests do not need atomicity such as logging internal traces or errors. To address the problem, Libnvmmio exposes two version of memcpy: POSIX version and Libnvmmio version. Libnvmmio versions are prefixed with nv (e.g., nvmmap, nvmemcpy, nvmunmap, etc.) and provide atomic-durability. Libnvmmio avoids intrusive modifications of existing applications in order to use the Libnvmmio APIs. Instead, we instrument the application binary with an in-house tool, which lists the files the application accesses and asks developers which files need atomic-updates. With the list of files requiring atomic-durability, we patches the binary to use Libnvmmio APIs. In most cases, applications use read, write, or memcpy APIs, which are easy to patch for the application binary. However, in case of manipulating files with pointers, we need source-level modifications (e.g., 182 lines in the MongoDB MMAPv1 engine).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Scalable Logging</head><p>Applications such as in-memory database and key-value stores, that benefit from Libnvmmio, require high concurrency level to sustain high throughput. Libnvmmio responds to the high concurrency requirement with scalable logging that is based on per-block data logging and indexing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Scalable per-block logging</head><p>Finding proper logging granularity is necessary to achieve high concurrency. Application-centric techniques such as per-thread and per-transaction logging are widely adopted in databases, providing high concurrency. However, these techniques rely on the strong assumption that data is only visible and applicable to the current thread or transaction; e.g., data in logs need not to be shared among threads or transactions, which is guaranteed by isolation property. Logging without needing to consider shared data allows for high scalability. However, the assumptions do not hold in general IO cases; sharing IO data among threads is a common use case. Moreover, the transaction boundary is not visible to the current design of Libnvmmio.</p><p>Instead, Libnvmmio performs data-centric logging. It divides the file space into multiple file blocks (4 KB∼2 MB) and creates a log entry for each file block. Log entries in Libnvmmio are visible to all threads. The fine-grained, per-block logging allows a flexible way to share data among threads. When an update is made to a mapped file, Libnvmmio creates a log entry indexed by the offset, where the update occurred in the memory-mapped file. If other threads read the updated offset, it serves data from the log entry instead of the original</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Global</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Upper</head><p>Middle Figure 3: Indexing structure of Libnvmmio.</p><p>mapped file. When another update comes to the same file offset, it overwrites the update in the existing log entry. For shared data reads, per-block logging provides better performance than per-thread logging, as per-thread logging needs to search all the logs of all threads to gather all the updates made to the same file blocks. In addition to per-block logging, Libnvmmio takes advantage of the byte-addressable characteristics of NVM and reduces write amplification by performing differential logging for a partial update, where the update size is smaller than log block size.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Scalable log indexing</head><p>Along with data logging, indexing design is also critical to achieve high concurrency. Libnvmmio uses a file offset as an index key to a log block. To index many log blocks, Libnvmmio uses multi-level indexing to reduce space overhead. Similar to the page table, it uses radix trees for indexing. Fixed-depth trees allow lock-free mechanisms, which provide better concurrency than balanced trees such as red-black trees.</p><p>As balanced trees require coarse-grained locks to protect the entire trees for tree re-balancing, their algorithms severely hurt concurrency <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b10">11]</ref>. <ref type="figure">Figure 3</ref> shows the index design of Libnvmmio. Each internal node is an array of buckets pointing to the next level internal nodes. Each set of 9 bits from file offset is used to locate a bucket in a corresponding internal node. Each leaf node points to an index entry, where entry field points to log entry. The index entry also contains other metadata for the given file offset. Libnvmmio supports variable-size log entries for large IO requests. Log entries range from 4KB to 2MB, doubling the size. To index 4KB log entries, it uses 9 bits for <ref type="table" target="#tab_4">Table and 12</ref> bits for Offset. For 2 MB log entry, it uses 21 bits for Offset without using <ref type="table">Table.</ref> In an index entry, offset and len are used for updated data offset within a log entry and update size, respectively. If update size in len is smaller than the log entry size, it means the log entry contains partial updates (Delta). The log entry can hold a single delta chunk indicated by offset and len. If another delta chunk needs to be added in the same log entry, the two chunks are merged. The virtual address of the memory mapped file specified in dest is the location where the log will be checkpointed. The logging policy for the corresponding data is specified in policy, which decides whether Libnvmmio uses undo log or redo log ( §3.4). To determine if the log entry should be checkpointed, the number in epoch is used <ref type="figure">( §3.3)</ref>.</p><p>The radix tree has a fixed depth to implement a lock-free mechanism. The four-level radix tree can support 256 TiB file size, but it can cause unnecessary search overhead for small files. Libnvmmio uses a skip pointer to implement a lock-free radix tree while also reducing the search overhead. As shown in <ref type="figure">Figure 3</ref>, the radix_root has a skip field. If the file size is small, Libnvmmio uses the field to skip unnecessary parent nodes. When the file size changes, Libnvmmio can adjust the skip pointer.</p><p>To achieve fast indexing, Libnvmmio manages the internal nodes of the radix tree in DRAM and does not persist them to NVM. It persists only the index entries and the log entries. Libnvmmio does not need to build the entire radix tree for recovery. On a crash, it simply scans the persisted index and log entries, which are committed but not checkpointed yet. It can copy the log entries to the original file by referring the dest attribute in the corresponding index entries and the per-file metadata. To achieve high concurrency, Libnvmmio does not use any coarse-grained locks to update internal nodes of the radix tree. Instead, it updates each bucket of internal nodes with an atomic operation. Only when it needs to update index entry, it holds the per-entry, reader-writer lock.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Epoch-based Background Checkpointing</head><p>Log entries are committed on SYNC 3 . The committed log entries must be checkpointed to the corresponding memorymapped file and cleaned. To make the checkpoint operations out of the performance critical path, Libnvmmio checkpoints the log entries in the background. It periodically wakes up checkpointing threads for copying and cleaning log entries <ref type="bibr" target="#b3">4</ref> . While checkpointing, the background threads do not need to obtain a coarse-grained tree lock. This minimizes disruption on on-going read/write operations. The background threads holds a per-entry writer lock to serialize checkpoint operations and read/write requests on the log entry.</p><p>Libnvmmio uses per-block logging. When an application calls SYNC, it must convert many of the corresponding perblock logs to committed status. This increases the commit overhead significantly. To avoid such overhead, Libnvmmio performs committing and checkpointing based on the epoch, which increases monotonically. Libnvmmio maintains two types of epoch numbers; each index entry has an epoch number for its update log and per-file metadata carries the current global epoch number. When allocating an index entry, it assigns the current global epoch number for file to the epoch number for the index entry. Libnvmmio increases the current global epoch number, when applications issue SYNC calls to the file. The epoch numbers are used to distinguish committed (but yet to be checkpointed) log entries from the uncommitted ones. If a log entry has a smaller epoch number than the current global epoch number, it indicates that the log entry is committed. If the epoch number of a log entry is the same as the global epoch number, the log entry is not yet committed. Libnvmmio checkpoints only committed log entries in the background threads. After being checkpointed, log entries are cleaned and reused later.</p><p>The epoch-based approach allows fast commit of log entries, as Libnvmmio does not need to traverse the radix tree and mark log entries as committed. Instead, it simply increases the current global epoch number in the per-file metadata, which reduces SYNC latency greatly. Commit operations are performed synchronously and atomically, when the application calls SYNC. Meanwhile, checkpoint operations are done asynchronously by background threads. Consequently, there are committed logs and uncommitted logs mixed in the radix tree. When applications request writes, the corresponding log entries are overwritten for uncommitted ones. Meanwhile, Libnvmmio synchronously checkpoints the committed logs first for committed ones. After completing the checkpointing, it allocates a new uncommitted log and processes write requests.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Hybrid Logging</head><p>Libnvmmio uses a hybrid logging technique to optimize IO latency and throughput. As pointed out in §2.2.2, undo logging performs better when accesses are mostly reads, whereas redo logging is better when accesses are mostly writes. To achieve the best performance of both logging policies, Libnvmmio transparently monitors the access patterns of each file and applies different logging policies depending on current read and write intensity.</p><p>Libnvmmio maintains counters to record read and write operations for a file ( §3.5). When SYNC is called, Libnvmmio checks the counters to determine whether which type of logging would be better for the next epoch. If the logging policy changes, Libnvmmio carries out both committing and checkpointing synchronously. SYNC is a clean transition point for changing the logging policy, as current log data are checkpointed and cleaned. This allows Libnvmmio to avoid complex cases where it otherwise has to maintain two log policies at the same time. The per-file, hybrid logging enables the fine-grained logging policy, allowing Libnvmmio to adopt the individually best logging mechanism for each file. By </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Per-File Metadata</head><p>Libnvmmio maintains two types of metadata in persistent memory; the index entry is the metadata for each log entry, and the per-file metadata shown in <ref type="figure" target="#fig_2">Figure 4</ref> is the metadata for each file. Libnvmmio stores both metadata as well as log entries in NVM, which enables Libnvmmio to recover its data in case of system failures.</p><p>When Libnvmmio accesses a file, it first gets the per-file metadata of the file and the index entry corresponding to the file offset. If applications access a file with nvmemcpy interface, it needs to find the per-file metadata by using access address of the nvmemcpy. The approach Libnvmmio takes for this purpose is to employ a red-black tree and perform range searches with virtual addresses. To speed up the search process, Libnvmmio caches recently used per-file metadata in the per-thread cache. Meanwhile, Libnvmmio can quickly obtain the per-file metadata through the file descriptor, if applications access files with read/write interface.</p><p>The per-file metadata consists of ten fields. The rwlock is a reader-writer lock. During SYNC process, this lock prevents other threads from accessing the file. The start and end fields store the location of the virtual address to which the file is mapped. The ino and offset fields record which part of a file is mapped. The epoch field stores the current global epoch number for the file. The policy field stores the current logging policy for the file. The read_cnt and write_cnt are counters of read and write operations during the current epoch, respectively. The radix_root field stores the root node of the radix tree indexing for index entries and log entries. Write. <ref type="bibr" target="#b0">1</ref> The thread holds the reader lock in the per-file metadata of the file and increases the write counter with atomic operations. Holding the reader lock in per-file metadata allows multiple threads to access the file concurrently.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2</head><p>The thread traverses the in-memory radix tree to locate the corresponding index entry and holds the writer lock for the index entry. <ref type="bibr" target="#b2">3</ref> Depending on the current logging policy in the per-file metadata, Libnvmmio creates an undo or redo log entry. <ref type="bibr" target="#b3">4</ref> The thread writes data to the log entry with the non-temporal store instruction, and Libnvmmio updates the index entry of the log entry. <ref type="bibr" target="#b4">5</ref> Libnvmmio calls sfence indicating logging is done and unlocks the index entry and per-file metadata, and returns to the application.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SYNC. 1</head><p>Libnvmmio holds the writer lock in the per-file metadata and increases the global epoch counter by one. Holding the writer lock of the per-file metadata prevents other threads from accessing the file. <ref type="bibr" target="#b1">2</ref> Libnvmmio calculates the write ratio from the write and read counters. In the example in <ref type="figure" target="#fig_3">Figure 5</ref>, Libnvmmio continues to use redo logging for the next epoch, as the access pattern is write-intensive (4 writes out of 4 accesses). After determining the logging policy, Libnvmmio initializes the counters. When logging policy is unchanged, Libnvmmio lets checkpointing threads commit log entries in the background. If Libnvmmio decides to change logging policy, it synchronously checkpoints all committed log entries before the new epoch begins. <ref type="bibr" target="#b2">3</ref> Finally, Libnvmmio unlocks the per-file metadata and returns to the application.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.7">Crash Consistency and Recovery</head><p>Libnvmmio preserves write ordering of a sequence of write requests. For each write, Libnvmmio writes data to the log and flushes the CPU cache. The order-preserving write provides In the recovery phase, Libnvmmio checks whether the index entries are committed, while scanning the index entries. If Libnvmmio finds a committed log, whose epoch number is smaller than the global epoch number, it finds the per-file metadata from the index entry's dest attribute. Then, it redoes or undoes according to the logging policy. Libnvmmio can efficiently parallelize this recovery task by using multithreading.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Evaluation</head><p>We implemented Libnvmmio from scratch. Our prototype of Libnvmmio has a total 3,452 LOC 5 in C code. To persist data to NVM, Libnvmmio employs the PMDK library <ref type="bibr" target="#b19">[20]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experimental setup</head><p>To evaluate Libnvmmio on different types of NVM, we used NVDIMM-N <ref type="bibr" target="#b44">[45]</ref> and Intel Optane DC Persistent Memory Module <ref type="bibr" target="#b18">[19]</ref>. The system with 32GB NVDIMM-N has 20 cores and 32GB DRAM. Another system with 256GB Optane has 16 cores and 64GB DRAM. In the Optane server, we used two 128GB Optanes configured in interleaved App Direct mode. <ref type="table">Table 1</ref> shows the results of measuring the performance of each memory using Intel Memory Latency Checker (MLC) <ref type="bibr" target="#b17">[18]</ref>.</p><p>In our experiment, Libnvmmio used NOVA [68] running on Linux kernel 5.1 as its underlying file system. To compare Libnvmmio with various file systems, we experimented with four file systems: Two of these, Ext4-DAX and PMFS <ref type="bibr" target="#b12">[13]</ref>, journal only metadata and perform in-place writes for data. The two others, NOVA and SplitFS <ref type="bibr" target="#b23">[24]</ref>, guarantee dataatomicity for each operation. We configured NOVA to use CoW updates, but without enabling checksums. For SplitFS, we configured it to use strict mode. We ran PMFS and SplitFS on Linux kernel 4.13, and Ext4-DAX and NOVA on Linux kernel 5.1. Kernel versions are the latest versions that support the underlying file systems. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>.1 Hybrid logging</head><p>Most logging systems adopt only one logging policy (redo or undo). Each logging policy has different strengths and weaknesses, depending on the type of file accesses. While redo logging is better for write-intensive workloads, undo logging is better for read-intensive workloads. <ref type="figure" target="#fig_4">Figure 6</ref> shows how logging policies (redo, undo, and hybrid logging) affect the performance of Libnvmmio. Undo logging shows better performance than redo, when the workload has high read ratio. Redo logging shows better performance than undo, when the workload has high write ratio. When the R:W ratio is 60:40, the two logging policies show the same level of the performance. Based on this observation, Libnvmmio uses the ratio as a change point for its hybrid logging policy. As shown in <ref type="figure" target="#fig_4">Figure 6</ref>, hybrid logging in Libnvmmio achieves the best case performance of the two logging policies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Throughput</head><p>We measured the bandwidth performance by using FIO <ref type="bibr" target="#b4">[5]</ref>. It repeatedly accesses a 4GB file in units of 4KB for 60 seconds in a single thread. Two graphs in <ref type="figure">Figure 7</ref> show the experiment results on NVDIMM-N (A) and Optane (B), respectively. Four file access patterns are used for our experiment: sequential read (SR), random read (RR), sequential write (SW), and random write (RW). All the other file systems except Libnvmmio perform the file IO at kernel level. Libnvmmio avoids the kernel IO stack overhead and performs file IO mostly at user level.</p><p>As shown in <ref type="figure">Figure 7</ref>, Libnvmmio provides the highest throughput on all access patterns, outperforming the other file systems by 1.66∼2.20× on NVDIMM-N and 1.14∼1.74× on Optane. The performance improvements are more noticeable in NVDIMM-N than in Optane. The maximum achievable bandwidths on Optane are 2.5GB/s and 1.46GB/s for FIO mmap based read and write without atomicity support. These are indicated as red dotted lines in <ref type="figure">Figure 7</ref> (B). The performance results on Optane are almost near the maximum achievable bandwidths for Libnvmmio, which suggests the performance on Optane is limited by the hardware limit, not The performance in Libnvmmio is also improved over the other file systems by maximizing logging efficiency in hybrid logging. For read access patterns (SR and RR), Libnvmmio performs only user-level memcpy from the memory-mapped file to the user buffer under the undo logging. For write access patterns (SW and RW), Libnvmmio updates only the log, not the memory-mapped file, under the redo logging and asynchronously writes the data from the redo log on SYNC call at the file close. <ref type="figure" target="#fig_5">Figure 8</ref> shows the performance of the FIO sequential write on various IO sizes. Libnvmmio performs per-block logging, but provides various log block sizes. With this feature, Libnvmmio can keep the high performance across different IO sizes. The performance generally improves on the increased IO sizes for all file systems and Libnvmmio, as the number of write system calls decreases within the 60 second duration of FIO experiment. Libnvmmio shows significantly higher performance than the other file systems when the IO size is smaller than the page size (128B, 1KB). This is mainly due to the differential logging feature in Libnvmmio. For file systems that use CoW for atomicity, such as NOVA, write amplification becomes a large overhead on sub-page size data writes. <ref type="figure">Figure 9</ref> shows the performance of the FIO sequential write on different fsync intervals. The horizontal axis represents the fsync frequency. For example, the interval 10 means FIO performed fsync after every ten writes issued. The performance of Ext4-DAX and PMFS slightly increased as the fsync interval increased. Since Ext4-DAX and PMFS perform only metadata journaling, there is no dramatic performance improvement. NOVA shows the same performance regardless of the fsync interval. Since NOVA performs all the writes atomically and fsync actually does nothing, its performance is not sensitive to the fsync intervals. Libnvmmio implements fsync efficiently with almost little overhead by increasing the current global epoch number at user level. A heavy-lifting work for checkpointing data log is processed in the background. As the fsync interval increases, checkpointing can be done in a batch even in the background. Thus, Libnvmmio can slightly increase the performance on long intervals. <ref type="figure" target="#fig_6">Figure 10</ref> shows the performance of multithreaded file IO with FIO random write. In private file configuration, each thread writes data to its private file. Whereas, all threads write data to one shared file in shared file configuration.   <ref type="figure">Figure 11</ref>: Latency breakdown the shared file simultaneously. The scalability on Optane is limited mainly due to the memory bandwidth limitation, but Libnvmmio on Optane still shows a little promising results than the others. The other two file systems, Ext4-DAX and PMFS rarely scale on multi-threaded experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3">Scalability</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.4">Latency</head><p>We measured write and read latencies of various NVM-aware file systems and Libnvmmio. To make a fair comparison, all operations are synchronous (fsync on every write operation).  <ref type="figure">Figure 11</ref> shows the latency breakdown of read and write for two logging policies (undo and redo). As for write, the portion of non-temporal store (NT Store) is dominating. However, the overheads of the memory fence and cache flush is low due to NT store. In this experiment, we confirmed that it is crucial to select an appropriate logging policy according to access types, as the time spent on memory copy (memcpy, NT Store) varies greatly depending on logging policy. The actual seconds for read and write latencies in <ref type="figure">Figure 11</ref> are bigger than the latency in <ref type="table" target="#tab_4">Table 2</ref>, as time measurement routines for breakdown have been injected.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Real applications</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">SQLite</head><p>We experimented with SQLite <ref type="bibr" target="#b60">[59]</ref> to see how Libnvmmio performs in real applications. To guarantee data-atomicity, SQLite uses its own journaling by default. SQLite calls fsync on commit to ensure that all data updated in a transaction is persistent. Libnvmmio keeps updated data in its logs and atomically writes to the original file when fsync called. This is how data-atomicity can be guaranteed on SQLite on Libnvmmio without the journaling provided by SQLite. However, the file systems we experimented with cannot turn off the journaling. Even file systems that provide data-atomicity for each operation cannot guarantee the atomicity at transaction level without the journaling. We used Mobibench <ref type="bibr" target="#b40">[41]</ref> to evaluate the basic performance of SQLite. In this experiment, we ran SQLite on NOVA with various journal modes: delete (DEL), truncate (TRUNC), write-ahead logging (WAL), no-journaling (OFF). <ref type="figure" target="#fig_0">Figure 12</ref> shows that Libnvmmio outperforms all journaling modes on insert and update queries. Even when no journaling is provided from SQLite, Libnvmmio outperforms as all file accesses are handled at user level. Compared to WAL mode on NVDIMM-N, insert and update queries have 60% and 93%  <ref type="figure" target="#fig_7">Figure 13</ref> shows that running on Libnvmmio exhibits better performance than running only on underlying file systems. The performance gains range from 16% to 27% on NVDIMM-N and from 13% to 27% on Optane. Since Libnvmmio processes file IO at user level, most of file IO operations can be handled efficiently. As for SplitFS <ref type="bibr" target="#b23">[24]</ref>, which is built as user-level file system, Libnvmmio uses only mmap interface from SplitFS and performs all other functionalities with its own mechanism. This is why the performance on SplitFS is better for Libnvmmio than only SplitFS. Data updates are kept in its staging files in SplitFS. When applications call fsync, SplitFS relinks the updated blocks in staging files into the original file without additional data copying. To make the relink mechanism work, a complete content of the block is required. If applications update only part of a block, SplitFS must copy the rest of the partial data for that block on fsync. The relink mechanism also needs splitting and remapping the existing mapping. Since mapping changes require expensive TLB-shootdown, remapping can cause a higher cost than copying <ref type="bibr" target="#b36">[37]</ref>. Additionally, frequent relinks can cause extent fragmentation, as SplitFS uses Ext4-DAX as its underlying file system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">MongoDB MMAPv1</head><p>To evaluate Libnvmmio for applications that use memorymapped IO, we experimented with MongoDB [44] MMAPv1 engine. MongoDB MMAPv1 maps DB files onto its address space, and read/write data with memcpy. We have modified 182 lines of source code to make MongoDB MMAPv1 engine use interfaces in Libnvmmio. <ref type="figure" target="#fig_2">Figure 14</ref> shows the performance of YCSB workloads on MongoDB. MongoDBJournaling represents the performance when MongoDB uses its own journaling. In order to ensure that all modifications to a MongoDB data set are durably written to DB files, MongoDB, by default, records all modifications to a journal file. After persisting the data in journal, MongoDB writes the data to a memory-mapped file. Then, it calls msync periodically to flush the data in the memory to its file image on the persistent storage. If a system failure occurs during the synchronization, MongoDB can redo the updates by using the journal. Atomic-mmap represents the performance when MongoDB uses atomic-mmap provided by NOVA <ref type="bibr" target="#b68">[67]</ref>. NOVA maps the replica pages of files onto the user memory, and later when msync is called, it copies the replica pages atomically to the original file. In this case, MongoDB can guarantee dataatomicity without using its own journaling. Libnvmmio also ensures the same level of data-atomicity as the atomic-mmap in NOVA. Libnvmmio represents the performance when Libnvmmio is used without MongoDB journaling. Compared to MongoDB journaling, Libnvmmio shows 31∼42% performance gains on write intensive workloads (A and F). On read intensive workloads (B, C, D, and E), it shows 6∼15% gains.</p><p>Libnvmmio shows the highest performance for all workloads. In YCSB workloads, the default record size is 1KB. Since MongoDB-Journaling uses msync provided by the OS kernel, the synchronization is performed at page granularity. This increases the write amplification but also incurs TLBshootdown overhead. Whereas, Libnvmmio uses differential logging and user-level msync to minimize write amplification and eliminate unnecessary TLB-shootdown. Atomic-mmap also performs synchronization at page granularity. Besides, as all the replica pages of the file are synchronized regardless of their states (clean or dirty), huge write amplification occurs. Due to such inefficiency, the atomic-mmap feature has been removed from the latest NOVA <ref type="bibr" target="#b69">[68]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Work</head><p>In NVMM systems, file operations travel through memory bus led significantly improved latency. In traditional systems, storage latency was dominant in the total file IO overhead, but in NVMM systems, inefficient behavior of software stacks becomes a dominating overhead. State-of-the-art NVMMaware file systems bypass the block layer and the page cache layer to avoid the software overhead. Many optimizations take the characteristics of NVMM into account in the file system design. Some suggest to fundamentally change the way file operations work from kernel space to user space.</p><p>BPFS and PMFS are early versions of NVMM-aware file systems. BPFS <ref type="bibr" target="#b11">[12]</ref> manages the CPU cache based on epoch to provide an accurate ordering and provides atomic data persistence with short-circuit shadow paging. PMFS <ref type="bibr" target="#b12">[13]</ref> came up with eXecute In Place (XIP) which nowadays call Direct Access (DAX). PMFS pointed out that NVMM systems should bypass the block layer and page cache to remove unnecessary management schemes from past days.</p><p>NOVA <ref type="bibr" target="#b68">[67,</ref><ref type="bibr" target="#b69">68]</ref> suggested more efficient software layer to manage NVMM. NOVA extends the log-structuring technique optimized for block devices to NVMM. NOVA gives each inode a separate log. This technique is suited well in NVMM utilizing fast random access characteristics of NVMM. NOVA provides protection against media errors as well as software errors.</p><p>Aerie <ref type="bibr" target="#b63">[62]</ref> is a user-level file system that provides flexible file system interfaces. Aerie maximizes the benefits of lowlatency NVMM by implementing file system functionality at the user-level. However, Aerie does not guarantee dataatomicity and does not support POSIX semantics.</p><p>Strata <ref type="bibr" target="#b27">[28]</ref> is a cross-media file system that suggested separation of kernel and user responsibilities. While providing fast performance for read and write, Strata does not support atomic memory-mapped IO. Strata brought data into user space and processes metadata in kernel space.</p><p>FLEX <ref type="bibr" target="#b67">[66]</ref> replaces read/write system calls with memorymapped IO to avoid entering the OS kernel. FLEX provides transparent user-level file IO, allowing existing applications to utilize the characteristics of NVMM efficiently. However, FLEX does not guarantee data-atomicity.</p><p>SplitFS <ref type="bibr" target="#b23">[24]</ref> supports user-level IO while providing flexible crash-consistency guarantees. The relink mechanism proposed by SplitFS allows atomic file updates with minimal data copying. SplitFS handles common data operations at the user level and offloads complex and uncommon metadata operations to kernel file systems. SplitFS proposed the proper role of user libraries and kernel file systems for efficient file IO.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>Libnvmmio is a simple and practical solution, which provides low-latency and scalable IO while guaranteeing data atomicity. Libnvmmio rebuilds performance-critical software IO path for NVM. It leverages the memory-mapped IO for fast data access and makes applications free from the crashconsistency concerns by providing failure-atomicity. Source code is publicly available at: https://github.com/chjs/ libnvmmio.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Libnvmmio Overview</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 shows</head><label>2</label><figDesc>the overall architecture of Libnvmmio. When an application opens a file, Libnvmmio interposes the open call with a user-level open API. Within the open API, it maps the whole content of the file onto the user memory space and initializes per-file metadata ( §3.5). The metadata Libnvmmio initializes includes inode number, logging policy, epoch number, etc. After the initialization, it returns the file descriptor to the application.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Per-File Metadata</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Epoch-based committing</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Performance on different logging policies</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 8 :</head><label>8</label><figDesc>Figure 7: Performance on different access patterns</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 10 :</head><label>10</label><figDesc>Figure 9: Performance on different fsync intervals</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 13 :</head><label>13</label><figDesc>Figure 12: Mobibench on SQLite</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table Offset</head><label>Offset</label><figDesc></figDesc><table>rwlock 
entry 
offset 
len 
dest 
policy 
epoch 

File 
Offset 

lgd 
skip 

radix_root 

LGD 

LUD 

LMD 

Table 
Index 
Entry 
(32B) 

Delta 

Log 
Entry 
(4KB~2MB) 

9 
9 
9 
9~0 
12~21 

Lock-Free Radix Tree 

Persistent Memory 

size 

21 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>4KB read and write latencies on Optane 

0 
2 
4 
6 
8 
10 
12 

Elapsed Time (microsecond) 

WR (REDO) 

WR (UNDO) 

RD (REDO) 

RD (UNDO) 

(A) NVDIMM-N 

0 
2 
4 
6 
8 
10 
12 

Elapsed Time (microsecond) 

WR (REDO) 

WR (UNDO) 

RD (REDO) 

RD (UNDO) 

(B) Optane 

Per-File Metadata 
Index Log 
Alloc Log 

NT Store 
Memory Fence 
Manage Log 

Cache Flush 
memcpy 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 2 shows</head><label>2</label><figDesc></figDesc><table>the latency of 4KB IO by a single thread. 
The results were measured on Optane. Libnvmmio outper-
forms all the other file systems. The advantage of Libnvmmio 
comes from writing logs in user space and background check-
pointing. Ext4-DAX requires copying data between user 
and kernel buffers, PMFS involves modification of complex 
data structures, and NOVA requires CoW. Low tail laten-
cies on 99.999th show that Libnvmmio has a high chance to 
meet the demand for target applications. Since Libnvmmio 
hooks read/write calls and does not involve any kernel mode 
switches, Libnvmmio on any file systems can remove the 
complex techniques the kernel level file systems use. The 
Libnvmmio latencies on other file systems exhibit almost the 
same as the ones in Table 2. Our results indicate that applica-
tions sensitive to tail latency can adopt Libnvmmio on top of 
their file systems and drop tail latency dramatically. 
</table></figure>

			<note place="foot" n="1"> Some NVM file systems such as NOVA avoid it. 2 2020 USENIX Annual Technical Conference USENIX Association</note>

			<note place="foot" n="4"> 2020 USENIX Annual Technical Conference USENIX Association</note>

			<note place="foot" n="2"> This term means both fsync and msync.</note>

			<note place="foot" n="3"> This term means both fsync and msync. 4 Through sensitivity studies, we configured Libnvmmio wakes up the threads every 100 microsecond. 6 2020 USENIX Annual Technical Conference USENIX Association</note>

			<note place="foot" n="5"> we measure LOC with sloccount [64] 8 2020 USENIX Annual Technical Conference USENIX Association</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This research was supported in part by Samsung Electronics and the National Research Foundation in Korea under PF Class Heterogeneous High Performance Computer Development NRF-2016M3C4A7952587. We would like to thank our shepherd, Ric Wheeler, and the anonymous reviewers for their insightful comments and suggestions.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Adaptive incremental checkpointing for massively parallel systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saurabh</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rahul</forename><surname>Garg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meeta</forename><forename type="middle">S</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jose</forename><forename type="middle">E</forename><surname>Moreira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th Annual International Conference on Supercomputing, ICS &apos;04</title>
		<meeting>the 18th Annual International Conference on Supercomputing, ICS &apos;04<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page" from="277" to="286" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">DCS: A Fast and Scalable Device-centric Server Architecture</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaehyung</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongup</forename><surname>Kwon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youngsok</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammadamin</forename><surname>Ajdari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaewon</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jangwoo</forename><surname>Kim</surname></persName>
		</author>
		<idno>MICRO-48</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 48th International Symposium on Microarchitecture</title>
		<meeting>the 48th International Symposium on Microarchitecture</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Optimizing the tlb shootdown algorithm with page access tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nadav</forename><surname>Amit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 USENIX Conference on Usenix Annual Technical Conference, USENIX ATC &apos;17</title>
		<meeting>the 2017 USENIX Conference on Usenix Annual Technical Conference, USENIX ATC &apos;17<address><addrLine>Berkeley, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="27" to="39" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Spin-transfer torque magnetic random access memory (stt-mram)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmytro</forename><surname>Apalkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Khvalkovskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Watts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Nikitin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xueti</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Lottis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kiseok</forename><surname>Moon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adrian</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Driskill-Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamad</forename><surname>Krounbi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Emerg. Technol. Comput. Syst</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2013-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jens</forename><surname>Axboe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I/O</forename><surname>Flexible</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tester</surname></persName>
		</author>
		<ptr target="https://github.com/axboe/fio" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Efficient virtual memory for big memory servers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arkaprava</forename><surname>Basu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jayneel</forename><surname>Gandhi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jichuan</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><forename type="middle">D</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">M</forename><surname>Swift</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th Annual International Symposium on Computer Architecture, ISCA &apos;13</title>
		<meeting>the 40th Annual International Symposium on Computer Architecture, ISCA &apos;13<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="237" to="248" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Providing safe, user space access to fast, solid state disks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adrian</forename><forename type="middle">M</forename><surname>Caulfield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todor</forename><forename type="middle">I</forename><surname>Mollov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Louis</forename><forename type="middle">Alex</forename><surname>Eisner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arup</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Coburn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Swanson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventeenth International Conference on Architectural Support for Programming Languages and Operating Systems, ASPLOS XVII</title>
		<meeting>the Seventeenth International Conference on Architectural Support for Programming Languages and Operating Systems, ASPLOS XVII</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">In-memory file system with efficient swap support for mobile smart devices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ryu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Consumer Electronics</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="275" to="282" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Efficient Memory Mapped File I/O for In-Memory File Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jungsik</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hwansoo</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">9th USENIX Workshop on Hot Topics in Storage and File Systems (HotStorage 17). USENIX Association</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Scalable address spaces using rcu balanced trees</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Austin</forename><forename type="middle">T</forename><surname>Clements</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">Frans</forename><surname>Kaashoek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nickolai</forename><surname>Zeldovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventeenth International Conference on Architectural Support for Programming Languages and Operating Systems, ASPLOS XVII</title>
		<meeting>the Seventeenth International Conference on Architectural Support for Programming Languages and Operating Systems, ASPLOS XVII<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="199" to="210" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Radixvm: Scalable address spaces for multithreaded applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Austin</forename><forename type="middle">T</forename><surname>Clements</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">Frans</forename><surname>Kaashoek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nickolai</forename><surname>Zeldovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th ACM European Conference on Computer Systems, EuroSys &apos;13</title>
		<meeting>the 8th ACM European Conference on Computer Systems, EuroSys &apos;13<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="211" to="224" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Better I/O Through Byte-addressable, Persistent Memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeremy</forename><surname>Condit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edmund</forename><forename type="middle">B</forename><surname>Nightingale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Frost</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Engin</forename><surname>Ipek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Doug</forename><surname>Burger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Derrick</forename><surname>Coetzee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGOPS 22nd Symposium on Operating Systems Principles, SOSP &apos;09</title>
		<meeting>the ACM SIGOPS 22nd Symposium on Operating Systems Principles, SOSP &apos;09</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">System Software for Persistent Memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Subramanya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjay</forename><surname>Dulloor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anil</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Keshavamurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dheeraj</forename><surname>Lantz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajesh</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Sankaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jackson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth European Conference on Computer Systems, EuroSys &apos;14</title>
		<meeting>the Ninth European Conference on Computer Systems, EuroSys &apos;14</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Spacejmp: Programming with multiple virtual address spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Izzat El Hajj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerd</forename><surname>Merritt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dejan</forename><surname>Zellweger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reto</forename><surname>Milojicic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Achermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Mei</forename><surname>Faraboschi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Hwu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karsten</forename><surname>Roscoe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schwan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems, ASPLOS &apos;16</title>
		<meeting>the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems, ASPLOS &apos;16<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="353" to="368" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Transparent, incremental checkpointing at kernel level: a foundation for fault tolerance for parallel computers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Gioiosa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Sancho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Petrini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SC &apos;05: Proceedings of the 2005 ACM/IEEE Conference on Supercomputing</title>
		<imprint>
			<date type="published" when="2005-11" />
			<biblScope unit="page" from="9" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Reimplementing the cedar file system using logging and group commit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hagmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh ACM Symposium on Operating Systems Principles, SOSP &apos;87</title>
		<meeting>the Eleventh ACM Symposium on Operating Systems Principles, SOSP &apos;87<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1987" />
			<biblScope unit="page" from="155" to="162" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">File system design for an nfs file server appliance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dave</forename><surname>Hitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Lau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Malcolm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the USENIX Winter 1994 Technical Conference on USENIX Winter 1994 Technical Conference, WTEC&apos;94</title>
		<meeting>the USENIX Winter 1994 Technical Conference on USENIX Winter 1994 Technical Conference, WTEC&apos;94<address><addrLine>Berkeley, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="1994" />
			<biblScope unit="page" from="19" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Latency</forename><surname>Intel Memory</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Checker</surname></persName>
		</author>
		<ptr target="https://software.intel.com/en-us/articles/intelr-memory-latency-checker" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Intel</forename><surname>Optane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tm Dc Persistent</forename><surname>Memory</surname></persName>
		</author>
		<ptr target="https://www.intel.com/content/www/us/en/architecture-and-technology/optane-dc-persistent-memory.html" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Intel Persistent Memory Programming</title>
		<ptr target="https://pmem.io/pmdk/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Micron&amp;apos;s 3d</forename><surname>Intel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Xpoint</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Technology</surname></persName>
		</author>
		<ptr target="https://www.micron.com/about/our-innovation/3d-xpoint-technology" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Supporting filesystems in persistent memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Corbet</surname></persName>
		</author>
		<ptr target="https://lwn.net/Articles/610174/" />
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Differential logging: a commutative and associative logging scheme for highly parallel main memory database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juchang</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kihong</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">K</forename><surname>Cha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings 17th International Conference on Data Engineering</title>
		<meeting>17th International Conference on Data Engineering</meeting>
		<imprint>
			<date type="published" when="2001-04" />
			<biblScope unit="page" from="173" to="182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Splitfs: Reducing software overhead in file systems for persistent memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rohan</forename><surname>Kadekodi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanidhya</forename><surname>Se Kwon Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taesoo</forename><surname>Kashyap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aasheesh</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Kolli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chidambaram</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th ACM Symposium on Operating Systems Principles, SOSP &apos;19</title>
		<meeting>the 27th ACM Symposium on Operating Systems Principles, SOSP &apos;19<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="494" to="508" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">NVMeDirect: A User-space I/O Framework for Application-specific Optimization on NVMe SSDs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyeong-Jun</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Young-Sik</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jin-Soo</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">8th USENIX Workshop on Hot Topics in Storage and File Systems, HotStorage &apos;16. USENIX Association</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">In-memory file system for nonvolatile memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyunjun</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joonwook</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungtae</forename><surname>Ryu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jungsik</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hwansoo</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Research in Adaptive and Convergent Systems, RACS &apos;13</title>
		<meeting>the 2013 Research in Adaptive and Convergent Systems, RACS &apos;13<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="479" to="484" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Beomseok Nam, and Youjip Won. NVWAL: Exploiting NVRAM in Write-Ahead Logging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wook-Hee</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinwoong</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Woongki</forename><surname>Baek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems, ASPLOS &apos;16</title>
		<meeting>the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems, ASPLOS &apos;16</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Strata: A cross media file system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youngjin</forename><surname>Kwon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henrique</forename><surname>Fingler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tyler</forename><surname>Hunt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emmett</forename><surname>Witchel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Anderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th Symposium on Operating Systems Principles, SOSP &apos;17</title>
		<meeting>the 26th Symposium on Operating Systems Principles, SOSP &apos;17<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="460" to="477" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Coordinated and efficient huge page management with ingens</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youngjin</forename><surname>Kwon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hangchen</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">J</forename><surname>Rossbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emmett</forename><surname>Witchel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th USENIX Conference on Operating Systems Design and Implementation, OSDI&apos;16</title>
		<meeting>the 12th USENIX Conference on Operating Systems Design and Implementation, OSDI&apos;16<address><addrLine>USA</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="705" to="721" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Evaluating stt-ram as an energy-efficient main memory alternative</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Kültürsay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kandemir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sivasubramaniam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Mutlu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2013 IEEE International Symposium on Performance Analysis of Systems and Software, ISPASS &apos;13</title>
		<imprint>
			<date type="published" when="2013-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Hints for computer system design</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Butler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lampson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth ACM Symposium on Operating Systems Principles, SOSP &apos;83</title>
		<meeting>the Ninth ACM Symposium on Operating Systems Principles, SOSP &apos;83<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1983" />
			<biblScope unit="page" from="33" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Phase-change technology and the future of main memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">C</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ipek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Mutlu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Burger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Micro</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="143" to="143" />
			<date type="published" when="2010-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Architecting phase change memory as a scalable dram alternative</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Benjamin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Engin</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Onur</forename><surname>Ipek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Doug</forename><surname>Mutlu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Burger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th Annual International Symposium on Computer Architecture, ISCA &apos;09</title>
		<meeting>the 36th Annual International Symposium on Computer Architecture, ISCA &apos;09</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Petal: Distributed virtual disks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Edward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chandramohan</forename><forename type="middle">A</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Thekkath</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh International Conference on Architectural Support for Programming Languages and Operating Systems, AS-PLOS VII</title>
		<meeting>the Seventh International Conference on Architectural Support for Programming Languages and Operating Systems, AS-PLOS VII<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1996" />
			<biblScope unit="page" from="84" to="92" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A case for hardware-based demand paging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gyusun</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenjing</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wonsuk</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeonghun</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonghyun</forename><surname>Bae</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tae Jun</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jae</forename><forename type="middle">W</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinkyu</forename><surname>Jeong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 47th Annual International Symposium on Computer Architecture, ISCA &apos;20</title>
		<meeting>the 47th Annual International Symposium on Computer Architecture, ISCA &apos;20<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1103" to="1116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Design of flash-based dbms: An in-page logging approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bongki</forename><surname>Sang-Won Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Moon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2007 ACM SIGMOD International Conference on Management of Data, SIGMOD &apos;07</title>
		<meeting>the 2007 ACM SIGMOD International Conference on Management of Data, SIGMOD &apos;07<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="55" to="66" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Socksdirect: Datacenter sockets can be fast and compatible</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bojie</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianyi</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zibo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lintao</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Special Interest Group on Data Communication, SIGCOMM &apos;19</title>
		<meeting>the ACM Special Interest Group on Data Communication, SIGCOMM &apos;19<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="90" to="103" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Pmtest: A fast and flexible testing framework for persistent memory programs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sihang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yizhou</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jishen</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aasheesh</forename><surname>Kolli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samira</forename><surname>Khan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Fourth International Conference on Architectural Support for Programming Languages and Operating Systems, ASPLOS &apos;19</title>
		<meeting>the Twenty-Fourth International Conference on Architectural Support for Programming Languages and Operating Systems, ASPLOS &apos;19<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="411" to="425" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Breeze : User-Level Access to Non-Volatile Main Memories for Legacy Software</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amirsaman</forename><surname>Memaripour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Swanson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE 36st International Conference on Computer Design, ICCD &apos;18</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Understanding manycore scalability of file systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changwoo</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanidhya</forename><surname>Kashyap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steffen</forename><surname>Maass</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taesoo</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 USENIX Annual Technical Conference (USENIX ATC 16)</title>
		<meeting><address><addrLine>Denver, CO</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2016-06" />
			<biblScope unit="page" from="71" to="85" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mobibench</surname></persName>
		</author>
		<ptr target="https://github.com/ESOS-Lab/Mobibench" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Repeating history beyond aries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Mohan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th International Conference on Very Large Data Bases, VLDB &apos;99</title>
		<meeting>the 25th International Conference on Very Large Data Bases, VLDB &apos;99<address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="1999" />
			<biblScope unit="page" from="1" to="17" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Aries: A transaction recovery method supporting fine-granularity locking and partial rollbacks using write-ahead logging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Mohan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Don</forename><surname>Haderle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bruce</forename><surname>Lindsay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hamid</forename><surname>Pirahesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Schwarz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Database Syst</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="94" to="162" />
			<date type="published" when="1992-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mongodb</surname></persName>
		</author>
		<ptr target="https://www.mongodb.com" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Netlist</forename><surname>Nvvault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ddr4</forename><surname>Nvdimm-N</surname></persName>
		</author>
		<ptr target="https://www.netlist.com/products/specialty-dimms/nvvault-ddr4-nvdimm" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">A High Performance File System for Non-volatile Main Memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaxin</forename><surname>Ou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwu</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youyou</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh European Conference on Computer Systems, EuroSys &apos;16</title>
		<meeting>the Eleventh European Conference on Computer Systems, EuroSys &apos;16</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Making huge pages actually useful</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Panwar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aravinda</forename><surname>Prasad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gopinath</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Third International Conference on Architectural Support for Programming Languages and Operating Systems, ASPLOS &apos;18</title>
		<meeting>the Twenty-Third International Conference on Architectural Support for Programming Languages and Operating Systems, ASPLOS &apos;18<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="679" to="692" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Annual Update on Interfaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jim</forename><surname>Pappas</surname></persName>
		</author>
		<ptr target="https://www.flashmemorysummit.com/English/Collaterals/Proceedings/2014/20140805_U3_" />
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pappas</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">ijournaling: Finegrained journaling for improving the latency of fsync system call</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daejun</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongkun</forename><surname>Shin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 USENIX Annual Technical Conference (USENIX ATC 17)</title>
		<meeting><address><addrLine>Santa Clara, CA</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2017-07" />
			<biblScope unit="page" from="787" to="798" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Failure-atomic msync(): A simple and efficient mechanism for preserving the integrity of durable data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stan</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terence</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th ACM European Conference on Computer Systems, EuroSys &apos;13</title>
		<meeting>the 8th ACM European Conference on Computer Systems, EuroSys &apos;13</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Application Crash Consistency and Performance with CCFS</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramnatthan</forename><surname>Thanumalayan Sankaranarayana Pillai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lanyue</forename><surname>Alagappan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><forename type="middle">C</forename><surname>Chidambaram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Remzi H Arpaci-Dusseau</forename><surname>Arpaci-Dusseau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">15th USENIX Conference on File and Storage Technologies, FAST &apos;17. USENIX Association</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">All file systems are not created equal: On the complexity of crafting crash-consistent applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Thanumalayan Sankaranarayana Pillai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramnatthan</forename><surname>Chidambaram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samer</forename><surname>Alagappan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><forename type="middle">C</forename><surname>Al-Kiswany</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Remzi</forename><forename type="middle">H</forename><surname>Arpaci-Dusseau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Arpacidusseau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">11th USENIX Symposium on Operating Systems Design and Implementation, OSDI &apos;14. USENIX Association</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Analysis and evolution of journaling file systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><forename type="middle">C</forename><surname>Vijayan Prabhakaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Remzi</forename><forename type="middle">H</forename><surname>Arpaci-Dusseau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Arpaci-Dusseau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Conference on USENIX Annual Technical Conference, ATEC &apos;05</title>
		<meeting>the Annual Conference on USENIX Annual Technical Conference, ATEC &apos;05<address><addrLine>Berkeley, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="8" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Exploiting superpages in a nonvolatile memory file system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L N</forename><surname>Reddy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2012 IEEE 28th Symposium on Mass Storage Systems and Technologies (MSST)</title>
		<imprint>
			<date type="published" when="2012-04" />
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Raoux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">W</forename><surname>Burr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Breitwisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">T</forename><surname>Rettner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Shelby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Salinga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Krebs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Phase-change random access memory: A scalable technology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">H</forename><surname>Lung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IBM Journal of Research and Development</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="465" to="479" />
			<date type="published" when="2008-07" />
		</imprint>
	</monogr>
	<note>4.5</note>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Btrfs: The linux b-tree filesystem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ohad</forename><surname>Rodeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Bacik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Mason</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trans. Storage</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">32</biblScope>
			<date type="published" when="2013-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">FlexSC: Flexible System Call Scheduling with Exception-less System Calls</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Livio</forename><surname>Soares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Stumm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th USENIX Conference on Operating Systems Design and Implementation, OSDI&apos;10. USENIX Association</title>
		<meeting>the 9th USENIX Conference on Operating Systems Design and Implementation, OSDI&apos;10. USENIX Association</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Efficient Memory-Mapped I/O on Fast Storage Device</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Young</forename><surname>Nae</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongseok</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyuck</forename><surname>Son</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heon Young</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yeom</surname></persName>
		</author>
		<idno>19:1-19:27</idno>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Storage</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sqlite</surname></persName>
		</author>
		<ptr target="https://www.sqlite.org" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Towards o(1) memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">M</forename><surname>Swift</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th Workshop on Hot Topics in Operating Systems, HotOS &apos;17</title>
		<meeting>the 16th Workshop on Hot Topics in Operating Systems, HotOS &apos;17</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Didi: Mitigating the performance impact of tlb shootdowns using a shared tlb directory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Villavieja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Karakostas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Vilanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Etsion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ramirez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mendelson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Navarro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cristal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">S</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2011 International Conference on Parallel Architectures and Compilation Techniques</title>
		<imprint>
			<date type="published" when="2011-10" />
			<biblScope unit="page" from="340" to="349" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Aerie: Flexible File-system Interfaces to Storage-class Memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haris</forename><surname>Volos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanketh</forename><surname>Nalli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sankarlingam</forename><surname>Panneerselvam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Venkatanathan</forename><surname>Varadarajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prashant</forename><surname>Saxena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">M</forename><surname>Swift</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth European Conference on Computer Systems, EuroSys &apos;14</title>
		<meeting>the Ninth European Conference on Computer Systems, EuroSys &apos;14</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Robustness in the salus scalable block store</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manos</forename><surname>Kapritsos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zuocheng</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prince</forename><surname>Mahajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeevitha</forename><surname>Kirubanandam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorenzo</forename><surname>Alvisi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Dahlin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th USENIX Conference on Networked Systems Design and Implementation, nsdi&apos;13</title>
		<meeting>the 10th USENIX Conference on Networked Systems Design and Implementation, nsdi&apos;13<address><addrLine>USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="357" to="370" />
		</imprint>
	</monogr>
<note type="report_type">USENIX Association</note>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wheeler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sloccount</surname></persName>
		</author>
		<ptr target="https://dwheeler.com/sloccount/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">SCMFS: A File System for Storage Class Memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojian</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Narasimha Reddy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 2011 International Conference for High Performance Computing, Networking, Storage and Analysis, SC &apos;11</title>
		<meeting>2011 International Conference for High Performance Computing, Networking, Storage and Analysis, SC &apos;11</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Finding and fixing performance pathologies in persistent memory software stacks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juno</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amirsaman</forename><surname>Memaripour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Swanson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Fourth International Conference on Architectural Support for Programming Languages and Operating Systems, ASPLOS &apos;19</title>
		<meeting>the Twenty-Fourth International Conference on Architectural Support for Programming Languages and Operating Systems, ASPLOS &apos;19<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="427" to="439" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">NOVA: A Logstructured File System for Hybrid Volatile/Non-volatile Main Memories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Swanson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">14th USENIX Conference on File and Storage Technologies, FAST &apos;16. USENIX Association</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">NOVA-Fortis: A Fault-Tolerant Non-Volatile Main Memory File System</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amirsaman</forename><surname>Memaripour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akshatha</forename><surname>Gangadharaiah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amit</forename><surname>Borase</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tamires</forename><surname>Brito Da</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andy</forename><surname>Swanson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rudoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th Symposium on Operating Systems Principles, SOSP &apos;17</title>
		<meeting>the 26th Symposium on Operating Systems Principles, SOSP &apos;17</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">When poll is better than interrupt</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jisoo</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dave</forename><forename type="middle">B</forename><surname>Minturn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Hady</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th USENIX Conference on File and Storage Technologies, FAST&apos;12</title>
		<meeting>the 10th USENIX Conference on File and Storage Technologies, FAST&apos;12<address><addrLine>Berkeley, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="3" to="3" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Nv-tree: Reducing consistency cost for nvm-based single level systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingsong</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chundong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Khai Leong</forename><surname>Yong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bingsheng</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">13th USENIX Conference on File and Storage Technologies, FAST &apos;15. USENIX Association</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Torturing databases for fun and profit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mai</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Tucek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dachuan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Lillibridge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elizabeth</forename><forename type="middle">S</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shashank</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">11th USENIX Symposium on Operating Systems Design and Implementation, OSDI &apos;14. USENIX Association</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
