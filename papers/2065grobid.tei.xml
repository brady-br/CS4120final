<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2020-09-29T02:25+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">IASO: A Fail-Slow Detection and Mitigation Framework for Distributed Storage Services IASO: A Fail-Slow Detection and Mitigation Framework for Distributed Storage Services</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>July 10-12, 2019</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Biswaranjan</forename><surname>Panda</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Nutanix Inc.; Haryadi S. Gunawi</orgName>
								<orgName type="institution" key="instit1">Nutanix Inc</orgName>
								<orgName type="institution" key="instit2">Huan Ke</orgName>
								<orgName type="institution" key="instit3">University of Chicago</orgName>
								<orgName type="institution" key="instit4">University of Chicago</orgName>
								<orgName type="institution" key="instit5">Nutanix Inc. University of Chicago</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deepthi</forename><surname>Srinivasan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Nutanix Inc.; Haryadi S. Gunawi</orgName>
								<orgName type="institution" key="instit1">Nutanix Inc</orgName>
								<orgName type="institution" key="instit2">Huan Ke</orgName>
								<orgName type="institution" key="instit3">University of Chicago</orgName>
								<orgName type="institution" key="instit4">University of Chicago</orgName>
								<orgName type="institution" key="instit5">Nutanix Inc. University of Chicago</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karan</forename><surname>Gupta</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Nutanix Inc.; Haryadi S. Gunawi</orgName>
								<orgName type="institution" key="instit1">Nutanix Inc</orgName>
								<orgName type="institution" key="instit2">Huan Ke</orgName>
								<orgName type="institution" key="instit3">University of Chicago</orgName>
								<orgName type="institution" key="instit4">University of Chicago</orgName>
								<orgName type="institution" key="instit5">Nutanix Inc. University of Chicago</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vinayak</forename><surname>Khot</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Nutanix Inc.; Haryadi S. Gunawi</orgName>
								<orgName type="institution" key="instit1">Nutanix Inc</orgName>
								<orgName type="institution" key="instit2">Huan Ke</orgName>
								<orgName type="institution" key="instit3">University of Chicago</orgName>
								<orgName type="institution" key="instit4">University of Chicago</orgName>
								<orgName type="institution" key="instit5">Nutanix Inc. University of Chicago</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Biswaranjan</forename><surname>Panda</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Nutanix Inc.; Haryadi S. Gunawi</orgName>
								<orgName type="institution" key="instit1">Nutanix Inc</orgName>
								<orgName type="institution" key="instit2">Huan Ke</orgName>
								<orgName type="institution" key="instit3">University of Chicago</orgName>
								<orgName type="institution" key="instit4">University of Chicago</orgName>
								<orgName type="institution" key="instit5">Nutanix Inc. University of Chicago</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deepthi</forename><surname>Srinivasan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Nutanix Inc.; Haryadi S. Gunawi</orgName>
								<orgName type="institution" key="instit1">Nutanix Inc</orgName>
								<orgName type="institution" key="instit2">Huan Ke</orgName>
								<orgName type="institution" key="instit3">University of Chicago</orgName>
								<orgName type="institution" key="instit4">University of Chicago</orgName>
								<orgName type="institution" key="instit5">Nutanix Inc. University of Chicago</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huan</forename><surname>Ke</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Nutanix Inc.; Haryadi S. Gunawi</orgName>
								<orgName type="institution" key="instit1">Nutanix Inc</orgName>
								<orgName type="institution" key="instit2">Huan Ke</orgName>
								<orgName type="institution" key="instit3">University of Chicago</orgName>
								<orgName type="institution" key="instit4">University of Chicago</orgName>
								<orgName type="institution" key="instit5">Nutanix Inc. University of Chicago</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karan</forename><surname>Gupta</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Nutanix Inc.; Haryadi S. Gunawi</orgName>
								<orgName type="institution" key="instit1">Nutanix Inc</orgName>
								<orgName type="institution" key="instit2">Huan Ke</orgName>
								<orgName type="institution" key="instit3">University of Chicago</orgName>
								<orgName type="institution" key="instit4">University of Chicago</orgName>
								<orgName type="institution" key="instit5">Nutanix Inc. University of Chicago</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vinayak</forename><surname>Khot</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Nutanix Inc.; Haryadi S. Gunawi</orgName>
								<orgName type="institution" key="instit1">Nutanix Inc</orgName>
								<orgName type="institution" key="instit2">Huan Ke</orgName>
								<orgName type="institution" key="instit3">University of Chicago</orgName>
								<orgName type="institution" key="instit4">University of Chicago</orgName>
								<orgName type="institution" key="instit5">Nutanix Inc. University of Chicago</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haryadi</forename><forename type="middle">S</forename><surname>Gunawi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Nutanix Inc.; Haryadi S. Gunawi</orgName>
								<orgName type="institution" key="instit1">Nutanix Inc</orgName>
								<orgName type="institution" key="instit2">Huan Ke</orgName>
								<orgName type="institution" key="instit3">University of Chicago</orgName>
								<orgName type="institution" key="instit4">University of Chicago</orgName>
								<orgName type="institution" key="instit5">Nutanix Inc. University of Chicago</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">IASO: A Fail-Slow Detection and Mitigation Framework for Distributed Storage Services IASO: A Fail-Slow Detection and Mitigation Framework for Distributed Storage Services</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2019 USENIX Annual Technical Conference</title>
						<meeting>the 2019 USENIX Annual Technical Conference <address><addrLine>Renton, WA, USA</addrLine></address>
						</meeting>
						<imprint>
							<date type="published">July 10-12, 2019</date>
						</imprint>
					</monogr>
					<note>This paper is included in the Open access to the Proceedings of the 2019 USENIX Annual Technical Conference is sponsored by USENIX. https://www.usenix.org/conference/atc19/presentation/panda</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We address the problem of &quot;fail-slow&quot; fault, a fault where a hardware or software component can still function (does not fail-stop) but in much lower performance than expected. To address this, we built IASO, a peer-based, non-intrusive fail-slow detection framework that has been deployed for more than 1.5 years across 39,000 nodes in our customer sites and helped our customers reduce major outages due to fail-slow incidents. IASO primarily works based on timeout signals (a negligible overhead of monitoring) and converts them into a stable and accurate fail-slow metric. IASO can quickly and accurately isolate a slow node within minutes. Within a 7-month period, IASO managed to catch 232 fail-slow incidents in our large deployment field. In this paper, we have also assembled a large dataset of 232 fail-slow incidents along with our analysis. We found that the fail-slow annual failure rate in our field is 1.02%.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Maintaining high availability of distributed storage services in real deployment fields is challenging due to the various types of faults that can occur. In the last few years, there has been an emphasis on "fail-slow" fault mode <ref type="bibr" target="#b26">[28,</ref><ref type="bibr" target="#b31">32]</ref>. This means that a hardware or software component can still function (does not fail-stop) but in much lower performance than expected. Such faults have been studied under different names such "gray failure" <ref type="bibr" target="#b31">[32]</ref>, "limping" <ref type="bibr" target="#b22">[24,</ref><ref type="bibr" target="#b36">37]</ref>, and "partial failures" <ref type="bibr" target="#b28">[29]</ref>. We chose the term "fail-slow" for simplicity and reflecting a recent term <ref type="bibr" target="#b26">[28]</ref>.</p><p>The urgency here is that many distributed systems are still designed based on a binary model of no failure and fail-stop failures. Recent works shows that many distributed systems cannot gracefully tolerate fail-slow mode, i.e. the system cannot isolate and hide a fail-slow component, causing latency spikes or throughput degradation to users <ref type="bibr" target="#b22">[24,</ref><ref type="bibr" target="#b26">28,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b55">56]</ref>. Worse, it has been reported that a fail-slow component can cause cascade of performance failures across the cluster, bringing down services for hours <ref type="bibr" target="#b22">[24,</ref><ref type="bibr" target="#b26">28]</ref>. This calls for the importance of designing systems that tolerate not just absolute failure of sub-components but can also gracefully handle the occurrence of performance faults.</p><p>In this context, our work in this paper makes the two following contributions:</p><p>(1) Design and implementation of a fail-slow mitigation framework. The first contribution of the paper is IASO, our peer-based, non-intrusive fail-slow detection framework that has been deployed for more than 1.5 years across 39,000 nodes in our customer sites. Before the integration with IASO we had more than 25 full outages (IOPS went to zero) due to cascading impacts of fail-slow incidents, not to mention many other occurrences of partial slowdowns. Since the integration with IASO, we had only 2 major outages (false negative cases) caused by fail slow.</p><p>Motivation: IASO is motivated by the following reasons. First, we found that fail-slow faults can be caused by many root causes. Sole dependence on low-level detection tools <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b13">15,</ref><ref type="bibr" target="#b3">4]</ref> at various levels of the software and hardware stack might not be sufficient. Thus, we need a fail-slow detection system that works at the service (distributed system) level. Most existing work focuses on hardware level outlier detection or software performance bugs but they might not cover all of the detailed root causes occurring in the field ( §4.2.3).</p><p>Second, most existing efforts focus only on detection but not mitigation. We are only aware of a handful of works that perform mitigation in real deployments (more in §5). Yet, our findings suggest that if fail-slow incidents are not quickly and automatically isolated, it can cascade and directly affect users for hours or days. For this reason, it is paramount that deployed systems are equipped with fail-slow mitigation.</p><p>Third, although some computing frameworks such as MapReduce <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b21">23]</ref> are equipped with fail-slow mitigation (e.g., via speculative execution <ref type="bibr" target="#b58">[58]</ref> or cloning <ref type="bibr" target="#b8">[10]</ref>), the tail tolerance is built in their abstractions (e.g., "jobs", "tasks") and not directly generalizable to many other distributed systems. Recent works revealed that many other distributed systems are still not fail-slow tolerant [24, <ref type="figure">Figure 1</ref>][56, <ref type="figure" target="#fig_0">Figure  12</ref>]. Hence, we need a more general way of addressing failslow faults in many distributed storage services.</p><p>Challenges and solutions: A fail-slow detection framework must be non-intrusive (negligible overhead), stable and accurate, and not accidentally make wrong decisions (e.g., quarantine healthy nodes). To achieve this, we make IASO peer-based, i.e., a slow service instance should be compared against its peers of the same service (e.g., the performance of Cassandra instance should not be compared to ZooKeeper's). We also make IASO load aware, i.e., the relative performance of a service instance must not be improved or worsen just because the load on the node on which the instance is running on is different.</p><p>To achieve all of these, we created an algorithm ( §2.2) that can work solely based on timeout signals. Our algorithm can convert timeout and successful-response statistics into a stable and accurate fail-slow detector. Our framework does not need to monitor every request latency, hence achieving a neglibible overhead. IASO can quickly and accurately isolate a slow node within minutes. Within a 7-month period, IASO managed to catch 232 fail-slow incidents in our large deployment field. IASO also automatically quarantined the slow nodes and restored the clusters back to a healthier performance. We only encountered 9 confirmed false positives. Other false positives are because the fail-slowness disappeared when our engineers started diagnosing them (e.g., perhaps caused by unknown external conditions).</p><p>(2) A dataset and analysis of fail-slow incidents With IASO integration, we were able to capture many fail-slow incidents in the field. We have assembled a large dataset of fail-slow incidents along with our analysis <ref type="bibr" target="#b6">[7]</ref>. To the best of our knowledge, this is the largest dataset of fail-slow cases publicly reported from within a company. Furthermore, existing accounts of fail-slow accidents are anecdotal <ref type="bibr" target="#b10">[12,</ref><ref type="bibr" target="#b26">28,</ref><ref type="bibr" target="#b31">32]</ref>, while our contribution includes some quantitative analysis (e.g., AFR, age correlation).</p><p>The dataset: The dataset contains 232 validated cases collected from the deployment of 39,000 nodes throughout a period of 7 months. 1 This data pertains to a type of fully hyperconverged system <ref type="bibr">[9]</ref> that we deploy in customer sites.</p><p>Findings: Our rich dataset allows us to make some statistical findings. First, given 232 independent cases across 39,000 nodes over 7 months, we can derive that the annual failure rate is 1.02% (232 × 12 / 7 / 39,000), which is relatively significant compared to rates of other types of faults ( §4.2.1). Second, we uncovered a wide range of root causes (and the low-level sub-causes), which again accentuates the need for detection at the service level, not just at the individual hardware level. Third, we also observed the "infant mortality" pattern where younger machines exhibit more failslow incidents. Fourth, we show that if not mitigated properly, fail-slow cases can take hours or days to fully resolve, which again highlights the importance of automatically quar-1 For this publication we only have analyzed the dataset for a 7 month period in 2017. Data from 2018 is still being perused and cleaned. antining slow nodes.</p><p>The following sections present the design and implementation of IASO ( §2), experimental results ( §3), our dataset and findings ( §4), related work and conclusion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">IASO</head><p>This section presents IASO, our framework for detecting the presence of an unhealthy node and enabling self healing of the cluster. We name our system after "Iaso", the Greek goddess of recuperation from illness <ref type="bibr" target="#b7">[8]</ref>. IASO is comprised of three stages:</p><p>1. Detection ( §2.1-2.2): This step reduces the time to detect fail-slow incidents from hours to minutes while keeping false positives low.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Mitigation ( §2.3):</head><p>This step quarantines the faulty node and brings the cluster back to operation.</p><p>3. Resolution ( §2.4): IASO automatically pages site reliability engineers (SREs) to identify the failed component and help support to do breakfix and assimilate the fixed component back into operation.</p><p>When building IASO, we adhere to the following design principles.</p><p>• Non intrusive: We attempt to reach a near 0% overhead, hence we use raw metrics that the deployed services already collect (e.g., number of timeouts and successful responses).</p><p>• Peer based: A slow service instance should be compared against its peers of the same service, e.g., the performance of Cassandra instance should be compared to other Cassandra instances, not ZooKeeper instances, as different types of services observe different types of workload. For this reason, we monitor at service-level requests, not at OS or hardware level.</p><p>• Load aware: The slowdown detection system must be aware of the service load. The relative performance of a peer must not be improved or worsen just because the load on the node the peer is running on is different. This means that the performance of a node must be normalized based on the capacity of the node; in our deployment, a cluster can have different machine capacities with different loads.</p><p>• Stable and accurate: As a degraded node will be quarantined, it is important to have a stable and accurate algorithm that does not accidentally make wrong decisions (false positives).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VM1</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CS1 ZK1</head><p>Scr ..</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Scr</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VM2</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CS2 ZK2</head><p>Scr ..  <ref type="figure">Figure 1</ref>: IASO components. The figure is described in the last paragraph of page 2 and also in Section 2.1. "Scr" denotes the hook that sends score table to ScoreDB.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Scr</head><p>The following are the terms we use in this paper. As shown in <ref type="figure">Figure 1</ref>, our system S is a cluster of high-end machines (gray shades) running VMs wherein services are running (boxes). For example, S comprises a ZooKeeper (ZK) service for cluster configuration manager, a Cassandra service (CS) for storing metadata, and our own blob-store service for storing data. Each VM runs an instance of each of the services (e.g., a VM runs three service instances, Cassandra, ZooKeeper and blob-store instances). These VMs are also known as controller VMs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Detection</head><p>Our first goal is to detect which service instance is experiencing a slowdown. Currently we only address persistent fault, i.e., the instance is not being slowed down due to an intermittent condition such as a one-off high GC time. This section describes the main components of IASO as shown in <ref type="figure">Figure  1</ref>. The next section ( §2.2) presents the detailed algorithm.</p><p>RAW METRICS (LATENCY VS. TIMEOUTS): One naive method to measure degradation is to measure the latency of every request. However, with today's high-throughput services it is not amenable (e.g., per-node Cassandra throughput can reach 20,000 IOPS <ref type="bibr" target="#b4">[5]</ref>). Sampling can be a solution, but we explored a different method.</p><p>In this work, we try a much cheaper method to detect degradation: counting timeouts. Many services such as Cassandra already have a built-in metric that collects how many responses were successful as well as the failed ones due to timeouts. Another advantage of using timeouts is that our monitoring system is not intrusive to the performance of the service itself (a nearly 0% overhead as counting timeouts and successful responses is a simple increment operation).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SCORES:</head><p>We found that using raw timeout counts as a direct metric to measure outlier is not a stable and accurate way. Thus, we need to introduce the concept of "score". Given a cluster of N nodes with N instances of a service, every instance can observe the performance of its N −1 peers and maintain a "score table" (as shown in <ref type="figure">Figure 1</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>STABLE SCORES:</head><p>The primary challenge we address in this work is how to convert timeout and success statistics into a stable and accurate degradation detector. Noisy scores can lead to more false positives where healthy nodes might be accidentally removed and vice versa. Later, the experiment section shows other unsuccessful algorithms that we tried ( §3) which then led us to the current algorithm ( §2.2).</p><p>One key to prevent scores from fluctuating along with the number of timeouts is by incorporating additive increase and multiplicative decrease (AIMD) <ref type="bibr" target="#b16">[18]</ref> such as used in TCP congestion avoidance. Thus, our custom algorithm employs a technique similar to AIMD. SCOREDB SERVER: The scores collected from the service instances are stored in a database server called ScoreDB <ref type="figure">(Figure 1</ref>). For every peer, every instance keeps a score, hence in total ScoreDB maintains N ×(N −1) score variables (per every service monitored) including their historical values. Given these scores, ScoreDB runs an outlier detection part of our algorithm and quarantines the outlier. ScoreDB is also a replicated system (to anticipate degradation within itself).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Detection Algorithm</head><p>We now describe how IASO calculates the score metric and detects an outlier. The challenge is to convert timeout and success statistics into a stable and accurate degradation detector. For every equation listed below, the explanation is in the paragraph preceding the equation. Symbols † and ‡ are used for backward references.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Peer Scores</head><p>Given a cluster of N instances within a service (e.g., Cassandra), every instance observes the performance of its peers and puts the corresponding scores in a score table containing N −1 peer scores. In our scoring system below, a score ranges from 1 to 100 where a higher value implies more severe degradation. For example, in the score table in <ref type="figure">Figure 1</ref>, Cassandra instance on Node2 believes that Cassandra instane on Node1 is slow (a score of 98).</p><p>As score continues to change, below we use prev and score to represent the scores in the last and current epoch respectively. An epoch is the interval at which every service instance runs the equations below (i.e., calculates a new score). The epoch is set to be 5 seconds and prev to 1 in the beginning.</p><p>Next, we introduce ToRespRatio, the ratio of the number of timeouts and total responses between two peers within an epoch. This is essential to the load-awareness part of our algorithm, that timeout counts should be relative to the num-ber of total responses as the number of responses will vary across peers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ToRespRatio = #timeouts / #responses</head><p>We then set ratioThresh, a timeout-response ratio threshold, with a constant value of 0.1 (e.g., 10 timeouts for every 100 responses). In our experience, 10% timeouts from a peer can cause a whole-cluster degradation. A higher value may make IASO react too late, while a lower may lead to more false positives (i.e., too sensitive). If ToRespRatio is larger than the ratioThresh, it is likely a heavy degradation. Otherwise, it is likely caused by a temporary high load or a benign cause.</p><formula xml:id="formula_0">ratioThresh = 0.1</formula><p>Next, we introduce minTTR as the minimum time to observe zero timeout from a peer before the score assigned to it decreases from 100 to 1 (slow to healthy). We set the time to be 2 minutes. The idea is that when a peer exhibits a zero timeout, it might mean that this peer is temporarily healthy but might suffer degradation again soon. The 2-minute mark is the time window in which a peer must "prove" itself that it is really healthy. A smaller window increases the risk that we may start assigning good scores to a temporarily good peer and thereby creating an unstable score pattern. A larger window has the disadvantage that we may mark a peer as fail-slow even if it has just completely recovered but the 2-minute window hasn't passed. However, the latter scenario should be infrequent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>minTTR = 2 mins</head><p>With all of the values above, now we can stitch them into the score calculation. In every epoch, if ToRespRatio is 0 (no timeout), then the score will be calculated as shown below. This is the "additive decrease" part of our algorithm -the score will be slowly decreasing back to zero to show that the peer is really healthy.</p><formula xml:id="formula_1">[ if ToRespRatio is 0 ] score = prev − ( 100 × epoch / minTTR )</formula><p>Now, we discuss the case where some timeouts are observed (ToRespRatio is not zero). First, we introduce minRatio as a higher bound of the timeout-response ratio and threshold values. The idea here is that ToRespRatio can be very high (e.g., 90%, when a peer is highly unresponsive). This high value will make our algorithm below unstable. Thus, we cap it to the ratioThresh value (0.1), i.e., 10% already represents enough degradation.</p><formula xml:id="formula_2">minRatio = min ( ToRespRatio , ratioThresh ) †</formula><p>Finally, the last variable we introduce is nearThresh to measure how far the timeout-response ratio to the threshold (how far from the 10% timeouts). This threshold nearness ranges from 0 to 1.0.</p><formula xml:id="formula_3">nearThresh = minRatio / ratioThresh ‡</formula><p>With all the new variables above, we now can calculate the score when timeout-response ratio is higher than zero. The equation below represents the "multiplicative increase" part of our algorithm where the score is increased by the threshold nearness. We put more examples below.</p><p>[ if ToRespRatio is not 0 ]</p><formula xml:id="formula_4">score = prev + ( prev × nearThresh )</formula><p>Let's use an example where an instance gave a score of 32 for a peer instance in the last epoch. Now, the current epoch sees too many timeouts beyond the threshold such that nearThresh is 1.0. Thus, the current score will jump from 32 to 32+32 (i.e., the score increases multiplicatively). 2 score = 32 + ( 32 × 1.0 ) = 64</p><p>Let's imagine another scenario where the ToRespRatio is as small as 0.01 (1% timeouts) . Here, the minRatio will be 0.01 (see equation † ) and the nearThresh be 0.1 (see ‡ ). Thus, the next score will only increment fractionally:</p><formula xml:id="formula_5">score = 32 + ( 32 × 0.1 ) = 35.2</formula><p>To sum up, our algorithm prevents scores from fluctuating along with the number of timeouts. That is, we linearly decrement the score when we do not observe any timeouts from a peer, but multiplicatively increase the score when we observe timeouts from the peer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Scores Set</head><p>Every instance X then sends the scores of its peers (A, B, ...) to the ScoreDB server, which will then maintain a history of the scores. For example for a given peer A, there are N −1 scores for A collected in every 5-second epoch.</p><p>For every peer, all the scores given for that peer are collected within a 10-minute sliding window, where ScoreDB then picks the 30 th -percentile value to be the representative score for that peer, such as for instance A. The 30 thpercentile value implies that the peer instance must have 70% high score values within a 10-minute interval such that we do not inadvertently quarantine instances with mere transient faults. In our deployments, we have observed that a 10-minute window is wide enough to detect persistent faults. It may not be the absolute minimum but it does put an upper bound on the time to isolate a fail-slow peer.</p><p>At this point, ScoreDB has N representative scores for all the instances in the cluster and it submits these scores to the DBSCAN algorithm <ref type="bibr" target="#b5">[6]</ref>. ScoreDB performs this every minute, but using the data from the past 10 minutes (a sliding window). DBSCAN <ref type="bibr" target="#b5">[6]</ref> is an algorithm that takes a set of points and groups them such that points that are spatially close are grouped together while points which do not have enough close neighbors are classified as outliers. Thus, we configure DBSCAN to output a binary decision (whether an instance is "fast" or "slow"). We also only mark at most one outlier at a time to make sure we do not remove too many service instances (explained later in §2.3).</p><p>Finally, we emphasize that we only compare instances (scores) of the same service. We do not compare instance scores of Cassandra with those of ZooKeeper, thus the algorithm above runs for every service deployed. For example in <ref type="figure">Figure 1</ref>, the ScoreDB server maintains history of Cassandra and ZooKeeper peer scores separately.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Mitigation</head><p>After a service instance is marked as an outlier, IASO starts the mitigation process. Below are the three options that our customers can set in IASO configuration. The first one (service instance reboot) is the default configuration. The philosophy of our mitigation is that it is better to remove a highly degraded instance than allowing it to induce a cascading problem to the entire cluster. Other works <ref type="bibr" target="#b22">[24,</ref><ref type="bibr" target="#b55">56]</ref> already show how running with one less instance (N −1) can give a better performance than running a full cluster (N ) with a degraded instance. IASO only quarantines at most one instance to prevent the cluster drops below its fault-tolerant level.</p><p>(1) SERVICE INSTANCE REBOOT AND LEADERSHIP REMOVAL: Here, IASO will restart the slow instance and remove leadership leases (if any) from the service instance running on that node. We emphasize here that we only remove the service instance (e.g., Cassandra/ZooKeeper slow instance), but not the underlying VM or the machine. As a reason, imagine a machine where an instance of service X uses the underlying slow disk, but another instance of service Y only utilizes the memory (still fast). Here, we want X to be rebooted and its leadership removed, but let Y continue to run normally as it is not affected by the slow disk.</p><p>Regarding the removal of leadership, in ZooKeeper, if the instance is a leader, rebooting the instance will automatically make ZooKeeper choose a new leader. This way the old slow leader is no longer the single point of performance failure. The only cost associated with this action is the rebuilding of leader state on some other healthy peer.</p><p>In Cassandra, every instance is responsible for a key range (our deployment does not use Cassandra's virtual node feature). Here, we have two opposing options for mitigation. The expensive option is to remove the instance from the ring and trigger a whole-cluster key-range rebalancing, which might be a premature action as the instance perhaps can be fixed soon. The cheaper option is to let the slow instance be in the ring but not allow it to be part of the data transfer.</p><p>We chose the latter option and modified Cassandra slightly to achieve this. In this mode, the slow instance is no longer the primary owner of its key range, but rather one of the other replicas becomes the primary owner. The upside is that we postpone the need for whole-cluster key-range rebalancing. The downside is that the fault tolerance of newly added data will be down by one (e.g., we can only write to two replica nodes as the instance on the slow node is being isolated) and read throughput may be degraded due to the loss of one instance. We note that the fault tolerance of old data does not go down as the data is still there in the slow instance.</p><p>Regardless of the limitations of this default option, customers who have smaller clusters tend to choose this option as they do not have options to migrate the instance or VMs to another healthy machine. Below we discuss other options for customers with larger clusters.</p><p>(2) VM SHUTDOWN: This is a more severe action than the default option above. In this mode, the controller VM of the slow service instance is shut down and no services are started on the VM. The difference between this action and the default one above is that when VM is shut down, the services above will automatically run their recovery protocols (e.g., whole ring rebalancing). Thus, the fault tolerance of the data stays the same (e.g., 3-way replication is still maintained). The similarity is that there may also be a performance drop to the loss of a VM. When the problem is fixed, the VM is added backed and full performance can be restored.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(3) HOST MACHINE SHUTDOWN: This option is similar</head><p>to VM shutdown. The difference is that our system will automatically migrate the entire VM from this host to another, which is a process transparent to the services running on the VM. There may be a potential VM rebalancing issue (e.g., a machine has too many VMs). For VM balancing, we employ our own proprietary VM rebalancing that is outside the scope of the paper. We also emphasize that in our deployment, these machines are running the services that we deploy. The machines are not shared with other tenants, hence we have a full control of when to shut down the machine.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Resolution</head><p>The last stage, resolution, is the manual part of the whole IASO operational procedure, which we describe here for completeness.</p><p>When detecting a fail-slow node, IASO generates a user alert on the customer monitoring UI. IASO also pages our site-reliability engineers (SREs) such that they can work with the affected customer to fix the problem. If there had been a cluster outage (i.e., cluster IOPS went to almost zero) before the mitigation, IASO helps the customer and our SREs in identifying the faulty node and service.</p><p>It is also possible that before the SREs perform the full diagnosis, the problem already went away by itself from rebooting the slow node. We see this happens in cases such as CPU locks-ups or high heap usage levels. In such cases, IASO will no longer mark the node as a degraded node. In overall, when the problem is fixed, IASO immediately rolls back the fail-slow node actions executed before, and service instances on the newly recovered node regain their leadership responsibilities. Temporary fail-slow faults can be recurrent (e.g., high heap usage level). To prevent such recurrent faults, the root cause must be fixed. For example, we could apply some custom optimizations to our services to prevent it from entering such a state again.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Other Implementation Details</head><p>INTEGRATION: So far we have integrated IASO with Cassandra and ZooKeeper. The implementation complexity is shown in <ref type="table">Table 1</ref>. The changes to the target services are non-intrusive (less than 600 LOC). The service instances use IASO library to measure local scores and send them to the ScoreDB server where the rest of the complexity lies. The total score data size of ScoreDB server is only 0.27 MB per day per cluster on average as it only needs to keep the score history of the last 10 minutes. The CPU overhead is near 0%.</p><p>We envision that IASO can be easily integrated to other master-worker systems where data flows across workers. For example, in HDFS, write replication forms a pipeline of datanodes where each datanode can sense the performance of its peers. For systems like ZooKeeper, the integration involves a different type of modification due to ZooKeeper's "pure" leader-follower architecture (i.e., followers do not interact with each other). We describe these changes later below. As mentioned before, we also run our own blob-store service which can be integrated with IASO as well. This process is still in progress, not because of integration difficulty, but because so far our IASO integration in Cassandra and Zookeper seems to be sufficient. One limitation of our deployment is that a single blob-store instance can be misconfigured causing a fail-slow fault, but goes undetected (which again so far never happened).</p><p>ZOOKEEPER MODIFICATION: In our deployment, the Cassandra-side IASO so far has been very effective. But as we deal with deployments of tens of thousands of nodes, we can potentially cover a wider set of failure types if we can integrate IASO with another service as well. Hence, we attempted to integrate IASO to ZooKeeper, but ZooKeeper employs a pure leader-follower architecture where followers do not transfer data with each other (i.e., 3-way writes flow from the leader to three followers, unlike in HDFS or Cassandra). The leader is a single point of performance failure <ref type="bibr" target="#b22">[24]</ref>; if the leader's NIC is slow, the writes to all the followers will slow down, hence no outlier.</p><p>For this, we add a simple, lightweight background pingpong thread between ZooKeeper peers (only &lt;200 LOC). Every 10 seconds, every instance picks a maximum of 7 random peers and makes an RPC that includes a synchronous disk write. Checking the disk latency this way is also beneficial since most data operations in Cassandra hit the cache, hence disk monitoring is a bit lacking. Besides these small changes, we emphasize that the rest of the algorithm is the same -the instances send the median latencies of their peers (median of 1 minute window) to ScoreDB and the DBSCAN algorithm will compute the outlier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>THRESHOLDS:</head><p>We would like to emphasize that the threshold values we use in our algorithms ( §2.2) are based on our specific deployment experiences. It is possible that the values might not work in other cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head><p>This section presents our experimental results, starting with unsuccessful experiences ( §3.1) and then the successful ones ( §3.2) and the false positive rates ( §3.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Unsucessful Attempts</head><p>The first strawman approach we tried was to use the raw timeout count as a metric to sense service instance level performance degradation. <ref type="figure" target="#fig_0">Figure 2</ref> shows the number of timeouts observed in three samples of real degraded instances (in different time periods and clusters). As shown, the timeouts observed occur in bursts although the fault is severe throughout the time interval. Thus, without saving the ratio of timeouts and responses for every peer over a given period, there is no way to detect whether these high scores were merely transient or if they were truly persistent and possibly catastrophic faults.</p><p>For this reason, we next attempted to create a more stable algorithm by defining a score to be the percentage of timeouts over the total responses in every epoch. The first line below is the same as the first equation in §2.2, and in the second line, a peer score is essentially the ToRespRatio. ToRespRatio = #timeouts / #responses score = ToRespRatio Figure 3a shows the result. Ideally the score should stay high throughout the degraded period, but instead we see one big spike and one small spike. We then modified the scoring algorithm slightly by using the median of the last 3-minute window:</p><formula xml:id="formula_6">score = median ( ToRespRatio in last 3 mins )</formula><p>The result, as shown in <ref type="figure" target="#fig_1">Figure 3b</ref>, still shows the same behavior (a dip between the two spikes). We tried replacing the median using average and weighted average and the result is similar <ref type="figure" target="#fig_1">(Figures 3c-d</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Successful Results</head><p>The previous section provides the reason we invented our custom outlier detection. <ref type="figure" target="#fig_2">Figure 4a</ref> shows the resulting scores from our custom algorithm, as detailed in Section 2.2. We can see that the metadata service (Cassandra/MS) instance on the degraded node has high scores assigned to it from 11:30 to 13:15 hours. Note that this is the case where we have not enabled the mitigation procedure, i.e., the customer was experiencing degradation for almost 2 hours! Correspondingly, to check that the scores are accurate, we checked the standard network performance graphs and we found that there had been a network issue at the exact time interval. <ref type="figure" target="#fig_2">Figure 4b</ref> shows the TCP SEND Q size on the network connection between another node with this unhealthy node. Furthermore, <ref type="figure" target="#fig_2">Figure 4c</ref> shows the ping latencies to the degraded machine.</p><p>From these graphs, we can see that bad network performance on the slow machine correlated perfectly with the bad scores assigned to the nodes running on it. As a side note, we can see that the two metrics in Figures 4b-c cannot be used as raw scores as they also fluctuate. Next, <ref type="figure" target="#fig_3">Figure 5</ref> shows what is happening in the ScoreDB server side for a different fail-slow incident. The picture shows the representative scores by instance X measured for its N −1 peers on other nodes. For simplicity, the data here is from a cluster of 4 nodes. <ref type="figure" target="#fig_3">Figure 5a</ref> shows that Node3 has a high score compared to other peers. But at this point Node3 has not been marked as a definite outlier because its 30 th percentile score is not high yet. However, two minutes later, as shown in <ref type="figure" target="#fig_3">Figure 5b</ref>, we have sufficient scores for the 30 th percentile score to be high. When we plug this score into the DBSCAN algorithm, Node3 was marked as a definite outlier.</p><p>IASO automatically quarantines an outlier to prevent it slowing down the entire cluster. <ref type="figure" target="#fig_4">Figure 6</ref> shows another case after we deploy IASO. Here, the figure shows that the cluster-level IOPS drops to almost zero with the presence of one degraded machine, essentially showing how a degraded node can impact the entire cluster, as also shown by other works <ref type="bibr" target="#b22">[24,</ref><ref type="bibr" target="#b55">56]</ref>. Packet losses and the cluster-level degradation started occurring at around 09:15am but just after 10 minutes, IASO's mitigatory actions kicked in and the performance of the cluster was completely restored. Thus, with IASO, the time taken to quarantine a degraded node has now been brought down to the order of minutes. Note that the IOPS returns to "normal" although we lost a node, which is because in this scenario the 100K IOPS were far from the maximum throughput of the cluster. spectively. For <ref type="figure" target="#fig_5">Figure 7b</ref>, the figure combines the number of "confirmed" and "probable" false positives as explained below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">True and False Positives</head><p>Over a 7-month period, we encountered 9 confirmed false positives over the 232 true positives (confirmed fail-slow incidents), which brings our false positive rate to 3.7%. One major reason for our false positive is in our earlier versions of IASO where the cluster still sends data to a dead service instance and a healthy instance already becomes affected and "looks" slow as well. Here IASO incorrectly marks the healthy instance as an outlier. Due to space constraints, we put more false positive stories in our anonymized supplemental material <ref type="bibr" target="#b6">[7]</ref>.</p><p>We also encountered 41 probable false positives. We label these cases as "probable" because they do not necessarily suggest that IASO is imprecise. In these cases, by the time our SREs started debugging, the issue was no longer present and the service instances, VMs, and machines were healthy. Existing works gave some hints on the reasons behind this, for example, fail-slow incidents can be triggered by temporary environmental causes such as high temperature <ref type="bibr" target="#b26">[28]</ref>.  While we managed to record the false positives, we were not able to collect many false-negative reports (i.e., undetected fail-slow incidents). This is because the reality of a large company and our SREs have their own priorities and might not contact us when they found cases that were not but should have been detected by IASO. The false negatives we were aware of came from two 2 outages that happened after the deployment of IASO, which can be found in our supplemental material <ref type="bibr" target="#b6">[7]</ref>. Other false negatives we noticed include low workloads as fail-slow faults with low workloads might not necessarily result in timeouts. We did not fix this problem as almost all our customers heavily utilize their clusters.</p><p>From our perspective, we prefer false positives over false negatives as in our system IASO pages site-reliability engineers whenever it detects a fail-slow failure. This gives us a way to easily track and investigate such issues and improve our system over time. As for the worst case impact, a false positive can cause a cluster to temporarily operate in a reduced fault tolerance state as IASO's extreme mitigation strategy can bring down a node. However, in case of a false negative, there can be an entire cluster outage which can stay undetected for hours.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Fail-Slow Dataset and Analysis</head><p>The deployment of IASO allows us to analyze fail-slow incidents in our vast field of clusters, which then enables us to perform new statistical studies. This section first describes our dataset ( §4.1) followed with our findings ( §4.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Dataset</head><p>We first describe our deployment settings. Our field consists of 39,000 nodes spread across many clusters. A cluster size ranges from 3 to 56 nodes. Our various cluster models and configurations (RAM size, storage, etc.) can be found in our supplemental material <ref type="bibr" target="#b6">[7]</ref>. A cluster can contain heterogeneous nodes as we support heterogeneous applications and a broken hardware can be replaced with a higher-end one. Each node in a cluster runs a special VM called a controller VM where our data and control path services run. Among these services, Cassandra and Zookeeper run with IASO integration.  <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b53">54]</ref> fail-slow 1.02% Node-level fail-slow faults  As mentioned before, every time IASO detects a fail-slow fault, it raises an alert that triggers the opening of a support ticket to investigate the issue. The support case is investigated by a team of trained site reliability engineers (SREs), who in turn coordinate with the customer and debug the issue. Once the problem is identified, the SREs update the support ticket with a category of the root cause found and the steps to resolve the issue. Other information that is updated as part of the case includes the time of the incident, a cluster identification number, the software version on the customer's cluster, the model family of the node that was affected and the number of months the node has been with the customer at the time of the incident.</p><p>With 232 fail-slow related tickets, our dataset can be seen as the largest fail-slow data from within a company. The previous largest dataset was 101 cases from 12 different institutions (more in §5). The next section presents our findings from studying the support tickets. The dataset that we will make public and discuss here comes from a period of seven months in 2017. The dataset for 2018 is still being perused and cleaned, hence not part of this submission.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Findings</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Frequency</head><p>With a large dataset, we are able to measure the annual failure rate (AFR) of fail-slow incidents. Given 232 independent cases across 39,000 nodes over 7 months, we can derive that fail-slow AFR is 1.02% (232 × 12 / 7 / 39,000). <ref type="table" target="#tab_3">Table 2</ref> compares fail-slow AFR with the rates of other types of failures. As shown, fail-slow fault frequency is rel- atively significant and cannot be ignored. <ref type="figure" target="#fig_6">Figure 8</ref> breaks down the number of fail-slow incidents observed per day in our field over the 7 months. We see that barring a couple of days in between, there is at least one failure per day. These statistics accentuate the importance of fail-slow detection and mitigation frameworks such as IASO.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Root Causes</head><p>Next, we analyze the root causes of fail-slow incidents. To compare the frequencies of various different root causes of fail-slow incidents with those of fail-stop failures <ref type="bibr" target="#b50">[51]</ref>, we group the causes into six categories: Hardware, Software, Network, Environment, Human and Unknown. For example, all issues that had a tag of "memory" or "disk" in our support tickets are grouped under Hardware. <ref type="figure" target="#fig_7">Figure 9</ref> shows the breakdown of fail-slow root causes (and the comparison to fail-stop causes from a related work [51, <ref type="figure" target="#fig_2">Figure 4a]</ref>). Hardware and Network failures turn out to be the highest contributors of fail-slow incidents in our field. Their total is roughly the same as in the fail-stop cases. In the next section, we break down the sub-causes to understand more about the root causes.</p><p>The Unknown count is quite significant because of a couple of reasons. One common reason is when a customer becomes unresponsive during the support case or does not want the issue to be investigated further without providing a clear reason. We believe this can be either because the customer did not notice any issue around the time the fail-slow alert was generated (thereby a false positive) or fixed the issue themselves without our help. The other reason is when the SREs could not find a specific root cause for the issue or did not tag the support case with a clear cause.   For example, for hardware-induced slowdown, it can be because of faulty dimm, ECC/CRC errors, low memory, etc., while network-induced slowdown can be because of faulty NICs/switches, bad cables, packet drops, and network contention.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3">Root Sub-Causes</head><p>Our goal here is to show that fail-slow root causes vary widely. We believe this is a strong motivation why fail-slow detection and mitigation should be also deployed at the service level (not just low-level hardware level). Our findings are also consistent with those reported in a recent paper <ref type="bibr" target="#b26">[28]</ref>; we observed in our field how fault conversions take place and how different failure types such as fail-stop (e.g., disk/SSD failure), fail-transient (e.g., GC), and fail-partial (ECC errors) can transform into fail-slow failures at the service level [28, §3.2].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.4">Age and Model</head><p>As our ticketing system automatically collects machine age data, we are able to correlate fail-slow failures with machine ages, as shown in <ref type="figure" target="#fig_8">Figure 10,</ref>    <ref type="figure">Figure 11</ref>.</p><p>from 1 to 48. We can see the "infant mortality" trend where younger machines exhibit more issues, but older (perhaps more stable) machines exhibit fewer issues. This follows the same failure trend in fail-stop failures [51, <ref type="figure" target="#fig_2">Figure 4</ref>]. This also supports a continuous paradigm where when the rate of fail-stop errors drops so does the fail-slow ones. We also attempted to correlate fail-slow failures with the node model family and found no significant correlation, that every node model family suffers from faults across a majority of component types (see <ref type="bibr" target="#b6">[7]</ref> for more).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.5">Tickets TTR</head><p>Finally, <ref type="figure">Figure 11</ref> shows the distribution of time to resolve the tickets (in hours) across different root causes. <ref type="table" target="#tab_7">Table 4</ref> shows the median, mean, and max values of the data in <ref type="figure">Fig- ure 11</ref>. We emphasize that this metric does not represent the time for IASO to mitigate the issues (which is in the order of 10 minutes), but rather how long it takes to close a ticket. When a ticket is closed, the customer's cluster is guaranteed to be back fully healthy.</p><p>The reason we show this data is to point out that a failslow root cause can take days to be fully resolved. This is consistent with anecdotal experiences shared by large-scale operators from various institutions <ref type="bibr">[28, §3.5]</ref>). Hence, it is important to quickly quarantine the fail-slow component before the performance problem cascades to the entire cluster.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Work</head><p>We now discuss related work beyond the papers that we already cited earlier. In particular, we break the discussion here to two categories: (1) works related to fail-slow detection and mitigation systems and (2) publications that release information about fail-slow incidents. <ref type="table" target="#tab_9">Table 5</ref> shows that there are many tools, frameworks, and approaches that have been introduced or deployed for different levels of the hardware, software, and service stack. First, there are many bug-finding tools such as MacePC <ref type="bibr" target="#b37">[38]</ref>, PCatch <ref type="bibr" target="#b39">[40]</ref>, and Orca <ref type="bibr" target="#b13">[15]</ref>, but they are offline approaches. Second, there are online fail-slow detection tools across the hardware/software stack. For example, SMART <ref type="bibr" target="#b3">[4]</ref> is a monitoring tool that can be used to detect hardware degradation but does not include diagnosis capability. Third, Pip <ref type="bibr" target="#b47">[48]</ref>, PivotTracing <ref type="bibr" target="#b40">[41]</ref> and many others provide diagnosis approaches that work at the service level (not just one particular software) but they do not make quarantine decisions. Finally, IASO is in a category that performs detection and automated mitigation. In this space, we are not aware of many published works. The limitation of IASO is that it does not come with diagnosis tools. Thus, the diagnosis approaches in the 3rd row of <ref type="table" target="#tab_9">Table 5</ref> are orthogonal to our work. <ref type="table">Table 6</ref> shows publications that release datasets on performance problems. The table shows the year span (Y r), number of fail-slow failures/bugs reported (#F ), deployment size/number of nodes (#N ), the number of systems/services the data is collected from (#S) and the scope of the rootcause analysis (A). The top part of the table represents incidents that appear in live deployments while the bottom of the  <ref type="table" target="#tab_3">Yr  #F  #N  #S  A  IASO  '16-17 232  39k</ref> 1 ehmnsu Fail-slow <ref type="bibr" target="#b26">[28]</ref> '00-17 101 ≥10k 12 hn GrayFailure <ref type="bibr" target="#b31">[32]</ref> -4 -1 -Panorama <ref type="bibr" target="#b30">[31]</ref> '17-18 15 20 4 -COS <ref type="bibr" target="#b25">[27]</ref> '09-15 126 -32 ehmnsu CBS <ref type="bibr" target="#b24">[26]</ref> '11-14 860 -6 s PerfBugs <ref type="bibr" target="#b33">[34]</ref> '00-11 109 -5 s Limplock <ref type="bibr" target="#b22">[24]</ref> '13 28 ≥30 5 s <ref type="table">Table 6</ref>: Related work (fail-slow dataset).</p><p>For each related work, the columns show the year span (Y r), number of fail-slow failures/bugs reported (#F ), deployment size/number of nodes (#N ), the number of systems/services the data is collected from (#S) and the scope of the root-cause analysis (A). In the last column (analysis), "h" represents hardware, "s" software, "n" network, "e" environment, and "m" human. Papers with "s"-only label implies bug-study papers.</p><p>paper represents works that study/test software bugs. In the former category, our dataset can be considered as the largest dataset of fail-slow cases publicly reported from within a company. Our work strongly supplements existing anecdotes that fail-slow faults at all levels, hardware and software, have to be addressed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We have described our successful 1.5-year deployment of IASO. We found fail-slow detection and automated mitigation schemes are crucial in preventing fail-slow induced outages in our large deployment field. We would like to emphasize again that automatic fail-slow mitigation/quarantine schemes (beyond detection only) are relatively a new area of research. We hope our paper can provide insights to the development of better frameworks in the future.</p><p>As future work, we look forward to building a more aggressive algorithm that can quarantine a slow node shorter than our current 10-minute interval (and do so with low false positives) as well as automatically marking fail-slow faults that are resolved by themselves without depending on our customers or SREs (more in <ref type="bibr" target="#b6">[7]</ref>). Furthermore, as we continue to collect peer scores reported in the field, we hope to learn more detailed characteristics.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Timeout fluctuations ( §3.1). The figures show the number of timeouts observed over time in three samples of degraded nodes (different time period).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Unstable scores ( §3.1). Other attempts to create stable scores using timeout-response ratio as explained in §3.1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>FiguresFigure 4 :</head><label>4</label><figDesc>Figures 7a and 7b show the number of true and false positives we encountered every month across the 7 months, re-</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Mitigation ( §3.2). The top figure shows that Node3's score is high as observed by Node0 however it is not being marked as an outlier yet as its 30 th percentile score is still low. In the bottom figure, Node3 is marked as a definite outlier.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Restored performance ( §3.2). Within 10 minutes, IASO made the cluster-level IOPS return back to normal after isolating the slow node.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: True and false (confirmed+probable) positives ( §3.3). The figure shows the number of (a) true and (b) false positives every month. The false positives include the "confirmed" and "probable" false positives as described in §3.3.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Fail-slow per day ( §4.2.1). The figure shows the number of fail-slow incidents per day in our field over 7 months.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Fail-slow root causes ( §4.2.2). The figure shows the breakdown of fail-slow root causes (and the comparison to failstop causes).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 10 :</head><label>10</label><figDesc>Figure 10: Fail-slow vs. age ( §4.2.4). The figure correlates fail-slow incidents with machine ages.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Fail-slow AFR ( §4.2.1). Comparisons of annual 

failure rates of different types of failures 

0 
1 
2 
3 
4 
5 
6 

Jan 
Feb 
Mar 
Apr 
May 
Jun 
Jul 

#Faults 

Date (Month) 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="true"><head>Table 3 shows</head><label>3</label><figDesc>further the breakdown of the sub-causes within each of the five root categories in the previous sec- tion. The numbers in the parentheses are the count of tickets.</figDesc><table>Root 
Sub-causes 
Hardware 
Faulty dimm (15), ECC error (10), low mem-
ory (9), SATADOM (5), CRC error (1), RAID 
controller (1), LSI controller (1), unknown (5) 
Software 
Software upgrade (8), VM issue (6), GC (3), 
BIOS (1), scheduler (1), unknown (6) 
Network 
Faulty device (13), network outage (9), device 
replace(7), unreachability (6), packet drop (5), 
network contention (2), device reboot (1), un-
known (18) 
Environment Incorrect setting (11), high load (1), energy is-
sue (1) 
Human error Misconf (10), network migration (4), install 
/deploy (3), unplugged cable (2), unknown (4) 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Root sub-causes ( §4.2.3). The table shows the sub-

causes within each of the five categories of known root causes. The 
dataset will be released publicly. 

0 

5 

10 

15 

20 

25 

1 
5 
10 
15 
20 
25 29 31 34 48 
Number of Faults 

Age of Nodes in Month(s) 

Unknown 
Network 
Hardware 
Software 
Human 
Environment 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>bucketed into months ranging</head><label></label><figDesc></figDesc><table>0% 

20% 

40% 

60% 

80% 

100% 

4 
16 
64 256 1024 

Time to Resolve (Hours) 

CDF Faults by TTR 

Unknown 
Network 
Hardware 
Software 
Human 
Environment 

Figure 11: Tickets TTR ( §4.2.5). The figure shows the CDF 

of time to resolve tickets across different root-cause categories. 

Net Unk 
HW 
SW 
Human Env 
Median 
79 
145 
126 
234 
108 
65 
Mean 
149 
220 
244 
323 
165 
149 
Max 
721 1033 1705 1238 
625 
964 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>TTR tickets ( §4.2.5). The table shows the median, 

mean, and maximum values of the data in </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Related work (IASO). The table categorizes works 

that relate to fail-slow detection, diagnosis, and mitigation across 
hardware-, software-, and service levels. 

</table></figure>

			<note place="foot" n="2"> To make the score multiplication increases faster/slower (i.e., more configurable), we can introduce a score multiplier with a usage such as: e.g., 32 + scoreMultiplier × 32. We use scoreMultiplier =1.</note>

			<note place="foot" n="52"> 2019 USENIX Annual Technical Conference USENIX Association</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Acknowledgments</head><p>We thank Ric Wheeler, our shepherd, and the anonymous reviewers for their tremendous feedback and comments. We also would like to thank Roger Liao and Anshul Purohit for their significant contributions during the development of IASO. We learnt a lot from the actual customer cases where IASO was effective and also from a few scenarios where we hit false positives. Thanks to Rob Savino and Mark Czarnecki for their effort to make this information available to us and help us with quite some root cause analysis. University of Chicago authors were supported by funding from NSF grant No. CNS-1350499.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Apache</forename><surname>Hadoop</surname></persName>
		</author>
		<ptr target="http://hadoop.apache.org" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Intelligent Platform Management Interface (IPMI)</title>
		<ptr target="https://www.intel.com/content/www/us/en/servers/ipmi/ipmi-home.html" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title/>
		<ptr target="http://www.net-snmp.org/" />
	</analytic>
	<monogr>
		<title level="j">Simple Network Management Protocol (SNMP</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Self-Monitoring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M A R T</forename></persName>
		</author>
		<ptr target="http://en.wikipedia.org/wiki/S.M.A.R.T" />
	</analytic>
	<monogr>
		<title level="j">Analysis and Reporting Technology</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Apache Cassandra NoSQL Performance Benchmarks</title>
		<ptr target="https://academy.datastax.com/planet-cassandra/nosql-performance-benchmarks" />
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Density-based spatial clustering of applications with noise</title>
		<ptr target="https://en.wikipedia.org/wiki/DBSCAN" />
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title/>
		<ptr target="https://tinyurl.com/iaso-supplementalmaterial" />
	</analytic>
	<monogr>
		<title level="j">Iaso Supplementary Materials (Anonymized</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iaso</forename><surname>Wiki</surname></persName>
		</author>
		<ptr target="https://en.wikipedia.org/wiki/Iaso" />
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Effective Straggler Mitigation: Attack of the Clones</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ganesh</forename><surname>Ananthanarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Ghodsi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Shenker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ion</forename><surname>Stoica</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th Symposium on Networked Systems Design and Implementation (NSDI)</title>
		<meeting>the 10th Symposium on Networked Systems Design and Implementation (NSDI)</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Reining in the Outliers in Map-Reduce Clusters using Mantri</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srikanth</forename><surname>Ganesh Ananthanarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert</forename><surname>Kandula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ion</forename><surname>Greenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Stoica</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bikas</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Saha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Harris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th Symposium on Operating Systems Design and Implementation (OSDI)</title>
		<meeting>the 9th Symposium on Operating Systems Design and Implementation (OSDI)</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Fail-Stutter Fault Tolerance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Remzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><forename type="middle">C</forename><surname>Arpaci-Dusseau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Arpaci-Dusseau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Hot Topics in Operating Systems</title>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Automating Root-Cause Diagnosis of Performance Anomalies in Production Software</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mona</forename><surname>Attariyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Chow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><forename type="middle">Flinn</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">. X-Ray</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th Symposium on Operating Systems Design and Implementation (OSDI)</title>
		<meeting>the 10th Symposium on Operating Systems Design and Implementation (OSDI)</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Read Disturb Errors in MLC NAND Flash Memory: Characterization and Mitigation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixin</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saugata</forename><surname>Ghose</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Onur</forename><surname>Mutlu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Dependable Systems and Networks (DSN)</title>
		<meeting>the International Conference on Dependable Systems and Networks (DSN)</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">µChoices: An Object-Oriented Multimedia Operating System</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">H</forename><surname>Campbell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Fifth Workshop on Hot Topics in Operating Systems (HotOS-V)</title>
		<meeting><address><addrLine>Orcas Island, WA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1995-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Charaterizing private clouds: A large-scale empirical analysis of enterprise clusters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ignacio</forename><surname>Cano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srinivas</forename><surname>Aiyar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arvind</forename><surname>Krishnamurthy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th ACM Symposium on Cloud Computing (SoCC)</title>
		<meeting>the 7th ACM Symposium on Cloud Computing (SoCC)</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Correcting vibration-induced performance degradation in enterprise servers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christine</forename><forename type="middle">S</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boxiang</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenny</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenny</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tajana</forename><surname>Simunic Rosing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Greenmetrics workshop (Greenmetrics)</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Analysis of the increase and decrease algorithms for congestion avoidance in computer networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dah-Ming</forename><surname>Chiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raj</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Networks and ISDN Systems</title>
		<imprint>
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Hytrace: A Hybrid Approach to Performance Bug Diagnosis in Production Cloud Infrastructures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peipei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohui</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shan</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th ACM Symposium on Cloud Computing (SoCC)</title>
		<meeting>the 8th ACM Symposium on Cloud Computing (SoCC)</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">UBL: Unsupervised Behavior Learning for Predicting Performance Anomalies in Virtualized Cloud Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><forename type="middle">J</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiep</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohui</forename><surname>Gu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th ACM International Conference on Autonomic Computing (ICAC)</title>
		<meeting>the 9th ACM International Conference on Autonomic Computing (ICAC)</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">PerfScope: Practical Online Server Performance Bug Inference in Production Cloud Computing Infrastructures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><forename type="middle">J</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiep</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohui</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junghwan</forename><surname>Rhee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nipun</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoff</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th ACM Symposium on Cloud Computing (SoCC)</title>
		<meeting>the 5th ACM Symposium on Cloud Computing (SoCC)</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">PerfCompass: Online Performance Anomaly Fault Localization and Inference in Infrastructure-as-a-Service Clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><forename type="middle">J</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiep</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peipei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohui</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anca</forename><surname>Sailer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrzej</forename><surname>Kochut</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Parallel and Distributed Systems (TPDS)</title>
		<imprint>
			<date type="published" when="2016-06" />
			<biblScope unit="volume">27</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">MapReduce: Simplified Data Processing on Large Clusters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjay</forename><surname>Ghemawat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th Symposium on Operating Systems Design and Implementation (OSDI)</title>
		<meeting>the 6th Symposium on Operating Systems Design and Implementation (OSDI)</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Limplock: Understanding the Impact of Limpware on Scale-Out Cloud Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thanh</forename><surname>Do</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingzhe</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tanakorn</forename><surname>Leesatapornwongsa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tiratat</forename><surname>Patana-Anake</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haryadi</forename><forename type="middle">S</forename><surname>Gunawi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th ACM Symposium on Cloud Computing (SoCC)</title>
		<meeting>the 4th ACM Symposium on Cloud Computing (SoCC)</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">PERFBLOWER : Quickly Detecting Memory-Related Performance Problems via Amplification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guoqing</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">29th European Conference on Object-Oriented Programming (ECOOP)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">What Bugs Live in the Cloud? A Study of 3000+ Issues in Cloud Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Haryadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingzhe</forename><surname>Gunawi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tanakorn</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tiratat</forename><surname>Leesatapornwongsa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thanh</forename><surname>Patana-Anake</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffry</forename><surname>Do</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Adityatama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kurnia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Agung</forename><surname>Eliazar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><forename type="middle">F</forename><surname>Laksono</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincentius</forename><surname>Lukman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anang</forename><forename type="middle">D</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Satria</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th ACM Symposium on Cloud Computing (SoCC)</title>
		<meeting>the 5th ACM Symposium on Cloud Computing (SoCC)</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Why Does the Cloud Stop Computing? Lessons from Hundreds of Service Outages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Haryadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingzhe</forename><surname>Gunawi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Riza</forename><forename type="middle">O</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Agung</forename><surname>Suminto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anang</forename><forename type="middle">D</forename><surname>Laksono</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffry</forename><surname>Satria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurnia</forename><forename type="middle">J</forename><surname>Adityatama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Eliazar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th ACM Symposium on Cloud Computing (SoCC)</title>
		<meeting>the 7th ACM Symposium on Cloud Computing (SoCC)</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Haryadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Riza</forename><forename type="middle">O</forename><surname>Gunawi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Russell</forename><surname>Suminto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Casey</forename><surname>Sears</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Swaminathan</forename><surname>Golliher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xing</forename><surname>Sundararaman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lin</surname></persName>
		</author>
		<imprint>
			<pubPlace>Tim</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Fail-Slow at Scale: Evidence of Hardware Performance Faults in Large Production Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiguang</forename><surname>Emami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nematollah</forename><surname>Sheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caitie</forename><surname>Bidokhti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gary</forename><surname>Mccaffrey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Grider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Parks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Fields</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">B</forename><surname>Harms</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andree</forename><surname>Ross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Jacobson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kirk</forename><surname>Ricci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Webb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Alvaro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingzhe</forename><surname>Birali Runesha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huaicheng</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th USENIX Symposium on File and Storage Technologies (FAST)</title>
		<meeting>the 16th USENIX Symposium on File and Storage Technologies (FAST)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">High-availability at massive scale: Building google&apos;s data infrastructure for ads</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Shute</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of BIRTE</title>
		<meeting>of BIRTE</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">PeerReview: Practical Accountability for Distributed Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Haeberlen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petr</forename><surname>Kouznetsov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Druschel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 21st ACM SIGOPS Symposium on Operating Systems Principles (SOSP)</title>
		<meeting>21st ACM SIGOPS Symposium on Operating Systems Principles (SOSP)</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Capturing and Enhancing In Situ System Observability for Failure Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuanxiong</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><forename type="middle">R</forename><surname>Lorch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lidong</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingnong</forename><surname>Dang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th Symposium on Operating Systems Design and Implementation (OSDI)</title>
		<meeting>the 13th Symposium on Operating Systems Design and Implementation (OSDI)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Gray Failure: The Achilles&apos; Heel of Cloud Scale Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuanxiong</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lindong</forename><surname>Znhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><forename type="middle">R</forename><surname>Lorch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingnong</forename><surname>Dang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Murali</forename><surname>Chintalapati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Randonph</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 16th Workshop on Hot Topics in Operating Systems (HotOS XVII</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Cosmic rays don&apos;t strike twice: understanding the nature of DRAM errors and the implications for system design</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andy</forename><forename type="middle">A</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ioan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bianca</forename><surname>Stefanovici</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schroeder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS)</title>
		<meeting>the 17th International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS)</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Understanding and Detecting Real-World Performance Bugs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guoliang</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linhai</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoming</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Scherpelz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shan</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGPLAN 2012 Conference on Programming Language Design and Implementation (PLDI)</title>
		<meeting>the ACM SIGPLAN 2012 Conference on Programming Language Design and Implementation (PLDI)</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Tolerating Hardware Device Failures in Software</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asim</forename><surname>Kadav</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><forename type="middle">J</forename><surname>Renzelmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">M</forename><surname>Swift</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM Symposium on Operating Systems Principles (SOSP)</title>
		<meeting>the 22nd ACM Symposium on Operating Systems Principles (SOSP)</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Canopy: An End-to-End Performance Tracing And Analysis System</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Kaldor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Mace</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michal</forename><surname>Bejda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edison</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joe O&amp;apos;</forename><surname>Neill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kian</forename><forename type="middle">Win</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Schaller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pingjia</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brendan</forename><surname>Viscomi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vinod</forename><surname>Venkataraman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaushik</forename><surname>Veeraraghavan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yee Jiun</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th ACM Symposium on Operating Systems Principles (SOSP</title>
		<meeting>the 26th ACM Symposium on Operating Systems Principles (SOSP</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Black-Box Problem Diagnosis in Parallel File Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaqi</forename><surname>Kasick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajeev</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Priya</forename><surname>Gandhi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Narasimhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th USENIX Symposium on File and Storage Technologies (FAST)</title>
		<meeting>the 8th USENIX Symposium on File and Storage Technologies (FAST)</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Finding latent performance bugs in systems implementations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Killian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karthik</forename><surname>Nagaraj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salman</forename><surname>Pervez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Braud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">W</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ranjit</forename><surname>Jhala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighteenth ACM SIGSOFT International Symposium on Foundations of Software Engineering</title>
		<meeting>the Eighteenth ACM SIGSOFT International Symposium on Foundations of Software Engineering</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Testing Closed-Source Binary Device Drivers with DDT</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Volodymyr</forename><surname>Kuznetsov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vitaly</forename><surname>Chipounov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Candea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Switzerland</forename><surname>´ Ecole Polytechnique Fédérale De Lausanne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 USENIX Annual Technical Conference (ATC)</title>
		<meeting>the 2010 USENIX Annual Technical Conference (ATC)</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">PCatch: Automatically Detecting Performance Cascading Bugs in Cloud Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaxin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haopeng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shan</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haryadi</forename><forename type="middle">S</forename><surname>Gunawi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohui</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongsheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xicheng</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 EuroSys Conference (EuroSys)</title>
		<meeting>the 2018 EuroSys Conference (EuroSys)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Pivot Tracing: Dynamic Causal Monitoring for Distributed Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Mace</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Roelke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodrigo</forename><surname>Fonseca</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM Symposium on Operating Systems Principles (SOSP)</title>
		<meeting>the 25th ACM Symposium on Operating Systems Principles (SOSP)</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">The Ganglia Distributed Monitoring System: Design, Implementation, and Experience</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><forename type="middle">L</forename><surname>Massie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brent</forename><forename type="middle">N</forename><surname>Chun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">E</forename><surname>Culler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Parallel Computing</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">7</biblScope>
			<date type="published" when="2004-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Toddler: Detecting Performance Problems via Similar Memory-Access Patterns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adrian</forename><surname>Nistor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linhai</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Darko</forename><surname>Marinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shan</forename><forename type="middle">L</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th International Conference on Software Engineering (ICSE)</title>
		<meeting>the 35th International Conference on Software Engineering (ICSE)</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">DeepDive:Transparently Identifyingand Managing Performance Interference in Virtualized Environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dejan</forename><surname>Novakovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nedeljko</forename><surname>Vasic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stanko</forename><surname>Novakovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dejan</forename><surname>Kostic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ricardo</forename><surname>Bianchini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 USENIX Annual Technical Conference (ATC)</title>
		<meeting>the 2013 USENIX Annual Technical Conference (ATC)</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">AFD: Adaptive failure detection system for cloud computing infrastructures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Husanbir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianguo</forename><surname>Pannu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">31th IEEE -International Performance Computing and Communications Conference (IPCCC)</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Failure Trends in a Large Disk Drive Population</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduardo</forename><surname>Pinheiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolf-Dietrich</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luiz Andre</forename><surname>Barroso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th USENIX Symposium on File and Storage Technologies (FAST)</title>
		<meeting>the 5th USENIX Symposium on File and Storage Technologies (FAST)</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">SymDrive: Testing Drivers without Devices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><forename type="middle">J</forename><surname>Renzelmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asim</forename><surname>Kadav</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">M</forename><surname>Swift</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th Symposium on Operating Systems Design and Implementation (OSDI)</title>
		<meeting>the 10th Symposium on Operating Systems Design and Implementation (OSDI)</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Pip: Detecting the Unexpected in Distributed Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Reynolds</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Killian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janet</forename><forename type="middle">L</forename><surname>Wiener</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><forename type="middle">C</forename><surname>Mogul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehul</forename><forename type="middle">A</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amin</forename><surname>Vahdat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd Symposium on Networked Systems Design and Implementation (NSDI)</title>
		<meeting>the 3rd Symposium on Networked Systems Design and Implementation (NSDI)</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Passive Realtime Datacenter Fault Detection and Localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arjun</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyi</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jasmeet</forename><surname>Bagga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><forename type="middle">C</forename><surname>Snoeren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th Symposium on Networked Systems Design and Implementation (NSDI)</title>
		<meeting>the 13th Symposium on Networked Systems Design and Implementation (NSDI)</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Using Likely Invariants for Automated Software Fault Localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Swarup</forename><surname>Sahoo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Criswell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chase</forename><surname>Geigle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vikram</forename><surname>Adve</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS)</title>
		<meeting>the 18th International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS)</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">A large-scale study of failures in high-performance computing systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bianca</forename><surname>Schroeder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Garth</forename><forename type="middle">A</forename><surname>Gibson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Dependable Systems and Networks (DSN)</title>
		<meeting>the International Conference on Dependable Systems and Networks (DSN)</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Disk failures in the real world: What does an MTTF of 1,000,000 hours mean to you?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bianca</forename><surname>Schroeder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Garth</forename><forename type="middle">A</forename><surname>Gibson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th USENIX Symposium on File and Storage Technologies (FAST)</title>
		<meeting>the 5th USENIX Symposium on File and Storage Technologies (FAST)</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Flash Reliability in Production: The Expected and the Unexpected</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bianca</forename><surname>Schroeder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raghav</forename><surname>Lagisetty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arif</forename><surname>Merchant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th USENIX Symposium on File and Storage Technologies (FAST)</title>
		<meeting>the 14th USENIX Symposium on File and Storage Technologies (FAST)</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">DRAM errors in the wild: A Large-Scale Field Study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bianca</forename><surname>Schroeder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduardo</forename><surname>Pinheiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolf-Dietrich</forename><surname>Weber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2009 ACM International Conference on Measurement and Modeling of Computer Systems (SIGMETRICS)</title>
		<meeting>the 2009 ACM International Conference on Measurement and Modeling of Computer Systems (SIGMETRICS)</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Towards Pre-Deployment Detection of Performance Failures in Cloud Distributed Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Riza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Agung</forename><surname>Suminto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anang</forename><forename type="middle">D</forename><surname>Laksono</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thanh</forename><surname>Satria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haryadi</forename><forename type="middle">S</forename><surname>Do</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gunawi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 7th USENIX Workshop on Hot Topics in Cloud Computing (HotCloud)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Riza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cesar</forename><forename type="middle">A</forename><surname>Suminto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Stuardo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huan</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tanakorn</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Leesatapornwongsa</surname></persName>
		</author>
		<imprint>
			<pubPlace>Bo Fu, Daniar H</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">PBSE: A Robust Path-Based Speculative Execution for Degraded-Network Tail Tolerance in Data-Parallel Frameworks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincentius</forename><surname>Kurniawan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Uma Maheswara Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haryadi</forename><forename type="middle">S</forename><surname>Gunawi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th ACM Symposium on Cloud Computing (SoCC)</title>
		<meeting>the 8th ACM Symposium on Cloud Computing (SoCC)</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">PREPARE: Predictive Performance Anomaly Prevention for Virtualized Cloud Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongmin</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiep</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiming</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohui</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chitra</forename><surname>Venkatramani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deepak</forename><surname>Rajan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd International Conference on Distributed Computing Systems (ICDCS)</title>
		<meeting>the 32nd International Conference on Distributed Computing Systems (ICDCS)</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Improving MapReduce Performance in Heterogeneous Environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matei</forename><surname>Zaharia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andy</forename><surname>Konwinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><forename type="middle">D</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Randy</forename><surname>Katz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ion</forename><surname>Stoica</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th Symposium on Operating Systems Design and Implementation (OSDI)</title>
		<meeting>the 8th Symposium on Operating Systems Design and Implementation (OSDI)</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Deepview: Virtual Disk Failure Diagnosis and Pattern Detection for Azure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guo</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuanxiong</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingnong</forename><surname>Dang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nick</forename><surname>Swanson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinsheng</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Randolph</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Murali</forename><surname>Chintalapati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arvind</forename><surname>Krishnamurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Anderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th Symposium on Networked Systems Design and Implementation (NSDI)</title>
		<meeting>the 14th Symposium on Networked Systems Design and Implementation (NSDI)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Non-Intrusive Performance Profiling for Entire Software Stacks Based on the Flow Reconstruction Principle</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kirk</forename><surname>Rodrigues</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ding</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Stumm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th Symposium on Operating Systems Design and Implementation (OSDI)</title>
		<meeting>the 12th Symposium on Operating Systems Design and Implementation (OSDI)</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
