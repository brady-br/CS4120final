<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2020-09-29T02:11+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Implementing a Leading Loads Performance Predictor on Commodity Processors Implementing a Leading Loads Performance Predictor on Commodity Processors</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>June 19-20. 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Su</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">College of Computer</orgName>
								<orgName type="laboratory">Lab of HPC</orgName>
								<orgName type="institution" key="instit1">National University of Defense Technology</orgName>
								<orgName type="institution" key="instit2">National University of Defense Technology https</orgName>
								<orgName type="institution" key="instit3">USENIX Association</orgName>
								<orgName type="institution" key="instit4">National University of Defense Technology ‡ AMD Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><forename type="middle">L</forename><surname>Greathouse</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">College of Computer</orgName>
								<orgName type="laboratory">Lab of HPC</orgName>
								<orgName type="institution" key="instit1">National University of Defense Technology</orgName>
								<orgName type="institution" key="instit2">National University of Defense Technology https</orgName>
								<orgName type="institution" key="instit3">USENIX Association</orgName>
								<orgName type="institution" key="instit4">National University of Defense Technology ‡ AMD Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junli</forename><surname>Gu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">College of Computer</orgName>
								<orgName type="laboratory">Lab of HPC</orgName>
								<orgName type="institution" key="instit1">National University of Defense Technology</orgName>
								<orgName type="institution" key="instit2">National University of Defense Technology https</orgName>
								<orgName type="institution" key="instit3">USENIX Association</orgName>
								<orgName type="institution" key="instit4">National University of Defense Technology ‡ AMD Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Boyer</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">College of Computer</orgName>
								<orgName type="laboratory">Lab of HPC</orgName>
								<orgName type="institution" key="instit1">National University of Defense Technology</orgName>
								<orgName type="institution" key="instit2">National University of Defense Technology https</orgName>
								<orgName type="institution" key="instit3">USENIX Association</orgName>
								<orgName type="institution" key="instit4">National University of Defense Technology ‡ AMD Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amd</forename><surname>Research</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">College of Computer</orgName>
								<orgName type="laboratory">Lab of HPC</orgName>
								<orgName type="institution" key="instit1">National University of Defense Technology</orgName>
								<orgName type="institution" key="instit2">National University of Defense Technology https</orgName>
								<orgName type="institution" key="instit3">USENIX Association</orgName>
								<orgName type="institution" key="instit4">National University of Defense Technology ‡ AMD Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">;</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">College of Computer</orgName>
								<orgName type="laboratory">Lab of HPC</orgName>
								<orgName type="institution" key="instit1">National University of Defense Technology</orgName>
								<orgName type="institution" key="instit2">National University of Defense Technology https</orgName>
								<orgName type="institution" key="instit3">USENIX Association</orgName>
								<orgName type="institution" key="instit4">National University of Defense Technology ‡ AMD Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shen</forename></persName>
							<affiliation key="aff0">
								<orgName type="department">College of Computer</orgName>
								<orgName type="laboratory">Lab of HPC</orgName>
								<orgName type="institution" key="instit1">National University of Defense Technology</orgName>
								<orgName type="institution" key="instit2">National University of Defense Technology https</orgName>
								<orgName type="institution" key="instit3">USENIX Association</orgName>
								<orgName type="institution" key="instit4">National University of Defense Technology ‡ AMD Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiying</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">College of Computer</orgName>
								<orgName type="laboratory">Lab of HPC</orgName>
								<orgName type="institution" key="instit1">National University of Defense Technology</orgName>
								<orgName type="institution" key="instit2">National University of Defense Technology https</orgName>
								<orgName type="institution" key="instit3">USENIX Association</orgName>
								<orgName type="institution" key="instit4">National University of Defense Technology ‡ AMD Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Su</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">College of Computer</orgName>
								<orgName type="laboratory">Lab of HPC</orgName>
								<orgName type="institution" key="instit1">National University of Defense Technology</orgName>
								<orgName type="institution" key="instit2">National University of Defense Technology https</orgName>
								<orgName type="institution" key="instit3">USENIX Association</orgName>
								<orgName type="institution" key="instit4">National University of Defense Technology ‡ AMD Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><forename type="middle">L</forename><surname>Greathouse</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">College of Computer</orgName>
								<orgName type="laboratory">Lab of HPC</orgName>
								<orgName type="institution" key="instit1">National University of Defense Technology</orgName>
								<orgName type="institution" key="instit2">National University of Defense Technology https</orgName>
								<orgName type="institution" key="instit3">USENIX Association</orgName>
								<orgName type="institution" key="instit4">National University of Defense Technology ‡ AMD Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junli</forename><surname>Gu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">College of Computer</orgName>
								<orgName type="laboratory">Lab of HPC</orgName>
								<orgName type="institution" key="instit1">National University of Defense Technology</orgName>
								<orgName type="institution" key="instit2">National University of Defense Technology https</orgName>
								<orgName type="institution" key="instit3">USENIX Association</orgName>
								<orgName type="institution" key="instit4">National University of Defense Technology ‡ AMD Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Boyer</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">College of Computer</orgName>
								<orgName type="laboratory">Lab of HPC</orgName>
								<orgName type="institution" key="instit1">National University of Defense Technology</orgName>
								<orgName type="institution" key="instit2">National University of Defense Technology https</orgName>
								<orgName type="institution" key="instit3">USENIX Association</orgName>
								<orgName type="institution" key="instit4">National University of Defense Technology ‡ AMD Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Shen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">College of Computer</orgName>
								<orgName type="laboratory">Lab of HPC</orgName>
								<orgName type="institution" key="instit1">National University of Defense Technology</orgName>
								<orgName type="institution" key="instit2">National University of Defense Technology https</orgName>
								<orgName type="institution" key="instit3">USENIX Association</orgName>
								<orgName type="institution" key="instit4">National University of Defense Technology ‡ AMD Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiying</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">College of Computer</orgName>
								<orgName type="laboratory">Lab of HPC</orgName>
								<orgName type="institution" key="instit1">National University of Defense Technology</orgName>
								<orgName type="institution" key="instit2">National University of Defense Technology https</orgName>
								<orgName type="institution" key="instit3">USENIX Association</orgName>
								<orgName type="institution" key="instit4">National University of Defense Technology ‡ AMD Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">†</forename></persName>
							<affiliation key="aff0">
								<orgName type="department">College of Computer</orgName>
								<orgName type="laboratory">Lab of HPC</orgName>
								<orgName type="institution" key="instit1">National University of Defense Technology</orgName>
								<orgName type="institution" key="instit2">National University of Defense Technology https</orgName>
								<orgName type="institution" key="instit3">USENIX Association</orgName>
								<orgName type="institution" key="instit4">National University of Defense Technology ‡ AMD Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">State</forename><surname>Key</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">College of Computer</orgName>
								<orgName type="laboratory">Lab of HPC</orgName>
								<orgName type="institution" key="instit1">National University of Defense Technology</orgName>
								<orgName type="institution" key="instit2">National University of Defense Technology https</orgName>
								<orgName type="institution" key="instit3">USENIX Association</orgName>
								<orgName type="institution" key="instit4">National University of Defense Technology ‡ AMD Research</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Implementing a Leading Loads Performance Predictor on Commodity Processors Implementing a Leading Loads Performance Predictor on Commodity Processors</title>
					</analytic>
					<monogr>
						<title level="m">2014 USENIX Annual Technical Conference</title>
						<meeting> <address><addrLine>Philadelphia, PA</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page">205</biblScope>
							<date type="published">June 19-20. 2014</date>
						</imprint>
					</monogr>
					<note>This paper is included in the Proceedings of USENIX ATC &apos;14: Open access to the Proceedings of USENIX ATC &apos;14: 2014 USENIX Annual Technical Conference is sponsored by USENIX.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Modern CPUs employ Dynamic Voltage and Frequency Scaling (DVFS) to boost performance, lower power, and improve energy efficiency. Good DVFS decisions require accurate performance predictions across frequencies. A new hardware structure for measuring leading load cycles was recently proposed and demonstrated promising performance prediction abilities in simulation. This paper proposes a method of leveraging existing hardware performance monitors to emulate a leading loads predictor. Our proposal, LL-MAB, uses existing miss status handling register occupancy information to estimate leading load cycles. We implement and validate LL-MAB on a collection of commercial AMD CPUs. Experiments demonstrate that it can accurately predict performance with an average error of 2.7% using an AMD Opteron TM 4386 processor over a 2.2x change in frequency. LL-MAB requires no hardware-or application-specific training, and it is more accurate and requires fewer counters than similar approaches.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Dynamic voltage and frequency scaling (DVFS) is used to optimize performance under power and energy constraints, typically under the control of the OS or firmware. One of the key challenges of utilizing DVFS effectively is dynamically predicting the performance impact of frequency changes for arbitrary applications. This can be difficult because program execution time does not depend solely on core frequency. While some sections of a program will run faster at higher frequencies, others are limited by non-core components, such as DRAM latency. Because of this, simple linear scaling models (where performance is directly proportional to frequency) often yield inadequate estimates <ref type="bibr" target="#b4">[5]</ref>.</p><p>Unfortunately, it can be difficult to predict the effect of memory accesses on performance. Not all memory * This work took place while Bo Su interned with AMD <ref type="bibr">Research.</ref> accesses cause stalls to the core because of caches in the core clock domain. In addition, processors can exploit memory-level parallelism (MLP) by overlapping multiple cache misses. As such, not all cache misses directly affect the performance. Finally, DRAM access latency varies with access patterns, making it difficult to predict time spent waiting on memory from access counts alone.</p><p>One promising approach for predicting DVFS performance is the recently proposed leading loads model <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b9">10]</ref>, which splits the execution time of an application into time spent in the core (which changes along with frequency) and in the memory (which does not). It then uses new leading load performance counters to accurately estimate this memory time. Simulations demonstrated that this approach could predict application performance under DVFS with an order of magnitude higher accuracy than previously proposed models, while requiring no training (unlike regression-based models). These results led the authors to suggest that hardware support for leading loads should be added to future processors. This paper demonstrates how to leverage existing hardware performance counters that measure miss status handling register (MSHR) activity on commodity AMD processors in order to approximate a leading loads performance predictor. This predictor can accurately estimate the performance impact of DVFS changes on arbitrary applications running on real hardware. It requires no hardware-or application-specific training, and uses only a small number of performance counters.</p><p>We validate our method on three different AMD processors across multiple hardware generations. We compare our technique with previously proposed predictors and explain how it is different from an ideal leading load predictor. We show that our model provides a more accurate prediction with less variance in error rate than other predictors that work on existing hardware. To the best of our knowledge, this is the first time the leading loads model has been demonstrated on real hardware.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>There is a large body of work on performance modeling under frequency variation. Rountree et al. <ref type="bibr" target="#b9">[10]</ref> and Eeckhout <ref type="bibr" target="#b3">[4]</ref> describe many of the previous techniques. Eeckhout categorizes analytic performance estimation models into empirical models, which use black-box approaches, and mechanistic models which are designed from the underlying machine principals. Some of the most popular empirical models are based on regression <ref type="bibr" target="#b10">[11]</ref>. They can have good accuracy, but need many input variables and long training runs. Their accuracy is a function of the quality of the training set, and they must be retrained whenever the underlying machine changes.</p><p>Mechanistic models often include simplifications and abstractions to make the problem tractable. Proportional scaling models (or "linear scaling") are the simplest and assume that performance scales linearly with frequency. These are simple to implement, but only work well when the application spends little time accessing memory.</p><p>Recent mechanistic DVFS estimation models are built from the underlying concept that program execution time is split into core time (time doing work) and memory time (time stalled waiting for memory). Core time is inversely proportional to frequency. However, because the latency to memory does not change when the core's frequency changes, memory time is not affected by DVFS.</p><p>The difficulty of this performance estimation mechanism lies in appropriately characterizing these times. Modern processors can execute instructions out of order, with multiple loads accessing memory in parallel. Simple memory models do not capture this, which leads to incorrect estimates. For example, stall models monitor the amount of time that a core is not committing instructions and assume that this is due to time spent in the memory system <ref type="bibr" target="#b4">[5]</ref>. We will show later that this is often an inaccurate assumption, since processors can stall for numerous reasons besides memory latency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Leading Loads (LL) Model</head><p>Leading loads were simultaneously defined by three groups attempting to solve the problems of these linear and stall models <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b9">10]</ref>. They utilized the insight that, while many memory accesses may be outstanding, only one can stall the pipeline. As such, the first nonspeculative load that misses in the last level of the core's cache is considered a leading load. The time between the miss and when it returns is assumed to be memory time. This time is counted even if core work continues under the miss. All misses until this load returns are not leading loads -they represent MLP . A simplifying assumption of this model is that these MLP accesses will not eventually stall the pipeline.</p><p>Once a leading load returns, the next miss becomes the leading load. All time when there is no leading load is counted as core time. This is illustrated in <ref type="figure" target="#fig_0">Figure 1</ref>, where there are 3 load misses: A, B and C. The misses begin at t1, t2, and t6, then finish at t4, t5, and t8, respectively. A and C are leading loads; their delay is memory time. B is not a leading load because a leading load (A) already exists; it is MLP and does not stall the core. There are limitations to this model, such as the assumption that MLP loads will not stall the pipeline, and its inability to deal with bandwidth-bound applications <ref type="bibr" target="#b8">[9]</ref>. However, the simulated results for these counters appear promising (with estimation errors of 0.2%), and the hardware is simple, requiring only a single counter per core. The major impediment was the apparent lack of leading load hardware performance events, which prevented testing this mechanism outside of simulation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Green Governor (GG) Model</head><p>Because their newly proposed leading load counter did not yet exist in hardware, Spiliopoulos et al. also devised a simpler model in their Green Governors work that used existing counters <ref type="bibr" target="#b11">[12]</ref>. They monitor the number of last level cache (LLC) misses and number of cycles without a retired instruction. They then characterize the average miss latency using a tool such as lmbench <ref type="bibr" target="#b7">[8]</ref> and multiply this delay by the number of LLC misses to estimate memory time. If the amount of time not retiring instructions is less than this, the smaller time is used instead.</p><p>When predicting the program's performance from frequency f to f 񮽙 , this model can be described by Equation 1. The memory time M t is calculated using stall cycles S, the number of LLC misses N, the per-miss delay time D, and the original frequency f . The new execution time T 񮽙 is then calculated from M t , the original execution time T , and the ratio of frequency change.</p><formula xml:id="formula_0">T 񮽙 = (T − M t ) × f f 񮽙 + M t ; M t = min( S f , N × D) (1)</formula><p>This model makes a number of simplifying assumptions, since it is constrained by existing hardware. First, it assumes that LLC misses have a constant latency, since it only measures miss count. Second, it ignores MLP. Nonetheless, with careful tuning, it can yield reasonably accurate performance estimates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Implementing Leading Loads</head><p>On AMD CPUs, a Miss Address Buffer (MAB) 1 is a structure that tracks a single outstanding cache miss. Misses are assigned to available MABs based on a fixed priority; a miss that occurs when the highest priority MAB is available will always be assigned to that MAB. The first miss will be assigned to the highest priority MAB, as will the next miss after that one returns. Thus, the amount of time that the highest priority MAB is occupied represents the aggregate latency of all of the leading loads. This MAB's occupancy time can be measured directly (in clock cycles) using a hardware performance counter. To the best of our knowledge, no such mechanism exists in processors from other vendors.</p><p>We thus describe our LL-MAB model, which assumes that the wall-clock occupancy time of the highest priority MAB will remain unchanged across different core frequencies, since its occupancy relies on values returning from memory. The remaining execution time, when nothing is in the highest priority MAB, is core time, which is inversely proportional to frequency. More formally, if an application's execution time is T at frequency f and the highest priority MAB is occupied for M clock cycles, then the predicted execution time T 񮽙 of the same application at a frequency f 񮽙 is given by Equation 2.</p><formula xml:id="formula_1">T 񮽙 = M f + (T − M f ) × f f 񮽙<label>(2)</label></formula><p>While Family 15h cores measure MAB occupancy time for L2 cache misses, Family 10h cores measure L1 cache misses. For the purposes of implementing the LL model, this introduces two inaccuracies. First, a leading load from the L1 may still hit in the L2, which is also in the core clock domain. Second, for leading loads that miss in both the L1 and L2 caches, the MAB occupancy time includes the latency of the request from the L1 to L2. Neither should be counted as leading load time, since they will change as the core frequency changes.</p><p>In addition, the MABs hold prefetch misses, which should not be counted as leading loads because they will not cause the core to stall. We will show in Section 4 that these inaccuracies are small enough that LL-MAB model is still more accurate than existing predictors.</p><p>We implemented LL-MAB on three different AMD processors with two different microarchitectures, described in <ref type="table" target="#tab_0">Table 1</ref>. These cores assign MABs in slightly different orders: Family 10h and Family 15h processors give highest priority to MAB1 and MAB0, respectively. Our LL-MAB implementation uses these counters to estimate the leading load time.</p><p>We also implemented an enhanced version of the Green Governor (GG) performance estimation model for <ref type="bibr" target="#b0">1</ref> Commonly known as a Miss Status Handling Register (MSHR). Different memory access patterns cause different DRAM delays. As such, rather than using a single memory latency chosen arbitrarily from a microbenchmark, we instead search the space of possible latencies to find the value that yields the lowest estimation error. This means that we are testing the algorithm on its training data, which may yield optimistic results from the GG model. However, this allows us to operate under the assumption that the GG model's latency has been chosen well (which may not always be the case).</p><p>Finally, where possible, our GG models did not use cache misses caused by prefetchers. On Family 15h processors, specifying the appropriate selection of L3 performance events allows us to ignore prefetch misses. However, this is not possible on Family 10h processors. <ref type="table" target="#tab_0">Table 1</ref> shows the configurations of the systems we measured and the specific performance events we used to collect the data required by the predictors in our experiments. All of the predictors use the Program Cycles counter, though this could potentially be replaced by the hard-coded timestamp counter to reduce counter requirements. The linear estimation method uses only this, while the stall model also uses Stall Cycles. LL-MAB model needs only one additional counter: MAB Wait Cycles. The GG models need 2 or 3 more. GG-L3 uses Stall Cycles and L3 Misses (Family 15h uses 2 hardware counters for this in order to remove prefetch misses). In GG-L2, L3 Misses are replaced by L2 Misses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Evaluation Results and Analysis</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experimental Methodology</head><p>We validated our LL-MAB model using 66 singlethreaded benchmarks from the NAS Parallel Benchmarks <ref type="bibr" target="#b0">[1]</ref>  <ref type="bibr" target="#b1">2</ref> , PARSEC <ref type="bibr" target="#b1">[2]</ref> 3 , Rodinia <ref type="bibr" target="#b2">[3]</ref> 4 , and SPEC CPU2006 <ref type="bibr" target="#b5">[6]</ref>  <ref type="bibr" target="#b4">5</ref> . For comparison, we also tested the linear, stall, GG-L2 and GG-L3 models.</p><p>The AMD Phenom TM II 1090T processor ran Canonical Ubuntu Desktop 12.04 (kernel 3.2.0-24), the AMD Opteron TM 4386 processor ran Fedora <ref type="bibr">TM 19 Desktop (kernel 3.10.6-200)</ref>, and the AMD A10-5800K processor ran CentOS release 6.4 (kernel 2.6.32-358.23.2). We used msr-tools to set and read the performance counters, cpufreq to change DVFS states, and numactl to lock each benchmark to a single core. For each processor, we measured two frequencies, the higher at least twice the lower. We then estimated the change in user-level unhalted clock cycles between the two frequencies.</p><p>As mentioned, we chose the GG miss latency that provided the best average prediction accuracy across all of the benchmarks, based on an exhaustive search of all possible latency values from 0 to 200ns with a step size of 0.1ns. These values are also listed in <ref type="table" target="#tab_0">Table 1</ref>. Because the L3 misses on the AMD Phenom TM II 1090T processor include prefetch misses, the ideal L3 miss latency was lower than the L2 miss latency. These values are up to 2× different than those measured with microbenchmarks, which implies that our GG results are optimistic. <ref type="figure" target="#fig_2">Figures 2, 3, and 4</ref> show the average and standard deviation of the absolute value of the prediction errors. In this case, error is the difference between the estimated and the actual cycles at one frequency when gathering statistics at the other. Unless noted, all results are listed in the order: AMD Phenom TM II 1090T processor, AMD Opteron TM 4386 processor, AMD A10-5800K processor. The stall-based model had much higher average error than the others and is not shown. Its average errors were 21.7%, 31.3% and 32.0%, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Experimental Evaluation</head><p>As shown in the figures, our LL-MAB predictor had the lowest average error and standard deviation for all three processors. The GG-L2 and GG-L3 models are slightly worse, but have similar accuracy to one another. It is worth reiterating that their latency values were carefully tuned to reduce error rate, so these numbers do not necessarily mean that one is better than the other. Nonetheless, LL-MAB model's average error was 5.27%, 2.71%, and 4.80%, 1.22, 1.30, and 1.71 percentage points lower than the most accurate GG model. Linear estimation had the worst average prediction error among the models shown.</p><p>While a lower prediction error is preferred, the second graph in each of these figures demonstrates the standard deviation of these error rates. In this case, the LL-MAB model had a much smaller variance in its errors, implying a more consistent error rate. This is especially important for performance estimation, since an outlier can lead to a severe loss in performance or energy efficiency.</p><p>Figures 5 and 6 plot the absolute prediction error versus memory boundedness for each benchmark. As described by Rountree et al. <ref type="bibr" target="#b9">[10]</ref>, memory boundedness is the ratio of measured execution cycles at the two frequencies. For compute-bound applications, the number of execution cycles should be (approximately) fixed regardless of the frequency, so the memory boundedness should be (approximately) one. Larger values indicate applications that spend more time in the memory system.</p><p>By definition, the linear model's error is proportional to the memory boundedness, so its error rate was highest for memory-bound programs. The stall-based model, on the other hand, exhibited large errors for compute-bound programs, because it incorrectly assumed that computebound applications with many pipeline stalls (due to, for example, mispredicted branches) were memory bound.</p><p>The GG models use cache miss counts to reduce the prediction error when the memory boundedness is low. In this way, the GG models overcame the high error rate of the stall-based model for more compute-bound applications, while keeping the relatively low error rate of the stall-based model for more memory-bound applications.</p><p>Our LL-MAB model was accurate across a range of benchmarks and hardware, because it more directly measures the time spent in the memory system. However, as the memory boundedness increases, the limitations discussed in Section 3 cause some errors. For the programs whose memory boundedness is greater than 1.1, the average absolute error of LL-MAB is still the lowest.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">LL-MAB Model Discussion</head><p>LL-MAB demonstrates three primary advantages:</p><p>1. LL-MAB provides better average prediction accuracy. This was true despite the fact that we gave our comparison point, GG, as many advantages as possible. The accuracy of the GG models would be even worse using directly measured miss latencies.</p><p>2. LL-MAB is easier to implement. It only requires two performance counters, while the GG models need three or four. The LL-MAB model also requires no hardware-or application-specific training, unlike Green Governor or regression models.      </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Memory Boundedness</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Linear</head><p>Stall GG-L2 LL-MAB <ref type="figure">Figure 6</ref>: Error vs. memory boundedness on the AMD A10-5800K processor.</p><p>3. LL-MAB is more flexible to system configuration changes. For example, changing the DRAM frequency of a machine would not impact LL-MAB.</p><p>Other models would require retraining.</p><p>Unlike the leading loads results shown in the literature, LL-MAB has a higher average error rate, between 2.5% and 5%. All three initial papers that modeled LL showed average error rates of 0.2%, though Miftakhutdinov et al. ran simulations with a more complex memory system that showed worse LL results <ref type="bibr" target="#b8">[9]</ref>. Regardless, these results used LL counters that did not have the limitations of our MAB counter. For instance, they only counted misses to the LLC, they had no hardware prefetchers, and (often) assumed a constant delay to memory.</p><p>Others (such as those detailed by Rountree et al. <ref type="bibr" target="#b9">[10]</ref>) demonstrate regression models on real hardware with better accuracy than LL-MAB. We did not study these in detail, because they have the disadvantage of requiring offline training and more hardware counters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion and Future Work</head><p>In this paper, we presented LL-MAB, the first DVFS performance prediction model based on leading loads implemented on existing hardware. Experiments show it has better prediction accuracy than other state-of-the-art models. Moreover, it requires fewer hardware counters, is easier to use, and has less error variance. Because it is built using existing hardware, it can easily be used by software to enable online DVFS performance prediction with no further hardware changes.</p><p>Future work could include using the LL-MAB predictor over short periods for fine-grained DVFS decisions. Similarly, a regression model with this counter may show even better performance than previous regression models. Because LL-MAB requires so few hardware counters, it may also be possible to do online power estimation by monitoring other energy-hungry events.</p><p>There are also simple modifications that could increase the accuracy of the MAB event, such as filtering prefetches. Unlike the scheme described by Miftakhutdinov et al. <ref type="bibr" target="#b8">[9]</ref>, which would require at least an adder for every MAB, these approaches may yield better results with little added hardware.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Leading loads example.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>(b) Standard deviation of the absolute prediction error.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Average and standard deviation of prediction errors on the AMD Phenom TM II 1090T processor.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Average and standard deviation of prediction errors on the AMD Opteron TM 4386 processor.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>SPEC INT SPEC FP Rodinia ALL Standard Deviation (%) (b) Standard deviation of the absolute prediction error.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Average and standard deviation of prediction errors on the AMD A10-5800K processor.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>Figure 5: Prediction error vs. measured memory boundedness (higher means more time in the memory system).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="true"><head>Table 1 : Processor configurations and hardware events.</head><label>1</label><figDesc></figDesc><table>AMD 
AMD 
AMD 
Phenom TM II 
Opteron TM 
A10-
X6 1090T 
4386 
5800K 
Family 
10h 
15h 
15h 
Core Freq. 
1.6/3.2 GHz 
1.4/3.1 GHz 
1.4/3.8 GHz 
DRAM 
DDR3-800 
DDR3-1600 
DDR3-1066 
MAB Counter 
MAB1 
MAB0 
MAB0 
L3 Latency 
13.0ns 
32.2ns 
n/a 
L2 Latency 
24.7ns 
12.8ns 
32.3ns 

H/W Event 
Event Select Code 
E1 Exe. Cyc. 
0x00410076 
0x00410076 
0x00410076 
E2 MAB Cyc. 
0x00410169 
0x00410069 
0x00410069 
E3 Stall Cyc. 
0x014100c0 
0x014100c0 
0x014100c0 
E4 L3 Misses 
0x4004107e0 
0x40040f7e1 No L3 Cache 
0x40040ffe1 
E5 L2 Misses 
0x0001077e 
0x00410043 
0x00410043 

comparison. Because the L3 cache in AMD processors 
is in a separate clock domain from the cores, its access 
time will remain constant at different core frequencies. 
Spiliopoulos et al. measured last level cache misses, 
which means that they did not measure L2 (core domain) 
misses that hit in the L3 (memory domain). To compare 
both of these designs, we build two GG models: one that 
counts L2 misses, and one that counts L3 misses. 

</table></figure>

			<note place="foot" n="208"> 2014 USENIX Annual Technical Conference USENIX Association</note>

			<note place="foot" n="2"> NPB: All 10 SER programs; size &quot;B&quot; for DC and &quot;C&quot; for others. 3 PARSEC: All 13 gcc-serial benchmarks with native inputs. 4 Rodinia: bfs, b+tree, heartwall, hotspot, kmeans, lavaMD, leukocyte, lud, particlefilter, pathfinder, srad, cfd, nw, streamcluster. 5 SPEC CPU2006: All 29 benchmarks with ref inputs.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We would like to sincerely thank Barry Rountree for sharing his leading loads expertise and for his help discovering the relationship between leading loads and MAB occupancy. We would also like to thank Vasileios Spiliopoulos, for his help implementing our GG model, and the anonymous reviewers. This work is partially supported by 863 Program of China (2012AA010905), NSFC (61272144, 61272143) and NUDT/Hunan Innov. Fund. For PostGrad. (B120604, CX2012B029).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bailey</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Barszcz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Barton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Browning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Carter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Dagum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fatoohi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Finebert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Fred-Erickson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lasinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Schreiber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Venkatakrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weeratunga</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename></persName>
		</author>
		<idno>RNR-94-007</idno>
	</analytic>
	<monogr>
		<title level="j">The NAS Parallel Benchmarks. Tech. Rep</title>
		<imprint>
			<date type="published" when="1994-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The PAR-SEC Benchmark Suite: Characterization and Architectural Implications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bienia</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">I</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int&apos;l Conf. on Parallel Architectures and Compilation Techniques</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Rodinia: A Benchmark Suite for Heterogeneous Computing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Che</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Boyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tarjan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sheaffer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-H</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Skadron</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Int&apos;l Symp</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Computer Architecture Performance Evaluation Methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eeckhout</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<publisher>Morgan &amp; Claypool Publishers</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A Counter Architecture for Online DVFS Profitability Estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eyerman</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eeckhout</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Computers</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="page" from="1576" to="1583" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">SPEC CPU2006 Benchmark Descriptions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henning</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGARCH Computer Architecture News</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1" to="17" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Interval-Based Models for Run-Time DVFS Orchestration in Superscalar Processors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keramidas</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Spiliopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaxiras</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int&apos;l Conf. on Computing Frontiers</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Portable tools for performance analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mcvoy</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Staelin</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lmbench</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">USENIX Annual Technical Conf</title>
		<imprint>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Predicting Performance Impact of DVFS for Realistic Memory Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miftakhutdinov</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ebrahimi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patt</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">N</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int&apos;l Symp. on Microarchitecture</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Practical Performance Prediction Under Dynamic Voltage Frequency Scaling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rountree</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lowenthal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">K</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>And De Supinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">R</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int&apos;l Green Computing Conf. and Workshops</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Accurate Run-Time Prediction of Performance Degradation Under Frequency Scaling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Snowdon</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">C</forename><surname>Linden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">V D</forename><surname>Petters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heiser</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Operating System Platforms for Embedded Real-Time Applications</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Green Governors: A Framework for Continuously Adaptive DVFS</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Spiliopoulos</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kaxiras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keramidas</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int&apos;l Green Computing Conf. and Workshops</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
