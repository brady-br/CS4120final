<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2020-09-29T02:58+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Re-think Data Management Software Design Upon the Arrival of Storage Hardware with Built-in Transparent Compression</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ning</forename><surname>Zheng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">ScaleFlux Inc</orgName>
								<orgName type="department" key="dep2">ScaleFlux Inc</orgName>
								<orgName type="department" key="dep3">ScaleFlux Inc</orgName>
								<orgName type="department" key="dep4">ScaleFlux Inc</orgName>
								<orgName type="department" key="dep5">ScaleFlux Inc</orgName>
								<orgName type="department" key="dep6">ScaleFlux Inc</orgName>
								<orgName type="laboratory">ScaleFlux Inc. and RPI</orgName>
								<orgName type="institution" key="instit1">ScaleFlux Inc</orgName>
								<orgName type="institution" key="instit2">RPI</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xubin</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">ScaleFlux Inc</orgName>
								<orgName type="department" key="dep2">ScaleFlux Inc</orgName>
								<orgName type="department" key="dep3">ScaleFlux Inc</orgName>
								<orgName type="department" key="dep4">ScaleFlux Inc</orgName>
								<orgName type="department" key="dep5">ScaleFlux Inc</orgName>
								<orgName type="department" key="dep6">ScaleFlux Inc</orgName>
								<orgName type="laboratory">ScaleFlux Inc. and RPI</orgName>
								<orgName type="institution" key="instit1">ScaleFlux Inc</orgName>
								<orgName type="institution" key="instit2">RPI</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiangpeng</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">ScaleFlux Inc</orgName>
								<orgName type="department" key="dep2">ScaleFlux Inc</orgName>
								<orgName type="department" key="dep3">ScaleFlux Inc</orgName>
								<orgName type="department" key="dep4">ScaleFlux Inc</orgName>
								<orgName type="department" key="dep5">ScaleFlux Inc</orgName>
								<orgName type="department" key="dep6">ScaleFlux Inc</orgName>
								<orgName type="laboratory">ScaleFlux Inc. and RPI</orgName>
								<orgName type="institution" key="instit1">ScaleFlux Inc</orgName>
								<orgName type="institution" key="instit2">RPI</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Wu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">ScaleFlux Inc</orgName>
								<orgName type="department" key="dep2">ScaleFlux Inc</orgName>
								<orgName type="department" key="dep3">ScaleFlux Inc</orgName>
								<orgName type="department" key="dep4">ScaleFlux Inc</orgName>
								<orgName type="department" key="dep5">ScaleFlux Inc</orgName>
								<orgName type="department" key="dep6">ScaleFlux Inc</orgName>
								<orgName type="laboratory">ScaleFlux Inc. and RPI</orgName>
								<orgName type="institution" key="instit1">ScaleFlux Inc</orgName>
								<orgName type="institution" key="instit2">RPI</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">ScaleFlux Inc</orgName>
								<orgName type="department" key="dep2">ScaleFlux Inc</orgName>
								<orgName type="department" key="dep3">ScaleFlux Inc</orgName>
								<orgName type="department" key="dep4">ScaleFlux Inc</orgName>
								<orgName type="department" key="dep5">ScaleFlux Inc</orgName>
								<orgName type="department" key="dep6">ScaleFlux Inc</orgName>
								<orgName type="laboratory">ScaleFlux Inc. and RPI</orgName>
								<orgName type="institution" key="instit1">ScaleFlux Inc</orgName>
								<orgName type="institution" key="instit2">RPI</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Peng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">ScaleFlux Inc</orgName>
								<orgName type="department" key="dep2">ScaleFlux Inc</orgName>
								<orgName type="department" key="dep3">ScaleFlux Inc</orgName>
								<orgName type="department" key="dep4">ScaleFlux Inc</orgName>
								<orgName type="department" key="dep5">ScaleFlux Inc</orgName>
								<orgName type="department" key="dep6">ScaleFlux Inc</orgName>
								<orgName type="laboratory">ScaleFlux Inc. and RPI</orgName>
								<orgName type="institution" key="instit1">ScaleFlux Inc</orgName>
								<orgName type="institution" key="instit2">RPI</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Sun</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">ScaleFlux Inc</orgName>
								<orgName type="department" key="dep2">ScaleFlux Inc</orgName>
								<orgName type="department" key="dep3">ScaleFlux Inc</orgName>
								<orgName type="department" key="dep4">ScaleFlux Inc</orgName>
								<orgName type="department" key="dep5">ScaleFlux Inc</orgName>
								<orgName type="department" key="dep6">ScaleFlux Inc</orgName>
								<orgName type="laboratory">ScaleFlux Inc. and RPI</orgName>
								<orgName type="institution" key="instit1">ScaleFlux Inc</orgName>
								<orgName type="institution" key="instit2">RPI</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Zhong</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">ScaleFlux Inc</orgName>
								<orgName type="department" key="dep2">ScaleFlux Inc</orgName>
								<orgName type="department" key="dep3">ScaleFlux Inc</orgName>
								<orgName type="department" key="dep4">ScaleFlux Inc</orgName>
								<orgName type="department" key="dep5">ScaleFlux Inc</orgName>
								<orgName type="department" key="dep6">ScaleFlux Inc</orgName>
								<orgName type="laboratory">ScaleFlux Inc. and RPI</orgName>
								<orgName type="institution" key="instit1">ScaleFlux Inc</orgName>
								<orgName type="institution" key="instit2">RPI</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">ScaleFlux Inc</orgName>
								<orgName type="department" key="dep2">ScaleFlux Inc</orgName>
								<orgName type="department" key="dep3">ScaleFlux Inc</orgName>
								<orgName type="department" key="dep4">ScaleFlux Inc</orgName>
								<orgName type="department" key="dep5">ScaleFlux Inc</orgName>
								<orgName type="department" key="dep6">ScaleFlux Inc</orgName>
								<orgName type="laboratory">ScaleFlux Inc. and RPI</orgName>
								<orgName type="institution" key="instit1">ScaleFlux Inc</orgName>
								<orgName type="institution" key="instit2">RPI</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Re-think Data Management Software Design Upon the Arrival of Storage Hardware with Built-in Transparent Compression</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>This position paper advocates that storage hardware with built-in transparent compression brings new opportunities to innovate data storage management software (e.g., database and filesystem). Modern storage appliances (e.g., all-flash array) and some latest SSDs (solid-state drives) can perform data compression transparently from OS and user applications. Such storage hardware decouples logical storage space utilization efficiency from physical storage space utilization efficiency. This allows data storage management software intentionally waste logical storage space in return for employing simpler data structures, leading to lower implementation complexity and higher performance. Following this theme, we carried out three preliminary case studies in the context of relational database and key-value (KV) store. Initial experimental results well demonstrate the promising potential, and it is our hope that this preliminary study will attract more interest towards exploring this new research area.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>This position paper advocates that storage hardware with built-in transparent compression brings exciting opportunities to innovate data management software (e.g., database and filesystem). Commercial market has witnessed the rise of block storage appliances/devices that perform data compression with complete transparency to OS and user applications. Modern all-flash arrays (e.g., Dell EMC PowerMAX <ref type="bibr" target="#b0">[1]</ref>, HPE Nimble Storage <ref type="bibr" target="#b1">[2]</ref>, and Pure Storage FlashBlade <ref type="bibr" target="#b3">[4]</ref>) support block-level transparent compression. SSDs with built-in transparent compression are also emerging on the market (e.g., computational storage drive from ScaleFlux <ref type="bibr" target="#b4">[5]</ref> and Nytro SSD from Seagate <ref type="bibr" target="#b12">[13]</ref>).</p><p>In addition to its apparent benefit on reducing the storage cost, storage hardware with built-in transparent compression decouples the logical storage space utilization efficiency from the physical storage space utilization efficiency. This creates a new spectrum for data management software innovation, which can be explained as follows. When running on conventional storage hardware, data management software is solely responsible for the physical storage space utilization efficiency. As a result, data management software faces a stringent trade-off between storage utilization efficiency and implementation complexity: In order to improve the storage space utilization, data management software should make full use of the logical storage space and completely fill each 4KB LBA (logical block address) sector with user data, which demands more sophisticated data structures and algorithms. In comparison, when running on storage hardware with built-in transparent compression, data management software can purposely waste the logical storage space to reduce its implementation complexity, while relying on the storage hardware to retain physical storage space efficiency. Lower software implementation complexity may lead to higher speed performance and better system stability.</p><p>Little prior research has studied how data management software can effectively leverage the decoupled logical vs. physical storage utilization efficiency. Regardless of specific application, the essential design theme is that data management software judiciously wastes the logical storage space in return for lower implementation complexity and higher performance. As storage hardware with built-in transparent compression emerges on the mainstream market, it becomes increasingly necessary to re-think the data management software design under this framework. As the first effort along this direction, we carried out three preliminary case studies: (1) We show that PostgreSQL (the second most popular open-source relational database) can easily benefit from this theme by simply adjusting a parameter; (2) We show that log-structured data store can leverage this theme to reduce the impact of background GC (garbage collection); (3) We show that one could apply this theme to implement a hash-based KV store at almost zero memory usage. It is our hope that these preliminary case studies will contribute to attracting more research interest and activities towards this largely unexplored territory, which may lead to unforeseen opportunities to innovate future data management software.</p><p>For systems running on conventional storage hardware, their logical and physical storage space utilization always tightly couple together, i.e., the LBA space is (almost) equal to the physical storage space inside the storage hardware, and each 4KB LBA sector always occupies 4KB physical storage space. Therefore, data management software is solely responsible for the physical storage space utilization efficiency. As a result, data management software typically employs sophisticated data structures (e.g., B-tree and log-structured merge tree) and algorithms in order to fully utilize the physical storage space. This however leads to high implementation complexity, high CPU/memory resource usage, and difficulty on achieving high speed and stability. A majority of prior research on data management systems focused on searching for better design trade-offs between storage cost and implementation/performance cost.</p><p>For the purpose of illustration, <ref type="figure" target="#fig_0">Fig. 1</ref> shows the structure of an SSD with built-in transparent compression. Data com- pression and decompression are carried out on the IO path by the hardware engine inside the SSD controller, being transparent to the host software stack. The FTL (flash translation layer) inside SSD controller manages the mapping/indexing of all the variable-length compressed data blocks. By compressing each LBA sector and exposing a LBA space much larger than the physical storage space, storage hardware with built-in transparent compression decouples the logical storage space utilization efficiency from the physical storage space utilization efficiency. This allows data management software to purposely under-utilize the logical storage space in return for using less sophisticated data structures and algorithms. This can lead to lower implementation complexity, less CPU/memory resource usage, and higher performance and stability. Accordingly, we propose to re-think the design of data management software from two aspects:</p><p>1. Under-utilize LBA space: Storage hardware with builtin transparent compression can natively expose an LBA space that is much larger than the physical storage space. We should investigate whether data management software can employ simpler data structure and algorithm by intentionally wasting the abundant LBA space. 2. Under-utilize each LBA: We note that special data patterns (e.g., all-zero and all-one vectors) can be highly compressed even with simple compression algorithms such as lz4 and Snappy. Hence, we should investigate whether data management software can employ simpler data structure and algorithm by intentionally wasting the 4KB storage space of each LBA (i.e., leave each 4KB LBA sector partially filled with user data and padded with all-zero vectors).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Preliminary Case Studies</head><p>Following the theme presented above, we carried out three case studies that apply the proposed theme to (1) improve the performance of PostgreSQL at minimal storage space overhead, (2) reduce the impact of GC in log-structured data store, and (3) architect a new highly efficient KV store.</p><p>All the experiments were carried out based on commercial SSDs <ref type="bibr" target="#b4">[5]</ref> that support built-in transparent compression and achieve the same IOPS (IO per second) and throughput performance as leading-edge normal NVMe SSDs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Improve the Performance of PostgreSQL</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Background</head><p>PostgreSQL applies B-tree index to manages its data storage, and realizes MVCC (multi-version concurrency control) by storing all the row versions in the table space. Hence, instead of directly in-place updating a row, PostgreSQL always first stores the new row version at a new location and relies on a background vacuum process to reclaim the table space occupied by dead row versions. As a result, the performance of updating non-index fields in a row strongly depends on whether PostgreSQL can store the new row version in the same page as the old row version:</p><p>• If the page hosting the old row version is full, PostgreSQL has to store the new row version in another page. Hence, PostgreSQL must accordingly modify the B-tree structure by manipulating (and splitting or creating) one or multiple additional pages. This causes extra CPU usage and performance degradation.</p><p>• If the page hosting the old row version has sufficient empty space, PostgreSQL simply appends the new row version in that page. By keeping the B-tree structure intact, this causes very low CPU usage, leading to a higher speed performance. The above fact reveals a fundamental trade-off between TPS (transactions per second) performance and storage space usage: When inserting new rows into a page, if we do not completely fill the page and reserve the remaining empty space to absorb future updates, we can improve the TPS performance. Nevertheless, this meanwhile leads to larger storage space usage. PostgreSQL allows users to configure such a trade-off by exposing a parameter called fillfactor. Being a percentage value between 10 and 100, it controls how full each page will be filled with inserted rows. Its default value is 100, i.e., each page is 100% filled with inserted rows and hence does not reserve any space for future updates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Basic Concept and Experimental Results</head><p>Storage hardware with built-in transparent compression makes PostgreSQL much less subject to the above performance vs. storage cost trade-off, leading to a unique opportunity to improve the PostgreSQL TPS performance at minimal storage cost. As pointed out above in Section 2, special data patterns like all-zeros can be highly compressed. Meanwhile, with fillfactor being less than 100, PostgreSQL initializes the reserved space in each page as zeros. Hence, when running PostgreSQL on SSDs with built-in transparent compression, the all-zero segment in each page only occupies very small amount of physical flash memory storage space. Therefore, by decoupling the logical vs. physical storage space utilization efficiency, storage hardware with builtin transparent compression allows PostgreSQL aggressively reduce the fillfactor to improve the TPS performance at very small increase of physical storage space usage.</p><p>To further demonstrate this concept, we carried out experiments on PostgreSQL (version 10.10) using the Percona Sysbench-TPCC OLTP benchmark <ref type="bibr" target="#b2">[3]</ref>. We used a server with 32-core 3.3GHz Xeon CPU and 64 client threads. For the purpose of comparison, we run the same experiments on one 3.2TB NVMe SSD and one 3.2TB SSD with built-in transparent compression. By keeping the fillfactor as its default value of 100, the PostgreSQL TPS is 3,214 and physical storage usage is 740GB in the case of NVMe SSD, and the PostgreSQL TPS is 3,128 and physical storage usage is 178GB (i.e., the Sysbench dataset can be compressed from 740GB to 178GB) in the case of SSD with built-in transparent compression. By reducing the fillfactor to 75, the PostgreSQL TPS improves to 4,265 and physical storage usage jumps to 905GB in the case of NVMe SSD, and the PostgreSQL TPS improves to 4,330 and physical storage usage slightly increases to 198GB in the case of SSD with built-in transparent compression. As further illustrated in <ref type="figure" target="#fig_1">Fig. 2</ref>, the results suggest that, by simply configuring the fillfactor parameter, PostgreSQL can noticeably benefit from the decoupled logical vs. physical storage space utilization efficiency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Reduce the Impact of GC</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Background</head><p>Log-structured design principle <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b25">27]</ref> has been widely used to implement modern data management systems, e.g., SSD-oriented file systems <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b29">31]</ref>) and KV stores <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b24">24,</ref><ref type="bibr">26]</ref>. Because log-structured data stores do not perform in-place updates, stale data will accumulate over the time, leading to the data storage bloating (or space amplification). To limit the storage space amplification, storage systems must periodically carry out background GC operations to reclaim the storage space at the cost of write amplification. This leads to a fundamental trade-off between space amplification and write amplification: Let C val and C inval denote the amount of valid and invalid data in the log-structured data store. Define γ = (C val + C inval )/C val as the data bloating factor, and we trigger GC whenever γ is larger than a given threshold γ th . As we reduce the threshold γ th , the runtime data bloating will become less significant (i.e., the peak space amplification will reduce), and meanwhile GCinduced write amplification will increase and hence GC will more noticeably degrade the system performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Basic Design Concept</head><p>Following the proposed theme, we present a method called virtual data trim to make log-structured data store less subject to the space amplification vs. write amplification tradeoff. As illustrated in <ref type="figure" target="#fig_2">Fig. 3</ref>, the basic concept is to reset the content of invalid data elements to all-zeros, through which we can rely on the transparent compression, instead of GC, to reclaim the physical storage space occupied by invalid data. It only reduces the physical storage space bloating, and the logical storage space bloating remains unchanged. Therefore, once we schedule GC based on the physical storage space bloating, we can reduce the frequency of GC operations, which can reduce the GC-induced write amplification and hence reduce its impact to the system performance. We note that virtual data trim also induces write amplification, since it carries out read-modify-write in order to reset the data content. Therefore, we should perform virtual data trim only if it causes sufficiently small write amplification. Given the 4KB SSD sector size, we propose the following strategy to implement the virtual data trim: Within each 4KB sector, let S val denote the amount of valid data and define γ (s) = 4KB/S val . We perform virtual data trim only for those sectors whose γ s is larger than the threshold γ th . We note that, if S val is 0 (i.e., the 4KB sector contains only invalid data), we can simply trim the entire sector, instead of using virtual data trim. Accordingly, we should modify the GC schedul- inval denote the logical storage space occupied by the valid data and invalid data, and C (l) trim denote the amount of invalid data that have been trimmed. We define the adjusted bloating factor</p><formula xml:id="formula_0">γ t = C (l) val +C (l) inval −C (l) trim C (l) val ,<label>(1)</label></formula><p>and trigger GC whenever γ t is larger than the threshold γ th .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3">Preliminary Experimental Results</head><p>To preliminary evaluate the proposed design approach, we implement a simple log-structured data store that consists of a number of 64MB segments. At one time, only one segment is open to receive inserted/updated data elements in the append-only manner. Once the open segment reaches 64MB, it will be closed, and a new empty segment will be opened. During each GC operation, we search among all the closed segments and pick the ones with the highest garbage rate for recycling. For the purpose of comparison, we studied two scenarios: (1) Current practice: Following the current practice of log-structured data store design, all the closed segments are strictly immutable, and we do not apply data trim; (2) Trim-assisted: We apply the proposed virtual data trim to runtime reclaim the physical storage space, where all the segments are no longer strictly immutable. We set each data element is 2KB, and <ref type="table" target="#tab_0">Table 1</ref> lists the measured write amplification (WA) and physical space amplification (PSA). The results show that the proposed design approach indeed could enable a more favorable trade-off between write amplification and physical space amplification. 3.3 Hash-based KV Store</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Background</head><p>To implement a KV store, the core design decision is the index data structure, which can be either tree-based or hashbased. However, compared with significant prior efforts on tree-based KV store (e.g., see <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b22">22,</ref><ref type="bibr" target="#b24">24,</ref><ref type="bibr" target="#b27">30]</ref>), little prior efforts chose to focus on hash-based KV store <ref type="bibr" target="#b10">[11]</ref>, even though hash-based approach can support higher index access throughput. The in-memory data store Redis <ref type="bibr">[25]</ref> appears to be the only commercially successful hash-based KV store. Arguably, this is mainly due to the very high memory cost of hash-based approach, especially compared with the ones built upon log-structured merge tree.</p><p>In conventional practice, hash-based KV store must use an in-memory hash table to maintain the mapping from the key space to storage space. Such indirect addressing through the intermediate hash table can ensure the compact placement of KV pairs on the storage space and hence maximize the storage space utilization. Meanwhile, the memory footprint of hash table is directly proportional to the number of KV pairs, leading to prohibitively high memory cost for largescale hash-based KV stores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Basic Design Concept</head><p>Following the theme of leveraging the decoupled logical vs. physical storage utilization efficiency, we propose a table-less hash-based KV store design approach as illustrated in <ref type="figure" target="#fig_3">Fig. 4</ref>. The basic idea is to directly hash the key space onto the logical storage space, without going through an intermediate hash table. In particular, let K denote the key space of the KV store and L denote the logical LBA storage space. We use a hash function f K→L to hash each key K i ∈ K onto one LBA L j ∈ L. By obviating the use of a hash table, it eliminates the memory cost obstacle faced by conventional implementation of hash-based KV store. Moreover, it relieves CPU from managing/searching hash table, leading to less CPU usage. As pointed out above, indirect addressing through an in-memory hash table can ensure the compact placement of KV pairs on the logical storage space. In contrast, as illustrated in <ref type="figure" target="#fig_3">Fig. 4</ref>, the proposed approach is fundamentally subject to logical storage space under-utilization (i.e., almost all the LBAs have empty space left unoccupied). Once we keep the content of the unoccupied space as allzeros, storage hardware with built-in compression can naturally retain the physical storage under-utilization.</p><p>Converting this simple design approach into a commercially viable KV store certainly is nontrivial, and must adequately address several open issues and overcome many engineering challenges. For example, we should effectively handle the occurrence of hashing overflow when more than 4KB of KV pairs are hashed onto the same LBA. In this case, we should use a separate data store to host those spilled- over KV pairs. Moreover, given the key space K, we must make the LBA space (i.e., |L|) large enough in order to make the hashing overflow rate sufficiently low (e.g., below 1%). Therefore, as the size of the key space varies, we must accordingly adjust the size of the LBA space and meanwhile ensure minimal impact on the runtime KV store performance. It is also highly desirable to develop a mathematical formulation framework that can guide the runtime LBA space re-sizing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.3">Preliminary Experimental Results</head><p>We implemented a preliminary KV store prototype that can realize the basic GET and PUT operations, and use embedded SQLite <ref type="bibr">[29]</ref> to absorb the spilled-over KV pairs. The KV store serves all the PUT requests in an asynchronous manner, i.e., after recording the PUT requests in the write-ahead log (WAL), client threads submit PUT requests to a queue, and background threads process the queue in a batch mode with asynchronous IOs. As pointed out in <ref type="bibr" target="#b15">[16]</ref>, the use of asynchronous IOs can very effectively improve the throughput at low CPU usage. To improve the operational parallelism, we partition one table space into multiple sections, each section has its own PUT request queue and associates with one background thread that processes the PUT request queue. All the GET requests are served by client threads through synchronous direct-IOs. For the purpose of evaluation, we carried out experiments on this KV store prototype and RocksDB with the following configurations: We loaded 2 billion KV pairs, where each key and value is 16-byte and 400-byte, respectively. We kept the default RocksDB settings, and the background thread pool size is 32. For our KV store prototype, we partitioned the table space into 16 sections. <ref type="table" target="#tab_1">Table 2</ref> lists the measured results when running 32 client threads with 7:3 GET vs. PUT ratio. The results shows that the table-less hash-based KV store has a very promising potential to achieve significantly higher performance and meanwhile consume less CPU cycles and almost zero memory capacity, compared with the popular RocksDB. Given the wide landscape of data management software ecosystem, there will be numerous open questions and unforeseen opportunities as the research community start to explore this proposed direction. Here we list several open questions which hopefully may serve as a catalyst. Application to more relational databases: This position paper demonstrates how PostgreSQL may benefit from the proposed theme by simply configuring a parameter. It remains unclear how other popular relational databases (e.g., MySQL and Oracle) could utilize this theme. Because they implement MVCC using different strategies than PostgreSQL, we expect that one may need to appropriately modify their source code in order to gain similar benefits. Integration into log-structured data store: This position paper presents very preliminary results on applying virtual data trim to reduce the GC impact for log-structured data store. Much more research is needed to fully understand the trade-offs and study how to practically integrate the proposed technique into real-world log-structured data stores. Implementation of table-less hash-based KV store: This position paper outlines the basic idea of the proposed tableless hash-based KV store. By eliminating the memoryhungry hash table, it has a promising potential to enable high-performance, low-cost alternatives to existing KV stores such as RocksDB. Of course, there are many open issues to be addressed, e.g., how to most effectively handle hashing overflow, how to realize LBA space resizing at the minimal performance impact, and how it can support additional features such as snapshot and transaction. Application to data analytics: Data analytics typically employ column-store to improve the performance and reduce the storage cost. However, the heavy use of compression in today's column-store makes it almost impossible to effectively serve transactional queries. Column-stores may possibly leverage the decoupled logical vs. physical storage space utilization to mitigate this issue, which still remains a completely open question. Application to filesystems: As the core operation of any filesystems, storage space allocation and indexing involve a trade-off between storage space utilization efficiency and implementation complexity (and performance). This clearly leads to a potential of leveraging the proposed theme in the context of filesystems. Application to SSD-based caching for HDDs: Complementing HDDs with SSD-based cache can improve the storage system performance at modest cost overhead. In conventional practice, cache must maintain a complicated index data structure to manage the mapping between HDD storage space and SSD-based cache space. Following the proposed design theme, one could envision a cache design solution that obviates the explicit use of indexing, which can reduce the implementation complexity of the SSD-based cache.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Illustration of an SSD with built-in transparent compression.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Illustration of the measured Sysbench-TPCC TPS performance and physical storage usage, where TC-SSD means SSD with built-in transparent compression.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Illustration of the proposed virtual data trim design concept to reclaim physical storage space without GC.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Illustration of the proposed table-less hash-based KV store design approach.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="true"><head>Table 1 : Measured write and physical space amplification.</head><label>1</label><figDesc></figDesc><table>Current practice 
Trim-assisted 
γ th 
1.2 
1.3 
1.4 
1.2 
WA 
3.20 
2.34 
1.93 
2.16 
PSA 
120% 
131% 
141% 
119% 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Measured KV store performance and CPU usage. 

ops/s 
Read latency 
CPU 
Avg. 
99% 
utilization 
Proposed 
275K 
130µs 
605µs 
21.7% 
RocksDB 
182K 
240µs 
915µs 
43.7% </table></figure>

			<note place="foot" n="4"> Related Work Research community has long studied the benefit and tradeoff of applying compression in database [6, 19, 28, 14, 23], and investigated the implementation of transparent compression at the filesystem level [9, 8] and block device level [20, 17]. By implementing an emulator for SSD with built-in transparent compression, Zuck et al. [32] studied the options of integrating transparent compression into SSD, and demonstrated its potential of reducing storage cost for relational database without sacrificing TPS performance. Most prior work studied the use of compression solely for the purpose of reducing the data storage cost. In comparison, this work studies the potential of simplifying data management software in the presence of storage hardware with built-in transparent compression. 5 Conclusion This position paper for the first time points out that, by decoupling the logical storage space utilization from the physical storage space utilization, storage hardware with builtin transparent compression enables a promising potential to innovate data storage management software. The essential theme is to make data storage management software intentionally and appropriately under-utilize the logical storage space in return for employing simpler data structures and algorithms, which can further enable lower implementation complexity and higher performance. We carried out three preliminary case studies that apply this design theme in the context of relational database and KV store, and the results well demonstrate the promise.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emc</forename><surname>Dell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Powermax</surname></persName>
		</author>
		<ptr target="https://delltechnologies.com/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hpe Nimble Storage</surname></persName>
		</author>
		<ptr target="https://www.hpe.com/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percona</forename><surname>Sysbench</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-</forename><surname>Tpcc</surname></persName>
		</author>
		<ptr target="https://github.com/Percona-Lab/sysbench-tpcc" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pure Storage Flashblade</surname></persName>
		</author>
		<ptr target="https://purestorage.com/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title/>
		<ptr target="http://scaleflux.com" />
	</analytic>
	<monogr>
		<title level="j">ScaleFlux Computational Storage</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Space and time savings through large data base compression and dynamic restructuring. Proceedings of the IEEE</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alsberg</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">A</forename></persName>
		</author>
		<imprint>
			<date type="published" when="1975" />
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="page" from="1114" to="1122" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Creating synergies between memory, disk and log in log structured key-value stores</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Balmau</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Didona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Guerraoui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zwaenepoel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konka</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Triad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of USENIX Annual Technical Conference</title>
		<meeting>USENIX Annual Technical Conference</meeting>
		<imprint>
			<publisher>ATC</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="363" to="375" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">On-line data compression in a logstructured file system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Burrows</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Jerian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lampson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mann</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGPLAN Notices</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="2" to="9" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Combining the concepts of compression and caching for a two-level filesystem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cate</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gross</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGOPS Operating Systems Review</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="200" to="211" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
	<note>Special Issue</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Better space-time trade-offs for LSM-tree based key-value stores via adaptive removal of superfluous merging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dayan</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>And Idreos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Dostoevsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGMOD International Conference on Management of Data</title>
		<meeting>the ACM SIGMOD International Conference on Management of Data</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="505" to="520" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Skimpystash: Ram space skimpy key-value store on flash-based storage</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Debnath</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sengupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">I</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM International Conference on Management of data (SIGMOD</title>
		<meeting>the ACM International Conference on Management of data (SIGMOD</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="25" to="36" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Optimizing Space Amplification in RocksDB</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Callaghan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Galanis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Borthakur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Savor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Strum</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIDR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">SSD with Compression: Implementation, Interface and Use Case</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haratsch</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">F</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Flash Memory Summit</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Data compression support in databases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">R</forename><surname>Iyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wilhite</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VLDB</title>
		<imprint>
			<date type="published" when="1994" />
			<biblScope unit="volume">94</biblScope>
			<biblScope unit="page" from="695" to="704" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A new file system for flash storage</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lee</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cho</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>F2fs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">USENIX Conference on File and Storage Technologies (FAST) (2015)</title>
		<imprint>
			<biblScope unit="page" from="273" to="286" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">KVell: the design and implementation of a fast persistent key-value store</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lepers</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Balmau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zwaenepoel</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Symposium on Operating Systems Principles (SOSP) (2019)</title>
		<meeting>the ACM Symposium on Operating Systems Principles (SOSP) (2019)</meeting>
		<imprint>
			<biblScope unit="page" from="447" to="461" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Nitro: A capacityoptimized SSD cache for primary storage</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">I</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shilane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Douglis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Shim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Smal-Done</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wallace</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">USENIX Annual Technical Conference</title>
		<imprint>
			<publisher>ATC</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="501" to="512" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">U</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Pillai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Gopalakrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Arpaci-Dusseau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arpaci-Dusseau</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">H</forename><surname>Wisckey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Separating keys from values in SSD-conscious storage</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Application of data compression to a large bibliographic data base</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lynch</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">A</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brownrigg</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">B</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Very Large Data Bases</title>
		<meeting>the International Conference on Very Large Data Bases</meeting>
		<imprint>
			<date type="published" when="1981" />
			<biblScope unit="page" from="435" to="447" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Using transparent compression to improve SSD-based I/O caches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Makatos</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Klonatos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Marazakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Flouris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bilas</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European conference on Computer systems</title>
		<meeting>the European conference on Computer systems</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">The log-structured merge-tree</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O&amp;apos;neil</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Gawlick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>And O&amp;apos;neil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename></persName>
		</author>
		<imprint/>
	</monogr>
	<note>LSM-tree</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Acta Informatica</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="351" to="385" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Design and implementation of a fast and efficient scale-up key-value store</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Papagiannis</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Saloustros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gonz´alezgonz´ Gonz´alez-F ´ Erez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bilas</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tucana</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of USENIX Annual Technical Conference</title>
		<meeting>USENIX Annual Technical Conference</meeting>
		<imprint>
			<publisher>ATC</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="537" to="550" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Data compression in oracle</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Poess</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Potapov</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of VLDB Conference</title>
		<meeting>VLDB Conference</meeting>
		<imprint>
			<publisher>Elsevier</publisher>
			<date type="published" when="2003" />
			<biblScope unit="page" from="937" to="947" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Building key-value stores using fragmented log-structured merge trees</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raju</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kadekodi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chidambaram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abraham</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Pebblesdb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Symposium on Operating Systems Principles (SOSP</title>
		<meeting>the Symposium on Operating Systems Principles (SOSP</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="497" to="514" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">The design and implementation of a log-structured file system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rosenblum</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ousterhout</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">K</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Computer Systems (TOCS)</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="26" to="52" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A practitioner&apos;s guide to data base compression tutorial</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Severance</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Systems</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="51" to="62" />
			<date type="published" when="1983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Building an efficient put-intensive key-value store with skip-tree</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Parallel and Distributed Systems</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="961" to="973" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">ParaFS: A logstructured file system to exploit the internal parallelism of flash devices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">U</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">USENIX Annual Technical Conference (ACT) (2016)</title>
		<imprint>
			<biblScope unit="page" from="87" to="100" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Compression and SSDs: Where and how?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zuck</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Toledo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sotnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harnik</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Interactions of NVM/Flash with Operating Systems and Workloads (INFLOW)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
