<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2020-09-29T02:14+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">FastCDC: a Fast and Efficient Content-Defined Chunking Approach for Data Deduplication FastCDC: a Fast and Efficient Content-Defined Chunking Approach for Data Deduplication</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>June 22-24. 2016. 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">•</forename><surname>Denver</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Technology; Hong</forename><surname>Co</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jiang</surname></persName>
						</author>
						<title level="a" type="main">FastCDC: a Fast and Efficient Content-Defined Chunking Approach for Data Deduplication FastCDC: a Fast and Efficient Content-Defined Chunking Approach for Data Deduplication</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2016 USENIX Annual Technical Conference (USENIC ATC &apos;16)</title>
						<meeting>the 2016 USENIX Annual Technical Conference (USENIC ATC &apos;16) <address><addrLine>University of Texas at Arlington</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page">101</biblScope>
							<date type="published">June 22-24. 2016. 2016</date>
						</imprint>
					</monogr>
					<note>This paper is included in the Open access to the Proceedings of the 2016 USENIX Annual Technical Conference (USENIX ATC &apos;16) is sponsored by USENIX.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Content-Defined Chunking (CDC) has been playing a key role in data deduplication systems in the past 15 years or so due to its high redundancy detection ability. However, existing CDC-based approaches introduce heavy CPU overhead because they declare the chunk cut-points by computing and judging the rolling hashes of the data stream byte by byte. In this paper, we propose FastCDC, a Fast and efficient CDC approach, that builds and improves on the latest Gear-based CDC approach , one of the fastest CDC methods to our knowledge. The key idea behind FastCDC is the combined use of three key techniques, namely, simplifying and enhancing the hash judgment to address our observed challenges facing Gear-based CDC, skipping sub-minimum chunk cut-point to further speed up CDC, and normalizing the chunk-size distribution in a small specified region to address the problem of the decreased deduplication ratio stemming from the cut-point skipping. Our evaluation results show that, by using a combination of the three techniques, FastCDC is about 10× faster than the best of open-source Rabin-based CDC, and about 3× faster than the state-of-the-art Gear-and AE-based CDC, while achieving nearly the same deduplication ratio as the classic Rabin-based approach.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Data deduplication, an efficient approach to data reduction, has gained increasing attention and popularity in large-scale storage systems due to the explosive growth of digital data. It eliminates redundant data at the fileor chunk-level and identifies duplicate contents by their cryptographically secure hash signatures (e.g., SHA1 fingerprint). According to deduplication studies conducted by Microsoft <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b22">23]</ref> and EMC <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b32">33]</ref>, about 50% and 85% of the data in their production primary and secondary storage systems, respectively, are redundant and could be removed by the deduplication technology.</p><p>In general, chunk-level deduplication is more popular than file-level deduplication because it identifies and re- * Corresponding author: dfeng@hust.edu.cn. moves redundancy at a finer granularity. For chunk-level deduplication, the simplest chunking approach is to cut the file or data stream into equal, fixed-size chunks, referred to as Fixed-Size Chunking (FSC) <ref type="bibr" target="#b26">[27]</ref>. ContentDefined Chunking (CDC) based approaches are proposed to address the boundary-shift problem facing the FSC approach <ref type="bibr" target="#b24">[25]</ref>. Specifically, CDC declares chunk boundaries based on the byte contents of the data stream instead of on the byte offset, as in FSC, and thus helps detect more redundancy for deduplication. According to some recent studies <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b25">26]</ref>, CDC-based deduplication approaches are able to detect about 10-20% more redundancy than the FSC approach.</p><p>Currently, the most popular CDC approaches determine chunk boundaries based on the Rabin fingerprints of the content, which we refer to as Rabin-based CDC <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b27">28]</ref>. Rabin-based CDC is highly effective in duplicate detection but time-consuming, because it computes and judges (against a condition value) the Rabin fingerprints of the data stream byte by byte <ref type="bibr" target="#b10">[11]</ref>. A recent study, called QuickSync <ref type="bibr" target="#b8">[9]</ref>, suggests that CDC is computationally expensive for deduplication based synchronization in mobile cloud storage. In order to speed up the CDC process, other hash algorithms have been proposed to replace the Rabin algorithm for CDC, such as SampeByte <ref type="bibr" target="#b0">[1]</ref>, Gear <ref type="bibr" target="#b37">[38]</ref>, and AE <ref type="bibr" target="#b39">[40]</ref>. Meanwhile, the abundance of computation resources afforded by multicore and manycore processors <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b36">37]</ref> or GPU processors <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b14">15]</ref> has been leveraged for acceleration.</p><p>Generally, CDC consists of two distinctive and sequential stages: (1) hashing in which fingerprints of the data contents are generated and (2) hash judgment in which fingerprints are compared against a given value to identify and declare chunk cut-points. Our previous study of delta compression, Ddelta <ref type="bibr" target="#b37">[38]</ref>, suggests that the Gear hash (i.e., fp=(fp&lt;&lt;1)+G(b), see Section 3) is very efficient as a rolling hash for CDC. To the best of our knowledge, Gear appears to be one of the fastest rolling hash algorithms for CDC at present. However, according to our first observation from empirical and analytical studies, the Gear-based CDC has the potential problem of low deduplication ratio (i.e., the percentage of re-dundant data reduced) stemming from its hash judgment stage where the sliding window size is very small. Meanwhile, our second observation indicates that the hash judgment stage becomes the new performance bottleneck during CDC after the fast Gear <ref type="bibr" target="#b37">[38]</ref> is used in the hashing stage, because the accelerated hashing stage by Gear, has shifted the bottleneck to the hash judgment stage. Motivated by these two observations and the need to further accelerate the CDC process, we use an approach of enhancing and simplifying the hash judgment to further reduce the CPU operations during CDC.</p><p>Our third observation suggests that the predefined minimum chunk size used to avoid generating the very small-sized chunks ( e.g., LBFS <ref type="bibr" target="#b24">[25]</ref> employs the minimum chunk size of 2KB for Rabin-based CDC) can be employed for cut-point skipping during CDC, i.e., judiciously skipping some identified cut-points to eliminate the CDC operations in this region. Enlarging this minimum chunk size can further speed up the chunking process but at the cost of decreasing the deduplication ratio. This is because many chunks with skipped cut-points are not divided truly according to the data contents (i.e., content-defined). Thus, we propose a novel normalized Content-Defined Chunking scheme, called normalized chunking, that normalizes the chunk-size distribution to a specified region that is guaranteed to be larger than the minimum chunk size to effectively address the problem facing the cut-point skipping approach.</p><p>Therefore, motivated by the above observations, we proposed FastCDC, a Fast and efficient CDC approach that combines the following three key techniques.</p><p>• Simplified but enhanced hash judgment: By padding several zero bits into the mask value for the hash-judging statement of the CDC algorithm to enlarge the sliding window size while using the fast Gear hash, FastCDC is able to achieve nearly the same deduplication ratio as the Rabin-based CDC; By further simplifying and optimizing the hashjudging statement, FastCDC minimizes the CPU overhead for the hash judgment stage in CDC.</p><p>• Sub-minimum chunk cut-point skipping: Our large scale study suggests that skipping the predefined minimum chunk size (used for avoiding smallsized chunks) increases the chunking speed but decreases the deduplication ratio (about 15% decline in the worst case). This motivates us to further enlarge the minimum chunk size to maximize chunking speed while developing a counter measure for the decreased deduplication ratio in the following normalized chunking approach.</p><p>• Normalized chunking: By selectively changing the number of mask bits '1' in the hash-judging statement of CDC, FastCDC normalizes the chunksize distribution to a small specified region (e.g., 8KB∼16KB), i.e., the vast majority of the generated chunks fall into this size range, and thus minimizes the number of chunks of either too small or large in size. The benefits are twofold. First, it increases the deduplication ratio by reducing the number of large-sized chunks. Second, it reduces the number of small-sized chunks, which makes it possible to combine with the cut-point skipping technique above to maximize the CDC speed while without sacrificing the deduplication ratio.</p><p>Our evaluation results from a large-scale empirical study of CDC, based on seven datasets, demonstrate that FastCDC is about 10× faster than the Rabin-based CDC, and 3× faster than the state-of-the-art Gear-and AEbased CDC, while ensuring a high deduplication ratio.</p><p>The rest of the paper is organized as follows. Section 2 presents the necessary background for this research. Section 3 discusses our key observations that motivate the design of FastCDC. Section 4 describes the three key approaches used in FastCDC. Section 5 presents and discusses our experimental evaluation of FastCDC. Section 6 draws conclusions and outlines our future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head><p>Chunking is the first critical step in the operational path of data deduplication, in which a file or data stream is divided into small chunks so that each can be duplicateidentified. Fixed-Size Chunking (FSC) <ref type="bibr" target="#b26">[27]</ref> is simple and fast but may face the problem of low deduplication ratio that stems from the boundary-shift problem <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b39">40]</ref>. For example, if one or several bytes are inserted at the beginning of a file, all current chunk cutpoints (i.e., boundaries) declared by FSC will be shifted and no duplicate chunks will be detected.</p><p>Content-Defined Chunking (CDC) is proposed to solve the boundary-shift problem. CDC uses a slidingwindow technique on the content of files and computes a hash value (e.g., Rabin fingerprint <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b27">28]</ref>) of the window. A chunk cut-point is declared if the hash value satisfies some pre-defined condition. As shown in <ref type="figure">Figure 1</ref>, to chunk a file V 2 that is modified from the file V 1 , the CDC algorithm can still identify the correct boundary of chunks C 1 , C 3 , and C 4 , whose contents have not been modified. As a result, CDC outperforms FSC in terms of deduplication ratio and has been widely used in backup <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b41">42]</ref> and primary <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b22">23]</ref> storage systems.</p><p>Although the widely used Rabin-based CDC helps obtain a high deduplication ratio, it incurs heavy CPU overhead <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b36">37]</ref>. Specifically, in Rabin-based CDC, the Rabin hash for a sliding window containing the byte sequence B 1 ,B 2 ,...,B α is defined as a polynomial A(p): <ref type="figure">Figure 1</ref>: The sliding window technique for the CDC algorithm. The hash value of the sliding window, fp, is computed via the Rabin algorithm (this is the hashing stage of CDC). If the lowest log 2 D bits of the hash value matches a threshold value r, i.e., fp mod D = r, this offset (i.e., the current position) is marked as a chunk cut-point (this is the hash-judging stage of CDC).</p><formula xml:id="formula_0">Rabin(B1, B2, ..., Bα) = A(p) = { α ∑ x=1 Bxp α−x }mod D (1)      񮽙񮽙     񮽙         񮽙񮽙      </formula><p>where D is the average chunk size and α is the number of bytes in the sliding window. Rabin hash is a rolling hash algorithm since it is able to compute the hash in an iterative fashion, i.e., the current hash can be incrementally computed from the previous value as follows:</p><formula xml:id="formula_1">Rabin(B2, B3, ..., Bα+1) = {[Rabin(B1, ..., Bα) − B1P α−1 ]p + Bα+1}modS (2)</formula><p>However, Rabin-based CDC is time-consuming because it computes and judges the hashes of the data stream byte by byte, which renders the chunking process a performance bottleneck in deduplication systems. There are many approaches to accelerating the CDC process for deduplication systems and they can be broadly classified as either algorithmic oriented or hardware oriented. We summarize below some of these approaches that represent the state of the art.</p><p>Algorithmic-oriented CDC Optimizations. Since the frequent computations of Rabin fingerprints for CDC are time-consuming, many alternatives to Rabin have been proposed to accelerate the CDC process <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b39">40]</ref>. SampleByte <ref type="bibr" target="#b0">[1]</ref> is designed for providing fast chunking for fine-grained network redundancy elimination, usually eliminating duplicate chunks as small as 32-64 bytes. It uses one byte to declare a fingerprint for chunking, in contrast to Rabin that uses a sliding window, and skips 1 2 of the expected chunk size before chunking to avoid generating extremely small-sized strings or chunks (they called "avoid oversampling"). Gear <ref type="bibr" target="#b37">[38]</ref> uses fewer operations to generate rolling hashes by means of a small random integer table to map the values of the byte contents, so as to achieve higher chunking throughput. AE <ref type="bibr" target="#b39">[40]</ref> is a non-rolling-hash-based chunking algorithm that employs an asymmetric sliding window to identify extremums of data stream as cut-points, which reduces the computational overhead for CDC. <ref type="bibr">Yu et al. [39]</ref> adjust the function for selecting chunk boundaries such that if weak conditions are not met, the sliding window can jump forward, avoiding unnecessary calculation steps.</p><p>Hardware-oriented CDC Optimizations. StoreGPU <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b14">15]</ref> and Shredder <ref type="bibr" target="#b4">[5]</ref> make full use of GPGPU's computational power to accelerate popular computeintensive primitives (i.e., chunking and fingerprinting) in data deduplication. P-Dedupe <ref type="bibr" target="#b36">[37]</ref> pipelines deduplication tasks and then further parallelizes the sub-tasks of chunking and fingerprinting with multiple threads and thus achieves higher throughput.</p><p>It is noteworthy that there are other chunking approaches trying to achieve a higher deduplication ratio but introduce more computation overhead on top of the conventional CDC approach. TTTD <ref type="bibr" target="#b12">[13]</ref> and Regression chunking <ref type="bibr" target="#b11">[12]</ref> introduces one or more additional thresholds for chunking judgment, which leads to a higher probability of finding chunk boundaries and decreases the chunk size variance. MAXP <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b31">32]</ref> treats the extreme values in a fixed-size region as cut-points, which also results in smaller chunk size variance. In addition, Bimodal chunking <ref type="bibr" target="#b16">[17]</ref>, Subchunk <ref type="bibr" target="#b28">[29]</ref>, and FBC <ref type="bibr" target="#b20">[21]</ref> re-chunk the non-duplicate chunks into smaller ones to detect more redundancy.</p><p>For completeness and self-containment we briefly discuss other relevant deduplication issues here. A typical data deduplication system follows the workflow of chunking, fingerprinting, indexing, and storage management <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b41">42]</ref>. The fingerprinting process computes the cryptographically secure hash signatures (e.g., SHA1) of data chunks, which is also a computeintensive task but can be accelerated by certain pipelining or parallelizing techniques <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b36">37]</ref>. Indexing refers the process of identifying the identical fingerprints for checking duplicate chunks in large-scale storage systems, which has been well explored in many previous studies <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b41">42]</ref>. Storage management refers to the storage and possible post-deduplication processing of the non-duplicate chunks and their metadata, including such processes as related to further compression <ref type="bibr" target="#b37">[38]</ref>, defragmentation <ref type="bibr" target="#b17">[18]</ref>, reliability <ref type="bibr" target="#b3">[4]</ref>, security <ref type="bibr" target="#b40">[41]</ref>, etc. In this paper, we focus on designing a very fast and efficient chunking approach for data deduplication.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Observation and Motivation</head><p>In this section, we elaborate on and analyze the most relevant state-of-the-art CDC approaches to gain useful insights and observations. <ref type="table">Table 1</ref> shows a comparison among the three rolling hash algorithms for CDC, namely, Rabin, Adler, and Gear, which suggests Gear uses far fewer calculation operations than Rabin and Adler, thus being a good rolling hash candidate for CDC.</p><p>A good hash function must have a uniform distribution of hash values regardless of the hashed content. As shown in <ref type="figure" target="#fig_0">Figure 2</ref>, Gear-based CDC achieves this in two key ways: (1) It employs an array of 256 random 64-bit integers to map the values of the byte contents in the sliding window (i.e., the calculated bytes, whose size is the <ref type="table">Table 1</ref>: The hashing stage of the Rabin-, Adler-, and Gear-based CDC. Here 'a' and 'b' denote contents of the first and last byte of the sliding window respectively, 'N' is the length of the content-defined sliding window, and 'U', 'T', 'A', 'G' denote the predefined arrays <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b37">38]</ref>. 'fp' represents the fingerprint of the sliding window. bit-width of the fp); and <ref type="formula">(2)</ref> The addition ("+") operation adds the new byte in the sliding window into Gear hashes while the left-shift ("&lt;&lt;") operation helps strip away the last byte of the last sliding window (e.g., B i−1 in <ref type="figure" target="#fig_0">Figure 2</ref>). This is because, after the "&lt;&lt;" and modulo operations, the last byte B i−1 will be calculated into the fp as the (G[B i−1 ] &lt;&lt; n) mod 2 n , which will be equal to zero. As a result, Gear generates uniformly distributed hash values by using only three operations (i.e., "+", "&lt;&lt;", and an array lookup), enabling it to move quickly through the data content for the purpose of CDC. Note that the modulo operation is used in the hashingjudging stage as discussed later.</p><formula xml:id="formula_2">Name Pseudocode Speed Rabin fp = ((fp ∧ U (a)) &lt;&lt; 8)|b ∧ T [fp &gt;&gt; N ] Slow Adler S1+= A(b); S2+= S1; fp = (S2 &lt;&lt; 16)|S1 Slow Gear fp = (fp &lt;&lt; 1) + G(b) Fast</formula><formula xml:id="formula_3">                                                          񮽙           </formula><p>Gear-based CDC is first employed by Ddelta <ref type="bibr" target="#b37">[38]</ref> for delta compression, which helps provide a higher delta encoding speed. However, according to our experimental analysis, there are still challenges facing the Gear-based CDC. We elaborate on these issues as follows.</p><p>Limited sliding window size. The traditional hash judgment for the Rabin-based CDC, as shown in <ref type="figure">Figure 1</ref> (i.e., "fp mod D==r"), is also used by the Gear-based CDC <ref type="bibr" target="#b37">[38]</ref>. But this results in a smaller sized sliding window used by Gear-based CDC since it uses Gear hash for chunking. For example, as shown in <ref type="figure" target="#fig_3">Figure 5</ref>, the sliding window size of the Gear-based CDC will be equal to the number of the bits used by the mask value. Therefore, when using a mask value of 2 13 for the expected chunk size of 8KB, the sliding window for the Gear-based CDC would be 13 bytes while that of the Rabin-based CDC would be 48 bytes <ref type="bibr" target="#b24">[25]</ref>. The smaller sliding window size of the Gear-based CDC can lead to more chunking position collisions (i.e., randomly marking the different positions as the chunk cut-points), resulting in the decrease in deduplication ratio (see Section 5.2).</p><p>The time-consuming hash judgment. Our implemen- tation and in-depth analysis of the Gear-based CDC suggest that its hash-judging stage accounts for more than 60% of its CPU overhead during CDC after the fast Gear hash is used for fingerprinting. Thus, there is a lot of room for the optimization of the hash judging stage to further accelerate the CDC process.</p><p>Speed up chunking by skipping. Another observation is that the minimum chunk size used for avoiding extremely small-sized chunks, can be also employed to speed up CDC by the cut-point skipping, i.e., eliminating the chunking computation in the skipped region. <ref type="figure" target="#fig_1">Figure 3</ref> shows our experimental observation of Rabinbased CDC with two typical workloads of deduplication whose workload characteristics are detailed in <ref type="table" target="#tab_2">Table 2</ref> in Section 5.1. <ref type="figure" target="#fig_1">Figure 3</ref> (a) indicates that setting the minimum chunk size for cut-point skipping at 1 4 ×∼2× of the expected chunk size can effectively accelerate the CDC process. But this approach decreases the deduplication ratio by about 2∼15% (see <ref type="figure" target="#fig_1">Figure 3</ref> (b)) since many chunks are not divided truly according to the data contents, i.e., not really content-defined.</p><p>The observation suggested in <ref type="figure" target="#fig_1">Figure 3</ref> motivates us to consider a new CDC approach that (1) keeps all the chunk cut-points that generate chunks larger than a predefined minimum chunk size and (2) enables the chunksize distribution to be normalized to a relatively small specified region, an approach we refer to as normalized chunking in this paper, as described in Section 4.4.</p><p>In summary, the analysis and observation of the Gearbased CDC motivate us to propose FastCDC, a faster CDC approach with a higher deduplication ratio than the Gear-based CDC. The implementation of FastCDC will be detailed in the next section and its effectiveness and efficiency will be demonstrated in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">FastCDC Design and Implementation 4.1 FastCDC Overview</head><p>FastCDC is implemented on top of the Gear-based CDC, and aims to provide high performance CDC. Generally, there are three metrics for evaluating CDC performance, namely, deduplication ratio, chunking speed, and the average generated chunk size. Note that the average generated chunk size may be nearly equal to or larger than the predefined expected chunk size (e.g., 8KB) due to factors such as the detailed CDC methods and datasets. This is also an important CDC performance metric because it reflects the metadata overhead for deduplication indexing, i.e., the larger the generated chunk size is, the fewer the number of chunks and thus the less metadata will be processed by data deduplication. However, it is difficult, if not impossible, to improve these three performance metrics simultaneously because they can be conflicting goals. For example, a smaller average generated chunk size leads to a higher deduplication ratio, but at the cost of lower chunking speed and high metadata overheads. Thus, FastCDC is designed to strike a sensible tradeoff among these three metrics so as to strive for high performance CDC, by using a combination of the three techniques with their complementary features as shown in <ref type="figure" target="#fig_2">Figure 4</ref>.</p><p>• Optimizing hash judgment: using a zero-padding scheme and a simplified hash-judging statement to speed up CDC without compromising the deduplication ratio, as detailed in Section 4.2.</p><p>• Sub-minimum chunk cut-point skipping: enlarging the predefined minimum chunk size and skipping cut-points for chunks smaller than that to provide a higher chunking speed and a larger average generated chunk size, as detailed in Section 4.3.</p><p>• Normalized chunking: selectively changing the number of mask '1' bits for the hash judgment to approximately normalize the chunk-size distribution to a small specified region that is just larger than the predefined minimum chunk size, ensuring both a higher deduplication ratio and higher chunking speed, as detailed in Section 4.4.</p><p>In general, the key idea behind FastCDC is the combined use of the above three key techniques on top of Gear-based CDC, especially employing normalized chunking to address the problem of decreased deduplication ratio facing the cut-point skipping, and thus achieve high performance CDC on the three key metrics.   <ref type="figure">Figure 6</ref>: An example of the sliding window technique proposed for FastCDC. By padding y zero bits into the mask value for hash judgment, the size of the sliding window used in FastCDC is enlarged to about 5+y bytes, where y=5 in this example.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Optimizing Hash Judgment</head><p>In this subsection, we propose an enhanced but simplified hash-judging statement to accelerate the hash judgment stage of FastCDC to further accelerate the chunking process on top of the Gear-based CDC and increase the deduplication ratio to reach that of the Rabin-based CDC. More specifically, FastCDC incorporates two main optimizations as elaborated below.</p><p>Enlarging the sliding window size by zero padding. As discussed in Section 3, the Gear-based CDC employs the same conventional hash judgment used in the Rabinbased CDC, where a certain number of the lowest bits of the fingerprint are used to declare the chunk cut-point, leading to a shortened sliding window for the Gear-based CDC (see <ref type="figure" target="#fig_3">Figure 5</ref>) because of the unique feature of the Gear hash. To address this problem, FastCDC enlarges the sliding window size by padding a number of zero bits into the mask value. As illustrated by the example of <ref type="figure">Figure 6</ref>, FastCDC pads five zero bits into the mask value and changes the hash judgment statement to "fp &amp; mask == r". If the masked bits of fp match a threshold value r, the current position will be declared as a chunk cut-point. Since Gear hash uses one left-shift and one addition operation to compute the rolling hash, this zeropadding scheme enables 10 bytes (i.e., B i , ... , B i+9 ), instead of the original five bytes, to be involved in the final <ref type="figure">Figure 7</ref>: Chunk-size distribution of the Rabin-based CDC approach with average chunk size of 8KB and without the maximum and minimum chunk size requirements. "Rabin" and "Math" denote respectively our experimental observation and theoretical analysis (i.e., Equation <ref type="formula">(3)</ref>) of post-chunking chunk-size distribution, where they are shown to be nearly identical.</p><p>hash judgment by the five masked one bits (as the red box shown in <ref type="figure">Figure 6</ref>) and thus makes the sliding window size equal or similar to that of the Rabin-based CDC <ref type="bibr" target="#b24">[25]</ref>, minimizing the probability of the chunking position collision. As a result, FastCDC is able to achieve a deduplication ratio as high as that by the Rabin-based CDC.</p><p>Simplifying the hash judgment to accelerate CDC. The conventional hash judgment process, as used in the Rabin-based CDC, is expressed in the programming statement of "fp mod D==r" <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b37">38]</ref>. For example, the Rabin-based CDC usually defines D and r as 0x02000 and 0x78, according to the known open source project LBFS <ref type="bibr" target="#b24">[25]</ref>, to obtain the expected average chunk size of 8KB. In FastCDC, when combined with the zeropadding scheme introduced above and shown in <ref type="figure">Fig- ure 6</ref>, the hash judgment statement can be optimized to "fp &amp; Mask==0", which is equivalent to "!fp &amp; Mask". Therefore, FastCDC's hash judgment statement reduces the register space for storing the threshold value r and avoids the unnecessary comparison operation that compares "fp &amp; Mask" and r, thus further speeds up the CDC process as verified in Section 5.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Cut-point Skipping</head><p>Most of CDC-based deduplication systems impose a limit of the maximum and minimum chunk sizes, to avoid the pathological cases of generating many extremely large-or small-sized chunks by CDC <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b22">[23]</ref><ref type="bibr" target="#b23">[24]</ref><ref type="bibr" target="#b24">[25]</ref><ref type="bibr" target="#b28">29]</ref>. A common configuration of the average, minimum, and maximum parameters follows that used by LBFS <ref type="bibr" target="#b24">[25]</ref>, i.e., 8KB, 2KB, and 64KB. Our experimental observation and mathematical analysis suggest that the cumulative distribution of chunk size X in Rabin-based CDC approaches with an expected chunk size of 8 KB (without the maximum and minimum chunk size requirements) follows an exponential distribution as follows:</p><formula xml:id="formula_4">P (X ≤ x) = F (x) = (1 − e − x 8192 ), x ≥ 0. (3)</formula><p>Note that this theoretical exponential distribution in Equation 3 is based on the assumption that the data content and Rabin hashes of contents (recall Equation 1 and <ref type="figure">Figure 1</ref> for CDC) follow a uniform distribution. Equation 3 suggests that the value of the expected chunk size will be 8KB according to the exponential distribution. <ref type="figure">Figure 7</ref> shows a comparison between the actual chunk-size distribution of the real-world datasets after the Rabin-based CDC and the chunk-size distribution obtained by the mathematical analysis based on Equation 3, which indicates that the two are almost identical. According to Equation 3, the chunks smaller than 2KB and larger than 64KB would account for about 22.12% and 0.03% of the total number of chunks respectively. This means that imposing the maximum chunk size requirement only slightly hurts the deduplication ratio but skipping cut-points before chunking to avoid generating chunks smaller than the prescribed minimum chunk size, or called sub-minimum chunk cut-point skipping , will impact the deduplication ratio significantly as evidenced in <ref type="figure" target="#fig_1">Figure 3</ref>. This is because a significant portion of the chunks are not divided truly according to the data contents, but forced by this cut-point skipping.</p><p>Given FastCDC's goal of maximizing the chunking speed, enlarging the minimum chunk size and skipping sub-minimum chunk cut-point will help FastCDC achieve a higher CDC speed by avoiding the operations for the hash calculation and judgment in the skipped region. This gain in speed, however, comes at the cost of reduced deduplication ratio. To address this problem, we will develop a normalized chunking approach, to be introduced in the next subsection.</p><p>It is worth noting that this cut-point skipping approach, by avoiding generating chunks smaller than the minimum chunk size, also helps increase the average generated chunk size. In fact, the average generated chunk size exceeds the expected chunk size by an amount equal to the minimum chunk size. This is because the F(x) in Equation 3 is changed to (1 − e − x−M inSize 8192 ) after cut-point skipping, thus the value of the expected chunk size becomes 8KB + minimum chunk size, which will be verified in Section 5.3. The speedup achieved by skipping the sub-minimum chunk cut-point can be estimated by 1+ the minimum chunk size the expected chunk size . The increased chunking speed comes from the eliminated computation on the skipped region, which will also be verified in Section 5.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Normalized Chunking</head><p>In this subsection, we propose a novel chunking approach, called normalized chunking, to solve the problem of decreased deduplication ratio facing the cut-point skipping approach. As shown in <ref type="figure" target="#fig_4">Figure 8</ref>, normalized chunking generates chunks whose sizes are normalized to a specified region centered at the expected chunk size. After normalized chunking, there are almost no chunks of size smaller than the minimum chunk size, which means that normalized chunking enables skipping cutpoints for subminimum chunks to reduce the unnecessary chunking computation and thus speed up CDC. In our implementation of normalized chunking, we selectively change the number of effective mask bits (i.e., the number of '1' bits) for the hash-judging statement. For the traditional CDC approach with expected chunk size of 8KB (i.e., 2 13 ), 13 effective mask bits are used for hash judgment (e.g., fp &amp; 0x1fff==r). For normalized chunking, more than 13 effective mask bits are used for hash judgment (e.g., fp &amp; 0x7fff==r) when the current chunking position is smaller than 8KB, which makes it harder to generate chunks of size smaller than 8KB. On the other hand, fewer than 13 effective mask bits are used for hash judgment (e.g., fp &amp; 0x0fff==r) when the current chunking position is larger than 8KB, which makes it easier to generate chunks of size larger than 8KB. Therefore, by changing the number of '1' bits in FastCDC, the chunk-size distribution will be approximately normalized to a specified region always larger than the minimum chunk size, instead of following the exponential distribution (see <ref type="figure">Figure 7)</ref>.</p><p>Generally, there are three benefits or features of normalized chunking (NC):</p><p>• NC reduces the number of small-sized chunks, which makes it possible to combine it with the cutpoint skipping approach to achieve high chunking speed without sacrificing the deduplication ratio as suggested in <ref type="figure" target="#fig_4">Figure 8</ref>.</p><p>• NC further improves the deduplication ratio by reducing the number of large-sized chunks, which compensates for the reduced deduplication ratio caused by reducing the number of small-sized chunks in FastCDC. ply separates the hash judgment into two parts, before and after the expected chunk size. <ref type="figure" target="#fig_5">Figure 9</ref> shows the chunk-size distribution after normalized chunking in comparison with FastCDC without NC on the TAR dataset (whose workload characteristics are detailed in <ref type="table" target="#tab_2">Table 2</ref> in Section 5.1). The normalization levels 1, 2, 3 indicate that the normalized chunking uses the mask bits of <ref type="bibr" target="#b13">(14,</ref><ref type="bibr" target="#b11">12)</ref>, <ref type="bibr" target="#b14">(15,</ref><ref type="bibr" target="#b10">11)</ref>, <ref type="bibr" target="#b15">(16,</ref><ref type="bibr" target="#b9">10)</ref>, respectively, where the first and the second integers in the parentheses indicate the numbers of effective mask bits used in the hash judgment before and after the expected chunk size (or normalized chunk size) of 8KB . <ref type="figure" target="#fig_5">Figure 9</ref> suggests that the chunk-size distribution is a reasonably close approximation of the normal distribution centered on 8KB at the normalization level of 2 or 3.</p><p>As shown in <ref type="figure" target="#fig_5">Figure 9</ref>, there are only a very small number of chunks smaller than 2KB or 4KB after normalized chunking while FastCDC without NC has a large number of chunks smaller than 2KB or 4KB (consistent with the discussion in Section 4.3). Thus, when combining NC with the cut-point skipping to speed up the CDC process, only a very small portion of chunk cut-points will be skipped in FastCDC, leading to nearly the same deduplication ratio as the conventional CDC approaches without the minimum chunk size requirement. In addition, normalized chunking allows us to enlarge the minimum chunk size to maximize the chunking speed without sacrificing the deduplication ratio.</p><p>It is worth noting that the chunk-size distribution shown in <ref type="figure" target="#fig_5">Figure 9</ref> is not truly normal distribution but an approximation of it. <ref type="figure" target="#fig_5">Figures 9 (c) and (d)</ref> shows a closer approximation of normal distribution of chunk size achieved by using the normalization levels 2 and</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1: FastCDC8KB</head><p>Input: data buffer, src; buffer length, n Output: chunking breakpoint i MaskS ← 0x0003590703530000LL;</p><p>// 15 '1' bits MaskA ← 0x0000d90303530000LL; // 13 '1' bits MaskL ← 0x0000d90003530000LL;</p><p>// 11 '1' bits MinSize ← 2KB; MaxSize ← 64KB; fp ← 0; i ← MinSize; NormalSize ← 8KB; if n ≤ M inSize then return n;</p><p>if n ≥ MaxSize then n ← MaxSize; else if n ≤ NormalSize then NormalSize ← n; 3. Interestingly, the highest normalization level of NC would be equivalent to Fixed-Size Chunking (FSC), i.e., all the chunk sizes are normalized to be equal to the expected chunk size. Since FSC has a very low deduplication ratio but extremely high chunking speed, it means that there will be a "sweet spot" among the normalization level, deduplication ratio, and chunking speed, which will be studied and evaluated in Section 5.</p><formula xml:id="formula_5">for ; i &lt; N ormalSize; i++; do fp = (fp &lt;&lt; 1) + Gear[ src[i] ]; if ! ( fp &amp; MaskS ) then return i; //if</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Putting It All Together</head><p>To put things together and in perspective. Algorithm 1 describes FastCDC combining the three key techniques: optimizing hash judgment, cut-point skipping, and normalized chunking (with the expected chunk size of 8KB). The data structure "Gear" is a predefined array of 256 random 64-bit integers with one-to-one mapping to the values of byte contents for chunking <ref type="bibr" target="#b37">[38]</ref>. As shown in Algorithm 1, FastCDC uses normalized chunking to divide the chunking judgment into two loops with the optimized hash judgment. Note that FastCDC without normalized chunking is not shown here but can be easily implemented by using the new hash-judging statement "! fp &amp; MaskA" where the MaskA is padded with 35 zero bits to enlarge the sliding window size to 48 bytes as that used in the Rabin-based CDC <ref type="bibr" target="#b24">[25]</ref>. Note that MaskA, MaskS, and MaskL are three empirically derived values where the padded zero bits are almost evenly distributed for slightly higher deduplication ratio according to our large scale tests.   mask value MaskS and MaskL to make the chunking judgment harder or easier (to generate chunks smaller or larger than the expected chunk size) when the current position is smaller or larger than the expected chunk size, respectively. And the number of '1' bits in MaskS and MaskL can be changed for different normalization levels. The minimum chunk size used in Algorithm 1 is 2KB, which can be enlarged to 4KB or 8KB to further speed up the CDC process while combining with normalized chunking. Tuning the parameters of minimum chunk size and normalization level will be studied and evaluated in the next Section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Performance Evaluation 5.1 Experimental Setup</head><p>Experimental Platform. To evaluate FastCDC, we implement a prototype of the data deduplication system on the Ubuntu 12.04.2 operating system running on a quadcore Intel i7-4770 processor at 3.4GHz, with a 16GB RAM. To better evaluate the chunking speed, another quad-core Intel i7-930 processor at 2.8GHz is also used for comparison.</p><p>Configurations for CDC and deduplication. Three CDC approaches, Rabin-, Gear-, and AE-based CDC, are used as the baselines for evaluating FastCDC. Rabinbased CDC is implemented based on the open-source project LBFS <ref type="bibr" target="#b24">[25]</ref> (also used in many published studies <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b21">22]</ref> or project <ref type="bibr" target="#b5">[6]</ref>), where the sliding window size is configured to be 48 bytes. The Gear-and AE-based CDC schemes are implemented according to the algorithms described in their papers <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b39">40]</ref>, and we obtain performance results similar to and consistent with those reported in these papers. Here all the CDC approaches are configured with the maximum and minimum chunk sizes of 8× and 1 4 × of the expected chunk size, the same as configured in LBFS <ref type="bibr" target="#b24">[25]</ref>. The deduplication prototype consists of approximately 3000 lines of C code, which is compiled by GCC 4.7.3 with the "-O3" compiler option.  <ref type="table">Table 3</ref>: A comparison among the Rabin-based CDC (RC), Gear-based CDC (GC), and FastCDC (FC) approaches in terms of the deduplication ratio and the average size of generated chunks, as a function of the expected chunk size.</p><p>is measured by the in-memory processing speed of the evaluated CDC approaches and obtained by the average speed of five runs. Deduplication ratio is measured in terms of the percentage of duplicates detected after CDC, i.e., T he size of duplicate data detected T otal data size bef ore deduplication . Average chunk size is T otal data size N umber of chunks after CDC, which reflects the metadata overhead for deduplication indexing. Evaluated Datasets. Seven datasets with a total size of about 5 TB are used for evaluation as shown in <ref type="table" target="#tab_2">Table 2</ref>. These datasets consist of the various typical workloads of deduplication, including the source code files, virtual machine images, database snapshots, etc., whose deduplication ratios vary from 40% to 97%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">A Study of Optimizing Hash Judgment</head><p>This subsection discusses an empirical study of FastCDC using the optimized hash judgment. <ref type="figure" target="#fig_8">Figure 10</ref> shows the chunking speed of the five CDC approaches running on the RDB dataset, as a function of the expected chunk size and all using the minimum chunk size of 1 4 × of that for cut-point skipping. The Rabin-optimized approach employs the technique of simplifying the hash judgment proposed in Section 4.2 but only achieves a little acceleration, this is because the hashing stage is the main bottleneck for Rabin-based CDC. In general, the Rabin-based CDC has the lowest speed, and the AE-and Gear-based CDC are about 3× faster than Rabin. For the AE-based CDC, its chunking speed is similar to that of the Gearbased CDC when the expected chunk size ranges from 2∼16 KB but is much lower than that of Gear when the expected chunk size is smaller than 1 KB. FastCDC is about 5× faster than Rabin and 1.5× faster than Gear and AE regardless of the speed of the CPU processor and the expected chunk size. The high chunking speed of FastCDC stems from its simplification of the hash judgment after the fast Gear hash is used for chunking as described in Section 4.2. <ref type="table">Table 3</ref> shows the deduplication ratio and the average size of generated chunks (post-chunking) achieved by the three CDC approaches. We compare the Gear-based CDC (GC), and FastCDC (FC) approaches against the classic Rabin-based CDC (i.e., the baseline) and record the percentage differences (in parentheses). AE-based CDC has nearly the same deduplication ratio as Rabin, thus is not shown in this table due to space limit.</p><p>In general, FastCDC achieves nearly the same deduplication ratio as the Rabin-based CDC regardless of the expected chunk size and workload, and the difference between them is only about ±0.1∼1.4% as shown in the 3rd, 5th, 7th columns in <ref type="table">Table 3</ref>. On the other hand, the Gear-based CDC has a much lower deduplication ratio on the datasets TAR, WEB, and VMA due to its limited sliding window size as discussed in Section 3.</p><p>For the metric of the average size of generated chunks, the difference between the Rabin-based CDC and FastCDC is smaller than ±0.1% on most of the datasets. For the datasets TAR and WEB, FastCDC has 1∼7% larger average chunk size than Rabin-based CDC, which is acceptable since the larger average chunk size means fewer chunks and fingerprints for indexing in a deduplication system (without sacrificing deduplication ratio) <ref type="bibr" target="#b32">[33]</ref>. But for the Gear-based CDC, the average chunk size differs significantly in some datasets while its deduplication ratio is still a bit lower than other CDC approaches due to its smaller sliding window size.</p><p>In summary, FastCDC achieves a chunking speed that is 5× higher than the Rabin-based CDC while satisfactorily solving the problem of low deduplication ratio facing the Gear-based CDC, as shown in <ref type="figure" target="#fig_8">Figure 10</ref> and <ref type="table">Table 3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Evaluation of Cut-point Skipping</head><p>This subsection discusses the evaluation results of cutpoint skipping technique. <ref type="figure" target="#fig_9">Figures 11 (a)</ref> and (b) show the impact of applying different minimum chunk sizes on the chunking speed of FastCDC. Since the chunking speed is not so sensitive to the workloads, we only show the three typical workloads in <ref type="figure" target="#fig_9">Figure 11</ref>. In general, cut-point skipping greatly accelerates the CDC process since the skipped region will not be hash-processed by CDC. The speedup of the FastCDC applying the minimum chunk sizes of 4KB and 2KB over the FastCDC without the constraint of the minimum chunk size (i.e., Min-0KB) is about 1.25× and 1.50× respectively, which is consistent with the equation 1+ the minimum chunk size the expected chunk size as discussed in Section 4.3.</p><p>Figures 11 (c) and (d) show the impact of applying different minimum chunk sizes on the deduplication ratio and average generated chunk size of FastCDC. In general, deduplication ratio declines with the increase of the minimum chunk size applied in FastCDC, but not proportionally. For the metric of the average generated chunk size in FastCDC, it is approximately equal to the summation of the expected chunk size and the applied minimum chunk size. This means that the MIN-4KB solution has the average chunk size of 8+4=12 KB, leading to fewer chunks for fingerprints indexing in deduplication systems. Note that the increased portion of the average generated chunk size is not always equal to the size of the applied minimum chunk size, because the Rabin hashes of contents may not strictly follow the uniform distribution (as described in Equation 3 in Section 4.3) on some datasets. In summary, the results shown in <ref type="figure" target="#fig_9">Figure 11</ref> suggest that cut-point skipping helps obtain higher chunking speed and increase the average chunk size but at the cost of decreased deduplication ratio. The decreased deduplication ratio will be addressed by normalized chunking as evaluated in the next two subsections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Evaluation of Normalized Chunking</head><p>In this subsection, we conduct a sensitivity study of normalized chunking (NC) on the TAR dataset, as shown in <ref type="figure" target="#fig_0">Figure 12</ref>. Here the expected chunk size of FastCDC without NC is 8KB and the normalized chunk size of FastCDC with NC is configured as the 4KB + minimum chunk size. The normalization levels 1, 2, 3 refer to the three pairs of numbers of effective mask bits <ref type="bibr" target="#b13">(14,</ref><ref type="bibr" target="#b11">12)</ref>, <ref type="bibr" target="#b14">(15,</ref><ref type="bibr" target="#b10">11)</ref>, <ref type="bibr" target="#b15">(16,</ref><ref type="bibr" target="#b9">10)</ref> respectively that normalized chunking applies when the chunking position is smaller or larger than the normalized (or expected) chunk size, as discussed in Section 4. ing (NC) detects more duplicates when the minimum chunk size is about 4KB and 8KB but slightly reduces the average generated chunk size, in comparison with FastCDC without NC. This is because NC reduces the number of large-sized chunks as shown in <ref type="figure" target="#fig_5">Figure 9</ref> and discussed in Section 4.4. The results also suggest that NC touches the "sweet spot" of deduplication ratio at the normalization level of 2 when the minimum chunk size is 4KB or 8KB. This is because the very high normalization levels tend to have a similar chunk-size distribution to the Fixed-Size Chunking as shown in <ref type="figure" target="#fig_5">Figure 9</ref> in Section 4.4, which fails to address the boundary-shift problem and thus detects fewer duplicates. Figures 12 (c) and (d) suggest that NC, when combined with the approach of enlarging the minimum chunk size for cut-point skipping, greatly increases the chunking speed on the two tested processors. In addition, the average chunk sizes of datasets WEB and LNX are smaller than the minimum chunk size, which results from the many very small files whose sizes are much smaller than the minimum chunk size in the two datasets.</p><p>In general, considering the three metrics of chunking speed, average generated chunk size, and deduplication ratio as a whole, as shown in <ref type="figure" target="#fig_0">Figure 12</ref>, NC-2 with MinSize of 8KB maximizes the chunking speed without sacrificing the deduplication ratio. NC-2 with MinSize of 4KB achieves the highest deduplication ratio but with only a small acceleration of the chunking speed .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Comprehensive Evaluation of FastCDC</head><p>In this subsection, we comprehensively evaluate the performance of FastCDC with the combined capability of the three key techniques: optimizing hash judgment, cut-  <ref type="table">Table 4</ref>: Comparison of deduplication ratio achieved by the five chunking approaches. Note that "FC"and "FC-NC" refer to the full FastCDC without and with normalized chunking respectively, in this subsection. point skipping, and normalized chunking (using NC-2 as suggested by the last subsection). Four approaches are tested for evaluation: RC with Min2KB (or RC-MIN-2KB) is Rabin-based CDC used in LBFS <ref type="bibr" target="#b24">[25]</ref>; FC with Min2KB (or FC-MIN-2KB) uses the techniques of optimizing hash judgment and cut-point skipping with a minimum chunk size of 2KB; FC-NC with Min4KB and FC-NC with Min8KB refer to FastCDC using all the three techniques with a minimum chunk size of 4KB and 8KB, respectively. To better evaluate the deduplication ratio, Fixed-Size Chunking (XC) is also tested using the average chunk size of 10KB. Evaluation results in <ref type="table">Table 4</ref> suggest that FC with Min2KB achieves nearly the same deduplication ratio as Rabin-based approach. FC-NC with Min4KB achieves the highest deduplication ratio among the five approaches while Fixed-Size Chunking (XC) has the lowest deduplication ratio. Note that XC works well on the LNX, WEB, VMB datasets, because LNX and WEB datasets have many files smaller than the fixed-size chunk of 10KB (and thus the average generated chunk size also smaller than 10KB) and VMB has many structured backup data (and thus VMB is suitable for XC). <ref type="table" target="#tab_5">Table 5</ref> shows that RC and FC with Min2KB and XC generate similar average chunk size while FC-NC with Min4KB has a slightly small average chunk size. But the approach of FC-NC with Min8KB has a much smaller average chunk size, which means that it generates fewer chunks and thus less metadata for deduplication processing. Meanwhile, FC-NC with Min8KB still achieves a comparable deduplication ratio, slightly lower than RC as shown in <ref type="table">Table 4</ref>, while providing a much higher   chunking speed as discussed later. <ref type="figure" target="#fig_1">Figure 13</ref> suggests that FC-NC with Min8KB has the highest chunking speed, about 10× faster than the Rabin-based approach, about 2× faster than FC with Min2KB. This is because FC-NC with Min8KB is the final FastCDC using all the three techniques to speed up the CDC process. In addition, FC-NC with Min4KB is also a good CDC candidate since it has the highest deduplication ratio while also working well on the other two metrics of chunking speed and the average generated chunk size. Note that XC is not shown here because it has almost no computation overhead for chunking. <ref type="table" target="#tab_7">Table 6</ref> further studies the CPU overhead among the four CDC approaches. The CPU overhead is averaged on 1000 test runs by the Linux tool "Perf". The results suggest that FC-NC-MIN-8KB has the fewest instructions for CDC computation, the highest IPC (instructions per cycle), and thus the least CPU time overhead, i.e., CPU cycles. Generally, FastCDC greatly reduces the number of instructions for CDC computation by using the techniques of Gear-based hashing and optimizing hash judgment (i.e., "FC-MIN-2KB"), and then minimizes the number of computation instructions by enlarging the minimum chunk size for cut-point skipping and combining normalized chunking (i.e., "FC-NC-MIN-8KB"). In addition, FastCDC increases the IPC for the CDC computation by well pipelining the instructions of hashing and hash-judging tasks in up-to-date processors. Therefore, these results explain why FastCDC is about 10× faster than Rabin-based CDC is that the former not only reduces the number of instructions, but also increases the IPC for the CDC process.</p><p>In summary, as shown in <ref type="bibr">Tables 4, 5, 6 and Fig- ure 13, FastCDC (i.</ref>e., FC-NC-MIN-8KB) significantly speeds up the chunking process and achieves a comparable deduplication ratio while reducing the number of generated chunks by using a combination of the three key techniques proposed in Section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion and Future Work</head><p>In this paper, we propose FastCDC, a much faster CDC approach for data deduplication than the state-of-the-art CDC approaches while achieving a comparable deduplication ratio. The main idea behind FastCDC is the combined use of three key techniques, namely, optimizing the hash judgment for chunking, subminimum chunk cut-point skipping, and normalized chunking. Our experimental evaluation demonstrates that FastCDC obtains a chunking speed that is about 10× higher than that of the Rabin-based CDC and about 3× that of the Gear-and AE-based CDC while achieving nearly the same deduplication ratio as the Rabin-based CDC.</p><p>In our future work, we plan to incorporate FastCDC in some other deduplication systems that are sensitive to the CPU overhead of content-defined chunking, such as QuickSync <ref type="bibr" target="#b8">[9]</ref>, to further explore the potentials and benefits of FastCDC. We also plan to release the FastCDC source code to be shared with the deduplication and storage systems research community.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: A schematic diagram of the Gear hash.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Rabin-based CDC performance as a function of the minimum chunk size used for cut-points skipping before chunking. Here we use the average chunk size of 8KB, Intel i7-4770 processor, and the best open-source Rabin algorithm we have access to for the speed test.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: The three key techniques used in FastCDC and their corresponding benefits for high performance CDC.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: An example of the sliding window technique used in the Gear-based CDC. Here CDC consists of two stages: hashing and hash judgment. The size of the sliding window used for hash judgment is only 5 bytes because of the computation principles of the Gear hash.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: A conceptual diagram of the normalized chunking combined with the subminimum chunk cutpoint skipping. The dotted line shows a higher level of normalized chunking.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>•Figure 9 :</head><label>9</label><figDesc>Figure 9: Chunk-size distribution of FastCDC with normalized chunking (NC) at different normalization levels.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>the masked bits are all '0' for ; i &lt; n; i++; do fp = (fp &lt;&lt; 1) + Gear[ src[i] ]; if ! ( fp &amp; MaskL ) then return i; //if the masked bits are all '0' return i;</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>FastCDC</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 10 :</head><label>10</label><figDesc>Figure 10: Chunking speed, as a function of the expected chunk size, of Rabin-, Rabin (optimized)-Gear-, and AE-based CDC, and FastCDC on two CPU processors.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 11 :</head><label>11</label><figDesc>Figure 11: Chunking performance of FastCDC with the expected chunk size of 8KB but different minimum chunk sizes on two different CPU processors.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>4 .</head><label>4</label><figDesc>Figure 12: Evaluation of comprehensive performance of normalized chunking with different normalization levels.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 13 :</head><label>13</label><figDesc>Figure 13: Chunking speed of the four CDC approaches.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>implements normalized chunking by using Name Size Workload descriptions TAR 19 GB 85 tarred files from the open source projects such as GCC, GDB, Emacs, etc. LNX 105 GB 260 versions of Linux source code files. WEB 36 GB 15 days' snapshots of the website: news.sina.com, which are collected by crawling software wget with a maximum retrieval depth of 3.</head><label></label><figDesc></figDesc><table>VMA 117 GB 
75 virtual machine images of different OS release 
versions, including CentOS, Fedora, Debian, etc. 

VMB 1.9 TB 
125 backups of an Ubuntu 12.04 virtual machine 
image in use by a research group. 
RDB 1.1 TB 200 backups of the redis key-value store database. 

SYN 1.4 TB 
200 synthetic backups. The backup is simulated 
by the file create/delete/modify operations [31]. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc>Workload characteristics of the seven datasets used in the performance evaluation.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 5 :</head><label>5</label><figDesc>Average chunk size generated by the five chunk- ing approaches on the seven datasets.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table>Number of instructions, instructions per cycle 
(IPC), and CPU cycles required to chunk 1MB data by 
the four CDC approaches on the Intel i7-4770 processor. 

</table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We are grateful to our shepherd Scott Rixner and the anonymous reviewers for their insightful comments and feedback. </p></div>
			</div>

			<div type="annex">
			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">EndRE: an end-system redundancy elimination service for enterprises</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aggarwal</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Akella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Anand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">T</forename><surname>Al</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th USENIX conference on Networked Systems Design and Implementation (NSDI&apos;10)</title>
		<meeting>the 7th USENIX conference on Networked Systems Design and Implementation (NSDI&apos;10)<address><addrLine>San Jose, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-04" />
			<biblScope unit="page" from="14" to="28" />
		</imprint>
	</monogr>
	<note>USENIX Association</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">StoreGPU: exploiting graphics processing units to accelerate distributed storage systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Al-Kiswany</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gharaibeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Santos-Neto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">T</forename><surname>Al</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th international symposium on High Performance Distributed Computing (HPDC&apos;08)</title>
		<meeting>the 17th international symposium on High Performance Distributed Computing (HPDC&apos;08)<address><addrLine>Boston, MA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Association</publisher>
			<date type="published" when="2008-06" />
			<biblScope unit="page" from="165" to="174" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Redundancy in network traffic: findings and implications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anand</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Muthukrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Akella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramjee</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th international Joint Conference on Measurement and Modeling of Computer Systems (SIGMETRICS-Performance</title>
		<meeting>the 11th international Joint Conference on Measurement and Modeling of Computer Systems (SIGMETRICS-Performance<address><addrLine>WA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Association</publisher>
			<date type="published" when="2009-06" />
			<biblScope unit="page" from="37" to="48" />
		</imprint>
	</monogr>
	<note>Seattle</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Providing high reliability in a minimum redundancy archival storage system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bhagwat</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Pollack</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">D</forename><surname>Schwarz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">L</forename><surname>And P ˆ Aris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-F</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 14th IEEE International Symposium on Modeling, Analysis, and Simulation of Computer and Telecommunication Systems (MAS-COTS&apos;06)</title>
		<meeting>The 14th IEEE International Symposium on Modeling, Analysis, and Simulation of Computer and Telecommunication Systems (MAS-COTS&apos;06)<address><addrLine>Monterey, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="2006-09" />
			<biblScope unit="page" from="413" to="421" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Shredder: GPU-accelerated incremental storage and computation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bhatotia</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rodrigues</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Verma</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th USENIX Conference on File and Storage Technologies (FAST&apos;12)</title>
		<meeting>the 10th USENIX Conference on File and Storage Technologies (FAST&apos;12)<address><addrLine>San Jose, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-02" />
			<biblScope unit="page" from="1" to="15" />
		</imprint>
	</monogr>
	<note>USENIX Association</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The parsec benchmark suite: Characterization and architectural implications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bienia</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">I</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th international conference on Parallel architectures and compilation techniques (PACT&apos;08)</title>
		<meeting>the 17th international conference on Parallel architectures and compilation techniques (PACT&apos;08)<address><addrLine>Toronto, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008-10" />
			<biblScope unit="page" from="72" to="81" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Content-dependent chunking for differential compression, the local maximum approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bjørner</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Blass</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gurevich</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computer and System Sciences</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="154" to="203" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Some applications of Rabin&apos;s fingerprinting method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Broder</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Sequences II: Methods in Communications, Security, and Computer Science</title>
		<imprint>
			<date type="published" when="1993" />
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">QuickSync: Improving Synchronization Efficiency for Mobile Cloud Storage Services</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cui</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miao</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st Annual International Conference on Mobile Computing and Networking</title>
		<meeting>the 21st Annual International Conference on Mobile Computing and Networking<address><addrLine>Paris, France</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015-09" />
			<biblScope unit="page" from="592" to="603" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">ChunkStash: speeding up inline storage deduplication using flash memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Debnath</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sengupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">I</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 USENIX conference on USENIX annual technical conference (USENIX&apos;10)</title>
		<meeting>the 2010 USENIX conference on USENIX annual technical conference (USENIX&apos;10)<address><addrLine>Boston, MA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-06" />
			<biblScope unit="page" from="1" to="14" />
		</imprint>
	</monogr>
	<note>USENIX Association</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Methods and systems for data management using multiple selection criteria</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dubnicki</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kruus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Lichota</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Un-Gureanu</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename></persName>
		</author>
		<idno>App. 11/566</idno>
		<imprint>
			<date type="published" when="2006-01" />
			<biblScope unit="page">122</biblScope>
		</imprint>
	</monogr>
<note type="report_type">US Patent</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Primary data deduplication-large scale study and system design</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">El-Shimi</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kalach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">T</forename><surname>Al</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 conference on USENIX Annual Technical Conference (USENIX&apos;12)</title>
		<meeting>the 2012 conference on USENIX Annual Technical Conference (USENIX&apos;12)<address><addrLine>Boston, MA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-06" />
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
	<note>USENIX Association</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">A framework for analyzing and improving content-based chunking algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eshghi</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>And Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">K</forename></persName>
		</author>
		<idno>HPL-2005-30(R.1</idno>
		<imprint>
			<date type="published" when="2005" />
			<pubPlace>Palo Alto</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Hewlett Packard Laboratories</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Tech. Rep.</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Design tradeoffs for data deduplication performance in backup workloads</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">U</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tan</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th USENIX Conference on File and Storage Technologies (FAST&apos;15)</title>
		<meeting>the 13th USENIX Conference on File and Storage Technologies (FAST&apos;15)<address><addrLine>Santa Clara, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-02" />
			<biblScope unit="page" from="331" to="344" />
		</imprint>
	</monogr>
	<note>USENIX Association</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A GPU accelerated storage system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gharaibeh</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Al-Kiswany</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gopalakrish-Nan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">T</forename><surname>Al</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th ACM International Symposium on High Performance Distributed Computing (HPDC&apos;10)</title>
		<meeting>the 19th ACM International Symposium on High Performance Distributed Computing (HPDC&apos;10)<address><addrLine>Chicago, Illinois, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Association</publisher>
			<date type="published" when="2010-06" />
			<biblScope unit="page" from="167" to="178" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Building a highperformance deduplication system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guo</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Efstathopoulos</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2011 USENIX conference on USENIX Annual Technical Conference (USENIX&apos;11)</title>
		<meeting>the 2011 USENIX conference on USENIX Annual Technical Conference (USENIX&apos;11)<address><addrLine>Portland, OR, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-06" />
			<biblScope unit="page" from="1" to="14" />
		</imprint>
	</monogr>
	<note>USENIX Association</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Bimodal content defined chunking for backup streams</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kruus</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ungureanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dubnicki</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th USENIX Conference on File and Storage Technologies (FAST&apos;10)</title>
		<meeting>the 7th USENIX Conference on File and Storage Technologies (FAST&apos;10)<address><addrLine>San Jose, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-02" />
			<biblScope unit="page" from="1" to="14" />
		</imprint>
	</monogr>
	<note>USENIX Association</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Improving restore speed for backup systems that use inline chunk-based deduplication</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lillibridge</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Eshghi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bhagwat</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th USENIX Conference on File and Storage Technologies (FAST&apos;13)</title>
		<meeting>the 11th USENIX Conference on File and Storage Technologies (FAST&apos;13)<address><addrLine>San Jose, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-02" />
			<biblScope unit="page" from="183" to="197" />
		</imprint>
	</monogr>
	<note>USENIX Association</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Sparse indexing: Large scale, inline deduplication using sampling and locality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lillibridge</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Eshghi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bhagwat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">T</forename><surname>Al</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th USENIX Conference on File and Storage Technologies (FAST&apos;09)</title>
		<meeting>the 7th USENIX Conference on File and Storage Technologies (FAST&apos;09)<address><addrLine>San Jose, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009-02" />
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="111" to="123" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Parallel processing of input data to locate landmarks for chunks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lillibridge</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">US Patent</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">273</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Frequency based chunking for data de-duplication</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">U</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jin</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">U</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 2010 IEEE International Symposium on Modeling, Analysis &amp; Simulation of Computer and Telecommunication Systems (MASCOTS&apos;10)</title>
		<meeting>2010 IEEE International Symposium on Modeling, Analysis &amp; Simulation of Computer and Telecommunication Systems (MASCOTS&apos;10)<address><addrLine>Miami Beach, FL, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="2010-08" />
			<biblScope unit="page" from="287" to="296" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A study on data deduplication in HPC storage systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meister</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Brinkmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">T</forename><surname>Al</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on High Performance Computing, Networking, Storage and Analysis (SC&apos;02)</title>
		<meeting>the International Conference on High Performance Computing, Networking, Storage and Analysis (SC&apos;02)<address><addrLine>Salt Lake City, Utah, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="2012-06" />
			<biblScope unit="page" from="1" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A study of practical deduplication</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meyer</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bolosky</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the USENIX Conference on File and Storage Technologies (FAST&apos;11)</title>
		<meeting>the USENIX Conference on File and Storage Technologies (FAST&apos;11)<address><addrLine>San Jose, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-02" />
			<biblScope unit="page" from="229" to="241" />
		</imprint>
	</monogr>
	<note>USENIX Association</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Efficient deduplication techniques for modern backup operation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Won</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computers</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="page" from="824" to="840" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A low-bandwidth network file system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muthitacharoen</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mazieres</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Symposium on Operating Systems Principles (SOSP&apos;01)</title>
		<meeting>the ACM Symposium on Operating Systems Principles (SOSP&apos;01)<address><addrLine>Banff, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Association</publisher>
			<date type="published" when="2001-10" />
			<biblScope unit="page" from="1" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Alternatives for detecting redundancy in storage systems data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Policroniades</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pratt</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of USENIX Annual Technical Conference</title>
		<meeting>USENIX Annual Technical Conference<address><addrLine>Boston, MA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-06" />
			<biblScope unit="page" from="73" to="86" />
		</imprint>
	</monogr>
	<note>USENIX Association</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Venti: a new approach to archival storage</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quinlan</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dorward</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of USENIX Conference on File and Storage Technologies (FAST&apos;02)</title>
		<meeting>USENIX Conference on File and Storage Technologies (FAST&apos;02)<address><addrLine>Monterey, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002-01" />
			<biblScope unit="page" from="1" to="13" />
		</imprint>
	</monogr>
	<note>USENIX Association</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Fingerprinting by random polynomials</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rabin</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">O</forename></persName>
		</author>
		<imprint>
			<date type="published" when="1981" />
		</imprint>
		<respStmt>
			<orgName>Center for Research in Computing Techn., Aiken Computation Laboratory, Univ.</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Anchor-driven subchunk deduplication</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Roma´nskiroma´ Roma´nski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ł</forename><surname>Heldt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Kilian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lichota</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dubnicki</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 4th Annual International Systems and Storage Conference (SYSTOR&apos;11)</title>
		<meeting>The 4th Annual International Systems and Storage Conference (SYSTOR&apos;11)<address><addrLine>Haifa, Israel</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Association</publisher>
			<date type="published" when="2011-05" />
			<biblScope unit="page" from="1" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">WAN optimized replication of backup datasets using stream-informed delta compression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shilane</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wallace</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">T</forename><surname>Al</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth USENIX Conference on File and Storage Technologies (FAST&apos;12)</title>
		<meeting>the Tenth USENIX Conference on File and Storage Technologies (FAST&apos;12)<address><addrLine>San Jose, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-02" />
			<biblScope unit="page" from="1" to="14" />
		</imprint>
	</monogr>
	<note>USENIX Association</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Generating realistic datasets for deduplication analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tarasov</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Mudrankit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Buik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Shilane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kuenning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zadok</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 USENIX conference on Annual Technical Conference (USENIX&apos;12)</title>
		<meeting>the 2012 USENIX conference on Annual Technical Conference (USENIX&apos;12)<address><addrLine>Boston, MA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-06" />
			<biblScope unit="page" from="24" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Optimizing file replication over limited bandwidth networks using remote differential compression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Teodosiu</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bjorner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Gurevich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Man-Asse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Porkka</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
		<idno>TR-2006-157</idno>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
<note type="report_type">Microsoft Research</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Characteristics of backup workloads in production systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wallace</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Douglis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">T</forename><surname>Al</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth USENIX Conference on File and Storage Technologies (FAST&apos;12)</title>
		<meeting>the Tenth USENIX Conference on File and Storage Technologies (FAST&apos;12)<address><addrLine>San Jose, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-02" />
			<biblScope unit="page" from="1" to="14" />
		</imprint>
	</monogr>
	<note>USENIX Association</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Silo: a similarity-locality based near-exact deduplication scheme with low ram overhead and high throughput</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xia</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hua</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2011 USENIX conference on USENIX annual technical conference (USENIX&apos;11)</title>
		<meeting>the 2011 USENIX conference on USENIX annual technical conference (USENIX&apos;11)<address><addrLine>Portland, OR, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-06" />
			<biblScope unit="page" from="285" to="298" />
		</imprint>
	</monogr>
	<note>USENIX Association</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Similarity and locality based indexing for high performance data deduplication</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xia</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hua</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computers</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="page" from="1162" to="1176" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Accelerating data deduplication by exploiting pipelining and parallelism with multicore or manycore processors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xia</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tian</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th USENIX Conference on File and Storage Technologies (FAST&apos;12 Poster)</title>
		<meeting>the 10th USENIX Conference on File and Storage Technologies (FAST&apos;12 Poster)<address><addrLine>San Jose, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-02" />
			<biblScope unit="page" from="1" to="2" />
		</imprint>
	</monogr>
	<note>USENIX Association</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Exploiting parallelism in data deduplication system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xia</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>P-Dedupe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th International Conference onNetworking, Architecture and Storage (NAS&apos;12)</title>
		<meeting>the 7th International Conference onNetworking, Architecture and Storage (NAS&apos;12)<address><addrLine>Xiamen, China</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="2012-06" />
			<biblScope unit="page" from="338" to="347" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Ddelta: A deduplication-inspired fast delta compression approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xia</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhou</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Performance Evaluation</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="page" from="258" to="272" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Leap-based content defined chunking-theory and implementation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">U</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">I</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31th Symposium on Mass Storage Systems and Technologies (MSST&apos;15)</title>
		<meeting>the 31th Symposium on Mass Storage Systems and Technologies (MSST&apos;15)<address><addrLine>Santa Clara, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015-06" />
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">AE: An asymmetric extremum content defined chunking algorithm for fast and bandwidth-efficient data deduplication</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhou</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE INFOCOM 2015 (Hongkong</title>
		<meeting>IEEE INFOCOM 2015 (Hongkong</meeting>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="2015-04" />
			<biblScope unit="page" from="1337" to="1345" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">SecDep: A User-Aware Efficient Fine-Grained Secure Deduplication Scheme with MultiLevel Key Management</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhou</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">I</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE 31th Symposium on Mass Storage Systems and Technologies (MSST&apos;15)</title>
		<meeting>IEEE 31th Symposium on Mass Storage Systems and Technologies (MSST&apos;15)<address><addrLine>Santa Clara, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015-06" />
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Avoiding the disk bottleneck in the Data Domain Deduplication File System</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhu</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patterson</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">H</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th USENIX Conference on File and Storage Technologies (FAST&apos;08)</title>
		<meeting>the 6th USENIX Conference on File and Storage Technologies (FAST&apos;08)<address><addrLine>San Jose, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2008-02" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="1" to="14" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
