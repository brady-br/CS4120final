<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2020-09-29T02:38+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">This paper is included in the Proceedings of the 14th USENIX Conference on File and Storage Technologies (FAST &apos;16). Open access to the Proceedings of the 14th USENIX Conference on File and Storage Technologies is sponsored by USENIX Towards Accurate and Fast Evaluation of Multi-Stage Log-structured Designs Towards Accurate and Fast Evaluation of Multi-Stage Log-Structured Designs</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>February 22-25, 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyeontaek</forename><surname>Lim</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">G</forename><surname>Andersen</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Kaminsky</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyeontaek</forename><surname>Lim</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">G</forename><surname>Andersen</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Kaminsky</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">Intel Labs</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<settlement>Santa Clara</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Intel Labs</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">This paper is included in the Proceedings of the 14th USENIX Conference on File and Storage Technologies (FAST &apos;16). Open access to the Proceedings of the 14th USENIX Conference on File and Storage Technologies is sponsored by USENIX Towards Accurate and Fast Evaluation of Multi-Stage Log-structured Designs Towards Accurate and Fast Evaluation of Multi-Stage Log-Structured Designs</title>
					</analytic>
					<monogr>
						<title level="m">USENIX Association 14th USENIX Conference on File and Storage Technologies (FAST &apos;16)</title>
						<imprint>
							<biblScope unit="page">149</biblScope>
							<date type="published">February 22-25, 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Multi-stage log-structured (MSLS) designs, such as Lev-elDB, RocksDB, HBase, and Cassandra, are a family of storage system designs that exploit the high sequential write speeds of hard disks and flash drives by using multiple append-only data structures. As a first step towards accurate and fast evaluation of MSLS, we propose new analytic primitives and MSLS design models that quickly give accurate performance estimates. Our model can almost perfectly estimate the cost of inserts in LevelDB, whereas the conventional worst-case analysis gives 1.8-3.5X higher estimates than the actual cost. A few minutes of offline analysis using our model can find optimized system parameters that decrease LevelDB&apos;s insert cost by up to 9.4-26.2%; our analytic primitives and model also suggest changes to RocksDB that reduce its insert cost by up to 32.0%, without reducing query performance or requiring extra memory.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Log-structured store designs provide fast write and easy crash recovery for block-based storage devices that have considerably higher sequential write speed than random write speed <ref type="bibr" target="#b36">[37]</ref>. In particular, multi-stage versions of log-structured designs, such as LSM-tree <ref type="bibr" target="#b35">[36]</ref>, COLA <ref type="bibr" target="#b1">[2]</ref>, and SAMT <ref type="bibr" target="#b41">[42]</ref>, strive to balance read speed, write speed, and storage space use by segregating fresh and old data in multiple append-only data structures. These designs have been widely adopted in modern datastores including <ref type="bibr">LevelDB [19]</ref>, RocksDB <ref type="bibr" target="#b11">[12]</ref>, Bigtable <ref type="bibr" target="#b7">[8]</ref>, HBase <ref type="bibr" target="#b44">[45]</ref>, and Cassandra <ref type="bibr" target="#b25">[27]</ref>.</p><p>Given the variety of multi-stage log-structured (MSLS) designs, a system designer is faced with a problem of plenty, raising questions such as: Which design is best for this workload? How should the systems' parameters be set? How sensitive is that choice to changes in workload? Our goal in this paper is to move toward answering these questions and more through an improved-both in quality and in speed-analytical method for understanding and comparing the performance of these systems. This analytical approach can help shed light on how different design choices affect the performance of today's systems, and it provides an opportunity to optimize (based on the analysis) parameter choices given a workload. For example, in Section 6, we show that a few minutes of offline analysis can find improved parameters for LevelDB that decrease the cost of inserts by up to 9.4-26.2%. As another example, in Section 7, we reduce the insert cost in RocksDB by up to 32.0% by changing its system design based upon what we have learned from our analytic approach.</p><p>Prior evaluations of MSLS designs largely reside at the two ends of the spectrum: (1) asymptotic analysis and (2) experimental measurement. Asymptotic analysis of an MSLS design typically gives a big-O term describing the cost of an operation type (e.g., query, insert), but previous asymptotic analyses do not reflect real-world performance because they assume the worst case. Experimental measurement of an implementation produces accurate performance numbers, which are often limited to a particular implementation and workload, with lengthy experiment time to explore various system configurations.</p><p>This paper proposes a new evaluation method for MSLS designs that provides accurate and fast evaluation without needing to run the full implementations. Our approach uses new analytic primitives that help model the dynamics of MSLS designs. We build upon this model by combining it with a nonlinear solver to help automatically optimize system parameters to maximize performance. This paper makes four key contributions: • New analytic primitives to model creating the log structure and merging logs with redundant data ( §3); • System models for LevelDB and RocksDB, representative MSLS designs, using the primitives ( §4, §5); • Optimization of system parameters with the LevelDB model, improving real system performance ( §6); and • Application of lessons from the LevelDB model to the RocksDB system to reduce its write cost ( §7). Section 2 describes representative MSLS designs and common evaluation metrics for MSLS designs. Section 8 broadens the applications of our analytic primitives. Section 9 discusses the implications and limitations of our method. Appendix A provides proofs. Appendices B and C include additional system models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head><p>This section introduces a family of multi-stage logstructured designs and their practical variants, and explains metrics commonly used to evaluate these designs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Multi-Stage Log-Structured Designs</head><p>A multi-stage log-structured (MSLS) design is a storage system design that contains multiple append-only data structures, each of which is created by sequential writes; for instance, several designs use sorted arrays and tables that are often called SSTables <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b41">42]</ref>. These data structures are organized as stages, either logically or physically, to segregate different classes of data-e.g., fresh data and old data, frequently modified data and static data, small items and large items, and so forth. Components in LSM-tree <ref type="bibr" target="#b35">[36]</ref> and levels in many designs <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b41">42]</ref> are examples of stages.</p><p>MSLS designs exploit the fast sequential write speed of modern storage devices. On hard disk and flash drives, sequential writes are up to an order of magnitude faster than random writes. By restricting most write operations to incur only sequential I/O, MSLS can provide fast writes.</p><p>Using multiple stages reduces the I/O cost for data updates. Frequent changes are often contained within a few stages that either reside in memory and/or are cheap to rewrite-this approach shares the same insight as the generational garbage collection used for memory management <ref type="bibr" target="#b23">[25,</ref><ref type="bibr" target="#b26">28]</ref>. The downside is that the system may have to search in multiple stages to find a single item because the item can exist in any of these stages. This can potentially reduce query performance.</p><p>The system moves data between stages based upon certain criteria. Common conditions are the byte size of the data stored in a stage, the age of the stored data, etc. This data migration typically reduces the total data volume by merging multiple data structures and reducing the redundancy between them; therefore, it is referred to as "compaction" or "merge."</p><p>MSLS designs are mainly classified by how they organize log structures and how and when they perform compaction. The data structures and compaction strategy significantly affect the cost of various operations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1">Log-Structured Merge-Tree</head><p>The log-structured merge-tree (LSM-tree) <ref type="bibr" target="#b35">[36]</ref> is a writeoptimized store design with two or more components, each of which is a tree-like data structure <ref type="bibr" target="#b34">[35]</ref>. One component (C 0 ) resides in memory; the remaining components (C 1 ,C 2 ,.. .) are stored on disk. Each component can hold a set of items, and multiple components can contain multiple items of the same key. A lower-numbered component always stores a newer version of the item than any higher-numbered component does.</p><p>For query processing, LSM-tree searches in potentially multiple components. It starts from C 0 and stops as soon as the desired item is found.</p><p>Handling inserts involves updating the in-memory component and merging data between components. A new entry is inserted into C 0 (and is also logged to disk for crash recovery), and the new item is migrated over time from C 0 to C 1 , from C 1 to C 2 , and so on. Frequent updates of the same item are coalesced in C 0 without spilling them to the disk; cold data, in contrast, remains in C 1 and later components which reside on low-cost disk. The data merge in LSM-tree is mostly a sequential I/O operation. The data from C l is read and merged into C l+1 , using a "rolling merge" that creates and updates nodes in the C l+1 tree incrementally in the key space.</p><p>The authors of LSM-tree suggested maintaining component sizes to follow a geometric progression. The size of a component is r times larger than the previous component size, where r is commonly referred to as a "growth factor," typically between 10 and 20. With such size selection, the expected I/O cost per insert by the data migration is O((r + 1) log r N), where N is the size of the largest component, i.e., the total number of unique keys. The worst-case lookup incurs O(log r N) random I/O by accessing all components, if finding an item in a component costs O(1) random I/O.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2">LevelDB</head><p>LevelDB <ref type="bibr" target="#b18">[19]</ref> is a well-known variant of LSM-tree. It uses an in-memory table called a memtable, on-disk log files, and on-disk SSTables. The memtable plays the same role as C 0 of LSM-tree, and write-ahead logging is used for recovery. LevelDB organizes multiple levels that correspond to the components of LSM-tree; however, as shown in <ref type="figure">Figure 1</ref>, LevelDB uses a set of SSTables instead of a single tree-like structure for each level, and LevelDB's first level (level-0) can contain duplicate items across multiple SSTables.</p><p>Handing data updates in LevelDB is mostly similar to LSM-tree with a few important differences. Newly inserted data is stored in the memtable and appended to a log file. When the log size exceeds a threshold (e.g., 4 MiB 1 ), the content of the memtable is converted into an SSTable and inserted to level-0. When the table count in level-0 reaches a threshold (e.g., 4), LevelDB begins to migrate the data of level-0 SSTables into level-1. For level-1 and later levels, when the aggregate byte size of SSTables in a level reaches a certain threshold, LevelDB picks an SSTable from that level and merges it into the next level. <ref type="figure">Figure 2</ref> shows the compaction process; it takes all next-level SSTables whose key range overlaps with the SSTable being compacted, replacing the next-level SSTables with new SSTables containing merged items. The SSTables created by compaction follow several invariants. A new SSTable has a size limit (e.g., 2 MiB), which makes the compaction process incremental. An SSTable cannot have more than a certain amount of overlapping data (e.g., 20 MiB) in the next level, which limits the future cost of compacting the SSTable.</p><p>LevelDB compacts SSTables in a circular way within the key space for each level. Fine-grained SSTables and round-robin SSTable selection have interesting implications in characterizing LevelDB's write cost.</p><p>There are several variants of LevelDB. A popular version is RocksDB <ref type="bibr" target="#b11">[12]</ref>, which claims to improve write performance with better support for multithreading. Unlike LevelDB, RocksDB picks the largest SSTable available for concurrent compaction. We discuss the impact of this strategy in Section 7. RocksDB also supports "universal compaction," an alternative compaction strategy that trades read performance for faster writes.</p><p>We choose to apply our analytic primitives and modeling techniques to LevelDB in Section 4 because it creates interesting and nontrivial issues related to its use of SSTables and incremental compaction. We show how we can analyze complex compaction strategies such as RocksDB's universal compaction in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Common Evaluation Metrics</head><p>This paper focuses on analytic metrics (e.g., per-insert cost factors) more than on experimental metrics (e.g., insert throughput represented in MB/s or kOPS).</p><p>Queries and inserts are two common operation types. A query asks for one or more data items, which can also return "not found." An insert stores new data or updates existing item data. While it is hard to define a cost metric for every type of query and insert operation, prior studies extensively used two metrics defined for the amortized I/O cost per processed item: read amplification and write amplification.</p><p>Read amplification (RA) is the expected number of random read I/O operations to serve a query, assuming <ref type="bibr">1</ref> Mi denotes 2 20 . k, M, and G denote 10 3 , 10 6 , and 10 9 , respectively. that the total data size is much larger than the system memory size, which translates to the expected I/O overhead of query processing <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b27">29]</ref>. RA is based on the fact that random I/O access on disk and flash is a critical resource for query performance.</p><p>Write amplification (WA) is the expected amount of data written to disk or flash per insert, which measures the I/O overhead of insert processing. Its concept originates from a metric to measure the efficiency of the flash translation layer (FTL), which stores blocks in a log structurelike manner; WA has been adopted later in key-value store studies to project insert throughput and estimate the life expectancy of underlying flash drives <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b27">29,</ref><ref type="bibr" target="#b28">30,</ref><ref type="bibr" target="#b42">43]</ref>.</p><p>WA and insert throughput are inversely related. <ref type="figure" target="#fig_1">Fig- ure 3</ref> shows LevelDB's insert throughput for 1 kB items on a fast flash drive. <ref type="bibr" target="#b1">2</ref> We vary the total data volume from 1 GB to 10 GB and examine two distributions for the key popularity, uniform and Zipf. Each configuration is run 3 times. Workloads that produce higher WA (e.g., larger data volume and/or uniform workloads) have lower throughput.</p><p>In this paper, our main focus is WA. Unlike RA, whose effect on actual system performance can be reduced by dedicating more memory for caching, the effect of WA cannot be mitigated easily without changing the core system design because the written data must be eventually flushed to disk/flash to ensure durability. For the same reason, we do not to use an extended definition of WA that includes the expected amount of data read from disk per insert. We discuss how to estimate RA in Section 8.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Analytic Primitives</head><p>Our goal in later sections is to create simple but accurate models of the write amplification of different MSLS designs. To reach this goal, we first present three new analytic primitives, Unique, Unique −1 , and Merge, that form the basis for those models. In Sections 4 and 5, we show how to express the insert and growth behavior of LevelDB and RocksDB using these primitives.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Roles of Redundancy</head><p>Redundancy has an important effect on the behavior of an MSLS design. Any given table store (SSTable, etc.) contains at most one entry for a single key, no matter how many inserts were applied for that key. Similarly, when compaction merges tables, the resulting table will also contain only a single copy of the key, no matter how many times it appeared in the tables that were merged. Accurate models must thus consider redundancy.</p><p>Asymptotic analyses in prior studies ignore redundancy. Most analyses assume that compactions observe no duplicate keys from insert requests and input tables being merged <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b18">19]</ref>. The asymptotic analyses therefore give the same answer regardless of skew in the key popularity; it ignores whether all keys are equally popular or some keys are more popular than others. It also estimates only an upper bound on the compaction cost-duplicate keys mean that less total data is written, lowering real-world write amplification.</p><p>We first clarify our assumptions and then explain how we quantify the effect of redundancy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Notation and Assumptions</head><p>Let K be the key space. Without loss of generality, K is the set of all integers in [0, N − 1], where N is the total number of unique keys that the workload uses.</p><p>A discrete random variable X maps an insert request to the key referred to by the request. f X is the probability mass function for X, i.e., f X (k) for k ∈ K is the probability of having a specific key k for each insert request, assuming the keys in the requests are independent and identically distributed (i.i.d.) and have no spatial locality in popularity. As an example, a Zipf key popularity is defined as f X (h(i)) = (1/i s )/(∑ N n=1 1/n s ), where s is the skew and h maps the rank of each key to the key. <ref type="bibr" target="#b2">3</ref> Since there is no restriction on how f X should look, it can be built from a key popularity distribution inferred by an empirical workload characterization <ref type="bibr">[1,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b48">49]</ref>.</p><p>Without loss of generality, 0 &lt; f X (k) &lt; 1. We can remove any key k satisfying f X (k) = 0 from K because k will never appear in the workload. Similarly, f X (k) = 1 degenerates to a workload with exactly one key, which is trivial to analyze.</p><p>A table is a set of the items that contains no duplicate keys. Tables are constructed from a sequence of insert requests or merges of other tables.</p><p>L refers to the total number of standard levels in an MSLS design. Standard levels include only the levels that follow the invariants of the design; for example, the level-0 in LevelDB does not count towards L because level-0 <ref type="bibr" target="#b2">3</ref> Note that s = 0 leads to a uniform key popularity, i.e., f X (k) = 1/N. We use s = 0.99 frequently to describe a "skewed" or simply "Zipf" distribution for the key popularity, which is the default skew in YCSB <ref type="bibr" target="#b10">[11]</ref>. contains overlapping tables, while other levels do not, and has a different compaction trigger that is based on the table count in the level, not the aggregate size of tables in a level. L is closely related to read amplification; an MSLS design may require L random I/Os to retrieve an item that exists only in the last level (unless the design uses additional data structures such as Bloom filters <ref type="bibr" target="#b4">[5]</ref>).</p><p>To avoid complicating the analysis, we assume that all items have equal size (e.g., 1000 bytes). This assumption is consistent with YCSB <ref type="bibr" target="#b10">[11]</ref>, a widely-used key-value store benchmark. We relax this assumption in Section 8.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Counting Unique Keys</head><p>A sequence of insert requests may contain duplicate keys. The requests with duplicate keys overwrite or modify the stored values. When storing the effect of the requests in a table, only the final (combined) results survive. Thus, a table can be seen as a set of distinct keys in the requests.</p><p>We first formulate Unique, a function describing the expected number of unique keys that appear in p requests:</p><formula xml:id="formula_0">Definition 1. Unique(p) := N − ∑ k∈K (1 − f X (k)) p for p ≥ 0. Theorem 1. Unique(p)</formula><p>is the expected number of unique keys that appear in p requests. <ref type="figure" target="#fig_2">Figure 4</ref> plots the number of unique keys as a function of the number of insert requests for 100 million unique keys (N = 10 8 ). We use Zipf distributions with varying skew. The unique key count increases as the request count increases, but the increase slows down as the unique key count approaches the total unique key count. The unique key count with less skewed distributions increases more rapidly than with more skewed distributions until it is close to the maximum.</p><p>In the context of MSLS designs, Unique gives a hint about how many requests (or how much time) it takes for a level to reach a certain size from an empty state. With no or low skew, a level quickly approaches its full capacity and the system initiates compaction; with high skew, however, it can take a long time to accumulate enough keys to trigger compaction.</p><p>We examine another useful function, Unique −1 , which is the inverse function of Unique. Unique −1 (u) estimates the expected number of requests to observe u unique keys in the requests. <ref type="bibr" target="#b3">4</ref> By extending the domain of Unique to the real numbers, we can ensure the existence of Unique −1 :</p><formula xml:id="formula_1">Lemma 1. Unique −1 (u) exists for 0 ≤ u &lt; N.</formula><p>We further extend the domain of Unique −1 to include N by using limits. Unique(∞) := lim p→∞ Unique(p) = N;</p><formula xml:id="formula_2">Unique −1 (N) := lim u→N Unique −1 (u) = ∞.</formula><p>It is straightforward to compute the value of Unique −1 (u) by solving Unique(p) = u for p numerically or by approximating Unique and Unique −1 with piecewise linear functions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Merging Tables</head><p>Compaction takes multiple tables and creates a new set of tables that contain no duplicate keys. Nontrivial cases involve tables with overlapping key ranges. For such cases, we can estimate the size of merged tables using a combination of Unique and Unique −1 :</p><formula xml:id="formula_3">Definition 2. Merge(u, v) := Unique(Unique −1 (u) + Unique −1 (v)) for 0 ≤ u, v ≤ N. Theorem 2. Merge(u, v)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>is the expected size of a merged table that is created from two tables of sizes u and v.</head><p>In worst-case analysis, merging tables of size u and v results in a new table of size u + v, assuming the input tables contain no duplicate keys. The error caused by this assumption grows as u and v approach N and as the key popularity has more skew. For example, with 100 million (10 8 ) total unique keys and Zipf skew of 0.99, Merge(10 7 , 9 × 10 7 ) ≈ 9.03 × 10 7 keys, whereas the worst-case analysis expects 10 8 keys.</p><p>Finally, Unique is an isomorphism as shown in Figure 5. Unique maps the length of a sequence of requests to the number of unique keys in it, and Unique −1 does the opposite. Adding request counts corresponds to ap-plying Merge to unique key counts; the addition calculates the length of concatenated request sequences, and Merge obtains the number of unique keys in the merged table. Translating the number of requests to the number of unique keys and vice versa makes it easy to build an MSLS model, as presented in Section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Handling Workloads with Dependence</head><p>As stated in Section 3.2, our primitives assume i.i.d., that insertions are independent, yet real-world workloads can have dependence between keys. A common scenario is using composite keys to describe multiple attributes of a single entity <ref type="bibr" target="#b24">[26,</ref><ref type="bibr" target="#b32">34]</ref></p><formula xml:id="formula_4">: [book100|title], [book100|author], [book100|date]</formula><p>. Related composite keys are often inserted together, resulting in dependent inserts.</p><p>Fortunately, we can treat these dependent inserts as independent if each insert is independent of a large number of (but not necessarily all) other inserts handled by the system. The dependence between a few inserts causes little effect on the overall compaction process because compaction involves many keys; for example, the compaction cost difference between inserting keys independently and inserting 10 related keys sharing the same key prefix as a batch is only about 0.2% on LevelDB when the workload contains 1 million or more total unique keys (for dependent inserts, 100,000 or more independent key groups, each of which has 10 related keys). Therefore, our primitives give good estimates in many practical scenarios which lack strictly independent inserts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Modeling LevelDB</head><p>This section applies our analytic primitives to model a practical MSLS design, LevelDB. We explain how the dynamics of LevelDB components can be incorporated into the LevelDB model. We compare the analytic estimate with the measured performance of both a LevelDB simulator and the original implementation.</p><p>We assume that the dictionary-based compression <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b20">21]</ref> is not used in logs and SSTables. Using compression can reduce the write amplification (WA) by a certain factor; its effectiveness depends on how compressible the stored data is. Section 8 discusses how we handle variable-length items created as a result of compression.</p><p>Algorithm 1 summarizes the WA estimation for LevelDB. unique() and merge() calculate Unique and Merge as defined in Section 3. dinterval() calculates DInterval, defined in this section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Logging</head><p>LevelDB's write-ahead logging (WAL) writes roughly the same amount as the data volume of inserts. We do not need to account for key redundancy because logging does not perform redundancy removal. As a consequence, // mem -&gt; log 10 WA = 1;</p><formula xml:id="formula_5">11 12 // mem -&gt; level-0 13 WA += unique(wal) / wal; 14 15 // level-0 -&gt; level-1 16 interval[0] = wal * c0; 17 write[1] = merge(unique(interval[0]), size[1]); 18 WA += write[1] / interval[0]; 19 20 // level-l -&gt; level-(l+1) 21 for (l = 1; l &lt; L; l++) { 22 interval[l] = interval[l-1] + dinterval(size, l); 23 write[l+1] = merge(unique(interval[l]), size[l+1]) + unique(interval[l]); 24 WA += write[l+1] / interval[l]; 25 } 26 27</formula><p>return WA; 28 } Algorithm 1: Pseudocode of a model of WA of LevelDB.</p><p>logging contributes 1 unit of WA (line #10). An advanced WAL scheme <ref type="bibr" target="#b8">[9]</ref> can lower the logging cost below 1 unit.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Constructing Level-0 SSTables</head><p>LevelDB stores the contents of the memtable as a new SSTable in level-0 whenever the current log size reaches a threshold wal, which is 4 MiB by default. <ref type="bibr" target="#b4">5</ref> Because an SSTable contains no redundant keys, we use Unique to compute the expected size of the SSTable corresponding to the accumulated requests; for every wal requests, LevelDB creates an SSTable of Unique(wal), which adds Unique(wal)/wal to WA (line #13).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Compaction</head><p>LevelDB compacts one or more SSTables in a level into the next level when any of the following conditions is satisfied: (1) level-0 has at least c0 SSTables; (2) the aggregate size of SSTables in a level-l (1 ≤ l ≤ L) reaches Size(l) bytes; or (3) an SSTable has observed a certain number of seeks from query processing. The original LevelDB defines c0 = 4 SSTables 6 and Size(l) = 10 l MiB. The level to compact is chosen based on the ratio of the current SSTable count or level size to the triggering condition, which can be approximated as prioritizing levels in their order from 0 to L in the model. The seek trigger depends on the distribution of queries as well as of insert requests, which is beyond the scope of this paper. We examine two quantities to estimate the amortized compaction cost: a certain interval (a request count) that is large enough to capture the average compaction behavior of level-l, denoted as Interval(l); and the expected amount of data written to level-(l + 1) during that interval, denoted as Write(l + 1). The contribution to WA by the compaction from level-l to level-(l + 1) is given by Write(l +1)/ Interval(l) by the definition of WA (line #18, #24).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Compacting Level-0 SSTables</head><p>LevelDB picks a level-0 SSTable and other level-0 SSTables that overlap with the first SSTable picked. It chooses overlapping level-1 SSTables as the other compaction input, and it can possibly choose more level-0 SSTables as long as the number of overlapping level-1 SSTables remains unchanged. Because level-0 contains overlapping SSTables with a wide key range, a single compaction commonly picks multiple level-0 SSTables; to build a concise model, we assume that all level-0 SSTables are chosen for compaction whenever the trigger for level-0 is met.</p><p>Let Interval(0) be the interval of creating c0 SSTables, where Interval(0) = wal · c0 (line #16). Compaction performed for that duration merges the SSTables created from Interval(0) requests, which contain Unique(Interval(0)) unique keys, into level-1 with Size(1) unique keys. Therefore, Write(1) = Merge(Unique(Interval(0)), Size(1)) (line #17).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">Compacting Non-Level-0 SSTables</head><p>While the compaction from level-l to level-(l + 1) (1 ≤ l &lt; L) follows similar rules as level-0 does, it is more complicated because of how LevelDB chooses the next SSTable to compact. LevelDB remembers LastKey(l), the last key of the SSTable used in the last compaction for level-l and picks the first SSTable whose smallest key succeeds LastKey(l); if there exists no such SSTable, LevelDB picks the SSTable with the smallest key in the level. This compaction strategy chooses SSTables in a circular way in the key space for each level.</p><p>Non-uniformity arises from round-robin compaction.</p><p>Compaction removes items from a level, but its effect is localized in the key space of that level. Compaction from a lower level into that level, however, tends to push items across the key space of the receiving level: the lower level makes faster progress compacting the entire key space because it contains fewer items, as depicted in <ref type="figure" target="#fig_5">Figure 6</ref>. As a result, the recently-compacted part of the key space has a lower chance of having items (low density), whereas the other part, which has not been compacted recently, is more likely to have items (high density). Because the maximum SSTable size is constrained, the low density area has SSTables covering a wide key range, and the high density area has SSTables with a narrow key range. This non-uniformity makes compaction cheaper. Compaction occurs for an SSTable at the dense part of the key space. The narrow key range of the dense SSTable means a relatively small number of overlapping SSTables in the next level. Therefore, the compaction of the SSTable results in less data written to the next level.</p><p>Some LevelDB variants <ref type="bibr" target="#b21">[22]</ref> explicitly pick an SSTable that maximizes the ratio of the size of that SSTable to the size of all overlapping SSTables in the next level, in hope of making the compaction cost smaller. Interestingly, due to the non-uniformity, LevelDB already implicitly realizes a similar compaction strategy. Our simulation results (not shown) indicate that the explicit SSTable selection brings a marginal performance gain over LevelDB's circular SSTable selection.</p><p>To quantify the effect of the non-uniformity to compaction, we model the density distribution of a level. Let DInterval(l) be the expected interval between compaction of the same key in level-l. This is also the interval to merge the level-l data into the entire key space of level-(l + 1). We use d to indicate the unidirectional distance from the most recently compacted key LastKey(l) to a key in the key space, where 0 ≤ d &lt; N. d = 0 represents the key just compacted, and d = N − 1 is the key that will be compacted next time. Let Density(l, d) be the probability of having an item for the key with distance d in level-l. Because we assume no spatial key locality, we can formulate Density by approximating LastKey(l) to have a uniform distribution:</p><formula xml:id="formula_6">Theorem 3. Assuming P(LastKey(l) = k) = 1/N for 1 ≤ l &lt; L, k ∈ K, then Density(l, d) = Unique(DInterval(l) · d/N)/N for 1 ≤ l &lt; L, 0 ≤ d &lt; N.</formula><p>We also use a general property of the density:</p><formula xml:id="formula_7">Lemma 2. ∑ N−1 d=0 Density(l, d) = Size(l) for 1 ≤ l &lt; L.</formula><p>The value of DInterval(l) can be obtained by solving it numerically using Theorem 3 and Lemma 2.</p><p>We see that DInterval(l) is typically larger than Unique −1 (Size(l)) that represents the expected interval of compacting the same key without non-uniformity. Interval(l), the actual interval we use to calculate the amortized WA, is cumulative and increases by DInterval, i.e., Interval(l) = Interval(l −1)+DInterval(l) (line #22). Because compacting lower levels is favored over compacting upper levels, an upper level may contain more data than its compaction trigger as an overflow from lower levels. We use a simple approximation to capture this behavior by adding the cumulative term Interval(l − 1).</p><p>False overlaps are another effect caused by the incremental compaction using SSTables in LevelDB. Unlike non-uniformity, they increase the compaction cost slightly. For an SSTable being compacted, overlapping SSTables in the next level may contain items that lie outside the key range of the SSTable being compacted, as illustrated in <ref type="figure" target="#fig_6">Figure 7</ref>. Even though the LevelDB implementation attempts to reduce such false overlaps by choosing more SSTables in the lower level without creating new overlapping SSTables in the next level, false overlaps may add extra data writes whose size is close to that of the SSTables being compacted, i.e., Unique(Interval(l)) for Interval(l). Note that these extra data writes caused by false overlaps are more significant when Unique for the interval is large, i.e., under low skew, and they diminish as Unique becomes small, i.e., under high skew.</p><p>Several proposals <ref type="bibr" target="#b28">[30,</ref><ref type="bibr" target="#b40">41]</ref> strive to further reduce false overlaps by reusing a portion of input SSTables, essentially trading storage space and query performance for faster inserts. Such techniques can reduce WA by up to 1 per level, and even more if they address other types of false overlaps; the final cost savings, however, largely depend on the workload skew and the degree of the reuse.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Sensitivity to the Workload Skew</head><p>To examine how our LevelDB model reacts to the workload skew, we compare our WA estimates with worst-case analysis results. Our worst-case scenarios make the same assumption as prior asymptotic analyses <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b38">39]</ref>, that the workload has no redundancy; therefore, merging two SSTables yields an SSTable whose size is exactly the same as the sum of the input SSTable sizes. In other words, compacting levels of size u and v results in u + v items in the worst case. <ref type="figure" target="#fig_8">Figure 8</ref> plots the estimated WA for different Zipf skew parameters. Because our analytic model ("LevelDB-ana") considers the key popularity distribution of the workload in estimating WA, it clearly shows how WA decreases as LevelDB handles more skewed workloads; in contrast, the worst-case analysis ("Worst-case analysis") gives the same result regardless of the skew.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Comparisons with the Worst-Case Analysis, Simulation, and Experiment</head><p>We compare analytic estimates of WA given by our LevelDB model with the estimates given by the worst-case analysis, and the measured cost by running experiments on a LevelDB simulator and the original implementation. We built a fast LevelDB simulator in C++ that follows the LevelDB design specification <ref type="bibr" target="#b19">[20]</ref> to perform an itemlevel simulation and uses system parameters extracted from the LevelDB source code. This simulator does not intend to capture every detail of LevelDB implementation behaviors; instead, it realizes the high-level design components as explained in the LevelDB design document. The major differences are (1) our simulator runs in memory; (2) it performs compaction synchronously without concurrent request processing; and (3) it does not implement several opportunistic optimizations: (a) reducing false overlaps by choosing more SSTables in the lower level, (b) bypassing level-0 and level-1 for a newly created SSTable from the memtable if there are no overlapping SSTables in these levels, and (c) dynamically allowing more than 4 level-0 SSTables under high load.</p><p>For the measurement with the LevelDB implementation, we instrumented the LevelDB code (v1.18) to report Worst-case analysis LevelDB-sim (Uniform) LevelDB-sim (Zipf) LevelDB-impl (Uniform) LevelDB-impl (Zipf) LevelDB-ana (Uniform) LevelDB-ana (Zipf) <ref type="figure">Figure 9</ref>: Comparison of WA between the estimation from our LevelDB model, the worst-case analysis, LevelDB simulation, and implementation results, with a varying number of total unique keys. Using 1 kB item size. Simulation and implementation results with a large number of unique keys are unavailable due to excessive runtime. the number of bytes written to disk via system calls. We use an item size that is 18 bytes smaller than we do in the analysis and simulation, to compensate for the increased data writes due to LevelDB's own storage space overhead. For fast experiments, we disable fsync and checksumming, 7 which showed no effects on WA in our experiments. We also avoid inserting items at an excessive rate that can overload level-0 with many SSTables and cause a high lookup cost.</p><p>Both LevelDB simulator and implementation use a YCSB <ref type="bibr" target="#b10">[11]</ref>-like workload generator written in C++. Each experiment initializes the system by inserting all keys once and then measures the average WA of executing random insert requests whose count is 10 times the total unique key count. <ref type="figure">Figure 9</ref> shows WA estimation and measurement with a varying number of total unique keys. Due to excessive experiment time, the graph excludes some data points for simulation ("LevelDB-sim") and implementation ("LevelDB-impl") with a large number of unique keys. The graph shows that our LevelDB model successfully estimates WA that agrees almost perfectly with the simulation and implementation results. The most significant difference occurs at 330 M unique keys with the uniform popularity distribution, where the estimated WA is only 3.0% higher than the measured WA. The standard worst-case analysis, however, significantly overestimates WA by 1.8-3.5X compared to the actual cost, which highlights the accuracy of our LevelDB model. <ref type="figure" target="#fig_10">Figure 10</ref> compares results with different write buffer size (i.e., the memtable size), which determines how much data in memory LevelDB accumulates to create a level-0 SSTable (and also affects how long crash recovery may take). In our LevelDB model, wal reflects the write buffer size. We use write buffer sizes between LevelDB's default size of 4 MiB and 10% of the last level size. The result indicates that our model estimates WA with good accuracy, but the error increases as the write buffer size increases for uniform key popularity distributions. We suspect that the error comes from the approximation in the model to take into account temporal overflows of levels beyond their maximum size; the error diminishes when level sizes are set to be at least as large as the write buffer size. In fact, avoiding too small level-1 and later levels has been suggested by RocksDB developers <ref type="bibr" target="#b13">[14]</ref>, and our optimization performed in Section 6 typically results in moderately large sizes for lower levels under uniform distributions, which makes this type of error insignificant for practical system parameter choices.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Modeling Universal Compaction</head><p>This section focuses on how we can model complex compaction strategies such as "universal compaction" implemented in RocksDB <ref type="bibr" target="#b14">[15]</ref>. Section 7 revisits RocksDB to compare its "level style compaction" with LevelDB.</p><p>Universal compaction combines three small compaction strategies. RocksDB keeps a list of SSTables ordered by the age of their data, and compaction is restricted to adjacent tables. Compaction begins when the SSTable count exceeds a certain threshold (Precondition). First, RocksDB merges all SSTables whose total size minus the last one's size exceeds the last one's size by a certain factor (Condition 1); second, it merges consecutive SSTables that do not include a sudden increase in size beyond a certain factor (Condition 2); third, it merges the newest SSTables such that the total SSTable count drops below a certain threshold (Condition 3). Condition 1 avoids excessive duplicate data across SSTables, and Conditions 2 and 3 prevent high read amplification.</p><p>In such a multi-strategy system, it is difficult to determine how frequently each condition will cause compaction and what SSTables will be chosen for compaction.</p><p>We take this challenge as an opportunity to demonstrate how our analytic primitives are applicable to analyzing a complex system by using a table-level simulation. Unlike full simulators that keep track of individual items, a table-level simulator calculates only the SSTable size. It implements compaction conditions as the system design specifies, and it estimates the size of new or merged SSTables by using our analytic primitives. Dividing the total size of created SSTables by the total number of inserts gives the estimated WA. Unlike our LevelDB model that understands incremental compaction, a model for universal compaction does not need to consider non-uniformity and false overlaps. Interested readers may refer to Appendix C for the full pseudocode of the simulator. <ref type="figure" target="#fig_11">Figure 11</ref> compares WA obtained by our table-level simulation and the full RocksDB implementation. We use the default configuration, except for the SSTables count for compaction triggers set to 12. The simulation result ("RocksDBUC-sim") is close to the measured WA ("RocksDBUC-impl"). The estimated WA differs from the measured WA by up to 6.5% (the highest error with 33 M unique keys and skewed key inserts) though the overall accuracy remains as high as our LevelDB model presented in Section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Optimizing System Parameters</head><p>Compared to full simulators and implementations, an analytic model offers fast estimation of cost metrics for a given set of system parameters. To demonstrate fast evaluation of the analytic model, we use an example of optimizing LevelDB system parameters to reduce WA using our LevelDB model. Note that the same optimization effort could be made with the full LevelDB implementation by substituting our LevelDB model with the implementation and a synthetic workload generator. However, it would take prohibitively long to explore the large parameter space, as examined in Section 6.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Parameter Set to Optimize</head><p>The level sizes, Size(l), are important system parameters in LevelDB. They determine when LevelDB should initi- LevelDB-sim (Uniform) LevelDB-sim (Zipf) LevelDB-sim-opt (Uniform) LevelDB-sim-opt (Zipf) LevelDB-ana (Uniform) LevelDB-ana (Zipf) LevelDB-ana-opt (Uniform) LevelDB-ana-opt (Zipf) <ref type="figure" target="#fig_0">Figure 12</ref>: Improved WA using optimized level sizes on our analytic model and simulator for LevelDB. ate compaction for standard levels and affect the overall compaction cost of the system. The original LevelDB design uses a geometric progression of Size(l) = 10 l MiB. Interesting questions are (1) what level sizes different workloads favor; and (2) whether the geometric progression of level sizes is the optimal for all workloads.</p><p>Using different level sizes does not necessarily trade query performance or memory use. The log size, level-0 SSTable count, and total level count-the main determinants of query performance-are all unaffected by this system parameter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Optimizer</head><p>We implemented a system parameter optimizer based on our analytic model. The objective function to minimize is the estimated WA. Input variables are Size(l), excluding Size(L), which will be equal to the total unique key count. After finishing the optimization, we use the new level sizes to obtain new WA estimates and measurement results on our analytic model and simulator. We also force the LevelDB implementation to use the new level sizes and measure WA. Our optimizer is written in Julia <ref type="bibr" target="#b3">[4]</ref> and uses Ipopt <ref type="bibr" target="#b46">[47]</ref> for nonlinear optimization. To speed up Unique, we use a compressed key popularity distribution which groups keys with similar probabilities and stores   <ref type="table">Table 1</ref>: Breakdown of WA sources on the analysis and simulation without and with the level size optimization. Using 100 million unique keys, 1 kB item size, and a uniform key popularity distribution.</p><p>their average probability. 8</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Optimization Results</head><p>Our level size optimization successfully reduces the insert cost of LevelDB. <ref type="figure" target="#fig_0">Figures 12 and 13</ref> plot WA with optimized level sizes. Both graphs show that the optimization ("LevelDB-ana-opt," "LevelDB-sim-opt," and "LevelDBimpl-opt") improves WA by up to 9.4%. The analytic estimates and simulation results agree with each other as before, and the LevelDB implementation exhibits lower WA across all unique key counts. The optimization is effective because level sizes differ by the workload skew, as shown in <ref type="figure" target="#fig_2">Figure 14</ref>. Having larger lower levels is beneficial for relatively low skew as it reduces the size ratio of adjacent levels. On the other hand, high skew favors smaller lower levels and level sizes that grow faster than the standard geometric progression. With high skew, compaction happens more frequently in the lower levels to remove redundant keys; keeping these levels small reduces the cost of compaction. This result suggests that it is suboptimal to use fixed level sizes for different workloads and that using a geometric progression of level sizes is not always the best design to minimize WA. Figure 16: Improved WA using optimized level sizes on the LevelDB implementation, with a large write buffer. Using 10 million unique keys, 1 kB item size. <ref type="table">Table 1</ref> further examines how the optimization affects per-level insert costs, using the LevelDB model and simulation. Per-level WA tends to be more variable using the original level sizes, while the optimization makes them relatively even across levels except the last level. This result suggests that it may be worth performing a runtime optimization that dynamically adjusts level sizes to achieve the lower overall WA by reducing the variance of the per-level WA.</p><p>By lowering WA, the system can use fewer levels to achieve faster lookup speed without significant impact on insert costs. <ref type="figure" target="#fig_3">Figure 15</ref> reveals how much extra room for query processing the optimization can create. This analysis changes the level count by altering the growth factor of LevelDB, i.e., using a higher growth factor for a lower level count. The result shows that the optimization is particularly effective with a fewer number of levels, and it can save almost a whole level's worth of WA compared to using a fixed growth factor. For example, with the optimized level sizes, a system can use 3 levels instead of 4 levels without incurring excessively high insert costs.</p><p>A LevelDB system with large memory can further benefit from our level size optimization. <ref type="figure" target="#fig_5">Figure 16</ref> shows the result of applying the optimization to the LevelDB implementation, with a large write buffer. The improvement becomes more significant as the write buffer size increases, reaching 26.2% of WA reduction at the buffer size of 1 million items.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Optimizer Performance</head><p>The level size optimization requires little time due to the fast evaluation of our analytic model. For 100 million unique keys with a uniform key popularity distribution, the entire optimization took 2.63 seconds, evaluating 17,391 different parameter sets (6,613 evaluations per second) on a server-class machine equipped with Intel® Xeon® E5-2680 v2 processors. For the same-sized workload, but with Zipf skew of 0.99, the optimization time increased to 79 seconds, which is far more than the uniform case, but is less than 2 minutes; for this optimization, the model was evaluated 16,680 times before convergence (211 evaluations per second).</p><p>Evaluating this many system parameters using a full implementation-or even item-level simulation-is prohibitively expensive. Using the same hardware as above, our in-memory LevelDB simulator takes 45 minutes to measure WA for a single set of system parameters with 100 million unique keys. The full LevelDB implementation takes 101 minutes (without fsync) to 490 minutes (with fsync), for a smaller dataset with 10 million unique keys.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Improving RocksDB</head><p>In this section, we turn our attention to RocksDB <ref type="bibr" target="#b11">[12]</ref>, a well-known variant of LevelDB. RocksDB offers improved capabilities and multithreaded performance, and provides an extensive set of system configurations to temporarily accelerate bulk loading by sacrificing query performance or relaxing durability guarantees <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b13">14]</ref>; nevertheless, there have been few studies of how RocksDB's design affects its performance. We use RocksDB v4.0 and apply the same set of instrumentation, configuration, and workload generation as we do to LevelDB.</p><p>RocksDB supports "level style compaction" that is similar to LevelDB's data layout, but differs in how it picks the next SSTable to compact. RocksDB picks the largest SSTable in a level for compaction, 9 rather than keeping LevelDB's round-robin SSTable selection. We learned in Section 4, however, that LevelDB's compaction strategy is effective in reducing WA because it tends to pick SSTables that overlap a relatively small number of SSTables in the next level.</p><p>To compare the compaction strategies used by LevelDB and RocksDB, we measure the insert cost of both systems in <ref type="figure" target="#fig_6">Figure 17</ref>. Unfortunately, the current RocksDB strategy produces higher WA ("RocksDB-impl") than LevelDB does ("LevelDB-impl"). In theory, the RocksDB approach may help multithreaded compaction because large tables may be spread over the entire key space so that they facilitate parallel compaction; this effect, how- ever, was not evident in our experiments using multiple threads. The high insert cost of RocksDB is entirely caused by RocksDB's compaction strategy; implementing LevelDB's SSTable selection in RocksDB ("RocksDBimpl-rr") reduces RocksDB's WA by up to 32.0%, making it comparable to LevelDB's WA. This result confirms that LevelDB's strategy is good at reducing WA as our analytic model predicts.</p><p>We have not found a scenario where RocksDB's current strategy excels, though some combinations of workloads and situations may favor it. LevelDB and RocksDB developers may or may have not intended any of the effects on WA when designing their systems. Either way, our analytic model provides quantitative evidence that LevelDB's table selection will perform well under a wide range of workloads despite being the "conventional" solution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Estimating Read Amplification</head><p>This section presents read amplification (RA) estimation.</p><p>We introduce a weighted variant of our analytic primitives. A per-key weight w, which is nontrivial (i.e., w(k) 񮽙 = 0 for some k) and nonnegative, specifies how much contribution each key makes to the result:</p><formula xml:id="formula_8">Definition 3. Unique(p, w) := ∑ k∈K [1 − (1 − f X (k)) p ] w(k) for p ≥ 0.</formula><p>We construct w(k) to indicate the probability of having key k for each query. For level-l, let s(l) and e(l) be the expected age of the newest and oldest item in levell in terms of the number of inserts, obtained by using the system model presented in Section 4. We find c(l), the expected I/O cost to perform a query at level-l. The expected I/O cost to perform queries that finish at level-l is [Unique(e(l), w) − Unique(s(l), w)] · c(l). Adding the expected I/O cost of each level gives the overall RA.</p><p>As another use case, the weighted variant can add support for variable-length items to the system models presented in Sections 4 and 5. By setting w(k) to the size of the item for key k, Unique returns the expected size of unique items instead of their expected count. Because weighted Unique is still strictly monotonic, weighted Unique −1 and Merge exist.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Discussion</head><p>Analyzing an MSLS design with an accurate model can provide useful insights on how one should design a new MSLS to exploit opportunities provided by workloads. For example, our analytic model reveals that LevelDB's byte size-based compaction trigger makes compaction much less frequent and less costly under skew; such a design choice should be suitable for many real-world workloads with skew <ref type="bibr">[1]</ref>.</p><p>A design process complemented with accurate analysis can help avoid false conclusions about a design's performance. LevelDB's per-level WA is less (only up to 4-6) than assumed in the worst case (11-12 for a growth factor of 10), even for uniform workloads. Our analytical model justifies LevelDB's high growth factor, which turns out to be less harmful for insert performance than standard worst-case analysis implies.</p><p>Our analytic primitives and modeling are not without limitations. Assumptions such as independence and no spatial locality in requested keys may not hold if there are dependent keys that share the same prefix though a small amount of such dependence does not change the overall system behavior and thus can be ignored as discussed in Section 3.5. Our modeling in Section 4 does not account for time-varying workload characteristics (e.g., flash crowds) or special item types such as tombstones that represent item deletion, while the simulation-oriented modeling in Section 5 can handle such cases. We leave extending our primitives further to accommodate remaining cases as future work.</p><p>Both design and implementation influence the final system performance. Our primitives and modeling are useful for understanding the design of MSLS systems. Although we use precise metrics such as WA to describe the system performance throughout this work, these metrics are ultimately not identical to implementation-level metrics such as operations per second. Translating a good system design into an efficient implementation is critical to achieving good performance, and remains a challenging and important goal for system developers and researchers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10">Related Work</head><p>Over the past decade, numerous studies have proposed new multi-stage log-structured (MSLS) designs and evaluated their performance. In almost every case, the authors present implementation-level performance <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b27">29,</ref><ref type="bibr" target="#b28">30,</ref><ref type="bibr" target="#b30">32,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b47">48]</ref>. Some employ analytic metrics such as write amplification to explain the design rationale, facilitate design comparisons, and generalize experiment results <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b27">29,</ref><ref type="bibr" target="#b28">30,</ref><ref type="bibr" target="#b30">32,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b42">43]</ref>, and most of the others also use the concept of per-operation costs. However, they eventually rely on the experimental measurement because their analysis fails to offer suffi-ciently high accuracy to make meaningful performance comparisons. LSM-tree <ref type="bibr" target="#b35">[36]</ref>, LHAM <ref type="bibr" target="#b31">[33]</ref>, COLA <ref type="bibr" target="#b1">[2]</ref>, bLSM <ref type="bibr" target="#b38">[39]</ref>, and B-tree variants <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b22">24]</ref> provide extensive analysis on their design, but their analyses are limited to asymptotic complexities or always assume the worst case.</p><p>Despite such a large number of MSLS design proposals, there is little active research to devise improved evaluation methods for these proposals to fill the gap between asymptotic analysis and experimental measurement. The sole existing effort is limited to a specific system design <ref type="bibr" target="#b29">[31]</ref>, but does not provide general-purpose primitives. We are unaware of prior studies that successfully capture workload skew and the dynamics of compaction to the degree that the estimates are close to simulation and implementation results, as we present in this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="11">Conclusion</head><p>We present new analytic primitives for modeling multistage log-structured (MSLS) designs, which can quickly and accurately estimate their performance. We have presented a model for the popular LevelDB system, which estimates write amplification very close to experimentally determined actual costs; using this model, we were able to find more favorable system parameters that reduce the overall cost of writes. Based upon lessons learned from the model, we propose changes to RocksDB to lower its insert costs. We believe that our analytic primitives and modeling method are applicable to a wide range of MSLS designs and performance metrics. The insights derived from the models facilitate comparisons of MSLS designs and ultimately help develop new designs that better exploit workload characteristics to improve performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Proofs</head><p>This section provides proofs for theorems presented in this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Theorem 1. (in Section 3.3) Unique(p) is the expected number of unique keys that appear in p requests.</head><p>Proof. Key k counts towards the unique key count if k appears at least once in a sequence of p requests, whose probability is 1 − (1 − f X (k)) p . Therefore, the expected unique key count is</p><formula xml:id="formula_9">∑ k∈K (1 − (1 − f X (k)) p ) = N − ∑ k∈K (1 − f X (k)) p = Unique(p). Lemma 1. (in Section 3.3) Unique −1 (u) exists for 0 ≤ u &lt; N. Proof. Suppose 0 ≤ p &lt; q. (1 − f X (k)) q &lt; (1 − f X (k)) p because 0 &lt; 1 − f X (k) &lt; 1. Unique(q) − Unique(p) = − ∑ k∈K (1 − f X (k)) q + ∑ k∈K (1 − f X (k)) p &gt; 0. Thus, Unique is a strictly monotonic function that is defined over [0, N).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Theorem 2. (in Section 3.4) Merge(u, v) is the expected size of a merged table that is created from two tables whose size is u and v.</head><p>Proof. Let p and q be the expected numbers of insert requests that would produce tables of size u and v, respectively. The merged table is expected to contain all k ∈ K except those missing in both request sequences. Therefore, the expected merged table size is</p><formula xml:id="formula_10">N − ∑ k∈K (1 − f X (k)) p (1 − f X (k)) q = Unique(p + q). Because p = Unique −1 (u) and q = Unique −1 (v), Unique(Unique −1 (u) + Unique −1 (v)) = Merge(u, v).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Theorem 3. (in Section 4.3) Assuming P(LastKey</head><formula xml:id="formula_11">(l) = k) = 1/N for 1 ≤ l &lt; L, k ∈ K, then Density(l, d) = Unique(DInterval(l) · d/N)/N for 1 ≤ l &lt; L, 0 ≤ d &lt; N. Proof. Suppose LastKey(l) = k ∈ K. Let k 񮽙 be (k − d + N) mod N. Let r be DInterval(l) · d/N.</formula><p>There are r requests since the last compaction of k 񮽙 . Level-l has k 񮽙 if any of r requests contains k 񮽙 , whose probability is</p><formula xml:id="formula_12">1 − (1 − f X (k 񮽙 )) r .</formula><p>By considering all possible k and thus all possi-</p><formula xml:id="formula_13">ble k 񮽙 , Density(l, d) = ∑ k∈K (1/N)(1 − (1 − f X (k)) r ) = Unique(DInterval(l) · d/N)/N. Lemma 2. (in Section 4.3) ∑ N−1 d=0 Density(l, d) = Size(l) for 1 ≤ l &lt; L.</formula><p>Proof. The sum over the density equals to the expected unique key count, which is the number of keys level-l maintains, i.e., Size(l).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Theorem 4. (in Section 8) The expected I/O cost to perform queries that finishes at level-l is given by</head><p>[Unique(e(l), w) − Unique(s(l), w)] · c(l), where w describes the query distribution and c(l) is the expected I/O cost to perform a query at level-l.</p><p>Proof. For key k to exist in level-l and be used for query processing (without being served in an earlier level), it must appear in at least one of e(l) − s(l) requests and in none of other s(l) requests. The first condition ensures the existence of the key in level-l, and the second condition rejects the existence of the key in an earlier level (otherwise, queries for key k will be served in that level). Thus, the probability of such a case is</p><formula xml:id="formula_14">(1 − (1 − f X (k)) e(l)−s(l) ) · (1 − f X (k)) s(l) = (1 − f X (k)) s(l) − (1 − f X (k)) e(l) .</formula><p>The expected I/O cost to perform a query for key k that finishes at level-l is</p><formula xml:id="formula_15">񮽙 (1 − f X (k)) s(l) − (1 − f X (k)) e(l) 񮽙 · c(l).</formula><p>Because the fraction of the queries for key k among all queries is given by w(k), the expected I/O cost to perform queries that finishes at level-</p><formula xml:id="formula_16">l is ∑ k∈K 񮽙 (1 − f X (k)) s(l) − (1 − f X (k)) e(l) 񮽙 c(l)w(k) = ∑ k∈K 񮽙񮽙 (1 − (1 − f X (k)) e(l) 񮽙 − 񮽙 1 − (1 − f X (k)) s(l) 񮽙񮽙 w(k) c(l) = [Unique(e(l), w) − Unique(s(l), w)] · c(l).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Modeling COLA and SAMT</head><p>The cache-oblivious lookahead array (COLA) <ref type="bibr" target="#b1">[2]</ref> is a generalized and improved binomial list <ref type="bibr" target="#b2">[3]</ref>. Like LSMtree, COLA has multiple levels whose count is 񮽙log r N񮽙, where r is the growth factor. Each level contains zero or one SSTable. Unlike LSM-tree, however, COLA uses the merge count as the main compaction criterion; a level in COLA accepts r − 1 merges with the lower level before the level is merged into the next level. COLA has roughly similar asymptotic complexities to LSM-tree's. A query in COLA may cost O(log r N) random I/O per lookup if looking up a level costs O(1) random I/O. COLA's data migration costs O((r − 1) log r N) I/O per insert. r is usually chosen between 2 and 4.</p><p>The Sorted Array Merge Tree (SAMT) <ref type="bibr" target="#b41">[42]</ref> is similar to COLA but performs compaction differently. Instead of eagerly merging data to have a single log structure per level, SAMT keeps up to r SSTables before merging them and moving the merged data into the next level. Therefore, a lookup costs O(r log r N) random I/O, whereas the perupdate I/O cost decreases to O(log r N).</p><p>A few notable systems implementing a version of COLA and SAMT are HBase <ref type="bibr" target="#b44">[45]</ref> and Cassandra <ref type="bibr" target="#b25">[27,</ref><ref type="bibr" target="#b43">44]</ref>.</p><p>Algorithm 2 presents models for COLA and SAMT. Both models assume that the system uses write-ahead log files whose count is capped by the growth factor r. In COLA, line #15 calculates the amount of writes for a level that has already accepted j merges (0 ≤ j &lt; r − 1). Compaction of the second-to-last level is treated specially because the last level must be large enough to hold all unique keys and has no subsequent level (line #19). The SAMT model is simpler because it defers merging the data in the same level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Modeling Universal Compaction</head><p>Algorithm 3 models RocksDB's universal compaction using a table-level simulation presented in Section 5. Line #15 estimates the size of a new SSTable created from insert requests. Line #26, #43, and #55 predict the outcome of SSTable merges caused of different compaction triggers.</p><p>merge_all() takes a list of (multiple) SSTable sizes and returns the expected size of the merge result (i.e., Unique(∑ i Unique −1 (sizes[i]))). </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :Figure 2 :</head><label>12</label><figDesc>Figure 1: A simplified overview of LevelDB data structures. Each rectangle is an SSTable. Note that the x-axis is the key space; the rectangles are not to scale to indicate their byte size. The memtable and logs are omitted.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Write amplification is an important metric; increased write amplification decreases insert throughput on LevelDB.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Unique key count as a function of request count for 100 million unique keys, with varying Zipf skew (s).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Isomorphism of Unique. Gray bars indicate a certain redundant key.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Non-uniformity of the key density caused by the different compaction speed of two adjacent levels in the key space. Each rectangle represents an SSTable. Vertical dotted lines indicate the last compacted key; the rectangles right next to the vertical lines will be chosen for compaction next time.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: False overlaps that occur during the LevelDB compaction. Each rectangle indicates an SSTable; its width indicates the table's key range, not the byte size.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>By considering all of these factors, we can calculate the expected size of the written data. During Interval(l), level- l accepts Unique(Interval(l)) unique keys from the lower levels, which are merged into the next level containing Size(l + 1) unique keys. False overlaps add extra writes roughly as much as the compacted level-l data. Thus, Write(l +1) = Merge(Unique(Interval(l)), Size(l +1))+ Unique(Interval(l)) (line #23).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Effects of the workload skew on WA. Using 100 million unique keys, 1 kB item size.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 10 :</head><label>10</label><figDesc>Figure 10: Comparison of WA between the estimation from our LevelDB model and implementation results, with varying write buffer sizes. Using 10 million unique keys, 1 kB item size.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 11 :</head><label>11</label><figDesc>Figure 11: Comparison of WA between the estimation from our table-level simulation and implementation results for RocksDB's universal compaction, with a varying number of total unique keys. Using 1 kB item size.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 13 :</head><label>13</label><figDesc>Figure 13: Improved WA using optimized level sizes on the LevelDB implementation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 14 :</head><label>14</label><figDesc>Figure 14: Original and optimized level sizes with varying Zipf skew. Using 100 million unique keys, 1 kB item size.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Figure 15 :</head><label>15</label><figDesc>Figure 15: WA using varying numbers of levels. The level count excludes level-0. Using 100 million unique keys, 1 kB item size.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Figure 17 :</head><label>17</label><figDesc>Figure 17: Comparison of WA between LevelDB, RocksDB, and a modified RocksDB with LevelDB-like SSTable selection.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head></head><label></label><figDesc>Pseudocode of models of WA of COLA and SAMT.</figDesc></figure>

			<note place="foot" n="2"> We use Intel® SSDSC2BB160G4T with fsync enabled for LevelDB. 152 14th USENIX Conference on File and Storage Technologies (FAST &apos;16) USENIX Association</note>

			<note place="foot" n="4"> Unique −1 is similar to, but differs from, the generalized coupon collector&apos;s problem (CCP) [16]. Generalized CCP terminates as soon as a certain number of unique items has been collected, whereas Unique −1 is merely defined as the inverse of Unique. Numerically, solutions of the generalized CCP are typically smaller than those of Unique −1 due to CCP&apos;s eager termination.</note>

			<note place="foot" n="5"> We use the byte size and the item count interchangeably based on the assumption of fixed item size, as described in Section 3.2. 6 LevelDB begins compaction with 4 level-0 SSTables, and new insert requests stall if the compaction of level-0 is not fast enough that the level-0 SSTable count reaches 12.</note>

			<note place="foot" n="7"> MSLS implementations can use special CPU instructions to accelerate checksumming and avoid making it a performance bottleneck [23].</note>

			<note place="foot" n="8"> For robustness, we optimize using both the primal and a dual form of the LevelDB model presented in Section 4. The primal optimizes over Size(l) and the dual optimizes over Unique −1 (Size(l)). We pick the result of whichever model produces the smaller WA.</note>

			<note place="foot" n="9"> Recent versions of RocksDB support additional strategies for SSTable selection.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work was supported by funding from National Science Foundation under awards IIS-1409802 and CNS-1345305, and Intel via the Intel Science and Technology Center for Cloud Computing (ISTC-CC). We would like to thank anonymous FAST reviewers for their feedback and James Mickens for shepherding this paper. We appreciate Eddie Kohler, Mark Callaghan, Kai Ren, and anonymous SOSP reviewers for their comments on early versions of this work.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Workload analysis of a large-scale keyvalue store</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Atikoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Frachtenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Paleczny</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGMETRICS&apos;12</title>
		<meeting>the SIGMETRICS&apos;12</meeting>
		<imprint>
			<date type="published" when="2012-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Cacheoblivious streaming B-trees</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Bender</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Farach-Colton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Fineman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">R</forename><surname>Fogel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">C</forename><surname>Kuszmaul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Nelson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Nineteenth Annual ACM Symposium on Parallel Algorithms and Architectures</title>
		<meeting>the Nineteenth Annual ACM Symposium on Parallel Algorithms and Architectures</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Decomposable searching problems I: Static-to-dynamic transformations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Bentley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Saxe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Algorithms</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="301" to="358" />
			<date type="published" when="1980-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Julia: A fresh approach to numerical computing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bezanson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Edelman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Karpinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">B</forename><surname>Shah</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1411.1607" />
		<imprint>
			<date type="published" when="2014-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Space/time trade-offs in hash coding with allowable errors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">H</forename><surname>Bloom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="422" to="426" />
			<date type="published" when="1970" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Lower bounds for external memory dictionaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">S</forename><surname>Brodal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fagerberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourteenth Annual ACM-SIAM Symposium on Discrete Algorithms</title>
		<meeting>the Fourteenth Annual ACM-SIAM Symposium on Discrete Algorithms</meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Read Amplification Factor</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Callaghan</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Bigtable: A distributed storage system for structured data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">C</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Wallach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Burrows</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Chandra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fikes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">E</forename><surname>Gruber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 7th USENIX OSDI</title>
		<meeting>7th USENIX OSDI</meeting>
		<imprint>
			<date type="published" when="2006-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">From ARIES to MARS: Transaction support for next-generation, solid-state drives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Coburn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Bunker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schwarz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Swanson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 24th ACM Symposium on Operating Systems Principles (SOSP)</title>
		<meeting>24th ACM Symposium on Operating Systems Principles (SOSP)</meeting>
		<imprint>
			<date type="published" when="2013-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Collet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lz4</surname></persName>
		</author>
		<ptr target="https://github.com/Cyan4973/lz4" />
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Benchmarking cloud serving systems with YCSB</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Cooper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Silberstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Tam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ramakrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sears</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 1st ACM Symposium on Cloud Computing (SOCC)</title>
		<meeting>1st ACM Symposium on Cloud Computing (SOCC)</meeting>
		<imprint>
			<date type="published" when="2010-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Facebook</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rocksdb</surname></persName>
		</author>
		<ptr target="http://rocksdb.org/" />
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Performance Benchmarks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Facebook</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">RocksDB Tuning Guide</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Facebook</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">RocksDB Universal Compaction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Facebook</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Birthday paradox, coupon collectors, caching algorithms and self-organizing search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Flajolet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gardy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Thimonier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Discrete Applied Mathematics</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="1992-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-L</forename><surname>Gailly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Adler</surname></persName>
		</author>
		<ptr target="http://www.zlib.net/" />
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Fast compaction algorithms for NoSQL databases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 35th IEEE International Conference on Distributed Computing Systems (ICDCS)</title>
		<meeting>the 35th IEEE International Conference on Distributed Computing Systems (ICDCS)</meeting>
		<imprint>
			<date type="published" when="2015-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Google</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Leveldb</surname></persName>
		</author>
		<ptr target="https://github.com/google/leveldb" />
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">LevelDB file layout and compactions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Google</surname></persName>
		</author>
		<ptr target="https://github.com/google/leveldb/blob/master/doc/impl.html" />
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Google</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Snappy</surname></persName>
		</author>
		<ptr target="https://github.com/google/snappy" />
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hyperdex</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hyperleveldb</surname></persName>
		</author>
		<ptr target="http://hyperdex.org/performance/leveldb/" />
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">BetrFS: A rightoptimized write-optimized file system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Jannen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Akshintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Esmet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mittal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Pandey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Walsh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bender</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Farach-Colton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">C</forename><surname>Kuszmaul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">E</forename><surname>Porter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 13th USENIX Conference on File and Storage Technologies (FAST)</title>
		<meeting>13th USENIX Conference on File and Storage Technologies (FAST)</meeting>
		<imprint>
			<date type="published" when="2015-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">The Garbage Collection Handbook: The Art of Automatic Memory Management</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hosking</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Moss</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>Chapman &amp; Hall/CRC</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Easy freshness with Pequod cache joins</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kate</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Kohler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Kester</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Narula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Morris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 11th USENIX NSDI</title>
		<meeting>11th USENIX NSDI</meeting>
		<imprint>
			<date type="published" when="2014-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Cassandra: A decentralized structured storage system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lakshman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGOPS Operating System Review</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="35" to="40" />
			<date type="published" when="2010-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A real-time garbage collector based on the lifetimes of objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lieberman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hewitt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="1983-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">SILT: A memory-efficient, high-performance key-value store</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Andersen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kaminsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 23rd ACM Symposium on Operating Systems Principles (SOSP)</title>
		<meeting>23rd ACM Symposium on Operating Systems Principles (SOSP)</meeting>
		<imprint>
			<date type="published" when="2011-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">NVMKV: A scalable, lightweight, FTL-aware key-value store</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Marmol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sundararaman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Talagala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Rangaswami</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 USENIX Conference on Usenix Annual Technical Conference (USENIX ATC)</title>
		<meeting>the 2015 USENIX Conference on Usenix Annual Technical Conference (USENIX ATC)</meeting>
		<imprint>
			<date type="published" when="2015-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Optimizing key-value stores for hybrid storage architectures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Menon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Rabl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sadoghi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-A</forename><surname>Jacobsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CASCON</title>
		<meeting>CASCON</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Lightweight application-level crash consistency on transactional flash storage</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-H</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-W</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">I</forename><surname>Eom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 USENIX Conference on Usenix Annual Technical Conference (USENIX ATC)</title>
		<meeting>the 2015 USENIX Conference on Usenix Annual Technical Conference (USENIX ATC)</meeting>
		<imprint>
			<date type="published" when="2015-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">The LHAM log-structured history data access method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Muth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>O&amp;apos;neil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Pick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The VLDB Journal</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="199" to="221" />
			<date type="published" when="2000-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">NoSQL data modeling techniques</title>
		<ptr target="https://highlyscalable.wordpress.com/2012/03/0" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">/nosql-data-modeling-techniques</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">The SB-tree: An index-sequential structure for high-performance sequential access</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">E</forename><surname>O&amp;apos;neil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acta Inf</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="241" to="265" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">The log-structured merge-tree (LSM-tree)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">E</forename><surname>O&amp;apos;neil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gawlick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>O&amp;apos;neil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acta Inf</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="351" to="385" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">The design and implementation of a log-structured file system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rosenblum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">K</forename><surname>Ousterhout</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Computer Systems</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="26" to="52" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Dynamic performance profiling of cloud caches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Saemundsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bjornsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chockler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Vigfusson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 5th ACM Symposium on Cloud Computing (SOCC)</title>
		<meeting>5th ACM Symposium on Cloud Computing (SOCC)</meeting>
		<imprint>
			<date type="published" when="2014-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">bLSM: A general purpose log structured merge tree</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sears</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ramakrishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data</title>
		<meeting>the 2012 ACM SIGMOD International Conference on Management of Data</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Rose: Compressed, log-structured replication</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sears</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Callaghan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Brewer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. VLDB Endowment</title>
		<meeting>VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2008-08" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Building workloadindependent storage with VT-trees</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Shetty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Spillane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Malpani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Andrews</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Seyster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Zadok</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th USENIX Conference on File and Storage Technologies (FAST)</title>
		<meeting>the 11th USENIX Conference on File and Storage Technologies (FAST)</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">An efficient multi-tier tablet server storage architecture</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">P</forename><surname>Spillane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Shetty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Zadok</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Dixit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Archak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 2nd ACM Symposium on Cloud Computing (SOCC)</title>
		<meeting>2nd ACM Symposium on Cloud Computing (SOCC)</meeting>
		<imprint>
			<date type="published" when="2011-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">RIPQ: Advanced photo caching on flash for Facebook</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Lloyd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 13th USENIX Conference on File and Storage Technologies (FAST)</title>
		<meeting>13th USENIX Conference on File and Storage Technologies (FAST)</meeting>
		<imprint>
			<date type="published" when="2015-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">The Apache Software Foundation. Apache Cassandra</title>
		<ptr target="https://cassandra.apache.org/" />
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
				<ptr target="https://hbase.apache.org/" />
		<title level="m">The Apache Software Foundation. Apache HBase</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">LogBase: A scalable log-structured database system in the cloud</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">T</forename><surname>Vo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">C</forename><surname>Ooi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. VLDB Endowment</title>
		<meeting>VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2012-06" />
			<biblScope unit="volume">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">On the implementation of an interior-point filter line-search algorithm for large-scale nonlinear programming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wächter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">T</forename><surname>Biegler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematical Programming</title>
		<imprint>
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="25" to="57" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">An efficient design and implementation of LSM-tree based key-value store on open-channel SSD</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth European Conference on Computer Systems</title>
		<meeting>the Ninth European Conference on Computer Systems</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Characterizing storage workloads with counter stacks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wires</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ingram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Drudi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">J A</forename><surname>Harvey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Warfield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 11th USENIX OSDI</title>
		<meeting>11th USENIX OSDI</meeting>
		<imprint>
			<date type="published" when="2014-10" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
